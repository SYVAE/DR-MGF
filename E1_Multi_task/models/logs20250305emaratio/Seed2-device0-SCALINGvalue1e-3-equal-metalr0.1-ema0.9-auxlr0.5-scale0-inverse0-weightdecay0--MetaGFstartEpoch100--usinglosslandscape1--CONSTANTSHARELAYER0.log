--------0117  loss landscape--------
Parameter Space: ABS: 44229076.0, REL: 1.7705
LOSS FORMAT: SEMANTIC_LOSS MEAN_IOU PIX_ACC | DEPTH_LOSS ABS_ERR REL_ERR | NORMAL_LOSS MEAN MED <11.25 <22.5 <30
Applying data augmentation on NYUv2.
metalr:0.1
metaGF: modified by sy...(global view)
metaGF: modified by sy...
['encoder_block.0.forwardlist.0.bias', 'encoder_block.1.forwardlist.0.bias', 'encoder_block.2.forwardlist.0.bias', 'encoder_block.3.forwardlist.0.bias', 'encoder_block.4.forwardlist.0.bias', 'decoder_block.0.forwardlist.0.bias', 'decoder_block.1.forwardlist.0.bias', 'decoder_block.2.forwardlist.0.bias', 'decoder_block.3.forwardlist.0.bias', 'decoder_block.4.forwardlist.0.bias', 'conv_block_enc.0.forwardlist.0.bias', 'conv_block_enc.1.forwardlist.0.bias', 'conv_block_enc.2.forwardlist.0.forwardlist.0.bias', 'conv_block_enc.2.forwardlist.1.forwardlist.0.bias', 'conv_block_enc.3.forwardlist.0.forwardlist.0.bias', 'conv_block_enc.3.forwardlist.1.forwardlist.0.bias', 'conv_block_enc.4.forwardlist.0.forwardlist.0.bias', 'conv_block_enc.4.forwardlist.1.forwardlist.0.bias', 'conv_block_dec.0.forwardlist.0.bias', 'conv_block_dec.1.forwardlist.0.bias', 'conv_block_dec.2.forwardlist.0.forwardlist.0.bias', 'conv_block_dec.2.forwardlist.1.forwardlist.0.bias', 'conv_block_dec.3.forwardlist.0.forwardlist.0.bias', 'conv_block_dec.3.forwardlist.1.forwardlist.0.bias', 'conv_block_dec.4.forwardlist.0.forwardlist.0.bias', 'conv_block_dec.4.forwardlist.1.forwardlist.0.bias', 'encoder_att.0.0.0.bias', 'encoder_att.0.0.3.bias', 'encoder_att.0.1.0.bias', 'encoder_att.0.1.3.bias', 'encoder_att.0.2.0.bias', 'encoder_att.0.2.3.bias', 'encoder_att.0.3.0.bias', 'encoder_att.0.3.3.bias', 'encoder_att.0.4.0.bias', 'encoder_att.0.4.3.bias', 'encoder_att.1.0.0.bias', 'encoder_att.1.0.3.bias', 'encoder_att.1.1.0.bias', 'encoder_att.1.1.3.bias', 'encoder_att.1.2.0.bias', 'encoder_att.1.2.3.bias', 'encoder_att.1.3.0.bias', 'encoder_att.1.3.3.bias', 'encoder_att.1.4.0.bias', 'encoder_att.1.4.3.bias', 'encoder_att.2.0.0.bias', 'encoder_att.2.0.3.bias', 'encoder_att.2.1.0.bias', 'encoder_att.2.1.3.bias', 'encoder_att.2.2.0.bias', 'encoder_att.2.2.3.bias', 'encoder_att.2.3.0.bias', 'encoder_att.2.3.3.bias', 'encoder_att.2.4.0.bias', 'encoder_att.2.4.3.bias', 'decoder_att.0.0.0.bias', 'decoder_att.0.0.3.bias', 'decoder_att.0.1.0.bias', 'decoder_att.0.1.3.bias', 'decoder_att.0.2.0.bias', 'decoder_att.0.2.3.bias', 'decoder_att.0.3.0.bias', 'decoder_att.0.3.3.bias', 'decoder_att.0.4.0.bias', 'decoder_att.0.4.3.bias', 'decoder_att.1.0.0.bias', 'decoder_att.1.0.3.bias', 'decoder_att.1.1.0.bias', 'decoder_att.1.1.3.bias', 'decoder_att.1.2.0.bias', 'decoder_att.1.2.3.bias', 'decoder_att.1.3.0.bias', 'decoder_att.1.3.3.bias', 'decoder_att.1.4.0.bias', 'decoder_att.1.4.3.bias', 'decoder_att.2.0.0.bias', 'decoder_att.2.0.3.bias', 'decoder_att.2.1.0.bias', 'decoder_att.2.1.3.bias', 'decoder_att.2.2.0.bias', 'decoder_att.2.2.3.bias', 'decoder_att.2.3.0.bias', 'decoder_att.2.3.3.bias', 'decoder_att.2.4.0.bias', 'decoder_att.2.4.3.bias', 'encoder_block_att.0.forwardlist.0.bias', 'encoder_block_att.1.forwardlist.0.bias', 'encoder_block_att.2.forwardlist.0.bias', 'encoder_block_att.3.forwardlist.0.bias', 'encoder_block_att.4.forwardlist.0.bias', 'decoder_block_att.0.forwardlist.0.bias', 'decoder_block_att.1.forwardlist.0.bias', 'decoder_block_att.2.forwardlist.0.bias', 'decoder_block_att.3.forwardlist.0.bias', 'decoder_block_att.4.forwardlist.0.bias', 'pred_task1.forwardlist.0.bias', 'pred_task1.forwardlist.1.bias', 'pred_task2.forwardlist.0.bias', 'pred_task2.forwardlist.1.bias', 'pred_task3.forwardlist.0.bias', 'pred_task3.forwardlist.1.bias']
lr:0.0001
[0.  0.5 0.5]
-----------end of analyzing the loss ratio:0.0005393028259277344
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cca5dc0feb0>
---------------------------------
SparseEpoch: [0][1/398]	Time 0.891	Data 0.000	Loss 11.2148	
SparseEpoch: [0][101/398]	Time 0.628	Data 0.000	Loss 4.4521	
SparseEpoch: [0][201/398]	Time 0.624	Data 0.000	Loss 3.5957	
SparseEpoch: [0][301/398]	Time 0.624	Data 0.000	Loss 3.9851	
lr:0.0001
[0.5 0.  0.5]
-----------end of analyzing the loss ratio:0.00016641616821289062
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cca5e6e7d00>
---------------------------------
SparseEpoch: [0][1/398]	Time 0.609	Data 0.000	Loss 9.8074	
SparseEpoch: [0][101/398]	Time 0.629	Data 0.000	Loss 4.6320	
SparseEpoch: [0][201/398]	Time 0.627	Data 0.000	Loss 4.2351	
SparseEpoch: [0][301/398]	Time 0.627	Data 0.000	Loss 3.6111	
lr:0.0001
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:0.0001468658447265625
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cca5e3541c0>
---------------------------------
SparseEpoch: [0][1/398]	Time 0.608	Data 0.000	Loss 15.2522	
SparseEpoch: [0][101/398]	Time 0.624	Data 0.000	Loss 4.9796	
SparseEpoch: [0][201/398]	Time 0.625	Data 0.000	Loss 3.9274	
SparseEpoch: [0][301/398]	Time 0.627	Data 0.000	Loss 5.5693	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 4.3475	
Epoch(adapt):{0} Loss 2.7207	
Epoch(adapt):{0} Loss 3.6851	
Epoch(adapt):{0} Loss 3.7124	
------------------the total time cost:993.9786043167114
>>>>>meta updating
Epoch: 0000 | TRAIN: 2.0186 0.0724 0.3572 | 0.9121 0.9121 0.4302 | 0.3256 43.9907 42.2322 0.0451 0.1687 0.2913 ||TEST: 2.1265 0.0780 0.3653 | 1.0727 1.0727 0.4085 | 0.3231 43.8806 42.3343 0.0437 0.1651 0.2884 | 115.2415
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[2.00008484 2.00008154 2.00006449 2.0000469  2.00001549 2.00000942
 2.00003852 2.00000695 2.00002141 2.00001191 1.99999328 1.99997245
 1.99986709 1.9999065  1.99988394 1.99988438 1.99989988 1.99987541
 1.99987164 1.99983671]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[2.00002862 2.00001243 2.00003376 2.00002159 2.00001434 2.00003066
 2.00003291 2.00002433 2.00001234 2.00000734 2.00000001 1.99999343
 1.99998227 1.99998392 1.99997394 1.99995627 1.99996206 1.99994878
 1.99995004 1.99994153]
[0.  0.5 0.5]
-----------end of analyzing the loss ratio:73.89955949783325
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cca5e465e70>
---------------------------------
SparseEpoch: [1][1/398]	Time 0.619	Data 0.000	Loss 4.4056	
SparseEpoch: [1][101/398]	Time 0.622	Data 0.000	Loss 4.2489	
SparseEpoch: [1][201/398]	Time 0.622	Data 0.000	Loss 3.4632	
SparseEpoch: [1][301/398]	Time 0.623	Data 0.000	Loss 4.4530	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[15.22829762 14.25560923 13.44368162 12.75834103 12.16093526 11.62733498
 11.1478858  10.70742793 10.31840363  9.95710893  9.62475262  9.31851068
  9.02608991  8.75950747  8.5083396   8.2787241   8.05669432  7.84613833
  7.64449701  7.46193018]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[9.78739877 9.78745723 9.78736882 9.78733244 9.7871285  9.78720531
 9.78714581 9.78716316 9.78705606 9.78710179 9.78699083 9.78675332
 9.786693   9.78655753 9.78622279 9.78611879 9.78598447 9.78577285
 9.78566875 9.7855545 ]
[0.5 0.  0.5]
-----------end of analyzing the loss ratio:73.6158492565155
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc93988eda0>
---------------------------------
SparseEpoch: [1][1/398]	Time 0.651	Data 0.000	Loss 3.9991	
SparseEpoch: [1][101/398]	Time 0.626	Data 0.000	Loss 3.2413	
SparseEpoch: [1][201/398]	Time 0.628	Data 0.000	Loss 3.7299	
SparseEpoch: [1][301/398]	Time 0.626	Data 0.000	Loss 3.3868	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.34027784 0.34027314 0.3402552  0.34025491 0.34025567 0.34026496
 0.34027139 0.34026696 0.34026098 0.34026018 0.34025732 0.34025487
 0.34025686 0.34025683 0.3402583  0.34025105 0.34024708 0.34025452
 0.34025729 0.34025859]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.34032691 0.34032599 0.34034724 0.34032907 0.34032164 0.34029977
 0.34030406 0.34029596 0.34025137 0.34026884 0.34025946 0.34025711
 0.34026029 0.34028164 0.34028406 0.34026604 0.34026205 0.34028513
 0.34027997 0.34026076]
[0.34210526 0.         0.        ]
-----------end of analyzing the loss ratio:73.54741764068604
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938fef280>
---------------------------------
SparseEpoch: [1][1/398]	Time 0.645	Data 0.000	Loss 4.6967	
SparseEpoch: [1][101/398]	Time 0.630	Data 0.000	Loss 3.8058	
SparseEpoch: [1][201/398]	Time 0.628	Data 0.000	Loss 3.2833	
SparseEpoch: [1][301/398]	Time 0.627	Data 0.000	Loss 3.5779	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 3.4319	
Epoch(adapt):{0} Loss 3.1477	
Epoch(adapt):{0} Loss 2.9539	
Epoch(adapt):{0} Loss 2.7886	
------------------the total time cost:1215.6782655715942
>>>>>meta updating
Epoch: 0001 | TRAIN: 1.8081 0.0854 0.3818 | 0.8068 0.8068 0.3985 | 0.2931 41.0585 39.5729 0.0622 0.2284 0.3498 ||TEST: 1.8201 0.0900 0.3895 | 0.8618 0.8618 0.3326 | 0.2837 40.4484 39.4613 0.0648 0.2273 0.3484 | 115.0417
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.74587538 1.74588015 1.7458644  1.74589529 1.74590195 1.74591435
 1.74591563 1.74591873 1.74593023 1.74592676 1.74592819 1.74593692
 1.74595159 1.74594773 1.74594177 1.74596028 1.74596469 1.74596666
 1.74599078 1.74599273]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.74594948 1.74595129 1.74595693 1.74595259 1.74594519 1.74594185
 1.74594151 1.7459332  1.74592584 1.74591533 1.74591521 1.74592398
 1.7459214  1.74592005 1.74592278 1.74592141 1.74591386 1.74590179
 1.74588797 1.74589508]
[0.         0.         0.44736842]
-----------end of analyzing the loss ratio:73.56760931015015
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc93992f100>
---------------------------------
SparseEpoch: [2][1/398]	Time 0.608	Data 0.000	Loss 3.1509	
SparseEpoch: [2][101/398]	Time 0.624	Data 0.000	Loss 3.4614	
SparseEpoch: [2][201/398]	Time 0.624	Data 0.000	Loss 3.3625	
SparseEpoch: [2][301/398]	Time 0.624	Data 0.000	Loss 3.0377	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.08120648 1.0811992  1.0811897  1.08118413 1.08117081 1.08115553
 1.08114442 1.08113302 1.08112787 1.08112285 1.08110719 1.08109306
 1.08107709 1.08107048 1.0810698  1.08105118 1.08103808 1.08103808
 1.08102503 1.08101965]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.08112923 1.0811268  1.08112481 1.08112069 1.08112219 1.08112902
 1.08112926 1.0811215  1.08111817 1.0811142  1.08111044 1.08111133
 1.08110374 1.08110411 1.08110052 1.08109372 1.08109086 1.0810858
 1.08108764 1.08108978]
[0.5        0.         0.39473684]
-----------end of analyzing the loss ratio:73.49933362007141
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc939947d30>
---------------------------------
SparseEpoch: [2][1/398]	Time 0.609	Data 0.000	Loss 3.2579	
SparseEpoch: [2][101/398]	Time 0.621	Data 0.000	Loss 2.7349	
SparseEpoch: [2][201/398]	Time 0.622	Data 0.000	Loss 3.1599	
SparseEpoch: [2][301/398]	Time 0.624	Data 0.000	Loss 3.0958	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.32243757 0.32243493 0.32243213 0.32242796 0.32242312 0.32241861
 0.32241387 0.32240945 0.32240596 0.32239951 0.3223951  0.32239377
 0.32238877 0.3223869  0.32238108 0.32237661 0.32237388 0.32237355
 0.32236954 0.32236459]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.32241999 0.32241991 0.32241647 0.32241343 0.32241032 0.32240772
 0.32240341 0.3224025  0.32240006 0.32240017 0.32240096 0.32240224
 0.32239984 0.32239947 0.32240079 0.32239684 0.32239676 0.32239787
 0.32239271 0.32239332]
[0.5        0.44736842 0.        ]
-----------end of analyzing the loss ratio:73.56649589538574
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938feef80>
---------------------------------
SparseEpoch: [2][1/398]	Time 0.612	Data 0.000	Loss 4.3677	
SparseEpoch: [2][101/398]	Time 0.627	Data 0.000	Loss 4.3217	
SparseEpoch: [2][201/398]	Time 0.625	Data 0.000	Loss 4.4969	
SparseEpoch: [2][301/398]	Time 0.625	Data 0.000	Loss 4.0645	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 2.7818	
Epoch(adapt):{0} Loss 2.3109	
Epoch(adapt):{0} Loss 3.9404	
Epoch(adapt):{0} Loss 3.3545	
------------------the total time cost:1214.0512256622314
>>>>>meta updating
Epoch: 0002 | TRAIN: 1.7390 0.0903 0.4040 | 0.8012 0.8012 0.4121 | 0.2776 39.8011 37.8589 0.0630 0.2402 0.3748 ||TEST: 1.7439 0.0939 0.4030 | 0.8383 0.8383 0.3290 | 0.2694 39.2604 37.7020 0.0647 0.2406 0.3754 | 114.7793
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.90319552 1.90320905 1.90320418 1.9031811  1.90316    1.90317694
 1.90318182 1.90317755 1.90317667 1.90320106 1.90320383 1.90318494
 1.90321991 1.90324022 1.9032187  1.90319721 1.90318891 1.90317448
 1.90320036 1.90323675]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.90324966 1.9032534  1.90323976 1.90325001 1.90322989 1.90325284
 1.90322338 1.90320696 1.90320487 1.90318217 1.90319113 1.90319867
 1.90320116 1.90319952 1.90320892 1.90322605 1.90321789 1.90319467
 1.90321022 1.90322392]
[0. 0. 0.]
-----------end of analyzing the loss ratio:73.65685486793518
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938d3d960>
---------------------------------
SparseEpoch: [3][1/398]	Time 0.605	Data 0.000	Loss 1.7744	
SparseEpoch: [3][101/398]	Time 0.624	Data 0.000	Loss 1.7953	
SparseEpoch: [3][201/398]	Time 0.625	Data 0.000	Loss 1.6647	
SparseEpoch: [3][301/398]	Time 0.627	Data 0.000	Loss 1.6685	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.78650578 0.78643913 0.7863589  0.78627413 0.78621832 0.78615337
 0.78609701 0.78600072 0.78592501 0.78590365 0.78585937 0.78579343
 0.78577931 0.78571214 0.78568168 0.78560138 0.78555283 0.78548301
 0.78543226 0.78533621]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.78591611 0.78591007 0.78590735 0.78590968 0.78590908 0.7859045
 0.785899   0.78589028 0.78588663 0.78588544 0.78588576 0.78589244
 0.78589023 0.78588518 0.78588422 0.78588492 0.78588382 0.78587072
 0.78587505 0.78586337]
[0.5 0.  0.5]
-----------end of analyzing the loss ratio:73.68740034103394
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938b68c10>
---------------------------------
SparseEpoch: [3][1/398]	Time 0.609	Data 0.000	Loss 2.8924	
SparseEpoch: [3][101/398]	Time 0.624	Data 0.000	Loss 2.4233	
SparseEpoch: [3][201/398]	Time 0.624	Data 0.000	Loss 3.1010	
SparseEpoch: [3][301/398]	Time 0.624	Data 0.000	Loss 3.0172	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.30057369 0.30057092 0.3005658  0.3005612  0.30056798 0.30056331
 0.30055662 0.30055606 0.30055996 0.30055453 0.30054637 0.30053925
 0.30053667 0.30052669 0.30051965 0.30051385 0.30051176 0.30051534
 0.30051037 0.30050356]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.30055326 0.30055624 0.30055232 0.30055257 0.3005529  0.30055605
 0.3005576  0.30055906 0.30055575 0.30055363 0.30055373 0.30055088
 0.30054934 0.30054665 0.30054452 0.30054523 0.3005424  0.30054115
 0.30054034 0.30053769]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:73.51841807365417
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cca5e465c30>
---------------------------------
SparseEpoch: [3][1/398]	Time 0.604	Data 0.000	Loss 3.4394	
SparseEpoch: [3][101/398]	Time 0.621	Data 0.000	Loss 4.5559	
SparseEpoch: [3][201/398]	Time 0.621	Data 0.000	Loss 4.2617	
SparseEpoch: [3][301/398]	Time 0.622	Data 0.000	Loss 3.9583	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 3.3873	
Epoch(adapt):{0} Loss 2.6031	
Epoch(adapt):{0} Loss 2.3616	
Epoch(adapt):{0} Loss 2.7326	
------------------the total time cost:1214.610279083252
>>>>>meta updating
Epoch: 0003 | TRAIN: 1.6821 0.0992 0.4226 | 0.7776 0.7776 0.3643 | 0.2755 39.6403 37.5973 0.0622 0.2417 0.3759 ||TEST: 1.6878 0.1024 0.4254 | 0.8470 0.8470 0.3174 | 0.2670 39.0481 37.3326 0.0647 0.2429 0.3783 | 114.9475
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.57781136 1.57780259 1.57780149 1.57779019 1.57776753 1.57775815
 1.57774637 1.57774385 1.57774142 1.57774252 1.57771775 1.5777226
 1.57772123 1.57774944 1.57773322 1.5777279  1.57774066 1.57775326
 1.57775397 1.57776605]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.57774189 1.57773817 1.57774545 1.57774462 1.57774779 1.57775214
 1.57774601 1.57773538 1.57773986 1.57773298 1.57774044 1.57772839
 1.57772849 1.57772622 1.57772433 1.57771912 1.57772146 1.5777222
 1.57772712 1.57772601]
[0.         0.02631579 0.28947368]
-----------end of analyzing the loss ratio:73.63758850097656
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938b45ff0>
---------------------------------
SparseEpoch: [4][1/398]	Time 0.605	Data 0.000	Loss 2.8857	
SparseEpoch: [4][101/398]	Time 0.622	Data 0.000	Loss 2.2453	
SparseEpoch: [4][201/398]	Time 0.623	Data 0.000	Loss 2.4621	
SparseEpoch: [4][301/398]	Time 0.624	Data 0.000	Loss 2.3301	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.86223102 0.86220895 0.8621608  0.86213941 0.86211603 0.86210237
 0.86208702 0.86208683 0.86208901 0.8620423  0.86201405 0.86199546
 0.86194918 0.86193728 0.86188661 0.86188154 0.86186652 0.8618715
 0.86181574 0.86180487]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.86204075 0.86204955 0.86205747 0.86206492 0.86206176 0.86206662
 0.8620607  0.86204407 0.86203609 0.86202706 0.86202883 0.8620203
 0.86201788 0.86202171 0.86200703 0.86200873 0.86199546 0.8619963
 0.86200085 0.86199262]
[0.5 0.  0.5]
-----------end of analyzing the loss ratio:73.52564024925232
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938d3ead0>
---------------------------------
SparseEpoch: [4][1/398]	Time 0.623	Data 0.000	Loss 2.4526	
SparseEpoch: [4][101/398]	Time 0.622	Data 0.000	Loss 3.2850	
SparseEpoch: [4][201/398]	Time 0.624	Data 0.000	Loss 2.9798	
SparseEpoch: [4][301/398]	Time 0.624	Data 0.000	Loss 2.5547	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.30182807 0.30182651 0.30182199 0.30182003 0.30182024 0.30181224
 0.30181205 0.30180877 0.30180458 0.30180086 0.30180013 0.30179889
 0.3017976  0.3017927  0.3017893  0.30178618 0.30178427 0.30177892
 0.3017823  0.30178251]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.3018038  0.30180172 0.30180044 0.30179806 0.30179803 0.30179798
 0.30179819 0.30180064 0.30180209 0.30180113 0.30179933 0.30179927
 0.30179998 0.30180137 0.30180007 0.30180056 0.30179898 0.30180036
 0.30180275 0.30180278]
[0.39473684 0.         0.        ]
-----------end of analyzing the loss ratio:73.57412719726562
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9398f8a00>
---------------------------------
SparseEpoch: [4][1/398]	Time 0.606	Data 0.000	Loss 4.2108	
SparseEpoch: [4][101/398]	Time 0.624	Data 0.000	Loss 3.7387	
SparseEpoch: [4][201/398]	Time 0.623	Data 0.000	Loss 3.2925	
SparseEpoch: [4][301/398]	Time 0.623	Data 0.000	Loss 4.0238	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 2.3046	
Epoch(adapt):{0} Loss 3.0924	
Epoch(adapt):{0} Loss 2.7295	
Epoch(adapt):{0} Loss 2.8648	
------------------the total time cost:1215.1999552249908
>>>>>meta updating
Epoch: 0004 | TRAIN: 1.6321 0.1076 0.4393 | 0.7809 0.7809 0.3785 | 0.2626 38.4266 36.1505 0.0713 0.2641 0.3993 ||TEST: 1.6512 0.1092 0.4361 | 0.8190 0.8190 0.3161 | 0.2551 37.9085 36.1355 0.0748 0.2653 0.3992 | 114.8901
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.73436916 1.73437858 1.73438482 1.73442736 1.73443121 1.73443524
 1.7344539  1.7344696  1.73447247 1.73447007 1.73446189 1.73447527
 1.73446871 1.73446428 1.73445547 1.73446145 1.73447524 1.73449796
 1.73451641 1.73455514]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.73450787 1.73450614 1.73450028 1.73449874 1.73449107 1.73449382
 1.73448191 1.73447558 1.73446485 1.73445487 1.73445413 1.73445675
 1.73447036 1.73447642 1.73448232 1.73448598 1.73447379 1.73447825
 1.73448176 1.73446399]
[0.         0.         0.02631579]
-----------end of analyzing the loss ratio:73.94520425796509
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cca5e46d090>
---------------------------------
SparseEpoch: [5][1/398]	Time 0.606	Data 0.000	Loss 2.6332	
SparseEpoch: [5][101/398]	Time 0.624	Data 0.000	Loss 1.8704	
SparseEpoch: [5][201/398]	Time 0.621	Data 0.000	Loss 1.5951	
SparseEpoch: [5][301/398]	Time 0.623	Data 0.000	Loss 2.0356	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.82442038 0.82441241 0.8244084  0.82441375 0.8244177  0.82440703
 0.82441525 0.82440645 0.82440606 0.82439637 0.82441029 0.82441212
 0.82440009 0.82440502 0.82440156 0.8243969  0.8243627  0.82436607
 0.82435677 0.8243605 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.82439259 0.82439271 0.82438171 0.82437866 0.82438755 0.82439696
 0.82439785 0.82440189 0.82440893 0.82440807 0.82440192 0.82440672
 0.82440326 0.8244053  0.82441085 0.82440817 0.82440531 0.82441484
 0.82441531 0.82440944]
[0.44736842 0.         0.        ]
-----------end of analyzing the loss ratio:73.66275715827942
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc939947a60>
---------------------------------
SparseEpoch: [5][1/398]	Time 0.606	Data 0.000	Loss 1.9043	
SparseEpoch: [5][101/398]	Time 0.626	Data 0.000	Loss 1.5426	
SparseEpoch: [5][201/398]	Time 0.624	Data 0.000	Loss 1.4994	
SparseEpoch: [5][301/398]	Time 0.623	Data 0.000	Loss 1.0792	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.27845201 0.27844709 0.27843931 0.27843531 0.27844216 0.27843271
 0.27842659 0.2784252  0.2784377  0.27842527 0.27842414 0.27842582
 0.27841921 0.27839909 0.27839758 0.27839823 0.27838418 0.27838967
 0.27837684 0.27838538]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.27842431 0.27842002 0.2784242  0.27843021 0.27843164 0.2784358
 0.27844077 0.27842945 0.27842088 0.27842135 0.27842738 0.27842546
 0.27842683 0.27842711 0.27842733 0.27842516 0.27843404 0.27843254
 0.27843285 0.2784246 ]
[0.44736842 0.         0.        ]
-----------end of analyzing the loss ratio:73.53946709632874
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cca5e4f59c0>
---------------------------------
SparseEpoch: [5][1/398]	Time 0.609	Data 0.000	Loss 2.7749	
SparseEpoch: [5][101/398]	Time 0.624	Data 0.000	Loss 4.1243	
SparseEpoch: [5][201/398]	Time 0.625	Data 0.000	Loss 3.8697	
SparseEpoch: [5][301/398]	Time 0.627	Data 0.000	Loss 4.3541	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 3.1083	
Epoch(adapt):{0} Loss 3.0266	
Epoch(adapt):{0} Loss 2.9271	
Epoch(adapt):{0} Loss 3.0497	
------------------the total time cost:1214.360414981842
>>>>>meta updating
Epoch: 0005 | TRAIN: 1.6071 0.1155 0.4468 | 0.7517 0.7517 0.3823 | 0.2603 38.1315 35.9614 0.0827 0.2684 0.4012 ||TEST: 1.6214 0.1184 0.4457 | 0.7980 0.7980 0.3113 | 0.2528 37.5554 35.7891 0.0876 0.2746 0.4061 | 114.9895
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.63296913 1.63299109 1.63301331 1.63305519 1.63308661 1.63309114
 1.63309944 1.63314462 1.63314966 1.63314003 1.63311185 1.63313621
 1.63314873 1.63319559 1.63320909 1.63324566 1.63327558 1.63328825
 1.63331249 1.63332181]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.63322124 1.63319936 1.63318752 1.6331461  1.63312811 1.63312596
 1.63310571 1.63310277 1.63310431 1.63311428 1.63312074 1.63312535
 1.63312596 1.63315351 1.63314952 1.63314208 1.63313231 1.63310794
 1.63308461 1.63308077]
[0.  0.  0.5]
-----------end of analyzing the loss ratio:73.78247833251953
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cca5e6e7f40>
---------------------------------
SparseEpoch: [6][1/398]	Time 0.606	Data 0.000	Loss 2.5078	
SparseEpoch: [6][101/398]	Time 0.623	Data 0.000	Loss 2.8071	
SparseEpoch: [6][201/398]	Time 0.622	Data 0.000	Loss 3.4582	
SparseEpoch: [6][301/398]	Time 0.623	Data 0.000	Loss 3.2489	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.0932076  1.09305431 1.09292924 1.09286093 1.0927819  1.09279051
 1.09271101 1.09266585 1.09259019 1.09244134 1.09232051 1.09220779
 1.09214321 1.09199135 1.09194443 1.09190212 1.0918498  1.09174784
 1.09163494 1.09156599]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.09256161 1.0925536  1.0925422  1.09250391 1.09247752 1.09243453
 1.09243135 1.09241526 1.09240659 1.09237008 1.09236587 1.09235768
 1.0923371  1.09230801 1.0923015  1.09227776 1.09226571 1.09224925
 1.09224605 1.09222825]
[0.5 0.  0.5]
-----------end of analyzing the loss ratio:73.56613230705261
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cca5e592a40>
---------------------------------
SparseEpoch: [6][1/398]	Time 0.605	Data 0.000	Loss 3.9085	
SparseEpoch: [6][101/398]	Time 0.620	Data 0.000	Loss 2.3836	
SparseEpoch: [6][201/398]	Time 0.621	Data 0.000	Loss 2.9166	
SparseEpoch: [6][301/398]	Time 0.623	Data 0.000	Loss 4.7734	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.29756586 0.29755996 0.29755434 0.29754543 0.29754086 0.29753895
 0.29753463 0.29753386 0.297531   0.29752502 0.29752501 0.29752923
 0.29752708 0.29751997 0.2975149  0.29751116 0.29750611 0.29751397
 0.29750894 0.29750348]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.29753608 0.29753613 0.29753799 0.29753774 0.29753194 0.29753223
 0.29753235 0.2975273  0.29752546 0.29752517 0.29752539 0.29752777
 0.29752699 0.29752844 0.29752768 0.29752759 0.29752729 0.29752538
 0.29752159 0.29752005]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:73.60362672805786
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc93901c610>
---------------------------------
SparseEpoch: [6][1/398]	Time 0.608	Data 0.000	Loss 3.7638	
SparseEpoch: [6][101/398]	Time 0.626	Data 0.000	Loss 4.1519	
SparseEpoch: [6][201/398]	Time 0.625	Data 0.000	Loss 4.1148	
SparseEpoch: [6][301/398]	Time 0.624	Data 0.000	Loss 3.7817	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 2.7874	
Epoch(adapt):{0} Loss 2.8974	
Epoch(adapt):{0} Loss 2.8064	
Epoch(adapt):{0} Loss 3.5792	
------------------the total time cost:1213.7710466384888
>>>>>meta updating
Epoch: 0006 | TRAIN: 1.5728 0.1256 0.4649 | 0.7454 0.7454 0.3554 | 0.2433 36.4802 33.9952 0.0980 0.2991 0.4363 ||TEST: 1.6057 0.1241 0.4494 | 0.8127 0.8127 0.3028 | 0.2356 35.8829 33.8627 0.1053 0.3052 0.4389 | 115.0027
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.52868409 1.52867678 1.52868564 1.52865208 1.52866209 1.52868261
 1.52866908 1.52868634 1.5286883  1.52869527 1.52871504 1.52868992
 1.52869662 1.52870652 1.52871992 1.52871028 1.52869201 1.52869491
 1.5286814  1.52870198]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.52870446 1.52870377 1.52871203 1.52870167 1.52870442 1.5286985
 1.52869486 1.52869999 1.52870179 1.52870933 1.52870799 1.52869533
 1.52868779 1.52869782 1.52870548 1.52869605 1.52869977 1.52870486
 1.52870957 1.52870653]
[0.         0.         0.13157895]
-----------end of analyzing the loss ratio:73.66973900794983
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc939946f80>
---------------------------------
SparseEpoch: [7][1/398]	Time 0.605	Data 0.000	Loss 1.8564	
SparseEpoch: [7][101/398]	Time 0.616	Data 0.000	Loss 1.9417	
SparseEpoch: [7][201/398]	Time 0.620	Data 0.000	Loss 1.8220	
SparseEpoch: [7][301/398]	Time 0.621	Data 0.000	Loss 2.0356	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.8469101  0.8469257  0.84692382 0.84694135 0.84695089 0.84696384
 0.84697356 0.84697705 0.84698007 0.84698826 0.84698551 0.84701136
 0.84700705 0.84700101 0.84698899 0.84700671 0.84703883 0.84703219
 0.84704471 0.84702836]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.84697078 0.84696625 0.84697458 0.84696485 0.84696373 0.84697021
 0.84696643 0.84696422 0.84698013 0.84698443 0.84699087 0.84698319
 0.84699678 0.84700672 0.84699854 0.84700007 0.84699936 0.84700138
 0.84698083 0.84698663]
[0. 0. 0.]
-----------end of analyzing the loss ratio:73.71221780776978
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938b47e50>
---------------------------------
SparseEpoch: [7][1/398]	Time 0.605	Data 0.000	Loss 0.5839	
SparseEpoch: [7][101/398]	Time 0.625	Data 0.000	Loss 0.9557	
SparseEpoch: [7][201/398]	Time 0.624	Data 0.000	Loss 0.6075	
SparseEpoch: [7][301/398]	Time 0.623	Data 0.000	Loss 0.7047	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.29841653 0.29839875 0.29838955 0.29835155 0.29833283 0.29831424
 0.2982841  0.29826362 0.29824865 0.29823198 0.29823673 0.2982177
 0.29817721 0.29814466 0.29813474 0.29812931 0.29813181 0.29811906
 0.29812068 0.29809932]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.29826016 0.29826153 0.29824961 0.29825452 0.29824925 0.29824077
 0.29823566 0.2982365  0.29824415 0.29824366 0.29824432 0.29823951
 0.2982401  0.29823896 0.29823142 0.29822439 0.29822294 0.29820856
 0.29820571 0.29819835]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:73.57373762130737
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc93997e5f0>
---------------------------------
SparseEpoch: [7][1/398]	Time 0.606	Data 0.000	Loss 3.1595	
SparseEpoch: [7][101/398]	Time 0.625	Data 0.000	Loss 4.0284	
SparseEpoch: [7][201/398]	Time 0.625	Data 0.000	Loss 2.5844	
SparseEpoch: [7][301/398]	Time 0.627	Data 0.000	Loss 4.4682	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 2.4420	
Epoch(adapt):{0} Loss 2.4401	
Epoch(adapt):{0} Loss 2.5484	
Epoch(adapt):{0} Loss 2.1113	
------------------the total time cost:1212.918628692627
>>>>>meta updating
Epoch: 0007 | TRAIN: 1.5700 0.1206 0.4651 | 0.7187 0.7187 0.3408 | 0.2404 35.9664 33.2555 0.1157 0.3157 0.4493 ||TEST: 1.5781 0.1208 0.4610 | 0.7864 0.7864 0.2942 | 0.2311 35.2149 33.0705 0.1254 0.3244 0.4537 | 115.2444
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.72562431 1.72560749 1.72555898 1.72554401 1.72547764 1.72544402
 1.72538114 1.72536846 1.72532674 1.7252642  1.72516767 1.72515088
 1.72510724 1.72503127 1.72502581 1.72493526 1.72490513 1.72487038
 1.72486882 1.72482136]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.72521946 1.72521448 1.72521014 1.72520763 1.72518395 1.72518693
 1.72520722 1.72520771 1.72521033 1.72521287 1.72521739 1.72523271
 1.72524239 1.72524167 1.72525676 1.72525544 1.72526653 1.72526696
 1.72525076 1.7252564 ]
[0.  0.5 0. ]
-----------end of analyzing the loss ratio:73.80953979492188
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938b473d0>
---------------------------------
SparseEpoch: [8][1/398]	Time 0.604	Data 0.000	Loss 1.9033	
SparseEpoch: [8][101/398]	Time 0.625	Data 0.000	Loss 2.1027	
SparseEpoch: [8][201/398]	Time 0.623	Data 0.000	Loss 1.6845	
SparseEpoch: [8][301/398]	Time 0.624	Data 0.000	Loss 2.0671	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.79810057 0.79809445 0.79807057 0.79807998 0.79808726 0.79809837
 0.79808764 0.79807173 0.79807504 0.7980812  0.79805961 0.79804941
 0.79805074 0.79803535 0.79804124 0.79804545 0.79803492 0.79800933
 0.79798824 0.79798898]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.79799121 0.79798763 0.79800651 0.79800751 0.79800688 0.79803874
 0.79803497 0.7980453  0.79804259 0.7980593  0.79807855 0.79806197
 0.79806266 0.79808184 0.79808555 0.79808964 0.79808568 0.79808813
 0.79808103 0.79808468]
[0.44736842 0.         0.        ]
-----------end of analyzing the loss ratio:73.73028993606567
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9398f9d20>
---------------------------------
SparseEpoch: [8][1/398]	Time 0.604	Data 0.000	Loss 2.3112	
SparseEpoch: [8][101/398]	Time 0.624	Data 0.000	Loss 1.4424	
SparseEpoch: [8][201/398]	Time 0.626	Data 0.000	Loss 2.4126	
SparseEpoch: [8][301/398]	Time 0.623	Data 0.000	Loss 2.2913	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.27592759 0.27589822 0.27589628 0.27590286 0.27588786 0.27585778
 0.27584688 0.27582393 0.27579207 0.27579257 0.27579187 0.27578099
 0.275778   0.27575297 0.27572094 0.27571926 0.27573816 0.27572657
 0.27572179 0.27570143]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.27588618 0.27586174 0.27585862 0.27586139 0.27585666 0.27584185
 0.27582386 0.27580076 0.27578843 0.27579645 0.27578506 0.27578605
 0.27578444 0.27578342 0.27577201 0.27574586 0.27572629 0.27572072
 0.27574062 0.27573749]
[0.5        0.39473684 0.        ]
-----------end of analyzing the loss ratio:73.85562467575073
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938e16aa0>
---------------------------------
SparseEpoch: [8][1/398]	Time 0.607	Data 0.000	Loss 2.7952	
SparseEpoch: [8][101/398]	Time 0.623	Data 0.000	Loss 4.1030	
SparseEpoch: [8][201/398]	Time 0.622	Data 0.000	Loss 3.2027	
SparseEpoch: [8][301/398]	Time 0.624	Data 0.000	Loss 3.6247	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 2.7286	
Epoch(adapt):{0} Loss 2.8316	
Epoch(adapt):{0} Loss 3.1062	
Epoch(adapt):{0} Loss 1.8032	
------------------the total time cost:1215.1019887924194
>>>>>meta updating
Epoch: 0008 | TRAIN: 1.5298 0.1322 0.4754 | 0.6990 0.6990 0.3419 | 0.2419 36.3556 33.8273 0.1017 0.2992 0.4359 ||TEST: 1.5616 0.1312 0.4650 | 0.7558 0.7558 0.2910 | 0.2332 35.6868 33.7575 0.1086 0.3035 0.4392 | 114.8122
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.55984389 1.5598512  1.55987408 1.55984015 1.55982207 1.55973407
 1.55972487 1.55972138 1.55969016 1.55963342 1.55962878 1.5595537
 1.55952947 1.55960475 1.5596715  1.55965344 1.5597186  1.559682
 1.55965468 1.55962388]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.55969407 1.55970939 1.55971044 1.55968817 1.55965196 1.55964495
 1.55964368 1.5596202  1.55960898 1.55962298 1.55960372 1.55960886
 1.55962701 1.55960733 1.55961303 1.5596028  1.55961339 1.55960072
 1.55962475 1.55961258]
[0.         0.13157895 0.39473684]
-----------end of analyzing the loss ratio:73.66936731338501
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938b16ef0>
---------------------------------
SparseEpoch: [9][1/398]	Time 0.608	Data 0.000	Loss 2.1668	
SparseEpoch: [9][101/398]	Time 0.622	Data 0.000	Loss 2.6069	
SparseEpoch: [9][201/398]	Time 0.623	Data 0.000	Loss 2.3340	
SparseEpoch: [9][301/398]	Time 0.624	Data 0.000	Loss 3.5080	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.94313991 0.94312331 0.94307478 0.94305622 0.94307294 0.94305252
 0.94301898 0.94303398 0.94301255 0.94297206 0.94293523 0.9429101
 0.94289957 0.94285715 0.9428213  0.94279361 0.94277551 0.94273844
 0.94275064 0.94271869]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.94296928 0.94295814 0.94296505 0.94296144 0.94296237 0.94295607
 0.94296061 0.94296501 0.9429447  0.94294556 0.94295436 0.94295813
 0.94294749 0.94294977 0.94294828 0.94295376 0.942955   0.94295396
 0.94295738 0.94294998]
[0.5 0.  0. ]
-----------end of analyzing the loss ratio:73.56886529922485
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938e58bb0>
---------------------------------
SparseEpoch: [9][1/398]	Time 0.618	Data 0.000	Loss 1.4925	
SparseEpoch: [9][101/398]	Time 0.622	Data 0.000	Loss 1.9769	
SparseEpoch: [9][201/398]	Time 0.621	Data 0.000	Loss 1.1700	
SparseEpoch: [9][301/398]	Time 0.619	Data 0.000	Loss 1.4576	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.24469243 0.24467742 0.2446628  0.24466078 0.24464762 0.24463233
 0.24462377 0.24461492 0.2446196  0.24461082 0.24462733 0.24462053
 0.24459516 0.24458739 0.24458088 0.24457778 0.24458078 0.24457266
 0.24455059 0.24454584]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.24466286 0.24465275 0.24464785 0.24464269 0.24463662 0.2446346
 0.24462963 0.24461998 0.24461295 0.24461623 0.24462554 0.24461984
 0.24461296 0.24461333 0.24461892 0.24460503 0.24459998 0.24459511
 0.24459741 0.2445893 ]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:73.52040076255798
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938b17d30>
---------------------------------
SparseEpoch: [9][1/398]	Time 0.605	Data 0.000	Loss 4.3384	
SparseEpoch: [9][101/398]	Time 0.626	Data 0.000	Loss 4.6451	
SparseEpoch: [9][201/398]	Time 0.627	Data 0.000	Loss 3.0165	
SparseEpoch: [9][301/398]	Time 0.624	Data 0.000	Loss 2.8968	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 3.0967	
Epoch(adapt):{0} Loss 2.2560	
Epoch(adapt):{0} Loss 3.5578	
Epoch(adapt):{0} Loss 1.9438	
------------------the total time cost:1210.8025841712952
>>>>>meta updating
Epoch: 0009 | TRAIN: 1.5153 0.1415 0.4767 | 0.7001 0.7001 0.3414 | 0.2353 35.5830 32.9089 0.1163 0.3185 0.4536 ||TEST: 1.5408 0.1422 0.4700 | 0.7621 0.7621 0.2855 | 0.2250 34.7680 32.6023 0.1233 0.3260 0.4602 | 114.6978
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.58925576 1.58927187 1.58930748 1.58930048 1.58931239 1.58930309
 1.58929256 1.58930857 1.58930014 1.58931472 1.58930401 1.58928647
 1.58928808 1.58931037 1.58930181 1.58930018 1.58928359 1.58927406
 1.58925606 1.5892361 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.58932045 1.58930485 1.58929145 1.58929539 1.58930991 1.58930475
 1.58929967 1.58929253 1.58930124 1.58930866 1.58931173 1.58931959
 1.58931324 1.58931385 1.589314   1.58930802 1.58931106 1.58931047
 1.58932183 1.58931612]
[0.  0.5 0. ]
-----------end of analyzing the loss ratio:73.7901828289032
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938e599c0>
---------------------------------
SparseEpoch: [10][1/398]	Time 0.614	Data 0.000	Loss 1.7704	
SparseEpoch: [10][101/398]	Time 0.619	Data 0.000	Loss 1.9955	
SparseEpoch: [10][201/398]	Time 0.621	Data 0.000	Loss 1.6835	
SparseEpoch: [10][301/398]	Time 0.622	Data 0.000	Loss 1.6791	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.74216434 0.74214584 0.74213166 0.74212034 0.74212053 0.74211313
 0.74212835 0.7421226  0.74210243 0.74210639 0.74211283 0.74210038
 0.74211586 0.74212098 0.74213056 0.74215086 0.74215232 0.74213231
 0.74212708 0.74211653]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.74210641 0.74211473 0.74212736 0.74212617 0.74213614 0.74213087
 0.74212233 0.74212509 0.74212871 0.7421205  0.74211102 0.74210236
 0.7421027  0.74211053 0.74211219 0.74214101 0.74215347 0.7421693
 0.74217823 0.74219213]
[0.07894737 0.         0.07894737]
-----------end of analyzing the loss ratio:73.75313067436218
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938b158d0>
---------------------------------
SparseEpoch: [10][1/398]	Time 0.606	Data 0.000	Loss 0.5814	
SparseEpoch: [10][101/398]	Time 0.627	Data 0.000	Loss 1.0627	
SparseEpoch: [10][201/398]	Time 0.625	Data 0.000	Loss 0.8024	
SparseEpoch: [10][301/398]	Time 0.625	Data 0.000	Loss 0.8643	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.25485523 0.25484244 0.25485408 0.25484914 0.25483907 0.25484498
 0.25485246 0.25485222 0.25484304 0.25484729 0.25484421 0.25483316
 0.25481614 0.25480163 0.25479184 0.25478323 0.25476713 0.25476242
 0.25475942 0.25476735]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.25478792 0.25479876 0.25480887 0.25480777 0.25481527 0.25482222
 0.25482153 0.25482409 0.25484084 0.25484627 0.25484666 0.25485564
 0.25485243 0.25484982 0.25485278 0.2548534  0.25485359 0.25485685
 0.25485153 0.25484045]
[0.44736842 0.         0.        ]
-----------end of analyzing the loss ratio:73.59090185165405
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938a88670>
---------------------------------
SparseEpoch: [10][1/398]	Time 0.688	Data 0.000	Loss 3.6045	
SparseEpoch: [10][101/398]	Time 0.625	Data 0.000	Loss 3.6404	
SparseEpoch: [10][201/398]	Time 0.624	Data 0.000	Loss 2.2901	
SparseEpoch: [10][301/398]	Time 0.623	Data 0.000	Loss 3.0557	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 2.2413	
Epoch(adapt):{0} Loss 1.8810	
Epoch(adapt):{0} Loss 2.9094	
Epoch(adapt):{0} Loss 2.6947	
------------------the total time cost:1212.3306913375854
>>>>>meta updating
Epoch: 0010 | TRAIN: 1.4956 0.1394 0.4884 | 0.6894 0.6894 0.3150 | 0.2309 35.0227 32.1127 0.1258 0.3345 0.4686 ||TEST: 1.5031 0.1433 0.4871 | 0.7603 0.7603 0.2767 | 0.2174 33.9162 31.5049 0.1371 0.3459 0.4792 | 114.9490
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.53164741 1.53172253 1.53171362 1.53172622 1.53173181 1.53175133
 1.53176378 1.53175882 1.5317453  1.53171463 1.53169241 1.53168737
 1.53169236 1.53172126 1.53167816 1.5316878  1.5316963  1.53172146
 1.53177711 1.53179437]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.53180805 1.53182123 1.53179512 1.53178154 1.53175904 1.53174363
 1.53172489 1.5317072  1.53170948 1.53170048 1.53168545 1.53168361
 1.53169886 1.53169734 1.53168908 1.53166742 1.53165921 1.53166568
 1.53165154 1.5316645 ]
[0.         0.         0.44736842]
-----------end of analyzing the loss ratio:73.61630034446716
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc93901d090>
---------------------------------
SparseEpoch: [11][1/398]	Time 0.615	Data 0.000	Loss 3.3780	
SparseEpoch: [11][101/398]	Time 0.627	Data 0.000	Loss 2.5268	
SparseEpoch: [11][201/398]	Time 0.626	Data 0.000	Loss 2.8826	
SparseEpoch: [11][301/398]	Time 0.623	Data 0.000	Loss 4.0989	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.78997935 0.78997343 0.78997625 0.790023   0.79002877 0.78997808
 0.78996723 0.78994821 0.78994897 0.78993936 0.78999783 0.7899679
 0.79001358 0.7900198  0.78999407 0.79000418 0.78998978 0.78997868
 0.7899812  0.78998713]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.7899414  0.78995478 0.78996386 0.78996215 0.78997093 0.78997074
 0.78998039 0.78998992 0.7899932  0.78999304 0.78999182 0.78998889
 0.78998764 0.78999287 0.78999792 0.79000528 0.79000022 0.79000058
 0.78999678 0.7899886 ]
[0. 0. 0.]
-----------end of analyzing the loss ratio:73.58966827392578
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cca5e1f9db0>
---------------------------------
SparseEpoch: [11][1/398]	Time 0.605	Data 0.000	Loss 1.4566	
SparseEpoch: [11][101/398]	Time 0.626	Data 0.000	Loss 0.8091	
SparseEpoch: [11][201/398]	Time 0.621	Data 0.000	Loss 0.3756	
SparseEpoch: [11][301/398]	Time 0.621	Data 0.000	Loss 0.7375	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.25759149 0.25759848 0.2576031  0.25760028 0.25760589 0.25761573
 0.25760657 0.25761667 0.257599   0.25757836 0.25757119 0.25758286
 0.2575615  0.2575491  0.25753617 0.25752219 0.2575105  0.25752859
 0.25753439 0.25752972]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.25760188 0.2575985  0.25759743 0.25758703 0.2575868  0.25757788
 0.25757678 0.25757678 0.25758075 0.25757395 0.25757547 0.25756393
 0.25756148 0.2575662  0.25755895 0.25755982 0.25755881 0.2575545
 0.25754856 0.25754474]
[0.34210526 0.5        0.        ]
-----------end of analyzing the loss ratio:73.7513427734375
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938ce2a70>
---------------------------------
SparseEpoch: [11][1/398]	Time 0.612	Data 0.000	Loss 3.8422	
SparseEpoch: [11][101/398]	Time 0.624	Data 0.000	Loss 3.0422	
SparseEpoch: [11][201/398]	Time 0.624	Data 0.000	Loss 3.6232	
SparseEpoch: [11][301/398]	Time 0.624	Data 0.000	Loss 3.5906	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 2.6253	
Epoch(adapt):{0} Loss 2.1638	
Epoch(adapt):{0} Loss 1.8095	
Epoch(adapt):{0} Loss 1.9914	
------------------the total time cost:1213.497508764267
>>>>>meta updating
Epoch: 0011 | TRAIN: 1.4815 0.1501 0.4950 | 0.6856 0.6856 0.3171 | 0.2272 34.7489 31.8711 0.1247 0.3355 0.4726 ||TEST: 1.4979 0.1521 0.4896 | 0.7372 0.7372 0.2770 | 0.2149 33.7259 31.2429 0.1350 0.3471 0.4829 | 115.1039
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.51651133 1.51644533 1.51643629 1.51632998 1.51624519 1.51618435
 1.51615509 1.5160792  1.5159927  1.51598337 1.51584826 1.51572104
 1.51574707 1.51562066 1.51556833 1.51548208 1.51547314 1.5153419
 1.51527839 1.51520736]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.51593163 1.51592396 1.51591402 1.51591707 1.51591834 1.51591384
 1.51591002 1.51588788 1.5158793  1.51588802 1.51588666 1.51588923
 1.51588001 1.51588361 1.51588026 1.51587529 1.51587715 1.51588669
 1.51588564 1.51589597]
[0.         0.5        0.28947368]
-----------end of analyzing the loss ratio:73.72341299057007
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938e021d0>
---------------------------------
SparseEpoch: [12][1/398]	Time 0.605	Data 0.000	Loss 2.5931	
SparseEpoch: [12][101/398]	Time 0.625	Data 0.000	Loss 2.5383	
SparseEpoch: [12][201/398]	Time 0.624	Data 0.000	Loss 2.5323	
SparseEpoch: [12][301/398]	Time 0.625	Data 0.000	Loss 2.6848	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.85027654 0.85030876 0.850309   0.85031841 0.85033035 0.85033985
 0.85036324 0.85037745 0.85036176 0.85037042 0.85034806 0.85037072
 0.8503795  0.85036622 0.85035574 0.85033405 0.85034105 0.85031613
 0.85027308 0.85028784]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.85032555 0.85032268 0.85033925 0.85034692 0.85036842 0.85037584
 0.85038114 0.85036166 0.850353   0.8503637  0.85035834 0.85034626
 0.85035297 0.85035176 0.85035037 0.8503539  0.8503752  0.85037899
 0.85039298 0.85039928]
[0.44736842 0.         0.        ]
-----------end of analyzing the loss ratio:73.60949802398682
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cca5df80dc0>
---------------------------------
SparseEpoch: [12][1/398]	Time 0.619	Data 0.000	Loss 1.2635	
SparseEpoch: [12][101/398]	Time 0.622	Data 0.000	Loss 1.3915	
SparseEpoch: [12][201/398]	Time 0.625	Data 0.000	Loss 1.3440	
SparseEpoch: [12][301/398]	Time 0.624	Data 0.000	Loss 1.8990	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.31198843 0.31195471 0.31190633 0.31185787 0.31182263 0.31178375
 0.31175681 0.3117199  0.31168056 0.31167475 0.31161721 0.3115766
 0.31154932 0.31149349 0.3114857  0.31144533 0.31140122 0.31134602
 0.31128194 0.31125827]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.31168818 0.3116904  0.31168471 0.31166745 0.3116774  0.31166514
 0.31167357 0.31167474 0.31166829 0.31166807 0.31164578 0.31163378
 0.31161386 0.31158956 0.31158278 0.31157555 0.31157914 0.31157011
 0.31157202 0.3115688 ]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:73.68218612670898
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cca5e354430>
---------------------------------
SparseEpoch: [12][1/398]	Time 0.606	Data 0.000	Loss 3.0243	
SparseEpoch: [12][101/398]	Time 0.624	Data 0.000	Loss 3.4003	
SparseEpoch: [12][201/398]	Time 0.624	Data 0.000	Loss 5.3554	
SparseEpoch: [12][301/398]	Time 0.624	Data 0.000	Loss 3.1220	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 2.2914	
Epoch(adapt):{0} Loss 2.4048	
Epoch(adapt):{0} Loss 2.4084	
Epoch(adapt):{0} Loss 2.4904	
------------------the total time cost:1214.102318763733
>>>>>meta updating
Epoch: 0012 | TRAIN: 1.4458 0.1579 0.5027 | 0.6537 0.6537 0.3181 | 0.2214 34.2507 31.3989 0.1284 0.3428 0.4792 ||TEST: 1.4828 0.1563 0.4932 | 0.7030 0.7030 0.2784 | 0.2139 33.6767 31.2156 0.1336 0.3483 0.4838 | 114.9502
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.50018553 1.50015141 1.50017728 1.50019096 1.500161   1.50020783
 1.50023575 1.50021709 1.50023397 1.50017576 1.50021542 1.50028479
 1.50033588 1.5003147  1.5002896  1.50027831 1.5002425  1.50024046
 1.50022008 1.50021839]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.5002521  1.50023131 1.5002324  1.50021195 1.50018567 1.50018303
 1.50018135 1.50020266 1.50019962 1.5002133  1.5002117  1.50020465
 1.5002027  1.50022595 1.50023167 1.50025781 1.50025879 1.50027785
 1.50029541 1.5002715 ]
[0. 0. 0.]
-----------end of analyzing the loss ratio:73.65943336486816
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938fee9b0>
---------------------------------
SparseEpoch: [13][1/398]	Time 0.606	Data 0.000	Loss 1.1961	
SparseEpoch: [13][101/398]	Time 0.625	Data 0.000	Loss 1.5028	
SparseEpoch: [13][201/398]	Time 0.623	Data 0.000	Loss 1.5038	
SparseEpoch: [13][301/398]	Time 0.623	Data 0.000	Loss 1.1282	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.99549687 0.99553328 0.9955313  0.99549507 0.99547346 0.99549147
 0.99551251 0.99551444 0.99548948 0.99551077 0.99547669 0.99545887
 0.99544217 0.99542751 0.99546365 0.99543908 0.99544507 0.99543579
 0.9954293  0.99542928]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.99548814 0.99550862 0.9954935  0.99549776 0.99549883 0.99550391
 0.99550456 0.99550405 0.99548206 0.99547765 0.99546728 0.99547209
 0.99547157 0.99546545 0.99545822 0.99546315 0.99545612 0.99545096
 0.99546224 0.99545566]
[0.18421053 0.         0.39473684]
-----------end of analyzing the loss ratio:73.5942816734314
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9386a56c0>
---------------------------------
SparseEpoch: [13][1/398]	Time 0.606	Data 0.000	Loss 1.3860	
SparseEpoch: [13][101/398]	Time 0.622	Data 0.000	Loss 2.8805	
SparseEpoch: [13][201/398]	Time 0.622	Data 0.000	Loss 2.5228	
SparseEpoch: [13][301/398]	Time 0.623	Data 0.000	Loss 1.4612	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.22389163 0.22389293 0.22390134 0.2238992  0.22389582 0.2238846
 0.22388205 0.22386613 0.2238622  0.22383878 0.22383459 0.22381969
 0.22382683 0.22380471 0.22379788 0.22379003 0.22378345 0.22378239
 0.2237593  0.2237571 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.2239899  0.22398039 0.22395875 0.22393938 0.22391894 0.22391574
 0.22389029 0.22387938 0.2238736  0.22384123 0.22382855 0.22380163
 0.22379499 0.22379749 0.22377222 0.22375457 0.22374742 0.22372191
 0.22369379 0.22368535]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:73.89412522315979
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938b7c640>
---------------------------------
SparseEpoch: [13][1/398]	Time 0.613	Data 0.000	Loss 2.7147	
SparseEpoch: [13][101/398]	Time 0.625	Data 0.000	Loss 3.3141	
SparseEpoch: [13][201/398]	Time 0.625	Data 0.000	Loss 3.2450	
SparseEpoch: [13][301/398]	Time 0.624	Data 0.000	Loss 3.1271	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 2.1306	
Epoch(adapt):{0} Loss 2.9066	
Epoch(adapt):{0} Loss 2.0936	
Epoch(adapt):{0} Loss 2.1058	
------------------the total time cost:1214.624417066574
>>>>>meta updating
Epoch: 0013 | TRAIN: 1.4465 0.1697 0.5067 | 0.6491 0.6491 0.3146 | 0.2182 33.7263 30.5983 0.1426 0.3587 0.4949 ||TEST: 1.4759 0.1705 0.4984 | 0.7094 0.7094 0.2732 | 0.2087 32.9882 30.2324 0.1486 0.3661 0.5009 | 114.6765
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.38188221 1.381801   1.3818131  1.38183021 1.38189092 1.38189676
 1.3819229  1.38194888 1.3819645  1.3819355  1.38196393 1.38196248
 1.38198665 1.38207773 1.38208865 1.38214453 1.38217774 1.3821733
 1.38220789 1.38219551]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.38207183 1.38207148 1.38204765 1.38203062 1.38200051 1.38198398
 1.38196555 1.38196942 1.38196124 1.38196476 1.381947   1.38193291
 1.38195186 1.38194495 1.38194057 1.38194839 1.3819481  1.38196366
 1.3819907  1.38196734]
[0.         0.         0.07894737]
-----------end of analyzing the loss ratio:73.7951910495758
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc93995f3a0>
---------------------------------
SparseEpoch: [14][1/398]	Time 0.605	Data 0.000	Loss 1.4026	
SparseEpoch: [14][101/398]	Time 0.631	Data 0.000	Loss 2.0230	
SparseEpoch: [14][201/398]	Time 0.627	Data 0.000	Loss 1.2302	
SparseEpoch: [14][301/398]	Time 0.627	Data 0.000	Loss 1.5271	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.19673626 1.19652115 1.19654889 1.19641904 1.19625198 1.19620432
 1.19601799 1.19585986 1.19561092 1.19557673 1.1954739  1.19538833
 1.19531093 1.19525345 1.19519257 1.19509559 1.19496105 1.19482071
 1.19483497 1.19469491]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.19555163 1.19554629 1.19555273 1.19555401 1.19556609 1.19554455
 1.1955522  1.19554504 1.19554269 1.19554311 1.19549221 1.19550764
 1.19551392 1.19550292 1.19552469 1.19551219 1.19552933 1.19555598
 1.1955346  1.19550788]
[0.5        0.         0.02631579]
-----------end of analyzing the loss ratio:73.69554853439331
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938837160>
---------------------------------
SparseEpoch: [14][1/398]	Time 0.608	Data 0.000	Loss 2.3313	
SparseEpoch: [14][101/398]	Time 0.623	Data 0.000	Loss 1.7117	
SparseEpoch: [14][201/398]	Time 0.622	Data 0.000	Loss 1.3459	
SparseEpoch: [14][301/398]	Time 0.622	Data 0.000	Loss 1.8602	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.21364177 0.21363477 0.21364784 0.21365595 0.2136494  0.21362135
 0.21360649 0.21359363 0.21358063 0.21358305 0.21357208 0.21356641
 0.21356167 0.21355942 0.21354636 0.21354432 0.21354227 0.21353594
 0.21352434 0.21352171]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.21357644 0.21358184 0.2135806  0.2135823  0.21357943 0.21358385
 0.21358372 0.21358504 0.21358272 0.21358353 0.21357624 0.21358411
 0.21358432 0.21358339 0.21358306 0.21358191 0.21357608 0.21358164
 0.21358092 0.213577  ]
[0.5        0.34210526 0.        ]
-----------end of analyzing the loss ratio:73.79117965698242
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cca5e466e30>
---------------------------------
SparseEpoch: [14][1/398]	Time 0.632	Data 0.000	Loss 3.8824	
SparseEpoch: [14][101/398]	Time 0.623	Data 0.000	Loss 2.6730	
SparseEpoch: [14][201/398]	Time 0.624	Data 0.000	Loss 2.7974	
SparseEpoch: [14][301/398]	Time 0.623	Data 0.000	Loss 2.7204	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.9525	
Epoch(adapt):{0} Loss 2.5799	
Epoch(adapt):{0} Loss 2.1207	
Epoch(adapt):{0} Loss 2.2840	
------------------the total time cost:1214.0326464176178
>>>>>meta updating
Epoch: 0014 | TRAIN: 1.4009 0.1851 0.5188 | 0.6489 0.6489 0.3153 | 0.2172 33.5704 30.4282 0.1468 0.3636 0.4984 ||TEST: 1.4386 0.1829 0.5111 | 0.7005 0.7005 0.2766 | 0.2078 32.8004 30.0529 0.1574 0.3721 0.5041 | 115.0671
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.48170891 1.48171735 1.48173387 1.48168434 1.48167868 1.48171923
 1.48171331 1.48173927 1.48169893 1.48165785 1.48163021 1.48162451
 1.48161223 1.48160619 1.48160357 1.48162268 1.48164988 1.48164723
 1.48168517 1.4816712 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.48163695 1.48162279 1.48161798 1.48162726 1.48165303 1.4816424
 1.48162546 1.48161294 1.48161753 1.48164014 1.48163004 1.48164352
 1.48168004 1.48166604 1.48164409 1.48166287 1.48165154 1.48165165
 1.4816432  1.48165218]
[0.         0.23684211 0.        ]
-----------end of analyzing the loss ratio:73.87708902359009
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc93988caf0>
---------------------------------
SparseEpoch: [15][1/398]	Time 0.605	Data 0.000	Loss 1.6756	
SparseEpoch: [15][101/398]	Time 0.623	Data 0.000	Loss 1.3914	
SparseEpoch: [15][201/398]	Time 0.624	Data 0.000	Loss 1.7374	
SparseEpoch: [15][301/398]	Time 0.625	Data 0.000	Loss 1.6692	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.4159478  1.41612846 1.41634197 1.41640524 1.41654072 1.41675196
 1.41690735 1.41707521 1.41722488 1.41734338 1.41742139 1.41755982
 1.41767755 1.41779765 1.41796871 1.41814806 1.41830214 1.41851885
 1.41862925 1.41875104]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.41697362 1.41703682 1.41706081 1.41709829 1.41715724 1.41719015
 1.41723539 1.41724895 1.4173348  1.41737413 1.41740491 1.41743759
 1.41745981 1.41751607 1.4175686  1.41760895 1.41765761 1.41763653
 1.41769357 1.4177414 ]
[0. 0. 0.]
-----------end of analyzing the loss ratio:73.92691683769226
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc93988d990>
---------------------------------
SparseEpoch: [15][1/398]	Time 0.605	Data 0.000	Loss 0.8208	
SparseEpoch: [15][101/398]	Time 0.623	Data 0.000	Loss 0.7066	
SparseEpoch: [15][201/398]	Time 0.623	Data 0.000	Loss 0.5377	
SparseEpoch: [15][301/398]	Time 0.622	Data 0.000	Loss 0.6546	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.24676647 0.24676078 0.24667678 0.24665493 0.24656507 0.24654372
 0.24654295 0.2465014  0.24645978 0.24641082 0.24637592 0.24633769
 0.24630893 0.24630176 0.24627758 0.24624746 0.24620035 0.24612072
 0.24603293 0.24598824]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.24647058 0.24647722 0.24648815 0.24646277 0.24645507 0.24643713
 0.24642665 0.24642475 0.24641391 0.2464074  0.24638284 0.24637777
 0.24637763 0.24637917 0.24639857 0.24638464 0.24639327 0.24640237
 0.2463976  0.2463792 ]
[0.5        0.13157895 0.        ]
-----------end of analyzing the loss ratio:73.99510312080383
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc939e6ed70>
---------------------------------
SparseEpoch: [15][1/398]	Time 0.606	Data 0.000	Loss 3.0388	
SparseEpoch: [15][101/398]	Time 0.626	Data 0.000	Loss 4.1207	
SparseEpoch: [15][201/398]	Time 0.626	Data 0.000	Loss 3.7872	
SparseEpoch: [15][301/398]	Time 0.626	Data 0.000	Loss 3.4563	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 2.6138	
Epoch(adapt):{0} Loss 2.6222	
Epoch(adapt):{0} Loss 1.8209	
Epoch(adapt):{0} Loss 2.7239	
------------------the total time cost:1214.2841832637787
>>>>>meta updating
Epoch: 0015 | TRAIN: 1.4010 0.1795 0.5246 | 0.6322 0.6322 0.3033 | 0.2183 33.7258 30.5070 0.1429 0.3613 0.4949 ||TEST: 1.4208 0.1806 0.5178 | 0.6928 0.6928 0.2681 | 0.2092 32.9454 30.2073 0.1556 0.3700 0.5010 | 114.9291
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.30241735 1.30239915 1.30238596 1.30242503 1.30243914 1.30243248
 1.30241648 1.30239117 1.30239794 1.30241762 1.30241944 1.30236505
 1.30236822 1.30240341 1.30237968 1.30236017 1.30240617 1.30239512
 1.30237577 1.30239824]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.3024318  1.30243606 1.30242897 1.30241483 1.30241128 1.30241894
 1.30243549 1.30242714 1.30244073 1.30242995 1.30242165 1.30241544
 1.30239421 1.30239178 1.30238032 1.30240467 1.30239086 1.30239668
 1.30239823 1.30239265]
[0.         0.28947368 0.23684211]
-----------end of analyzing the loss ratio:73.94674181938171
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc93997d690>
---------------------------------
SparseEpoch: [16][1/398]	Time 0.767	Data 0.000	Loss 2.5977	
SparseEpoch: [16][101/398]	Time 0.619	Data 0.000	Loss 2.6270	
SparseEpoch: [16][201/398]	Time 0.625	Data 0.000	Loss 1.8627	
SparseEpoch: [16][301/398]	Time 0.624	Data 0.000	Loss 1.8717	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.0047106  1.00468732 1.00469293 1.00470538 1.00467581 1.00469003
 1.00467333 1.0046814  1.00466663 1.00464379 1.00463818 1.00464293
 1.0046402  1.00463654 1.00461757 1.004605   1.00462114 1.00462548
 1.0046185  1.00457919]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.00466404 1.00466206 1.00465224 1.00465897 1.00465152 1.00465789
 1.00465506 1.00464477 1.0046401  1.00464777 1.00464588 1.00464284
 1.00463952 1.00463629 1.00462655 1.00463911 1.00464502 1.00464186
 1.00462807 1.0046185 ]
[0.5 0.  0.5]
-----------end of analyzing the loss ratio:73.75765919685364
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9386a5240>
---------------------------------
SparseEpoch: [16][1/398]	Time 0.605	Data 0.000	Loss 3.4873	
SparseEpoch: [16][101/398]	Time 0.628	Data 0.000	Loss 2.1851	
SparseEpoch: [16][201/398]	Time 0.623	Data 0.000	Loss 2.0541	
SparseEpoch: [16][301/398]	Time 0.623	Data 0.000	Loss 3.5350	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.25735576 0.25735992 0.25734968 0.25734913 0.25733078 0.25731632
 0.25730811 0.2573016  0.25727749 0.25727324 0.25725498 0.25724564
 0.25723795 0.25723444 0.25723582 0.25723649 0.25721814 0.25721003
 0.25720187 0.25718775]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.25728489 0.25727931 0.25727777 0.25727812 0.25727862 0.25727556
 0.25727124 0.2572684  0.25726542 0.25726026 0.25726314 0.25725507
 0.257249   0.25725384 0.25725548 0.25725127 0.25724581 0.25724493
 0.25724653 0.25724491]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:73.71445083618164
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938a8dc30>
---------------------------------
SparseEpoch: [16][1/398]	Time 0.606	Data 0.000	Loss 3.3862	
SparseEpoch: [16][101/398]	Time 0.626	Data 0.000	Loss 4.2846	
SparseEpoch: [16][201/398]	Time 0.625	Data 0.000	Loss 3.4812	
SparseEpoch: [16][301/398]	Time 0.625	Data 0.000	Loss 3.1006	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 3.0573	
Epoch(adapt):{0} Loss 2.8804	
Epoch(adapt):{0} Loss 2.1393	
Epoch(adapt):{0} Loss 2.4788	
------------------the total time cost:1215.9000928401947
>>>>>meta updating
Epoch: 0016 | TRAIN: 1.3789 0.1902 0.5298 | 0.6305 0.6305 0.3029 | 0.2117 32.9491 29.6580 0.1582 0.3776 0.5116 ||TEST: 1.4204 0.1859 0.5187 | 0.6869 0.6869 0.2716 | 0.2011 32.0821 29.0422 0.1666 0.3892 0.5212 | 115.0145
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.29015844 1.29019818 1.29016076 1.2901551  1.2901873  1.29015557
 1.29011497 1.29007989 1.29004324 1.29004245 1.29007117 1.2901318
 1.29012251 1.29011834 1.29007294 1.29004829 1.28999392 1.28994909
 1.28987797 1.28985061]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.29007735 1.29008905 1.2900912  1.29008461 1.29008811 1.29008681
 1.29007918 1.29007801 1.29005091 1.29004807 1.29005924 1.29006886
 1.2900633  1.29005316 1.29005472 1.29006891 1.29008008 1.29009225
 1.29007976 1.29006975]
[0.  0.5 0. ]
-----------end of analyzing the loss ratio:73.85652875900269
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938d3cf40>
---------------------------------
SparseEpoch: [17][1/398]	Time 0.607	Data 0.000	Loss 1.9668	
SparseEpoch: [17][101/398]	Time 0.624	Data 0.000	Loss 1.6343	
SparseEpoch: [17][201/398]	Time 0.623	Data 0.000	Loss 2.3575	
SparseEpoch: [17][301/398]	Time 0.623	Data 0.000	Loss 2.2305	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.86858882 0.86854491 0.86847346 0.86842834 0.86841392 0.86831316
 0.86830142 0.86823793 0.86821266 0.86815737 0.86813815 0.86806295
 0.8680595  0.86805868 0.86799322 0.8679427  0.86797825 0.86801933
 0.86792572 0.8679534 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.86811747 0.86812032 0.86812811 0.86811818 0.86814413 0.86814698
 0.86816268 0.8681458  0.86814202 0.86813419 0.86813701 0.86814346
 0.86815408 0.86814968 0.86816417 0.86816109 0.86815721 0.86815966
 0.86815911 0.86817383]
[0.44736842 0.         0.        ]
-----------end of analyzing the loss ratio:73.86187720298767
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cca5e356560>
---------------------------------
SparseEpoch: [17][1/398]	Time 0.605	Data 0.000	Loss 0.9924	
SparseEpoch: [17][101/398]	Time 0.619	Data 0.000	Loss 1.4221	
SparseEpoch: [17][201/398]	Time 0.620	Data 0.000	Loss 1.2680	
SparseEpoch: [17][301/398]	Time 0.623	Data 0.000	Loss 1.4865	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.22511354 0.2251451  0.22513373 0.22512388 0.22508656 0.22510639
 0.22509208 0.22507885 0.22504956 0.22502159 0.22500433 0.22499005
 0.2249758  0.22496148 0.2249455  0.22495879 0.22494854 0.22494544
 0.22495403 0.2249456 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.22501218 0.22501228 0.22501395 0.2250192  0.22502047 0.22502159
 0.22501711 0.22501987 0.22501943 0.22502045 0.22501911 0.2250147
 0.22502026 0.22502645 0.22503456 0.2250423  0.22504662 0.2250515
 0.22505571 0.22505422]
[0.39473684 0.         0.        ]
-----------end of analyzing the loss ratio:73.72378587722778
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cca5dec9d80>
---------------------------------
SparseEpoch: [17][1/398]	Time 0.604	Data 0.000	Loss 2.8937	
SparseEpoch: [17][101/398]	Time 0.627	Data 0.000	Loss 2.4844	
SparseEpoch: [17][201/398]	Time 0.625	Data 0.000	Loss 2.6558	
SparseEpoch: [17][301/398]	Time 0.625	Data 0.000	Loss 2.8092	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 2.1432	
Epoch(adapt):{0} Loss 2.8065	
Epoch(adapt):{0} Loss 2.3735	
Epoch(adapt):{0} Loss 2.3700	
------------------the total time cost:1213.9865264892578
>>>>>meta updating
Epoch: 0017 | TRAIN: 1.3496 0.1966 0.5367 | 0.6224 0.6224 0.2889 | 0.2119 32.9525 29.6884 0.1615 0.3773 0.5097 ||TEST: 1.3907 0.1931 0.5276 | 0.6877 0.6877 0.2591 | 0.2054 32.4327 29.6040 0.1700 0.3829 0.5114 | 115.2480
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.42408204 1.42406911 1.42401583 1.42402258 1.42403592 1.42397821
 1.42394761 1.42388927 1.42394141 1.4238726  1.42380942 1.42374109
 1.42369455 1.42372141 1.4237479  1.4237613  1.42373924 1.42382154
 1.42379291 1.42380325]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.42389477 1.42388381 1.42385858 1.42385721 1.42386478 1.42386
 1.4238616  1.4238704  1.42384562 1.42382379 1.42381406 1.42381028
 1.42380677 1.42381929 1.42381711 1.42380877 1.42381431 1.42383151
 1.4238304  1.42382977]
[0.         0.13157895 0.13157895]
-----------end of analyzing the loss ratio:73.69866442680359
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9386ca1a0>
---------------------------------
SparseEpoch: [18][1/398]	Time 0.659	Data 0.000	Loss 1.7644	
SparseEpoch: [18][101/398]	Time 0.625	Data 0.000	Loss 1.6486	
SparseEpoch: [18][201/398]	Time 0.626	Data 0.000	Loss 2.3995	
SparseEpoch: [18][301/398]	Time 0.626	Data 0.000	Loss 1.2941	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.80743318 0.80738832 0.80738376 0.80729339 0.80729229 0.80721846
 0.80716696 0.80712109 0.80714964 0.80712398 0.80711669 0.80704474
 0.80702524 0.80701678 0.80691977 0.80682022 0.80679143 0.80671525
 0.80667314 0.80657601]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.80717431 0.80716581 0.80717315 0.80717572 0.807186   0.8071829
 0.80717991 0.80717472 0.80715496 0.80714476 0.80713789 0.80714098
 0.80713362 0.80712351 0.80712077 0.80711277 0.80709549 0.80708222
 0.80708161 0.80708629]
[0.5        0.         0.44736842]
-----------end of analyzing the loss ratio:73.67019820213318
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938f176a0>
---------------------------------
SparseEpoch: [18][1/398]	Time 0.605	Data 0.000	Loss 2.5626	
SparseEpoch: [18][101/398]	Time 0.623	Data 0.000	Loss 2.2472	
SparseEpoch: [18][201/398]	Time 0.623	Data 0.000	Loss 2.2289	
SparseEpoch: [18][301/398]	Time 0.625	Data 0.000	Loss 2.0421	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.25318843 0.25315634 0.25315974 0.2531512  0.2531401  0.2531122
 0.2530962  0.2530854  0.25307498 0.25305594 0.25304942 0.25303829
 0.25300667 0.25297335 0.25296446 0.25295318 0.25293946 0.25293123
 0.25291566 0.25290022]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.2530681  0.25306523 0.25307173 0.25306638 0.25306529 0.25306599
 0.25306143 0.25306042 0.25304931 0.25305059 0.25304904 0.25304488
 0.25304524 0.25304025 0.25304524 0.25303446 0.25303547 0.25304078
 0.25303173 0.2530283 ]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:73.70114135742188
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9388c7f70>
---------------------------------
SparseEpoch: [18][1/398]	Time 0.606	Data 0.000	Loss 3.3903	
SparseEpoch: [18][101/398]	Time 0.628	Data 0.000	Loss 4.4001	
SparseEpoch: [18][201/398]	Time 0.625	Data 0.000	Loss 2.6878	
SparseEpoch: [18][301/398]	Time 0.624	Data 0.000	Loss 3.1780	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 2.2410	
Epoch(adapt):{0} Loss 2.0450	
Epoch(adapt):{0} Loss 2.4328	
Epoch(adapt):{0} Loss 2.2452	
------------------the total time cost:1215.2393071651459
>>>>>meta updating
Epoch: 0018 | TRAIN: 1.3331 0.2077 0.5457 | 0.6150 0.6150 0.2755 | 0.2083 32.6235 29.1486 0.1614 0.3841 0.5189 ||TEST: 1.3744 0.2013 0.5336 | 0.7036 0.7036 0.2636 | 0.1973 31.6863 28.6411 0.1738 0.3951 0.5278 | 115.1684
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.2860011  1.28601691 1.28599384 1.28592035 1.28591675 1.28590384
 1.2858843  1.28584145 1.28582343 1.28577679 1.28578497 1.28581398
 1.28578357 1.28577242 1.28577124 1.28573149 1.28575193 1.2857499
 1.28576207 1.28579943]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.2858149  1.2858262  1.28582123 1.28580997 1.28581029 1.28580731
 1.2858063  1.28579094 1.28576974 1.28576379 1.28576831 1.2857723
 1.28578135 1.28576509 1.2857868  1.28578961 1.28577328 1.28576076
 1.28575153 1.28575593]
[0.         0.28947368 0.44736842]
-----------end of analyzing the loss ratio:74.02170181274414
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cca5e401db0>
---------------------------------
SparseEpoch: [19][1/398]	Time 0.610	Data 0.000	Loss 2.7911	
SparseEpoch: [19][101/398]	Time 0.622	Data 0.000	Loss 2.5969	
SparseEpoch: [19][201/398]	Time 0.623	Data 0.000	Loss 3.3240	
SparseEpoch: [19][301/398]	Time 0.623	Data 0.000	Loss 2.7802	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.7082212  0.70816212 0.70815805 0.70813301 0.70811147 0.70807756
 0.70798824 0.70793064 0.70788568 0.70787112 0.70784315 0.7077825
 0.70777633 0.70773758 0.70768831 0.70763318 0.70754606 0.70745118
 0.70740774 0.70739964]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.70786222 0.70786761 0.7078891  0.70790021 0.70789137 0.70789477
 0.70786394 0.7078738  0.70788908 0.7078831  0.70786729 0.70784227
 0.70782902 0.70782362 0.70784237 0.70783637 0.70783308 0.70782033
 0.70781921 0.70782571]
[0.5        0.         0.44736842]
-----------end of analyzing the loss ratio:73.9639744758606
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc939ec9e10>
---------------------------------
SparseEpoch: [19][1/398]	Time 0.607	Data 0.000	Loss 2.5845	
SparseEpoch: [19][101/398]	Time 0.629	Data 0.000	Loss 2.0967	
SparseEpoch: [19][201/398]	Time 0.626	Data 0.000	Loss 2.4160	
SparseEpoch: [19][301/398]	Time 0.627	Data 0.000	Loss 2.1152	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.20121711 0.20114778 0.2011081  0.20106912 0.20100994 0.20096092
 0.20092861 0.20086334 0.20077621 0.20069436 0.20065686 0.2005983
 0.20052258 0.20049133 0.20049409 0.20047463 0.20044554 0.20040895
 0.20040601 0.20040293]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.20099342 0.2009976  0.20092607 0.2009008  0.20088477 0.20082991
 0.20080743 0.20073329 0.20069246 0.20065638 0.2006635  0.20064746
 0.20062342 0.20057458 0.2005358  0.20051705 0.20049904 0.20047895
 0.20048441 0.20046629]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:73.87743759155273
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9388c6590>
---------------------------------
SparseEpoch: [19][1/398]	Time 0.623	Data 0.000	Loss 3.2720	
SparseEpoch: [19][101/398]	Time 0.622	Data 0.000	Loss 4.3311	
SparseEpoch: [19][201/398]	Time 0.623	Data 0.000	Loss 3.0138	
SparseEpoch: [19][301/398]	Time 0.623	Data 0.000	Loss 3.1817	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 2.6025	
Epoch(adapt):{0} Loss 2.0611	
Epoch(adapt):{0} Loss 1.8908	
Epoch(adapt):{0} Loss 2.1567	
------------------the total time cost:1214.5067694187164
>>>>>meta updating
Epoch: 0019 | TRAIN: 1.3029 0.2215 0.5525 | 0.6184 0.6184 0.2846 | 0.2019 31.9246 28.2674 0.1717 0.4001 0.5344 ||TEST: 1.3520 0.2140 0.5411 | 0.6928 0.6928 0.2640 | 0.1939 31.2235 27.9471 0.1842 0.4089 0.5397 | 114.8666
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.37513342 1.37511246 1.37511129 1.37512543 1.3750779  1.37506226
 1.37505746 1.37504017 1.37504612 1.37503833 1.37500303 1.37497408
 1.37496915 1.37499076 1.37496936 1.37494298 1.37493871 1.3748993
 1.37483619 1.37488269]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.37501583 1.37500824 1.37500589 1.37503443 1.37502735 1.37502568
 1.37503895 1.37504988 1.37505953 1.37503048 1.37502561 1.37502546
 1.37501079 1.37502912 1.3750312  1.37506766 1.37506536 1.37507007
 1.37506422 1.37507359]
[0.         0.44736842 0.        ]
-----------end of analyzing the loss ratio:73.72397994995117
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938d3ffd0>
---------------------------------
SparseEpoch: [20][1/398]	Time 0.607	Data 0.000	Loss 2.4571	
SparseEpoch: [20][101/398]	Time 0.616	Data 0.000	Loss 1.6270	
SparseEpoch: [20][201/398]	Time 0.621	Data 0.000	Loss 1.4778	
SparseEpoch: [20][301/398]	Time 0.623	Data 0.000	Loss 1.6726	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.79267651 0.79266831 0.79266948 0.79265517 0.79263805 0.79257548
 0.79252999 0.79250728 0.7924773  0.7924844  0.79248832 0.79246742
 0.79242875 0.7924081  0.79237033 0.79231004 0.79229442 0.79221767
 0.79222781 0.79221212]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.79245138 0.79249203 0.79249199 0.79249236 0.79248877 0.79250253
 0.79251479 0.79249116 0.79249668 0.7924926  0.79249469 0.79251655
 0.79250802 0.7925079  0.79251038 0.79251614 0.79249299 0.79247449
 0.79247079 0.79249774]
[0.5 0.  0. ]
-----------end of analyzing the loss ratio:73.79196834564209
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9387c6d70>
---------------------------------
SparseEpoch: [20][1/398]	Time 0.609	Data 0.000	Loss 1.5489	
SparseEpoch: [20][101/398]	Time 0.624	Data 0.000	Loss 1.4427	
SparseEpoch: [20][201/398]	Time 0.623	Data 0.000	Loss 1.3533	
SparseEpoch: [20][301/398]	Time 0.623	Data 0.000	Loss 1.0509	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.18820796 0.18817729 0.18815334 0.18810034 0.18807541 0.18803108
 0.18802946 0.18801731 0.18794543 0.18790367 0.18784086 0.1877759
 0.18775723 0.1877341  0.18773242 0.1877102  0.18764673 0.18761093
 0.18757653 0.18757915]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.18799769 0.18799107 0.18797885 0.1879543  0.18796137 0.18793334
 0.18792682 0.18791248 0.18791034 0.18788885 0.1878497  0.18783467
 0.18783812 0.18781075 0.1878031  0.18779308 0.18779309 0.18775831
 0.18774999 0.18775598]
[0.44736842 0.44736842 0.        ]
-----------end of analyzing the loss ratio:73.81148624420166
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938a18e50>
---------------------------------
SparseEpoch: [20][1/398]	Time 0.616	Data 0.000	Loss 3.9038	
SparseEpoch: [20][101/398]	Time 0.621	Data 0.000	Loss 3.9627	
SparseEpoch: [20][201/398]	Time 0.624	Data 0.000	Loss 3.3759	
SparseEpoch: [20][301/398]	Time 0.625	Data 0.000	Loss 2.2167	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 2.5146	
Epoch(adapt):{0} Loss 2.0799	
Epoch(adapt):{0} Loss 2.7441	
Epoch(adapt):{0} Loss 3.0547	
------------------the total time cost:1213.6369178295135
>>>>>meta updating
Epoch: 0020 | TRAIN: 1.2921 0.2251 0.5579 | 0.5993 0.5993 0.2834 | 0.2059 32.3401 28.9303 0.1686 0.3875 0.5223 ||TEST: 1.3396 0.2168 0.5453 | 0.6600 0.6600 0.2575 | 0.1980 31.7154 28.7135 0.1760 0.3946 0.5263 | 115.3953
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.21140047 1.21135445 1.21131419 1.21133409 1.21130573 1.21125749
 1.21126574 1.21121399 1.21124956 1.21115364 1.21104473 1.21096534
 1.21094989 1.21093222 1.21093447 1.21084257 1.21085317 1.21080976
 1.21073481 1.21068096]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.21111164 1.2111191  1.21108927 1.21108479 1.21106452 1.21106775
 1.21105934 1.21107571 1.21108618 1.21109456 1.21109864 1.21111539
 1.21112153 1.21113696 1.21111135 1.21112816 1.21113039 1.21115259
 1.21113903 1.21113799]
[0.  0.5 0. ]
-----------end of analyzing the loss ratio:73.81658458709717
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc93995f040>
---------------------------------
SparseEpoch: [21][1/398]	Time 0.605	Data 0.000	Loss 1.4724	
SparseEpoch: [21][101/398]	Time 0.623	Data 0.000	Loss 1.3269	
SparseEpoch: [21][201/398]	Time 0.620	Data 0.000	Loss 1.6279	
SparseEpoch: [21][301/398]	Time 0.621	Data 0.000	Loss 1.7625	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.70833463 0.70811036 0.70806852 0.70793344 0.70782112 0.70760069
 0.70756851 0.70744862 0.70730904 0.70706262 0.7069471  0.70680521
 0.70655386 0.70638744 0.7061862  0.70592597 0.70575615 0.70576395
 0.70564224 0.70550191]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.70721549 0.70721189 0.70715209 0.70711121 0.70708521 0.70705945
 0.70705327 0.70702787 0.70701143 0.70704316 0.70702186 0.70698315
 0.70699981 0.70696353 0.7069151  0.7069407  0.70694132 0.70694928
 0.70693308 0.70692528]
[0.5        0.         0.23684211]
-----------end of analyzing the loss ratio:73.8043143749237
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc93875c160>
---------------------------------
SparseEpoch: [21][1/398]	Time 0.605	Data 0.000	Loss 1.7481	
SparseEpoch: [21][101/398]	Time 0.627	Data 0.000	Loss 1.8869	
SparseEpoch: [21][201/398]	Time 0.627	Data 0.000	Loss 1.4518	
SparseEpoch: [21][301/398]	Time 0.627	Data 0.000	Loss 2.3027	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.22429874 0.22429929 0.22429768 0.22429032 0.22427576 0.22426903
 0.22426257 0.22425324 0.22425393 0.2242454  0.22424635 0.22423797
 0.22422795 0.2242161  0.22421026 0.22419952 0.22419899 0.22420485
 0.22418795 0.22419744]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.22428353 0.22428413 0.22428807 0.22427689 0.22426814 0.22426291
 0.22426023 0.22425933 0.22425956 0.22424538 0.22425205 0.22423809
 0.22422467 0.2242194  0.2242249  0.22422802 0.22422892 0.22422172
 0.22421565 0.22421681]
[0.44736842 0.44736842 0.        ]
-----------end of analyzing the loss ratio:73.83266520500183
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cca5e210c40>
---------------------------------
SparseEpoch: [21][1/398]	Time 0.608	Data 0.000	Loss 3.6293	
SparseEpoch: [21][101/398]	Time 0.625	Data 0.000	Loss 2.7735	
SparseEpoch: [21][201/398]	Time 0.624	Data 0.000	Loss 2.8400	
SparseEpoch: [21][301/398]	Time 0.625	Data 0.000	Loss 3.2597	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 2.4471	
Epoch(adapt):{0} Loss 1.7582	
Epoch(adapt):{0} Loss 2.1725	
Epoch(adapt):{0} Loss 2.2874	
------------------the total time cost:1213.751219034195
>>>>>meta updating
Epoch: 0021 | TRAIN: 1.2803 0.2406 0.5625 | 0.5981 0.5981 0.2656 | 0.2057 32.2485 28.7278 0.1714 0.3944 0.5269 ||TEST: 1.3229 0.2288 0.5502 | 0.6704 0.6704 0.2518 | 0.1943 31.2244 27.9362 0.1867 0.4089 0.5390 | 114.9216
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.16744604 1.16744161 1.16746447 1.1674473  1.16743708 1.16735775
 1.1673736  1.1673996  1.16744844 1.16744314 1.16748353 1.16747415
 1.16745756 1.16740283 1.16739392 1.16738919 1.1674861  1.16743057
 1.16736817 1.16736209]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.16744702 1.16744921 1.16745483 1.16743036 1.16741098 1.16741267
 1.16741905 1.16742188 1.16742994 1.16745521 1.16745232 1.16745271
 1.16747203 1.16746214 1.16747048 1.16747466 1.16748084 1.16748506
 1.16748502 1.16751133]
[0. 0. 0.]
-----------end of analyzing the loss ratio:73.9674346446991
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9386a4970>
---------------------------------
SparseEpoch: [22][1/398]	Time 0.606	Data 0.000	Loss 1.7510	
SparseEpoch: [22][101/398]	Time 0.623	Data 0.000	Loss 1.1401	
SparseEpoch: [22][201/398]	Time 0.623	Data 0.000	Loss 1.6098	
SparseEpoch: [22][301/398]	Time 0.625	Data 0.000	Loss 2.1136	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.94333724 0.94332024 0.94333992 0.94325517 0.94331837 0.94335177
 0.94335405 0.94338153 0.94336783 0.94337983 0.9434048  0.94341042
 0.94344089 0.94342256 0.94342032 0.94341165 0.94344731 0.94345833
 0.94345638 0.94344789]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.94336872 0.94337156 0.94336638 0.9433617  0.94335991 0.94336037
 0.94334043 0.94334776 0.94335623 0.94334859 0.94336005 0.94337221
 0.9433858  0.94337552 0.94338918 0.943408   0.94339332 0.94341717
 0.94342791 0.94344474]
[0. 0. 0.]
-----------end of analyzing the loss ratio:73.91624093055725
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9398aa9e0>
---------------------------------
SparseEpoch: [22][1/398]	Time 0.624	Data 0.000	Loss 0.5468	
SparseEpoch: [22][101/398]	Time 0.614	Data 0.000	Loss 0.6333	
SparseEpoch: [22][201/398]	Time 0.616	Data 0.000	Loss 0.5466	
SparseEpoch: [22][301/398]	Time 0.616	Data 0.000	Loss 0.6209	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.23070181 0.23062539 0.23052991 0.23047709 0.23041505 0.2303672
 0.23030942 0.23022513 0.23018254 0.23014482 0.23012435 0.23009928
 0.23006577 0.23001117 0.22994378 0.22993534 0.22989873 0.22991715
 0.22991679 0.22986363]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.23021955 0.23021218 0.23018963 0.23017961 0.23015422 0.23014003
 0.23012999 0.2301359  0.23013781 0.23013345 0.23012211 0.23013144
 0.23012061 0.23011906 0.230108   0.23009858 0.23010539 0.23009366
 0.23006756 0.23004872]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:73.82600831985474
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cca5e2f34c0>
---------------------------------
SparseEpoch: [22][1/398]	Time 0.606	Data 0.000	Loss 2.5014	
SparseEpoch: [22][101/398]	Time 0.621	Data 0.000	Loss 3.5920	
SparseEpoch: [22][201/398]	Time 0.625	Data 0.000	Loss 2.8590	
SparseEpoch: [22][301/398]	Time 0.623	Data 0.000	Loss 2.6565	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 2.3952	
Epoch(adapt):{0} Loss 2.3265	
Epoch(adapt):{0} Loss 2.1428	
Epoch(adapt):{0} Loss 2.0966	
------------------the total time cost:1212.7765798568726
>>>>>meta updating
Epoch: 0022 | TRAIN: 1.2710 0.2464 0.5687 | 0.5733 0.5733 0.2791 | 0.2036 32.0229 28.5497 0.1768 0.3979 0.5299 ||TEST: 1.3225 0.2342 0.5536 | 0.6431 0.6431 0.2557 | 0.1957 31.3403 28.0754 0.1868 0.4081 0.5368 | 115.3961
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.49285773 1.49283407 1.49275875 1.49270346 1.49267578 1.49270499
 1.4927238  1.49267809 1.49268852 1.49264989 1.49262716 1.49258306
 1.49251083 1.49251096 1.49248896 1.49243984 1.49231395 1.49228421
 1.49217306 1.49213663]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.49263858 1.49264392 1.49263927 1.49264566 1.49263921 1.49263799
 1.49264309 1.4926484  1.49265502 1.49265444 1.49263722 1.49263229
 1.49261969 1.49262078 1.49261612 1.49260926 1.49260982 1.49263117
 1.49261264 1.49260669]
[0.  0.5 0.5]
-----------end of analyzing the loss ratio:73.83629536628723
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938c042e0>
---------------------------------
SparseEpoch: [23][1/398]	Time 0.605	Data 0.000	Loss 2.8405	
SparseEpoch: [23][101/398]	Time 0.624	Data 0.000	Loss 2.8084	
SparseEpoch: [23][201/398]	Time 0.621	Data 0.000	Loss 2.5332	
SparseEpoch: [23][301/398]	Time 0.623	Data 0.000	Loss 2.3386	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.72907348 0.72904099 0.72904788 0.72901064 0.72888465 0.72884898
 0.72870159 0.72863547 0.72854742 0.72841824 0.72835733 0.7282667
 0.72819378 0.72813348 0.72812197 0.72815225 0.7280774  0.72798045
 0.72794101 0.72788834]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.72850988 0.72850951 0.72849085 0.72846221 0.72844815 0.72840816
 0.72841048 0.72841763 0.72838619 0.72839344 0.72839509 0.72836957
 0.72835603 0.72837754 0.72839145 0.72838086 0.72837389 0.72832415
 0.72827698 0.72827684]
[0.5 0.  0.5]
-----------end of analyzing the loss ratio:73.73209357261658
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9385e6b00>
---------------------------------
SparseEpoch: [23][1/398]	Time 0.605	Data 0.000	Loss 2.4677	
SparseEpoch: [23][101/398]	Time 0.621	Data 0.000	Loss 1.9292	
SparseEpoch: [23][201/398]	Time 0.622	Data 0.000	Loss 2.0782	
SparseEpoch: [23][301/398]	Time 0.623	Data 0.000	Loss 2.5330	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.23417105 0.23414221 0.23413922 0.23411472 0.23409212 0.23408632
 0.23407601 0.23405501 0.23403349 0.23401738 0.2340009  0.23397833
 0.23396457 0.23394953 0.23393484 0.23392036 0.23392435 0.23390418
 0.23388374 0.23384786]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.23408262 0.23407504 0.23406483 0.23405553 0.23405041 0.2340501
 0.23403365 0.23401837 0.23402132 0.23401015 0.23401202 0.23399754
 0.23400251 0.23399631 0.23398113 0.23398555 0.23397459 0.2339831
 0.23396459 0.23396212]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:73.92519354820251
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cca5e212620>
---------------------------------
SparseEpoch: [23][1/398]	Time 0.607	Data 0.000	Loss 2.6273	
SparseEpoch: [23][101/398]	Time 0.626	Data 0.000	Loss 3.6275	
SparseEpoch: [23][201/398]	Time 0.622	Data 0.000	Loss 2.5259	
SparseEpoch: [23][301/398]	Time 0.625	Data 0.000	Loss 3.1839	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 2.3046	
Epoch(adapt):{0} Loss 1.6901	
Epoch(adapt):{0} Loss 2.1548	
Epoch(adapt):{0} Loss 1.8107	
------------------the total time cost:1215.7056353092194
>>>>>meta updating
Epoch: 0023 | TRAIN: 1.2599 0.2545 0.5712 | 0.5802 0.5802 0.2915 | 0.1959 31.2012 27.3232 0.1854 0.4171 0.5514 ||TEST: 1.3093 0.2413 0.5578 | 0.6429 0.6429 0.2679 | 0.1874 30.5575 27.0999 0.1917 0.4229 0.5544 | 115.0834
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.02455381 1.02458755 1.02443793 1.02447136 1.02443018 1.02428234
 1.02435852 1.02438617 1.02443905 1.02435895 1.02431196 1.02437723
 1.02424101 1.02421661 1.02421182 1.0242798  1.02435785 1.02448156
 1.02441795 1.02441772]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.02439412 1.02435437 1.02435992 1.02436109 1.02435336 1.02433279
 1.02430931 1.02429001 1.02430376 1.02426733 1.02427281 1.02427002
 1.02428908 1.02430179 1.02431939 1.02431852 1.02429914 1.02429628
 1.02428067 1.02428908]
[0.         0.23684211 0.        ]
-----------end of analyzing the loss ratio:74.15139746665955
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cca5e213d00>
---------------------------------
SparseEpoch: [24][1/398]	Time 0.608	Data 0.000	Loss 1.7949	
SparseEpoch: [24][101/398]	Time 0.625	Data 0.000	Loss 1.1094	
SparseEpoch: [24][201/398]	Time 0.625	Data 0.000	Loss 1.3749	
SparseEpoch: [24][301/398]	Time 0.626	Data 0.000	Loss 1.4911	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.86393292 0.86415903 0.8645292  0.86485937 0.86511707 0.86556458
 0.8658077  0.86599057 0.86619617 0.86634799 0.86660856 0.86685624
 0.86716425 0.86746337 0.86762698 0.86775375 0.86802434 0.86829681
 0.86853405 0.86875888]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.86643341 0.8664407  0.86646343 0.86646252 0.8664413  0.86644726
 0.86646307 0.86647696 0.86647446 0.86648653 0.86650121 0.86649993
 0.86649101 0.86649159 0.86650583 0.8665168  0.86651472 0.86650743
 0.86651164 0.86651499]
[0. 0. 0.]
-----------end of analyzing the loss ratio:73.8310272693634
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cca5e213a30>
---------------------------------
SparseEpoch: [24][1/398]	Time 0.604	Data 0.000	Loss 0.2968	
SparseEpoch: [24][101/398]	Time 0.624	Data 0.000	Loss 0.6958	
SparseEpoch: [24][201/398]	Time 0.623	Data 0.000	Loss 0.6245	
SparseEpoch: [24][301/398]	Time 0.623	Data 0.000	Loss 0.5223	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.20897623 0.20896332 0.20891666 0.20891934 0.20893199 0.20889821
 0.20890137 0.20886735 0.20888797 0.20888405 0.20888025 0.20889133
 0.20890197 0.20895539 0.20894906 0.20896942 0.20899245 0.20900406
 0.20900354 0.20900801]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.20884991 0.20886638 0.20886167 0.20889413 0.20888597 0.20886863
 0.20886163 0.2088735  0.20888075 0.20889497 0.2089088  0.20889048
 0.20888703 0.2088791  0.20889109 0.20890413 0.20892493 0.20892224
 0.20890954 0.20891479]
[0. 0. 0.]
-----------end of analyzing the loss ratio:73.81881546974182
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938a7ba00>
---------------------------------
SparseEpoch: [24][1/398]	Time 0.604	Data 0.000	Loss 1.7456	
SparseEpoch: [24][101/398]	Time 0.620	Data 0.000	Loss 1.8563	
SparseEpoch: [24][201/398]	Time 0.621	Data 0.000	Loss 2.1818	
SparseEpoch: [24][301/398]	Time 0.621	Data 0.000	Loss 3.2810	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.8456	
Epoch(adapt):{0} Loss 1.4505	
Epoch(adapt):{0} Loss 2.1119	
Epoch(adapt):{0} Loss 2.0797	
------------------the total time cost:1214.2800810337067
>>>>>meta updating
Epoch: 0024 | TRAIN: 1.2539 0.2677 0.5799 | 0.5707 0.5707 0.2785 | 0.2000 31.8411 28.3544 0.1691 0.3968 0.5337 ||TEST: 1.3130 0.2495 0.5597 | 0.6362 0.6362 0.2581 | 0.1940 31.4012 28.3632 0.1745 0.3989 0.5328 | 114.9389
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.33661839 1.33665538 1.3366242  1.336617   1.33660676 1.33661718
 1.33657579 1.33658931 1.33660872 1.33652398 1.33646631 1.33646098
 1.33648045 1.33645565 1.33644441 1.33637025 1.33632613 1.33637512
 1.33633647 1.33635415]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.33657282 1.33656455 1.33654774 1.33653826 1.33653765 1.33653322
 1.33652769 1.33650949 1.33652046 1.33649865 1.33647288 1.33646609
 1.33647193 1.33646352 1.33645354 1.3364495  1.33641821 1.3364154
 1.33639307 1.33638932]
[0.         0.34210526 0.5       ]
-----------end of analyzing the loss ratio:73.91971135139465
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9398aa4d0>
---------------------------------
SparseEpoch: [25][1/398]	Time 0.606	Data 0.000	Loss 2.3591	
SparseEpoch: [25][101/398]	Time 0.626	Data 0.000	Loss 2.4736	
SparseEpoch: [25][201/398]	Time 0.626	Data 0.000	Loss 2.8026	
SparseEpoch: [25][301/398]	Time 0.626	Data 0.000	Loss 2.8816	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.82153727 0.82155949 0.82149526 0.82147114 0.82147093 0.82143512
 0.82142213 0.82141256 0.82143142 0.82142767 0.82139743 0.8214082
 0.82137587 0.82136996 0.82132752 0.82135001 0.82133217 0.82129193
 0.82129962 0.82127669]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.82136342 0.82134795 0.82135765 0.8213768  0.82137254 0.82134919
 0.82135496 0.82137912 0.82142852 0.82141155 0.82140516 0.82140475
 0.82141504 0.82143386 0.82143035 0.82143422 0.82143172 0.82142298
 0.82141989 0.82140212]
[0.5 0.  0. ]
-----------end of analyzing the loss ratio:73.97117161750793
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc939946c50>
---------------------------------
SparseEpoch: [25][1/398]	Time 0.610	Data 0.000	Loss 1.5335	
SparseEpoch: [25][101/398]	Time 0.625	Data 0.000	Loss 1.0381	
SparseEpoch: [25][201/398]	Time 0.625	Data 0.000	Loss 1.1370	
SparseEpoch: [25][301/398]	Time 0.625	Data 0.000	Loss 1.1237	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.2416783  0.24164627 0.24163867 0.24163229 0.24157668 0.24151938
 0.24149011 0.24148846 0.24143339 0.24141774 0.24138046 0.24135492
 0.24134155 0.24131866 0.24131355 0.24128901 0.2412481  0.24121447
 0.24116417 0.24113547]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.24133855 0.24135532 0.241368   0.2413837  0.24138084 0.24138633
 0.24137068 0.24137874 0.24138744 0.24138188 0.24138352 0.24142348
 0.24142942 0.24143071 0.24142185 0.2414229  0.24141694 0.24140055
 0.24139645 0.24139645]
[0.5 0.  0. ]
-----------end of analyzing the loss ratio:73.72839140892029
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9386a7f70>
---------------------------------
SparseEpoch: [25][1/398]	Time 0.605	Data 0.000	Loss 2.1508	
SparseEpoch: [25][101/398]	Time 0.625	Data 0.000	Loss 3.3486	
SparseEpoch: [25][201/398]	Time 0.627	Data 0.000	Loss 2.7649	
SparseEpoch: [25][301/398]	Time 0.625	Data 0.000	Loss 3.3807	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.8396	
Epoch(adapt):{0} Loss 1.9238	
Epoch(adapt):{0} Loss 1.7312	
Epoch(adapt):{0} Loss 2.5038	
------------------the total time cost:1214.9975445270538
>>>>>meta updating
Epoch: 0025 | TRAIN: 1.2360 0.2719 0.5784 | 0.5650 0.5650 0.2764 | 0.2005 31.7758 28.1762 0.1751 0.4020 0.5363 ||TEST: 1.3001 0.2559 0.5592 | 0.6315 0.6315 0.2492 | 0.1929 31.1743 28.0022 0.1835 0.4071 0.5391 | 115.1467
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.23906827 1.23906664 1.23906922 1.23911619 1.23916976 1.23916758
 1.23920232 1.23909718 1.23913957 1.23912892 1.23916036 1.23914639
 1.2391687  1.23915858 1.23915961 1.23922724 1.2392557  1.239227
 1.23930047 1.23934327]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.23917221 1.23918025 1.23916563 1.23915032 1.23914434 1.23916448
 1.23916001 1.23915591 1.23914955 1.23912627 1.23915409 1.23914789
 1.23915937 1.23918148 1.23918523 1.23916487 1.23914319 1.23915254
 1.23914564 1.23914305]
[0. 0. 0.]
-----------end of analyzing the loss ratio:73.90604782104492
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc93901f130>
---------------------------------
SparseEpoch: [26][1/398]	Time 0.604	Data 0.000	Loss 1.1871	
SparseEpoch: [26][101/398]	Time 0.626	Data 0.000	Loss 1.1470	
SparseEpoch: [26][201/398]	Time 0.625	Data 0.000	Loss 1.0863	
SparseEpoch: [26][301/398]	Time 0.625	Data 0.000	Loss 1.1116	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.84862289 0.84869679 0.8487839  0.8488781  0.84895039 0.84906503
 0.84919116 0.84928079 0.84938169 0.84944991 0.84955412 0.84969493
 0.8497881  0.84999796 0.85010956 0.85018617 0.85028576 0.85043912
 0.85055776 0.850675  ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.84948301 0.8494931  0.84950241 0.84951029 0.84949559 0.84949641
 0.84950947 0.84952179 0.8495122  0.84951209 0.84951221 0.84951429
 0.84952036 0.84951981 0.84952093 0.84951624 0.84951468 0.84952059
 0.84951511 0.84950858]
[0. 0. 0.]
-----------end of analyzing the loss ratio:74.34859585762024
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9386a5ed0>
---------------------------------
SparseEpoch: [26][1/398]	Time 0.607	Data 0.000	Loss 0.6250	
SparseEpoch: [26][101/398]	Time 0.625	Data 0.000	Loss 0.4333	
SparseEpoch: [26][201/398]	Time 0.626	Data 0.000	Loss 0.4617	
SparseEpoch: [26][301/398]	Time 0.622	Data 0.000	Loss 0.7178	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.2053982  0.20536842 0.20534384 0.2053277  0.20530967 0.20527388
 0.20524373 0.20518472 0.20517411 0.20513968 0.2051379  0.20510216
 0.20508358 0.20506321 0.20502657 0.20500405 0.20498133 0.20495409
 0.20490203 0.2048942 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.20518727 0.20518531 0.20517914 0.20517083 0.20517469 0.20516721
 0.20515687 0.20513204 0.20512646 0.2051183  0.20512704 0.20513388
 0.20513374 0.20513871 0.20513844 0.20513862 0.20514352 0.20513996
 0.20511922 0.20511789]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:73.8335428237915
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9398f8220>
---------------------------------
SparseEpoch: [26][1/398]	Time 0.604	Data 0.000	Loss 3.5050	
SparseEpoch: [26][101/398]	Time 0.623	Data 0.000	Loss 2.5292	
SparseEpoch: [26][201/398]	Time 0.623	Data 0.000	Loss 3.9211	
SparseEpoch: [26][301/398]	Time 0.624	Data 0.000	Loss 3.1394	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 2.3187	
Epoch(adapt):{0} Loss 2.2356	
Epoch(adapt):{0} Loss 1.7176	
Epoch(adapt):{0} Loss 1.9891	
------------------the total time cost:1213.506202697754
>>>>>meta updating
Epoch: 0026 | TRAIN: 1.2187 0.2806 0.5925 | 0.5569 0.5569 0.2710 | 0.1975 31.3962 27.5945 0.1826 0.4124 0.5466 ||TEST: 1.2787 0.2595 0.5732 | 0.6299 0.6299 0.2552 | 0.1908 30.8771 27.3835 0.1883 0.4172 0.5488 | 115.1961
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.1374204  1.13731952 1.13730454 1.13728212 1.13718727 1.13712361
 1.13719243 1.13709773 1.13709435 1.13709171 1.13690374 1.1369328
 1.13700663 1.13708037 1.13705866 1.13705553 1.13723514 1.13723924
 1.13722797 1.13723043]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.13693993 1.13694168 1.13694433 1.13697287 1.13699387 1.13701112
 1.13702978 1.13702641 1.13700976 1.13702588 1.13701078 1.13700868
 1.13700963 1.13698698 1.13697781 1.13700677 1.13699285 1.13699057
 1.13698184 1.13698549]
[0.         0.02631579 0.        ]
-----------end of analyzing the loss ratio:73.91539144515991
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc939e6ffa0>
---------------------------------
SparseEpoch: [27][1/398]	Time 0.607	Data 0.000	Loss 1.4237	
SparseEpoch: [27][101/398]	Time 0.621	Data 0.000	Loss 1.6974	
SparseEpoch: [27][201/398]	Time 0.624	Data 0.000	Loss 0.9341	
SparseEpoch: [27][301/398]	Time 0.624	Data 0.000	Loss 1.0207	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.22840049 1.22842271 1.22846156 1.22849536 1.22850656 1.2285735
 1.22855675 1.22860588 1.22859676 1.22875239 1.22877008 1.22880068
 1.22887564 1.22890807 1.22894576 1.22901542 1.22900527 1.22902977
 1.22903458 1.22906673]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.2287256  1.22872818 1.22872536 1.22873663 1.22875295 1.22872631
 1.22872849 1.22872753 1.22874875 1.22875743 1.22876469 1.22876812
 1.22878518 1.22878574 1.22878804 1.22878101 1.22879347 1.22880422
 1.22880554 1.22881119]
[0. 0. 0.]
-----------end of analyzing the loss ratio:73.77164673805237
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938f154b0>
---------------------------------
SparseEpoch: [27][1/398]	Time 0.607	Data 0.000	Loss 0.6919	
SparseEpoch: [27][101/398]	Time 0.620	Data 0.000	Loss 0.4877	
SparseEpoch: [27][201/398]	Time 0.619	Data 0.000	Loss 0.5901	
SparseEpoch: [27][301/398]	Time 0.619	Data 0.000	Loss 0.3928	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.21599398 0.21595125 0.21590543 0.21590716 0.2158889  0.2158941
 0.21588498 0.21586932 0.21583806 0.21582291 0.21580188 0.21575922
 0.21572447 0.21573371 0.2157057  0.21565363 0.21568182 0.21565019
 0.21566741 0.21562332]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.21583821 0.21582543 0.21582074 0.21581223 0.21579918 0.21580541
 0.21580849 0.21582127 0.21580826 0.215828   0.21582611 0.2158105
 0.21579615 0.21579965 0.21579659 0.21577944 0.2157756  0.21576425
 0.21576902 0.21577058]
[0.5        0.39473684 0.        ]
-----------end of analyzing the loss ratio:74.1388750076294
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938d655d0>
---------------------------------
SparseEpoch: [27][1/398]	Time 0.613	Data 0.000	Loss 2.2530	
SparseEpoch: [27][101/398]	Time 0.620	Data 0.000	Loss 2.5697	
SparseEpoch: [27][201/398]	Time 0.621	Data 0.000	Loss 2.7131	
SparseEpoch: [27][301/398]	Time 0.622	Data 0.000	Loss 4.6630	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 2.0125	
Epoch(adapt):{0} Loss 1.7258	
Epoch(adapt):{0} Loss 1.6323	
Epoch(adapt):{0} Loss 2.2261	
------------------the total time cost:1213.272671699524
>>>>>meta updating
Epoch: 0027 | TRAIN: 1.2135 0.2784 0.5915 | 0.5616 0.5616 0.2696 | 0.2000 31.7377 28.0981 0.1747 0.4023 0.5367 ||TEST: 1.2879 0.2578 0.5679 | 0.6340 0.6340 0.2534 | 0.1937 31.2094 27.9100 0.1843 0.4082 0.5400 | 115.4240
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.2208871  1.22083145 1.22085055 1.22091458 1.22090783 1.22096935
 1.22101783 1.22099159 1.22096474 1.2209381  1.22094212 1.22090161
 1.22087586 1.22086291 1.22087441 1.22087787 1.22085224 1.22083285
 1.22084442 1.22082393]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.22082532 1.22084211 1.22083159 1.22084591 1.22087178 1.22090663
 1.22090093 1.22088743 1.22088497 1.22090832 1.22092295 1.22094402
 1.22094287 1.22095097 1.22095422 1.22096582 1.22095532 1.22099374
 1.22100976 1.22100211]
[0.  0.5 0. ]
-----------end of analyzing the loss ratio:74.14051127433777
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9398d35e0>
---------------------------------
SparseEpoch: [28][1/398]	Time 0.649	Data 0.000	Loss 1.4982	
SparseEpoch: [28][101/398]	Time 0.626	Data 0.000	Loss 1.0911	
SparseEpoch: [28][201/398]	Time 0.624	Data 0.000	Loss 1.8721	
SparseEpoch: [28][301/398]	Time 0.624	Data 0.000	Loss 1.4055	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.00149599 1.00146213 1.0014131  1.00141505 1.00132884 1.00122348
 1.00122954 1.00120197 1.00115654 1.00108603 1.00109209 1.00108263
 1.00101228 1.0010022  1.0009762  1.00090807 1.00082283 1.00080348
 1.00075648 1.00077564]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.00105028 1.00105588 1.00105573 1.00106404 1.00107232 1.00106691
 1.00106224 1.00108638 1.00108967 1.00109494 1.00110892 1.00110255
 1.00110304 1.00109163 1.00110722 1.00112255 1.00113082 1.0011413
 1.00116228 1.00114815]
[0.44736842 0.         0.        ]
-----------end of analyzing the loss ratio:74.07294917106628
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc93995d060>
---------------------------------
SparseEpoch: [28][1/398]	Time 0.605	Data 0.000	Loss 1.2194	
SparseEpoch: [28][101/398]	Time 0.621	Data 0.000	Loss 1.0039	
SparseEpoch: [28][201/398]	Time 0.621	Data 0.000	Loss 1.6577	
SparseEpoch: [28][301/398]	Time 0.622	Data 0.000	Loss 0.7730	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.23369145 0.23363034 0.23363001 0.23355868 0.23349656 0.23347278
 0.23341658 0.23335506 0.23335702 0.23329681 0.23322392 0.23319827
 0.23322839 0.23326836 0.23325921 0.23323656 0.23316746 0.23312241
 0.23311144 0.23308384]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.2335027  0.23349569 0.23346997 0.23344007 0.23341468 0.23334377
 0.23333045 0.23330478 0.23327945 0.23326534 0.23324776 0.23325914
 0.23324064 0.23318917 0.23316428 0.23314714 0.23314565 0.23315119
 0.23313194 0.23311822]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:73.76255655288696
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc939e98370>
---------------------------------
SparseEpoch: [28][1/398]	Time 0.605	Data 0.000	Loss 4.6640	
SparseEpoch: [28][101/398]	Time 0.624	Data 0.000	Loss 2.7497	
SparseEpoch: [28][201/398]	Time 0.625	Data 0.000	Loss 3.3578	
SparseEpoch: [28][301/398]	Time 0.623	Data 0.000	Loss 2.9663	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.4878	
Epoch(adapt):{0} Loss 1.8500	
Epoch(adapt):{0} Loss 1.7554	
Epoch(adapt):{0} Loss 3.1715	
------------------the total time cost:1212.5486333370209
>>>>>meta updating
Epoch: 0028 | TRAIN: 1.1875 0.2860 0.6001 | 0.5454 0.5454 0.2526 | 0.1985 31.5934 28.0954 0.1784 0.4033 0.5372 ||TEST: 1.2682 0.2646 0.5753 | 0.6359 0.6359 0.2498 | 0.1928 31.1742 28.0459 0.1835 0.4058 0.5378 | 115.1431
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.07985431 1.07981676 1.07979457 1.07979149 1.07987731 1.07988837
 1.07991651 1.07995297 1.07996259 1.07995257 1.07990493 1.07991994
 1.0799768  1.08004484 1.08009104 1.08013181 1.08015931 1.080195
 1.08021159 1.08025014]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.07988568 1.07989517 1.07989182 1.0798976  1.07988696 1.0798895
 1.07989186 1.07992251 1.07992814 1.07992665 1.07994496 1.0799544
 1.07995791 1.07994185 1.07996061 1.0799614  1.07994985 1.07994437
 1.07993576 1.07992679]
[0. 0. 0.]
-----------end of analyzing the loss ratio:73.92340755462646
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cca5decbd90>
---------------------------------
SparseEpoch: [29][1/398]	Time 0.604	Data 0.000	Loss 1.1978	
SparseEpoch: [29][101/398]	Time 0.622	Data 0.000	Loss 1.4102	
SparseEpoch: [29][201/398]	Time 0.623	Data 0.000	Loss 1.6452	
SparseEpoch: [29][301/398]	Time 0.624	Data 0.000	Loss 1.7758	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.73295892 0.73293775 0.73289455 0.73291405 0.7328999  0.73290395
 0.73283237 0.73276616 0.73273783 0.73267168 0.73259672 0.7325726
 0.73255191 0.73253263 0.73254107 0.73247197 0.73241574 0.73242155
 0.73241389 0.73234645]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.73266255 0.73265302 0.73264305 0.73264881 0.73264273 0.73263699
 0.73262837 0.7326217  0.73262732 0.73262051 0.73262338 0.73262996
 0.73262837 0.73265221 0.73263734 0.73264416 0.73264142 0.73264658
 0.73263926 0.73264386]
[0.5 0.  0. ]
-----------end of analyzing the loss ratio:74.0763635635376
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cca5e403640>
---------------------------------
SparseEpoch: [29][1/398]	Time 0.607	Data 0.000	Loss 1.3609	
SparseEpoch: [29][101/398]	Time 0.622	Data 0.000	Loss 1.2681	
SparseEpoch: [29][201/398]	Time 0.623	Data 0.000	Loss 1.1036	
SparseEpoch: [29][301/398]	Time 0.624	Data 0.000	Loss 1.0917	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.20394464 0.20395145 0.20395423 0.20394522 0.20394716 0.20393506
 0.20393459 0.20391349 0.20389881 0.20388892 0.20389209 0.20391108
 0.20389487 0.20387872 0.20390694 0.20390546 0.20389536 0.20391924
 0.20389501 0.20387196]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.20392679 0.20392879 0.20391958 0.20392665 0.20391381 0.20389758
 0.20390846 0.20390888 0.20390782 0.20389883 0.20388218 0.2038806
 0.20393229 0.20393677 0.20393084 0.20393568 0.20392789 0.20391858
 0.20393326 0.20393217]
[0.5        0.07894737 0.        ]
-----------end of analyzing the loss ratio:74.11896634101868
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cca5e464880>
---------------------------------
SparseEpoch: [29][1/398]	Time 0.609	Data 0.000	Loss 2.0027	
SparseEpoch: [29][101/398]	Time 0.621	Data 0.000	Loss 2.6454	
SparseEpoch: [29][201/398]	Time 0.623	Data 0.000	Loss 2.9134	
SparseEpoch: [29][301/398]	Time 0.623	Data 0.000	Loss 3.6666	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.7901	
Epoch(adapt):{0} Loss 2.0230	
Epoch(adapt):{0} Loss 1.7005	
Epoch(adapt):{0} Loss 2.1086	
------------------the total time cost:1214.7936325073242
>>>>>meta updating
Epoch: 0029 | TRAIN: 1.1568 0.3029 0.6086 | 0.5454 0.5454 0.2692 | 0.1988 31.5529 27.9122 0.1820 0.4067 0.5396 ||TEST: 1.2377 0.2818 0.5865 | 0.6139 0.6139 0.2500 | 0.1904 30.8152 27.4294 0.1929 0.4178 0.5473 | 115.3978
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.99868394 0.99867919 0.99863737 0.99864234 0.99862462 0.99865806
 0.99871923 0.99867655 0.9986735  0.99866108 0.99868841 0.99875591
 0.99876938 0.99874184 0.99873655 0.99872607 0.99867378 0.99870781
 0.99872916 0.99873222]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.99866353 0.99867833 0.99869647 0.99867725 0.99868696 0.99866669
 0.99866036 0.99867162 0.99867613 0.99866909 0.99866868 0.99867311
 0.99866816 0.99866971 0.99868326 0.99867354 0.99867091 0.99867629
 0.9986717  0.9986522 ]
[0.  0.  0.5]
-----------end of analyzing the loss ratio:73.98589396476746
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc939e6e0e0>
---------------------------------
SparseEpoch: [30][1/398]	Time 0.614	Data 0.000	Loss 2.3358	
SparseEpoch: [30][101/398]	Time 0.623	Data 0.000	Loss 2.6289	
SparseEpoch: [30][201/398]	Time 0.622	Data 0.000	Loss 3.4633	
SparseEpoch: [30][301/398]	Time 0.623	Data 0.000	Loss 3.4006	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.86287731 0.86283627 0.86249437 0.86233698 0.86217826 0.86193921
 0.86175786 0.86159528 0.86154411 0.86137844 0.86112909 0.86085836
 0.86069113 0.86063677 0.86046082 0.86024044 0.86029471 0.86004214
 0.86006787 0.85997483]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.8613968  0.86133575 0.86135458 0.86135105 0.86131057 0.8612783
 0.86124216 0.86120449 0.8611532  0.86111425 0.86111872 0.86115034
 0.8611796  0.86116511 0.86114706 0.8611424  0.86114025 0.86110048
 0.86110038 0.86104058]
[0.5 0.  0.5]
-----------end of analyzing the loss ratio:73.80826139450073
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938c40220>
---------------------------------
SparseEpoch: [30][1/398]	Time 0.606	Data 0.000	Loss 2.2164	
SparseEpoch: [30][101/398]	Time 0.623	Data 0.000	Loss 2.0290	
SparseEpoch: [30][201/398]	Time 0.623	Data 0.000	Loss 2.1461	
SparseEpoch: [30][301/398]	Time 0.624	Data 0.000	Loss 2.3903	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.22463839 0.22463701 0.22462139 0.22460601 0.22459961 0.22459261
 0.22459818 0.22458504 0.22457116 0.22456787 0.22457654 0.22458021
 0.2246114  0.22459181 0.22461222 0.22461656 0.22462028 0.2246156
 0.22459866 0.22457021]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.22460978 0.22460802 0.2245976  0.22459193 0.22460524 0.22459679
 0.22457987 0.22458591 0.22456799 0.22456512 0.22458372 0.22459546
 0.22462182 0.22464013 0.22462816 0.22462948 0.2246298  0.22462718
 0.22462989 0.22462723]
[0. 0. 0.]
-----------end of analyzing the loss ratio:74.0479006767273
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938a8a3b0>
---------------------------------
SparseEpoch: [30][1/398]	Time 0.605	Data 0.000	Loss 2.0426	
SparseEpoch: [30][101/398]	Time 0.619	Data 0.000	Loss 2.7871	
SparseEpoch: [30][201/398]	Time 0.620	Data 0.000	Loss 2.2868	
SparseEpoch: [30][301/398]	Time 0.622	Data 0.000	Loss 1.6483	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 2.0107	
Epoch(adapt):{0} Loss 1.8623	
Epoch(adapt):{0} Loss 1.9430	
Epoch(adapt):{0} Loss 1.8922	
------------------the total time cost:1214.0555350780487
>>>>>meta updating
Epoch: 0030 | TRAIN: 1.1777 0.2911 0.6059 | 0.5457 0.5457 0.2550 | 0.1900 30.6838 26.8425 0.1893 0.4255 0.5604 ||TEST: 1.2588 0.2699 0.5796 | 0.6199 0.6199 0.2465 | 0.1818 29.9930 26.3713 0.1974 0.4337 0.5672 | 115.1875
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.18458924 1.18464699 1.18459927 1.18454347 1.18454003 1.18451458
 1.18454459 1.1845039  1.18453665 1.18449632 1.18448052 1.18443605
 1.18442276 1.18445464 1.18450893 1.18454424 1.18458441 1.18455511
 1.18453256 1.18453346]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.18448348 1.18448975 1.18448013 1.18448937 1.18448967 1.18448404
 1.18448974 1.18447441 1.18447564 1.18448635 1.18450269 1.1844985
 1.184498   1.18450264 1.1844967  1.18449044 1.18449026 1.18447382
 1.18444425 1.18442374]
[0.         0.13157895 0.5       ]
-----------end of analyzing the loss ratio:74.16636943817139
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938f6edd0>
---------------------------------
SparseEpoch: [31][1/398]	Time 0.616	Data 0.000	Loss 2.3550	
SparseEpoch: [31][101/398]	Time 0.625	Data 0.000	Loss 2.6878	
SparseEpoch: [31][201/398]	Time 0.624	Data 0.000	Loss 2.4495	
SparseEpoch: [31][301/398]	Time 0.625	Data 0.000	Loss 2.0202	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.8160281  0.8160377  0.81614234 0.81621336 0.81617616 0.81612652
 0.81608229 0.81613449 0.81614899 0.81615671 0.81621588 0.81623881
 0.81620909 0.81629226 0.81628853 0.81630397 0.816335   0.81632775
 0.81634785 0.81630469]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.81613    0.81611839 0.81611928 0.81615738 0.81618103 0.81616681
 0.81617061 0.81618201 0.81617244 0.81617748 0.81619139 0.81619112
 0.81622117 0.8162308  0.81621196 0.81621587 0.81624416 0.81626771
 0.81625757 0.81625919]
[0. 0. 0.]
-----------end of analyzing the loss ratio:73.98369431495667
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9388ec280>
---------------------------------
SparseEpoch: [31][1/398]	Time 0.628	Data 0.000	Loss 0.4544	
SparseEpoch: [31][101/398]	Time 0.623	Data 0.000	Loss 0.6378	
SparseEpoch: [31][201/398]	Time 0.623	Data 0.000	Loss 0.4700	
SparseEpoch: [31][301/398]	Time 0.623	Data 0.000	Loss 0.6271	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.19833941 0.19829563 0.19828957 0.19823502 0.19823021 0.19819275
 0.19815813 0.19812978 0.19807999 0.19806749 0.19798301 0.19797556
 0.19793882 0.19786501 0.19778827 0.19773145 0.1977236  0.19772729
 0.19768026 0.19762215]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.19801146 0.19800248 0.19797917 0.19798112 0.1979955  0.19798852
 0.19799388 0.19799846 0.19801243 0.19801623 0.19802353 0.19804286
 0.19805409 0.19803298 0.19803835 0.19804443 0.19805132 0.1980514
 0.19805033 0.19804636]
[0.5 0.  0. ]
-----------end of analyzing the loss ratio:73.86753225326538
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938b44400>
---------------------------------
SparseEpoch: [31][1/398]	Time 0.605	Data 0.000	Loss 2.4238	
SparseEpoch: [31][101/398]	Time 0.620	Data 0.000	Loss 3.2949	
SparseEpoch: [31][201/398]	Time 0.621	Data 0.000	Loss 2.1053	
SparseEpoch: [31][301/398]	Time 0.621	Data 0.000	Loss 2.0434	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 2.1028	
Epoch(adapt):{0} Loss 2.1962	
Epoch(adapt):{0} Loss 2.8621	
Epoch(adapt):{0} Loss 2.0426	
------------------the total time cost:1215.0505411624908
>>>>>meta updating
Epoch: 0031 | TRAIN: 1.1534 0.3099 0.6135 | 0.5457 0.5457 0.2705 | 0.1885 30.5288 26.6459 0.1914 0.4273 0.5622 ||TEST: 1.2539 0.2806 0.5814 | 0.6130 0.6130 0.2583 | 0.1814 29.9291 26.4169 0.2014 0.4340 0.5656 | 115.3246
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.18785564 1.18782984 1.18780991 1.18784615 1.1878529  1.18780763
 1.18786622 1.18781266 1.18781558 1.18786376 1.18790076 1.18791277
 1.18789855 1.18789988 1.18791693 1.187939   1.18794119 1.18802848
 1.18799816 1.18803411]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.18791849 1.18793895 1.18793957 1.18795552 1.18795918 1.18795962
 1.18793707 1.18792565 1.1878831  1.18784702 1.18786177 1.18784904
 1.18784687 1.18787516 1.18788081 1.18786944 1.18786122 1.18784161
 1.18781649 1.18780313]
[0.  0.  0.5]
-----------end of analyzing the loss ratio:73.9124813079834
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9398aa410>
---------------------------------
SparseEpoch: [32][1/398]	Time 0.608	Data 0.000	Loss 2.2997	
SparseEpoch: [32][101/398]	Time 0.620	Data 0.000	Loss 2.2438	
SparseEpoch: [32][201/398]	Time 0.623	Data 0.000	Loss 3.4951	
SparseEpoch: [32][301/398]	Time 0.623	Data 0.000	Loss 1.5758	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.99843367 0.99843732 0.99852607 0.99853572 0.99861481 0.99865947
 0.998692   0.99873405 0.99883689 0.99888128 0.99892448 0.99902301
 0.99905173 0.99919692 0.99932128 0.99948755 0.99955981 0.99962586
 0.99977133 0.99991285]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.9989137  0.99892055 0.99891025 0.99888037 0.99884981 0.99884784
 0.99886302 0.99887877 0.99888048 0.99888766 0.99888636 0.99887686
 0.99885757 0.99886453 0.99886299 0.99887115 0.99888    0.9988453
 0.99884539 0.99885221]
[0.         0.         0.39473684]
-----------end of analyzing the loss ratio:73.85296607017517
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9385e5990>
---------------------------------
SparseEpoch: [32][1/398]	Time 0.608	Data 0.000	Loss 1.2381	
SparseEpoch: [32][101/398]	Time 0.621	Data 0.000	Loss 1.0694	
SparseEpoch: [32][201/398]	Time 0.621	Data 0.000	Loss 1.6618	
SparseEpoch: [32][301/398]	Time 0.622	Data 0.000	Loss 1.4150	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.25599412 0.25591903 0.25582787 0.25574414 0.2557295  0.25565074
 0.2556409  0.25559492 0.25556145 0.25554338 0.25545216 0.25536027
 0.25530441 0.25526363 0.25522992 0.25520971 0.25515456 0.25508781
 0.25506644 0.25499611]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.25564572 0.25562366 0.25562677 0.25562935 0.25561175 0.25561372
 0.25558455 0.25555177 0.25551807 0.25549269 0.25549123 0.255458
 0.25543495 0.25541663 0.25541015 0.25536667 0.25535306 0.25533843
 0.25530532 0.25528338]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:73.94126987457275
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938504d00>
---------------------------------
SparseEpoch: [32][1/398]	Time 0.606	Data 0.000	Loss 3.4504	
SparseEpoch: [32][101/398]	Time 0.625	Data 0.000	Loss 4.1904	
SparseEpoch: [32][201/398]	Time 0.626	Data 0.000	Loss 2.9996	
SparseEpoch: [32][301/398]	Time 0.626	Data 0.000	Loss 3.8408	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 2.4970	
Epoch(adapt):{0} Loss 2.0009	
Epoch(adapt):{0} Loss 2.1851	
Epoch(adapt):{0} Loss 1.4630	
------------------the total time cost:1215.3919622898102
>>>>>meta updating
Epoch: 0032 | TRAIN: 1.1556 0.3020 0.6135 | 0.5448 0.5448 0.2602 | 0.1885 30.5229 26.7377 0.1913 0.4273 0.5629 ||TEST: 1.2369 0.2777 0.5880 | 0.6263 0.6263 0.2436 | 0.1801 29.8211 26.2551 0.2003 0.4357 0.5694 | 115.4816
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.96744978 0.9674359  0.96751137 0.96742816 0.96744005 0.96739084
 0.96738046 0.96739869 0.96743735 0.96740806 0.96745845 0.96742832
 0.9674849  0.96753483 0.96758138 0.96752484 0.96764237 0.96765742
 0.96770687 0.96769996]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.96744157 0.96741625 0.96742559 0.96741502 0.96742098 0.9674288
 0.96741993 0.96746082 0.96747098 0.96745923 0.96744047 0.96743137
 0.96743515 0.96741643 0.96741934 0.96741392 0.96740128 0.9674027
 0.96739372 0.96737769]
[0.  0.  0.5]
-----------end of analyzing the loss ratio:74.26307034492493
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cca5e592bc0>
---------------------------------
SparseEpoch: [33][1/398]	Time 0.606	Data 0.000	Loss 1.8744	
SparseEpoch: [33][101/398]	Time 0.626	Data 0.000	Loss 2.1080	
SparseEpoch: [33][201/398]	Time 0.624	Data 0.000	Loss 1.8343	
SparseEpoch: [33][301/398]	Time 0.622	Data 0.000	Loss 1.8597	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.85934117 0.85947976 0.85945946 0.85943683 0.85959653 0.85961272
 0.85971249 0.85979449 0.85981262 0.85987312 0.86003186 0.86000241
 0.86010062 0.86001728 0.86002098 0.86002889 0.86019188 0.86010774
 0.86006333 0.86008385]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.8599455  0.85993786 0.85993888 0.85991732 0.85991226 0.85988885
 0.85990485 0.8598773  0.85989244 0.85988794 0.85987849 0.85984995
 0.85988127 0.85988712 0.85986938 0.8598836  0.85989464 0.85988661
 0.859889   0.85989425]
[0.         0.         0.07894737]
-----------end of analyzing the loss ratio:74.09842777252197
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc939ee7970>
---------------------------------
SparseEpoch: [33][1/398]	Time 0.607	Data 0.000	Loss 0.4741	
SparseEpoch: [33][101/398]	Time 0.629	Data 0.000	Loss 0.7598	
SparseEpoch: [33][201/398]	Time 0.625	Data 0.000	Loss 1.2746	
SparseEpoch: [33][301/398]	Time 0.626	Data 0.000	Loss 0.4574	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.19292332 0.19286382 0.19282043 0.19275833 0.19273466 0.19272527
 0.19269678 0.19266072 0.19263219 0.19264018 0.19264033 0.19263113
 0.19255499 0.19258351 0.19253791 0.19248957 0.19242901 0.19236506
 0.19230667 0.19233841]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.19274318 0.1927536  0.19277018 0.19273174 0.19272116 0.19268944
 0.19265126 0.19264613 0.19263532 0.19264352 0.19263319 0.19260675
 0.19262295 0.19254862 0.1925594  0.19256494 0.19252802 0.19252504
 0.19251758 0.19246684]
[0.44736842 0.5        0.        ]
-----------end of analyzing the loss ratio:73.8825740814209
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9398d0d60>
---------------------------------
SparseEpoch: [33][1/398]	Time 0.608	Data 0.000	Loss 3.1488	
SparseEpoch: [33][101/398]	Time 0.623	Data 0.000	Loss 3.2928	
SparseEpoch: [33][201/398]	Time 0.624	Data 0.000	Loss 3.0158	
SparseEpoch: [33][301/398]	Time 0.626	Data 0.000	Loss 3.6241	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 2.0970	
Epoch(adapt):{0} Loss 1.9900	
Epoch(adapt):{0} Loss 1.9474	
Epoch(adapt):{0} Loss 1.9850	
------------------the total time cost:1215.4661271572113
>>>>>meta updating
Epoch: 0033 | TRAIN: 1.1648 0.3116 0.6114 | 0.5301 0.5301 0.2566 | 0.1884 30.4320 26.4718 0.1962 0.4320 0.5659 ||TEST: 1.2332 0.2892 0.5892 | 0.6162 0.6162 0.2412 | 0.1796 29.7530 26.1322 0.2025 0.4373 0.5703 | 115.5839
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.21802296 1.21803766 1.21807054 1.21806647 1.21803326 1.21810211
 1.21798618 1.21798329 1.21791443 1.21792805 1.21783996 1.21781483
 1.21782808 1.21771899 1.21773444 1.2176944  1.21770311 1.21787885
 1.21791558 1.21783746]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.21782303 1.21782398 1.21784566 1.21786579 1.2178606  1.21785548
 1.21784915 1.21785324 1.21785161 1.21784533 1.21785068 1.21784534
 1.21784007 1.21785929 1.21785442 1.21784795 1.21785812 1.21786975
 1.21788727 1.21787716]
[0.         0.28947368 0.        ]
-----------end of analyzing the loss ratio:74.09507060050964
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9384ff040>
---------------------------------
SparseEpoch: [34][1/398]	Time 0.610	Data 0.000	Loss 1.2011	
SparseEpoch: [34][101/398]	Time 0.626	Data 0.000	Loss 1.1733	
SparseEpoch: [34][201/398]	Time 0.627	Data 0.000	Loss 1.6587	
SparseEpoch: [34][301/398]	Time 0.626	Data 0.000	Loss 1.1050	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.81223595 0.81193704 0.81172298 0.81132852 0.8109504  0.81075416
 0.81027918 0.80981818 0.80932451 0.80894314 0.80849221 0.80809951
 0.80787091 0.80730734 0.80702907 0.80662627 0.80617996 0.80577179
 0.80525749 0.80474795]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.80906531 0.80896784 0.80896256 0.80893728 0.80888809 0.80886689
 0.8087914  0.80877009 0.80871711 0.8086575  0.80862436 0.80865354
 0.80865198 0.80856641 0.80850146 0.80851849 0.80845239 0.80843487
 0.80840726 0.80837981]
[0.5 0.  0.5]
-----------end of analyzing the loss ratio:74.30895328521729
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9389014e0>
---------------------------------
SparseEpoch: [34][1/398]	Time 0.607	Data 0.000	Loss 2.2044	
SparseEpoch: [34][101/398]	Time 0.628	Data 0.000	Loss 2.0190	
SparseEpoch: [34][201/398]	Time 0.628	Data 0.000	Loss 1.8185	
SparseEpoch: [34][301/398]	Time 0.626	Data 0.000	Loss 2.6150	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.20678011 0.2067668  0.20677118 0.20677525 0.20677745 0.20677419
 0.20676257 0.2067543  0.20674073 0.20674945 0.20675725 0.20676095
 0.2067574  0.20676442 0.20675863 0.20674942 0.2067538  0.20675219
 0.20675011 0.20673947]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.20677152 0.20677071 0.20676712 0.20675689 0.20676143 0.20676371
 0.20675476 0.20675406 0.20674685 0.20674882 0.20675155 0.20675594
 0.20676256 0.20676792 0.20676106 0.20675866 0.2067598  0.20676382
 0.20676547 0.20676312]
[0.5 0.  0. ]
-----------end of analyzing the loss ratio:74.08257412910461
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9398fb010>
---------------------------------
SparseEpoch: [34][1/398]	Time 0.604	Data 0.000	Loss 2.1372	
SparseEpoch: [34][101/398]	Time 0.620	Data 0.000	Loss 2.4568	
SparseEpoch: [34][201/398]	Time 0.622	Data 0.000	Loss 2.3471	
SparseEpoch: [34][301/398]	Time 0.622	Data 0.000	Loss 2.4522	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.9875	
Epoch(adapt):{0} Loss 2.0096	
Epoch(adapt):{0} Loss 2.1266	
Epoch(adapt):{0} Loss 1.4930	
------------------the total time cost:1215.4590961933136
>>>>>meta updating
Epoch: 0034 | TRAIN: 1.1157 0.3249 0.6265 | 0.5282 0.5282 0.2471 | 0.1860 30.2778 26.4685 0.1940 0.4317 0.5679 ||TEST: 1.2200 0.2915 0.5943 | 0.6145 0.6145 0.2402 | 0.1814 29.9708 26.4623 0.1975 0.4316 0.5653 | 115.7236
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.9868745  0.9868591  0.98678854 0.98678191 0.9867354  0.98672634
 0.98674116 0.98669857 0.986718   0.98670701 0.98665956 0.9866446
 0.98664427 0.98656016 0.98656004 0.98656949 0.98658898 0.98657217
 0.9865406  0.98652064]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.98667489 0.9866926  0.9867073  0.98669643 0.98673196 0.9866967
 0.98671125 0.9867033  0.98669576 0.98670417 0.98670807 0.98668748
 0.98664433 0.98662569 0.98661311 0.98659455 0.98660815 0.98662352
 0.98662704 0.98661906]
[0.         0.5        0.28947368]
-----------end of analyzing the loss ratio:74.11859774589539
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc93881e8c0>
---------------------------------
SparseEpoch: [35][1/398]	Time 0.608	Data 0.000	Loss 1.9027	
SparseEpoch: [35][101/398]	Time 0.625	Data 0.000	Loss 1.9284	
SparseEpoch: [35][201/398]	Time 0.623	Data 0.000	Loss 1.8074	
SparseEpoch: [35][301/398]	Time 0.625	Data 0.000	Loss 1.6360	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.90879083 0.90883376 0.90875617 0.90875052 0.90865903 0.90848234
 0.9083097  0.90813323 0.90795836 0.90786996 0.90775118 0.90762109
 0.90766813 0.90764514 0.90765769 0.9076353  0.907536   0.90753551
 0.90764597 0.90754499]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.90769827 0.90771679 0.90772256 0.90774581 0.90775563 0.90779718
 0.90780891 0.90779711 0.90782295 0.90783189 0.90790194 0.90791698
 0.90791015 0.90786703 0.90785739 0.90784973 0.90785474 0.90788208
 0.90790468 0.90791942]
[0.39473684 0.         0.        ]
-----------end of analyzing the loss ratio:74.16425061225891
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938506b90>
---------------------------------
SparseEpoch: [35][1/398]	Time 0.605	Data 0.000	Loss 1.1813	
SparseEpoch: [35][101/398]	Time 0.621	Data 0.000	Loss 0.8412	
SparseEpoch: [35][201/398]	Time 0.621	Data 0.000	Loss 0.8762	
SparseEpoch: [35][301/398]	Time 0.623	Data 0.000	Loss 1.2096	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.19563348 0.19562731 0.19562379 0.19561406 0.19560492 0.19559942
 0.19559922 0.19558061 0.19557227 0.19555681 0.19553612 0.19553516
 0.1955381  0.19554774 0.19554534 0.1955247  0.19552341 0.19549624
 0.19549893 0.19549711]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.19565578 0.19565859 0.1956423  0.19563617 0.19563159 0.19562594
 0.19561495 0.19560484 0.19557604 0.19555469 0.19555435 0.1955725
 0.19554089 0.19552063 0.19552056 0.19551116 0.19545487 0.19544981
 0.19544755 0.19541071]
[0.39473684 0.5        0.        ]
-----------end of analyzing the loss ratio:73.95471835136414
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc93995cbe0>
---------------------------------
SparseEpoch: [35][1/398]	Time 0.604	Data 0.000	Loss 2.9347	
SparseEpoch: [35][101/398]	Time 0.628	Data 0.000	Loss 2.4406	
SparseEpoch: [35][201/398]	Time 0.627	Data 0.000	Loss 2.7282	
SparseEpoch: [35][301/398]	Time 0.624	Data 0.000	Loss 1.8680	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.9983	
Epoch(adapt):{0} Loss 2.1491	
Epoch(adapt):{0} Loss 1.6971	
Epoch(adapt):{0} Loss 2.2197	
------------------the total time cost:1214.3099806308746
>>>>>meta updating
Epoch: 0035 | TRAIN: 1.1134 0.3248 0.6282 | 0.5326 0.5326 0.2388 | 0.1850 30.2253 26.3355 0.1905 0.4321 0.5703 ||TEST: 1.2040 0.2940 0.6003 | 0.6214 0.6214 0.2388 | 0.1791 29.8047 26.2937 0.1960 0.4339 0.5689 | 115.0848
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.02931584 1.02934199 1.02936199 1.02922955 1.02916576 1.02914753
 1.02924633 1.02932631 1.02946662 1.0294378  1.02937973 1.02932909
 1.02923805 1.02921415 1.02912768 1.0290857  1.02903442 1.02904345
 1.02903226 1.02903138]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.02939639 1.02938514 1.02938178 1.02938189 1.02939534 1.02940921
 1.02942734 1.02944036 1.02943342 1.02940443 1.02940297 1.02939054
 1.02937711 1.0293635  1.02936614 1.02936009 1.02934819 1.02935286
 1.02935888 1.02937703]
[0.         0.5        0.34210526]
-----------end of analyzing the loss ratio:74.32871389389038
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9389dba00>
---------------------------------
SparseEpoch: [36][1/398]	Time 0.604	Data 0.000	Loss 2.8380	
SparseEpoch: [36][101/398]	Time 0.623	Data 0.000	Loss 1.4386	
SparseEpoch: [36][201/398]	Time 0.626	Data 0.000	Loss 2.2823	
SparseEpoch: [36][301/398]	Time 0.626	Data 0.000	Loss 2.4484	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.72471142 0.72455986 0.72455956 0.7246612  0.72441046 0.72430106
 0.72421589 0.72410076 0.72407452 0.72406894 0.72417598 0.72404855
 0.72411587 0.72417139 0.72410725 0.72416896 0.72403063 0.7240952
 0.72385072 0.72390559]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.72403377 0.72399846 0.72400782 0.72399375 0.72405462 0.72409762
 0.7241123  0.72407722 0.72411814 0.72410794 0.72410915 0.72409738
 0.72408128 0.7241349  0.72414171 0.72416252 0.7242027  0.72419
 0.7242362  0.72421446]
[0.44736842 0.         0.        ]
-----------end of analyzing the loss ratio:74.06395816802979
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9389da3b0>
---------------------------------
SparseEpoch: [36][1/398]	Time 0.610	Data 0.000	Loss 0.9707	
SparseEpoch: [36][101/398]	Time 0.624	Data 0.000	Loss 1.0063	
SparseEpoch: [36][201/398]	Time 0.622	Data 0.000	Loss 1.3027	
SparseEpoch: [36][301/398]	Time 0.623	Data 0.000	Loss 0.9961	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.18677489 0.1865683  0.18640906 0.18625346 0.18609473 0.18586764
 0.18572936 0.18560719 0.18546984 0.18535042 0.18515305 0.18500352
 0.18492281 0.18476326 0.18456187 0.18438773 0.18416537 0.18397618
 0.18383778 0.18377239]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.18564454 0.18561084 0.18558159 0.18553199 0.18549224 0.18547102
 0.18545122 0.18542124 0.18535088 0.18528658 0.18523238 0.18516278
 0.1851     0.18505633 0.18502942 0.18497422 0.18493135 0.18490258
 0.18488355 0.18486153]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:74.01713418960571
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc939ee5570>
---------------------------------
SparseEpoch: [36][1/398]	Time 0.606	Data 0.000	Loss 2.8117	
SparseEpoch: [36][101/398]	Time 0.627	Data 0.000	Loss 3.1048	
SparseEpoch: [36][201/398]	Time 0.627	Data 0.000	Loss 2.4979	
SparseEpoch: [36][301/398]	Time 0.625	Data 0.000	Loss 2.9670	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.3278	
Epoch(adapt):{0} Loss 1.6776	
Epoch(adapt):{0} Loss 1.5952	
Epoch(adapt):{0} Loss 1.6911	
------------------the total time cost:1215.8028225898743
>>>>>meta updating
Epoch: 0036 | TRAIN: 1.0763 0.3377 0.6400 | 0.5169 0.5169 0.2507 | 0.1837 30.1038 26.2475 0.1932 0.4338 0.5709 ||TEST: 1.1957 0.3003 0.6013 | 0.5928 0.5928 0.2393 | 0.1781 29.6935 26.2272 0.1979 0.4349 0.5706 | 115.2958
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.06085755 1.06076122 1.06077697 1.06079277 1.06078593 1.06083452
 1.06090649 1.06099072 1.06090811 1.06091495 1.06089766 1.06092065
 1.0608856  1.06088181 1.06087368 1.06091181 1.06093518 1.06101335
 1.06106794 1.06105633]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.06077143 1.06078581 1.06082864 1.06083256 1.06083836 1.06082828
 1.06082597 1.06082587 1.06087003 1.06088452 1.06090167 1.06087282
 1.06087579 1.06089913 1.06091896 1.0609081  1.06097438 1.060998
 1.06098873 1.06101897]
[0. 0. 0.]
-----------end of analyzing the loss ratio:74.03375005722046
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9386cb520>
---------------------------------
SparseEpoch: [37][1/398]	Time 0.605	Data 0.000	Loss 1.0418	
SparseEpoch: [37][101/398]	Time 0.625	Data 0.000	Loss 1.0662	
SparseEpoch: [37][201/398]	Time 0.623	Data 0.000	Loss 1.1351	
SparseEpoch: [37][301/398]	Time 0.624	Data 0.000	Loss 1.3494	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.02354758 1.02345969 1.02339466 1.02340775 1.0232987  1.02326232
 1.02320489 1.02311031 1.02311102 1.02307886 1.02303033 1.02299728
 1.02298831 1.02301226 1.02301466 1.02299892 1.02299551 1.02302696
 1.02295974 1.02297965]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.02296881 1.02298711 1.02299076 1.02299128 1.02299016 1.02300783
 1.02301476 1.02302799 1.02303098 1.0230319  1.02303581 1.02304544
 1.02307242 1.02306855 1.02308882 1.02310168 1.02310953 1.02312314
 1.02311616 1.02315667]
[0.44736842 0.         0.        ]
-----------end of analyzing the loss ratio:74.01047468185425
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc93881ff10>
---------------------------------
SparseEpoch: [37][1/398]	Time 0.605	Data 0.000	Loss 1.0650	
SparseEpoch: [37][101/398]	Time 0.622	Data 0.000	Loss 1.0952	
SparseEpoch: [37][201/398]	Time 0.622	Data 0.000	Loss 1.4343	
SparseEpoch: [37][301/398]	Time 0.621	Data 0.000	Loss 1.0698	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.19582312 0.19580824 0.19568868 0.19558495 0.19548247 0.19540325
 0.19529109 0.19519399 0.19509596 0.19500186 0.1949192  0.19478306
 0.19468266 0.19461711 0.19444525 0.1943054  0.19422212 0.19413913
 0.19403833 0.19393789]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.19526095 0.19524425 0.19521354 0.19516462 0.19511622 0.19507619
 0.19506225 0.19503244 0.19498671 0.19496801 0.19495229 0.19491113
 0.19487675 0.19484893 0.19482206 0.19479473 0.19472278 0.19472539
 0.19467252 0.1946713 ]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:74.0753345489502
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc939e6e0b0>
---------------------------------
SparseEpoch: [37][1/398]	Time 0.620	Data 0.000	Loss 2.4709	
SparseEpoch: [37][101/398]	Time 0.629	Data 0.000	Loss 3.8342	
SparseEpoch: [37][201/398]	Time 0.628	Data 0.000	Loss 4.1864	
SparseEpoch: [37][301/398]	Time 0.628	Data 0.000	Loss 2.6717	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.6169	
Epoch(adapt):{0} Loss 2.3131	
Epoch(adapt):{0} Loss 1.2198	
Epoch(adapt):{0} Loss 1.7498	
------------------the total time cost:1215.2242403030396
>>>>>meta updating
Epoch: 0037 | TRAIN: 1.0663 0.3492 0.6387 | 0.5126 0.5126 0.2338 | 0.1847 30.1240 26.1464 0.1968 0.4358 0.5712 ||TEST: 1.1925 0.3082 0.6019 | 0.6004 0.6004 0.2374 | 0.1801 29.8078 26.1956 0.2004 0.4356 0.5699 | 115.5027
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.0011602  1.00114865 1.00103193 1.00104104 1.00097747 1.00096704
 1.00092955 1.00099608 1.00098575 1.00107101 1.00100114 1.00071599
 1.00073839 1.00068576 1.00062366 1.00057028 1.00052915 1.00064908
 1.00075911 1.00065767]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.0009558  1.00094692 1.00094033 1.00095243 1.00094835 1.00094221
 1.0008925  1.00091293 1.00091605 1.00095442 1.00092238 1.00097404
 1.00102305 1.00102023 1.00099755 1.00101772 1.00103661 1.00102056
 1.00104252 1.00104853]
[0.         0.34210526 0.        ]
-----------end of analyzing the loss ratio:74.1857852935791
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938f6eb60>
---------------------------------
SparseEpoch: [38][1/398]	Time 0.604	Data 0.000	Loss 0.9895	
SparseEpoch: [38][101/398]	Time 0.622	Data 0.000	Loss 1.7956	
SparseEpoch: [38][201/398]	Time 0.623	Data 0.000	Loss 0.9955	
SparseEpoch: [38][301/398]	Time 0.623	Data 0.000	Loss 1.1367	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.47287535 0.4728662  0.47287003 0.47284914 0.47287793 0.47288742
 0.4728724  0.47280974 0.47281697 0.47280673 0.47276154 0.47274133
 0.47273818 0.47272407 0.4727367  0.47267774 0.47272469 0.47274343
 0.47275333 0.47274634]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.47278588 0.47278123 0.47279137 0.47278128 0.47278068 0.47277996
 0.47278682 0.47276595 0.47275386 0.47276943 0.47278324 0.4727893
 0.47275303 0.47275971 0.47279341 0.47281177 0.47281736 0.47283505
 0.47283978 0.47286112]
[0.28947368 0.         0.13157895]
-----------end of analyzing the loss ratio:74.0059118270874
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cca5df80640>
---------------------------------
SparseEpoch: [38][1/398]	Time 0.607	Data 0.000	Loss 1.3541	
SparseEpoch: [38][101/398]	Time 0.627	Data 0.000	Loss 1.0440	
SparseEpoch: [38][201/398]	Time 0.625	Data 0.000	Loss 1.1590	
SparseEpoch: [38][301/398]	Time 0.623	Data 0.000	Loss 1.1620	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.20938806 0.20930869 0.2093193  0.20931476 0.20933477 0.20929967
 0.20925636 0.20917692 0.20914263 0.20910302 0.20905476 0.20900739
 0.20900084 0.2089112  0.20883297 0.20880214 0.2087768  0.2087194
 0.20868392 0.20866045]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.20909049 0.20910426 0.20910046 0.20908095 0.2090674  0.20903032
 0.20903595 0.2090457  0.20907239 0.20909864 0.2090732  0.20906276
 0.20906547 0.20907459 0.20903616 0.20903554 0.20901748 0.20901006
 0.20899662 0.20898534]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:74.03166198730469
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938d4f250>
---------------------------------
SparseEpoch: [38][1/398]	Time 0.612	Data 0.000	Loss 2.3919	
SparseEpoch: [38][101/398]	Time 0.625	Data 0.000	Loss 2.9482	
SparseEpoch: [38][201/398]	Time 0.624	Data 0.000	Loss 1.9965	
SparseEpoch: [38][301/398]	Time 0.624	Data 0.000	Loss 3.7374	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.2954	
Epoch(adapt):{0} Loss 1.7371	
Epoch(adapt):{0} Loss 1.3901	
Epoch(adapt):{0} Loss 2.4111	
------------------the total time cost:1214.9570045471191
>>>>>meta updating
Epoch: 0038 | TRAIN: 1.0627 0.3453 0.6429 | 0.5003 0.5003 0.2478 | 0.1849 30.1171 26.1517 0.1983 0.4363 0.5711 ||TEST: 1.1948 0.3001 0.6046 | 0.5887 0.5887 0.2481 | 0.1793 29.6799 26.0117 0.2044 0.4399 0.5733 | 115.5204
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.08343849 1.08346183 1.08345245 1.08345191 1.08354407 1.08355663
 1.08350245 1.08349816 1.08359013 1.0835633  1.08358676 1.0835893
 1.08362715 1.08368548 1.08368279 1.08369163 1.08368014 1.08373462
 1.08380888 1.08388231]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.08356457 1.08358184 1.08358178 1.08360637 1.08358763 1.08359171
 1.08358998 1.0835978  1.08358642 1.08359862 1.08355711 1.0835556
 1.08355133 1.08353807 1.08354489 1.08355568 1.08356553 1.08359857
 1.08356897 1.08361011]
[0.         0.         0.18421053]
-----------end of analyzing the loss ratio:74.21899747848511
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc93901ead0>
---------------------------------
SparseEpoch: [39][1/398]	Time 0.605	Data 0.000	Loss 1.2483	
SparseEpoch: [39][101/398]	Time 0.622	Data 0.000	Loss 1.1990	
SparseEpoch: [39][201/398]	Time 0.624	Data 0.000	Loss 1.5120	
SparseEpoch: [39][301/398]	Time 0.622	Data 0.000	Loss 1.8434	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.90208076 0.90204719 0.90191841 0.9019154  0.90174286 0.90156794
 0.90144852 0.90130396 0.9011113  0.90101097 0.90088851 0.90073967
 0.90069252 0.90061169 0.90050291 0.90028427 0.90016864 0.89991592
 0.89975456 0.89967052]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.90077564 0.90078112 0.90083009 0.90082857 0.90084693 0.90086578
 0.90087909 0.90089189 0.90091317 0.90093557 0.9009391  0.90095972
 0.90096726 0.90098642 0.90105572 0.90109227 0.90109661 0.90107442
 0.90106651 0.90107683]
[0.5 0.  0. ]
-----------end of analyzing the loss ratio:74.12869262695312
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc93882efe0>
---------------------------------
SparseEpoch: [39][1/398]	Time 0.609	Data 0.000	Loss 1.1425	
SparseEpoch: [39][101/398]	Time 0.624	Data 0.000	Loss 1.2035	
SparseEpoch: [39][201/398]	Time 0.626	Data 0.000	Loss 1.3369	
SparseEpoch: [39][301/398]	Time 0.624	Data 0.000	Loss 1.2229	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.23497356 0.23495746 0.23492515 0.23496391 0.23493592 0.2348793
 0.23490775 0.2348294  0.23478975 0.23472126 0.23467783 0.23467814
 0.23469594 0.23463981 0.2345866  0.23453801 0.23451185 0.23448995
 0.23451107 0.23450854]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.23477927 0.23478833 0.23480877 0.23477326 0.23476257 0.23476441
 0.23472894 0.23471509 0.23471041 0.23469754 0.23469044 0.23469539
 0.23469025 0.23469546 0.23469601 0.23467384 0.23466867 0.23463745
 0.23463178 0.23463433]
[0.39473684 0.44736842 0.        ]
-----------end of analyzing the loss ratio:73.96601605415344
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9388356c0>
---------------------------------
SparseEpoch: [39][1/398]	Time 0.608	Data 0.000	Loss 3.2031	
SparseEpoch: [39][101/398]	Time 0.620	Data 0.000	Loss 2.1826	
SparseEpoch: [39][201/398]	Time 0.622	Data 0.000	Loss 2.7779	
SparseEpoch: [39][301/398]	Time 0.623	Data 0.000	Loss 2.9878	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.6593	
Epoch(adapt):{0} Loss 1.8319	
Epoch(adapt):{0} Loss 1.6005	
Epoch(adapt):{0} Loss 1.7830	
------------------the total time cost:1213.388595342636
>>>>>meta updating
Epoch: 0039 | TRAIN: 1.0485 0.3526 0.6480 | 0.5171 0.5171 0.2415 | 0.1835 29.9863 26.0459 0.1997 0.4380 0.5739 ||TEST: 1.1730 0.3122 0.6098 | 0.6020 0.6020 0.2340 | 0.1771 29.5191 25.9191 0.2043 0.4406 0.5747 | 115.5352
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.95798077 0.95798803 0.95795726 0.95795072 0.95796676 0.95798423
 0.95806888 0.95805942 0.95804775 0.95801995 0.95807266 0.95810027
 0.95813762 0.95813636 0.95816882 0.95813578 0.95810727 0.95808107
 0.95803959 0.95803481]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.95804722 0.95804493 0.95804875 0.95804635 0.95804592 0.95804281
 0.95805642 0.95805067 0.95805303 0.95805609 0.95806154 0.95806279
 0.95806527 0.95806781 0.95805971 0.95805262 0.958057   0.95804871
 0.95803897 0.95803658]
[0.  0.  0.5]
-----------end of analyzing the loss ratio:74.19263076782227
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938a7be20>
---------------------------------
SparseEpoch: [40][1/398]	Time 0.606	Data 0.000	Loss 2.7583	
SparseEpoch: [40][101/398]	Time 0.623	Data 0.000	Loss 1.8656	
SparseEpoch: [40][201/398]	Time 0.624	Data 0.000	Loss 2.0772	
SparseEpoch: [40][301/398]	Time 0.624	Data 0.000	Loss 2.1687	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.60954196 0.60962119 0.60976365 0.60991871 0.61011052 0.61031706
 0.61053281 0.61071528 0.61084629 0.61093635 0.61108601 0.61127042
 0.61149159 0.61170983 0.61179066 0.61186579 0.61197661 0.61212651
 0.61215152 0.61227202]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.61107503 0.61106639 0.61106471 0.61105949 0.61104191 0.6110341
 0.6110389  0.6110435  0.61103368 0.61102605 0.61102618 0.61102528
 0.61103528 0.6110307  0.61102538 0.61102709 0.61101718 0.61101878
 0.61101328 0.6110098 ]
[0.  0.  0.5]
-----------end of analyzing the loss ratio:74.05511975288391
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938fc5c90>
---------------------------------
SparseEpoch: [40][1/398]	Time 0.604	Data 0.000	Loss 1.8689	
SparseEpoch: [40][101/398]	Time 0.624	Data 0.000	Loss 1.8154	
SparseEpoch: [40][201/398]	Time 0.626	Data 0.000	Loss 1.6808	
SparseEpoch: [40][301/398]	Time 0.621	Data 0.000	Loss 1.4005	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.26028109 0.26017062 0.26004655 0.25992813 0.25976789 0.25965045
 0.2595486  0.25941085 0.25934084 0.25922327 0.25910479 0.25898198
 0.25892806 0.25882125 0.25871451 0.25854077 0.25845824 0.25830275
 0.25813087 0.258009  ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.25928428 0.25926805 0.2592657  0.25925598 0.25924503 0.25924164
 0.25921393 0.25920165 0.25920182 0.25916557 0.25914145 0.25914755
 0.25912721 0.25911894 0.25909662 0.25908731 0.25906484 0.25906989
 0.25904856 0.25903456]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:74.09643816947937
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc93997d630>
---------------------------------
SparseEpoch: [40][1/398]	Time 0.605	Data 0.000	Loss 2.7811	
SparseEpoch: [40][101/398]	Time 0.623	Data 0.000	Loss 3.6332	
SparseEpoch: [40][201/398]	Time 0.623	Data 0.000	Loss 2.9058	
SparseEpoch: [40][301/398]	Time 0.622	Data 0.000	Loss 2.8055	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.8942	
Epoch(adapt):{0} Loss 1.7782	
Epoch(adapt):{0} Loss 2.4213	
Epoch(adapt):{0} Loss 1.6561	
------------------the total time cost:1213.227608203888
>>>>>meta updating
Epoch: 0040 | TRAIN: 1.0913 0.3473 0.6356 | 0.5035 0.5035 0.2452 | 0.1814 29.9428 26.0082 0.1881 0.4375 0.5781 ||TEST: 1.2131 0.3080 0.5971 | 0.5989 0.5989 0.2367 | 0.1737 29.3147 25.6502 0.1952 0.4441 0.5836 | 115.4813
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.23420954 1.23422257 1.2341525  1.23414539 1.23412053 1.2340525
 1.23402392 1.23400236 1.23396644 1.23374478 1.23364321 1.23360777
 1.23358197 1.23361366 1.2335741  1.23348686 1.23347345 1.23343739
 1.23347475 1.23340375]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.2338099  1.23380681 1.23378091 1.23377217 1.23377279 1.23376325
 1.23376356 1.23378079 1.23372747 1.23371593 1.23369222 1.2337128
 1.23371064 1.23370255 1.2337148  1.23369039 1.23370815 1.23368881
 1.23368835 1.23366389]
[0.  0.5 0.5]
-----------end of analyzing the loss ratio:74.49983310699463
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9386ca080>
---------------------------------
SparseEpoch: [41][1/398]	Time 0.606	Data 0.000	Loss 2.2015	
SparseEpoch: [41][101/398]	Time 0.625	Data 0.000	Loss 2.8492	
SparseEpoch: [41][201/398]	Time 0.626	Data 0.000	Loss 2.1872	
SparseEpoch: [41][301/398]	Time 0.626	Data 0.000	Loss 2.2934	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.71113788 0.71130088 0.71127598 0.71110816 0.71112524 0.71124
 0.7113476  0.71141132 0.71136419 0.71139724 0.71145755 0.71152337
 0.71135406 0.71145586 0.71159458 0.71160447 0.71143394 0.71156918
 0.71164243 0.71175867]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.71134666 0.71135781 0.71134627 0.71136754 0.71136672 0.71137215
 0.71138389 0.7113775  0.71139811 0.71143446 0.71145453 0.71148705
 0.71149682 0.71148756 0.71151084 0.71153487 0.71155268 0.71152255
 0.71150912 0.71152487]
[0. 0. 0.]
-----------end of analyzing the loss ratio:74.14407348632812
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938506170>
---------------------------------
SparseEpoch: [41][1/398]	Time 0.620	Data 0.000	Loss 0.3629	
SparseEpoch: [41][101/398]	Time 0.625	Data 0.000	Loss 0.6409	
SparseEpoch: [41][201/398]	Time 0.624	Data 0.000	Loss 0.5393	
SparseEpoch: [41][301/398]	Time 0.624	Data 0.000	Loss 0.5333	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.19270391 0.19266115 0.1926921  0.19260892 0.19256852 0.19253832
 0.19250273 0.19254025 0.19248582 0.19250069 0.19255409 0.19253418
 0.19253467 0.19250548 0.19248519 0.19247275 0.19248738 0.19251309
 0.19257259 0.19255919]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.19250052 0.19250811 0.19250404 0.19250355 0.19252045 0.19250784
 0.19250817 0.19251165 0.19253989 0.19253138 0.19253523 0.19253063
 0.19253567 0.19253293 0.19254737 0.19255531 0.19257532 0.19257018
 0.19258271 0.19259076]
[0.28947368 0.         0.        ]
-----------end of analyzing the loss ratio:73.99493503570557
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9399471c0>
---------------------------------
SparseEpoch: [41][1/398]	Time 0.605	Data 0.000	Loss 1.8243	
SparseEpoch: [41][101/398]	Time 0.619	Data 0.000	Loss 2.4052	
SparseEpoch: [41][201/398]	Time 0.623	Data 0.000	Loss 2.7126	
SparseEpoch: [41][301/398]	Time 0.624	Data 0.000	Loss 2.1275	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.3955	
Epoch(adapt):{0} Loss 1.6923	
Epoch(adapt):{0} Loss 1.8064	
Epoch(adapt):{0} Loss 1.4604	
------------------the total time cost:1216.0156908035278
>>>>>meta updating
Epoch: 0041 | TRAIN: 1.0275 0.3584 0.6579 | 0.5024 0.5024 0.2386 | 0.1770 29.4004 25.3958 0.2020 0.4487 0.5873 ||TEST: 1.1768 0.3111 0.6094 | 0.5891 0.5891 0.2333 | 0.1721 28.9828 25.2602 0.2107 0.4531 0.5884 | 115.5039
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.07058894 1.07056516 1.07060294 1.07064993 1.07068262 1.07069163
 1.07068272 1.07068384 1.07069812 1.07074144 1.07070816 1.07072627
 1.07066323 1.07066553 1.0706637  1.07067933 1.0706964  1.07065994
 1.07065475 1.07060778]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.07074927 1.07073255 1.07074708 1.07075596 1.07075233 1.07075035
 1.07072475 1.0707126  1.07071505 1.07072344 1.07071047 1.07069822
 1.07066107 1.07064486 1.07063769 1.0706221  1.07061545 1.07060052
 1.07058833 1.07057759]
[0.  0.  0.5]
-----------end of analyzing the loss ratio:74.09993267059326
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc93992fdc0>
---------------------------------
SparseEpoch: [42][1/398]	Time 0.604	Data 0.000	Loss 2.1475	
SparseEpoch: [42][101/398]	Time 0.618	Data 0.000	Loss 2.7970	
SparseEpoch: [42][201/398]	Time 0.622	Data 0.000	Loss 1.6181	
SparseEpoch: [42][301/398]	Time 0.622	Data 0.000	Loss 2.8025	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.66569771 0.66563545 0.66569502 0.66567791 0.66572466 0.66568676
 0.66565122 0.66570785 0.66565951 0.66567728 0.6656864  0.66571235
 0.66569876 0.6657149  0.66573824 0.66570469 0.66563955 0.66562236
 0.66551227 0.66551037]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.66535617 0.6653741  0.66537738 0.66544032 0.66549165 0.66555507
 0.66561546 0.66569704 0.66570624 0.66565493 0.66570009 0.66581197
 0.66590029 0.66593861 0.66594408 0.66597531 0.66597878 0.66600306
 0.66607542 0.66610401]
[0.5 0.  0. ]
-----------end of analyzing the loss ratio:74.12117004394531
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9398a9960>
---------------------------------
SparseEpoch: [42][1/398]	Time 0.605	Data 0.000	Loss 0.8456	
SparseEpoch: [42][101/398]	Time 0.616	Data 0.000	Loss 1.6054	
SparseEpoch: [42][201/398]	Time 0.620	Data 0.000	Loss 0.8245	
SparseEpoch: [42][301/398]	Time 0.622	Data 0.000	Loss 1.0364	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.18230864 0.18231127 0.18228973 0.18227437 0.18224543 0.18222308
 0.18222133 0.18219976 0.18218871 0.18215683 0.18214101 0.1821444
 0.18211284 0.18209767 0.18207782 0.18208411 0.18205331 0.1820512
 0.18204362 0.18200046]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.18243791 0.18238395 0.18233945 0.182305   0.18232971 0.18228375
 0.18228957 0.18222281 0.18219211 0.18217457 0.18214267 0.182099
 0.18207029 0.18204179 0.18204026 0.1820151  0.18197145 0.18190216
 0.18188196 0.18185395]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:74.021653175354
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938f17760>
---------------------------------
SparseEpoch: [42][1/398]	Time 0.606	Data 0.000	Loss 2.6559	
SparseEpoch: [42][101/398]	Time 0.625	Data 0.000	Loss 2.0082	
SparseEpoch: [42][201/398]	Time 0.622	Data 0.000	Loss 2.2613	
SparseEpoch: [42][301/398]	Time 0.623	Data 0.000	Loss 2.0687	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 2.4895	
Epoch(adapt):{0} Loss 1.9210	
Epoch(adapt):{0} Loss 2.0655	
Epoch(adapt):{0} Loss 1.7986	
------------------the total time cost:1212.9392297267914
>>>>>meta updating
Epoch: 0042 | TRAIN: 1.0368 0.3736 0.6513 | 0.4899 0.4899 0.2423 | 0.1795 29.5897 25.4915 0.2026 0.4464 0.5841 ||TEST: 1.1851 0.3177 0.6069 | 0.5778 0.5778 0.2370 | 0.1722 29.0054 25.2685 0.2096 0.4518 0.5876 | 115.1892
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.17863005 1.17864129 1.17858123 1.17858016 1.17863417 1.17867103
 1.17869222 1.17867119 1.17864449 1.17866705 1.1787389  1.17880498
 1.17885394 1.17887073 1.1788838  1.17887266 1.17890731 1.17894639
 1.17892354 1.1789548 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.17886134 1.17880867 1.17884119 1.17882632 1.17879578 1.17878713
 1.17876097 1.17874742 1.17871815 1.17871955 1.17869409 1.17862632
 1.17862459 1.17867619 1.17869785 1.1786162  1.17863747 1.17865141
 1.17862645 1.17858539]
[0.  0.  0.5]
-----------end of analyzing the loss ratio:74.14909768104553
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9386cb100>
---------------------------------
SparseEpoch: [43][1/398]	Time 0.605	Data 0.000	Loss 2.2685	
SparseEpoch: [43][101/398]	Time 0.627	Data 0.000	Loss 1.8620	
SparseEpoch: [43][201/398]	Time 0.627	Data 0.000	Loss 2.0559	
SparseEpoch: [43][301/398]	Time 0.627	Data 0.000	Loss 1.8636	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.8902329  0.89027175 0.89036776 0.89043462 0.89041963 0.89052978
 0.89055834 0.89070713 0.89073487 0.89087554 0.89093037 0.89102453
 0.89108039 0.89113016 0.89126981 0.89134721 0.8914147  0.89140381
 0.89141012 0.89154757]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.89087949 0.89087827 0.89088271 0.89086311 0.89085358 0.89090361
 0.89091451 0.890909   0.89090048 0.89092283 0.89089639 0.8909227
 0.89090587 0.89096806 0.89099491 0.89091205 0.89092422 0.89092758
 0.89091893 0.89095733]
[0. 0. 0.]
-----------end of analyzing the loss ratio:74.39957523345947
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938e5b640>
---------------------------------
SparseEpoch: [43][1/398]	Time 0.612	Data 0.000	Loss 0.2762	
SparseEpoch: [43][101/398]	Time 0.626	Data 0.000	Loss 0.7271	
SparseEpoch: [43][201/398]	Time 0.625	Data 0.000	Loss 0.4412	
SparseEpoch: [43][301/398]	Time 0.625	Data 0.000	Loss 0.4967	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.24162577 0.24157317 0.24155483 0.24147387 0.24144212 0.24142937
 0.24137782 0.24132285 0.2413012  0.24123808 0.24118582 0.24116192
 0.24111279 0.24113485 0.24112865 0.24113471 0.24107307 0.24100046
 0.24094418 0.24089923]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.24142748 0.24141072 0.24138672 0.24136891 0.24136127 0.24133358
 0.24130673 0.24126664 0.24124849 0.24120923 0.24122735 0.24118707
 0.24117566 0.24116199 0.24113716 0.24112684 0.24111763 0.241098
 0.24108768 0.24107248]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:74.14399552345276
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938e01d20>
---------------------------------
SparseEpoch: [43][1/398]	Time 0.605	Data 0.000	Loss 2.4117	
SparseEpoch: [43][101/398]	Time 0.632	Data 0.000	Loss 2.4279	
SparseEpoch: [43][201/398]	Time 0.630	Data 0.000	Loss 2.8608	
SparseEpoch: [43][301/398]	Time 0.628	Data 0.000	Loss 2.2337	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.7404	
Epoch(adapt):{0} Loss 1.3581	
Epoch(adapt):{0} Loss 1.8385	
Epoch(adapt):{0} Loss 1.6854	
------------------the total time cost:1216.473911523819
>>>>>meta updating
Epoch: 0043 | TRAIN: 1.0194 0.3769 0.6551 | 0.4937 0.4937 0.2328 | 0.1768 29.1775 24.9904 0.2147 0.4583 0.5933 ||TEST: 1.1740 0.3181 0.6076 | 0.5861 0.5861 0.2304 | 0.1725 28.8692 24.9748 0.2200 0.4588 0.5915 | 115.2718
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.07534889 1.07532698 1.07530404 1.07527366 1.07528367 1.07529437
 1.07524951 1.07530284 1.0753403  1.07539039 1.0753668  1.07534825
 1.0753781  1.07540269 1.07546672 1.07540579 1.07541695 1.07542926
 1.07546649 1.07547985]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.07535865 1.07536246 1.07537609 1.07536173 1.07537524 1.07535832
 1.07537113 1.07535327 1.07535121 1.07536316 1.0753787  1.07536412
 1.07537015 1.07536103 1.07536452 1.07538432 1.07537647 1.07537532
 1.07537342 1.07538133]
[0. 0. 0.]
-----------end of analyzing the loss ratio:74.23088502883911
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9398f9480>
---------------------------------
SparseEpoch: [44][1/398]	Time 0.604	Data 0.000	Loss 1.2897	
SparseEpoch: [44][101/398]	Time 0.623	Data 0.000	Loss 1.5702	
SparseEpoch: [44][201/398]	Time 0.622	Data 0.000	Loss 0.9215	
SparseEpoch: [44][301/398]	Time 0.622	Data 0.000	Loss 1.3598	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.18960595 1.18969085 1.18962771 1.18964173 1.18963451 1.18963297
 1.18961146 1.18959275 1.18962919 1.18958044 1.18946411 1.18946895
 1.18935795 1.18908878 1.18916106 1.18923167 1.18921186 1.18896737
 1.18890363 1.18880026]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.18959372 1.18960081 1.18960654 1.18961639 1.189604   1.1896146
 1.18959336 1.18956618 1.18951682 1.1894731  1.18944619 1.18944299
 1.18942757 1.18942066 1.18944137 1.1894235  1.18943225 1.18943934
 1.18944432 1.18945216]
[0.5        0.         0.18421053]
-----------end of analyzing the loss ratio:74.12985062599182
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938c05150>
---------------------------------
SparseEpoch: [44][1/398]	Time 0.693	Data 0.000	Loss 1.4592	
SparseEpoch: [44][101/398]	Time 0.630	Data 0.000	Loss 1.2932	
SparseEpoch: [44][201/398]	Time 0.628	Data 0.000	Loss 1.8474	
SparseEpoch: [44][301/398]	Time 0.627	Data 0.000	Loss 2.0964	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.1796775  0.17967075 0.179674   0.17966067 0.17962878 0.17963148
 0.17962937 0.17962504 0.17962105 0.17962734 0.1796241  0.17962841
 0.1796208  0.17961733 0.17961559 0.17962241 0.17960708 0.17957885
 0.17960017 0.17959664]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.17964489 0.17961576 0.17960563 0.17960164 0.17963115 0.17962441
 0.17961627 0.17961835 0.17962239 0.17963826 0.17962881 0.17962661
 0.17962803 0.17961618 0.1796335  0.179627   0.17964414 0.17964191
 0.17962165 0.17959933]
[0.39473684 0.5        0.        ]
-----------end of analyzing the loss ratio:74.1916971206665
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938625360>
---------------------------------
SparseEpoch: [44][1/398]	Time 0.615	Data 0.000	Loss 1.9023	
SparseEpoch: [44][101/398]	Time 0.623	Data 0.000	Loss 3.1255	
SparseEpoch: [44][201/398]	Time 0.623	Data 0.000	Loss 2.2732	
SparseEpoch: [44][301/398]	Time 0.622	Data 0.000	Loss 2.7440	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.9963	
Epoch(adapt):{0} Loss 2.6553	
Epoch(adapt):{0} Loss 1.7749	
Epoch(adapt):{0} Loss 1.6620	
------------------the total time cost:1215.1950182914734
>>>>>meta updating
Epoch: 0044 | TRAIN: 1.0026 0.3832 0.6661 | 0.5069 0.5069 0.2291 | 0.1776 29.4355 25.4282 0.2015 0.4485 0.5880 ||TEST: 1.1567 0.3222 0.6161 | 0.6084 0.6084 0.2322 | 0.1729 29.0835 25.3396 0.2074 0.4507 0.5869 | 115.4068
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.907679   0.90763819 0.90765071 0.90753378 0.90752856 0.90754185
 0.9076141  0.9076351  0.90751036 0.90750218 0.90745128 0.90745994
 0.90740742 0.90731165 0.9072482  0.90714157 0.90712838 0.90710331
 0.90708554 0.90705251]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.9075298  0.90753552 0.90752398 0.90754089 0.90753319 0.90752801
 0.90752418 0.90750263 0.90748332 0.90745203 0.90743054 0.90744326
 0.90742074 0.90739486 0.90741916 0.90741676 0.90742934 0.90744011
 0.90744014 0.90741951]
[0.         0.5        0.18421053]
-----------end of analyzing the loss ratio:74.09669208526611
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938b442e0>
---------------------------------
SparseEpoch: [45][1/398]	Time 0.605	Data 0.000	Loss 1.7658	
SparseEpoch: [45][101/398]	Time 0.626	Data 0.000	Loss 1.8883	
SparseEpoch: [45][201/398]	Time 0.625	Data 0.000	Loss 2.1477	
SparseEpoch: [45][301/398]	Time 0.624	Data 0.000	Loss 1.7883	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.53143147 0.53140613 0.5312852  0.53132524 0.53121656 0.53113182
 0.53107083 0.53100412 0.53098227 0.53096836 0.53083394 0.53077745
 0.53077618 0.53072427 0.53059401 0.53047538 0.53047136 0.53038548
 0.53044736 0.53028852]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.53098266 0.53099001 0.53098314 0.53096555 0.53095295 0.53096501
 0.53095658 0.53094611 0.53092777 0.53087584 0.53087375 0.53085988
 0.53083872 0.53084325 0.53085551 0.53080448 0.53083294 0.53081871
 0.53080479 0.53079292]
[0.5 0.  0.5]
-----------end of analyzing the loss ratio:74.40229749679565
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9389d8460>
---------------------------------
SparseEpoch: [45][1/398]	Time 0.605	Data 0.000	Loss 1.8269	
SparseEpoch: [45][101/398]	Time 0.628	Data 0.000	Loss 2.2014	
SparseEpoch: [45][201/398]	Time 0.626	Data 0.000	Loss 1.5898	
SparseEpoch: [45][301/398]	Time 0.627	Data 0.000	Loss 3.1174	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.20921621 0.20907117 0.20898294 0.20881264 0.20866895 0.20855065
 0.20845743 0.2082684  0.20818129 0.20800974 0.20787612 0.20777164
 0.20765706 0.20754017 0.20733522 0.20732676 0.20723175 0.20712571
 0.2070129  0.20691186]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.208228   0.2081745  0.20814829 0.20812225 0.20807585 0.20804759
 0.2080353  0.20801941 0.20799282 0.2079429  0.20790918 0.20789537
 0.20786176 0.20787143 0.20785697 0.20783613 0.20782906 0.20780222
 0.20775723 0.20772198]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:74.25435209274292
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938d4f2e0>
---------------------------------
SparseEpoch: [45][1/398]	Time 0.604	Data 0.000	Loss 2.2484	
SparseEpoch: [45][101/398]	Time 0.621	Data 0.000	Loss 2.0242	
SparseEpoch: [45][201/398]	Time 0.624	Data 0.000	Loss 1.8102	
SparseEpoch: [45][301/398]	Time 0.625	Data 0.000	Loss 3.0041	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.4098	
Epoch(adapt):{0} Loss 2.9159	
Epoch(adapt):{0} Loss 1.7311	
Epoch(adapt):{0} Loss 1.4960	
------------------the total time cost:1215.3055565357208
>>>>>meta updating
Epoch: 0045 | TRAIN: 0.9886 0.3879 0.6672 | 0.4859 0.4859 0.2495 | 0.1731 28.8175 24.4508 0.2156 0.4664 0.6033 ||TEST: 1.1524 0.3288 0.6194 | 0.5673 0.5673 0.2404 | 0.1678 28.4305 24.4474 0.2208 0.4685 0.6026 | 115.5683
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.9417666  0.94177117 0.94176243 0.94175662 0.94175417 0.94179893
 0.94188153 0.94180133 0.9419544  0.94187534 0.94202283 0.94205901
 0.94196804 0.942057   0.94200259 0.94199566 0.94191588 0.94188432
 0.94186102 0.94184006]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.9419861  0.94198752 0.94196355 0.94194609 0.94193716 0.9419286
 0.94192312 0.94192777 0.94193195 0.94193709 0.94191978 0.94193574
 0.94193549 0.94194287 0.94194394 0.94195446 0.94194584 0.94195495
 0.94194867 0.94194073]
[0.         0.         0.02631579]
-----------end of analyzing the loss ratio:74.03198003768921
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938fc4130>
---------------------------------
SparseEpoch: [46][1/398]	Time 0.605	Data 0.000	Loss 1.2316	
SparseEpoch: [46][101/398]	Time 0.623	Data 0.000	Loss 1.4216	
SparseEpoch: [46][201/398]	Time 0.623	Data 0.000	Loss 1.1228	
SparseEpoch: [46][301/398]	Time 0.623	Data 0.000	Loss 0.9802	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.0142254  1.01423323 1.01418931 1.01414588 1.01428005 1.01413837
 1.01419134 1.01418027 1.01418196 1.01414967 1.01418655 1.01422192
 1.01413233 1.01415725 1.01416837 1.01410771 1.01402104 1.01413163
 1.01408533 1.01413959]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.01417868 1.0141878  1.01419052 1.0142261  1.01424438 1.01421944
 1.01422664 1.01423724 1.01423275 1.01420335 1.01419526 1.01421484
 1.01423264 1.01419725 1.0142041  1.01420214 1.01419048 1.01421798
 1.01421075 1.01421451]
[0.34210526 0.         0.        ]
-----------end of analyzing the loss ratio:74.48535132408142
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938b7c670>
---------------------------------
SparseEpoch: [46][1/398]	Time 0.616	Data 0.000	Loss 1.5192	
SparseEpoch: [46][101/398]	Time 0.625	Data 0.000	Loss 0.7873	
SparseEpoch: [46][201/398]	Time 0.625	Data 0.000	Loss 0.7473	
SparseEpoch: [46][301/398]	Time 0.625	Data 0.000	Loss 1.1132	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.17170042 0.17170057 0.17171749 0.17172114 0.17171269 0.17172987
 0.17171998 0.17172405 0.17172163 0.17172958 0.1717455  0.17174444
 0.17173341 0.17173414 0.1717256  0.17170295 0.17169844 0.17169089
 0.1717079  0.1716989 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.17172794 0.17173914 0.17172701 0.17171398 0.17171762 0.17171474
 0.17172137 0.17172583 0.17171172 0.17173198 0.17174187 0.17174082
 0.17172326 0.17171608 0.17170547 0.17170893 0.17171341 0.17173663
 0.17173776 0.17173787]
[0.39473684 0.23684211 0.        ]
-----------end of analyzing the loss ratio:74.20665526390076
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938f177c0>
---------------------------------
SparseEpoch: [46][1/398]	Time 0.671	Data 0.000	Loss 1.9148	
SparseEpoch: [46][101/398]	Time 0.626	Data 0.000	Loss 3.0319	
SparseEpoch: [46][201/398]	Time 0.627	Data 0.000	Loss 2.5551	
SparseEpoch: [46][301/398]	Time 0.624	Data 0.000	Loss 2.6377	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.5604	
Epoch(adapt):{0} Loss 1.1227	
Epoch(adapt):{0} Loss 1.8494	
Epoch(adapt):{0} Loss 1.4415	
------------------the total time cost:1215.0075616836548
>>>>>meta updating
Epoch: 0046 | TRAIN: 0.9548 0.3987 0.6795 | 0.4745 0.4745 0.2268 | 0.1761 29.1182 24.8999 0.2153 0.4596 0.5944 ||TEST: 1.1405 0.3327 0.6233 | 0.5758 0.5758 0.2302 | 0.1728 28.9205 25.0231 0.2179 0.4581 0.5904 | 115.4996
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.02990302 1.02986321 1.02985145 1.02981401 1.02982346 1.02979876
 1.02982237 1.0298463  1.02987516 1.02986999 1.02983323 1.02986037
 1.02986664 1.02989136 1.0299083  1.02990378 1.02991715 1.02995511
 1.0298295  1.02980398]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.02990854 1.02988483 1.02987013 1.02986068 1.02983816 1.02984011
 1.02985278 1.02984373 1.02986537 1.02986467 1.02984296 1.02985181
 1.02987687 1.0298502  1.02985662 1.02983788 1.02983668 1.02984073
 1.02984621 1.02985511]
[0.         0.         0.34210526]
-----------end of analyzing the loss ratio:74.17243552207947
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938c41c00>
---------------------------------
SparseEpoch: [47][1/398]	Time 0.608	Data 0.000	Loss 1.1909	
SparseEpoch: [47][101/398]	Time 0.625	Data 0.000	Loss 1.4320	
SparseEpoch: [47][201/398]	Time 0.626	Data 0.000	Loss 2.6228	
SparseEpoch: [47][301/398]	Time 0.626	Data 0.000	Loss 1.6620	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.55764001 0.55765569 0.55745729 0.55737357 0.55725239 0.55701429
 0.5566346  0.55626039 0.55595523 0.55564886 0.55555504 0.5553957
 0.55526696 0.5549928  0.55478289 0.55453962 0.5544605  0.55389511
 0.55370562 0.5533648 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.55561311 0.55560129 0.55558625 0.55556868 0.55558399 0.55554059
 0.55555528 0.55555167 0.55556714 0.55558856 0.55554571 0.55555797
 0.55555536 0.55556815 0.55556694 0.55559441 0.55558902 0.55554478
 0.55557491 0.55556449]
[0.5 0.  0. ]
-----------end of analyzing the loss ratio:74.3796374797821
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cca5e52ba30>
---------------------------------
SparseEpoch: [47][1/398]	Time 0.604	Data 0.000	Loss 1.3677	
SparseEpoch: [47][101/398]	Time 0.622	Data 0.000	Loss 1.3386	
SparseEpoch: [47][201/398]	Time 0.623	Data 0.000	Loss 1.2066	
SparseEpoch: [47][301/398]	Time 0.623	Data 0.000	Loss 1.2212	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.2109288  0.21092892 0.21091442 0.2108981  0.21085452 0.21084336
 0.210835   0.21081432 0.21079958 0.2108     0.21080692 0.21080046
 0.21077008 0.21075816 0.21074194 0.21073205 0.21072483 0.21071483
 0.21071343 0.21067601]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.21083264 0.21082829 0.21080495 0.2108096  0.21079912 0.21080009
 0.21079714 0.21080543 0.21080185 0.2108034  0.21080824 0.21077687
 0.21077223 0.21077113 0.21077058 0.21076171 0.21075847 0.21076652
 0.21076927 0.21075491]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:74.0958936214447
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9387c6c50>
---------------------------------
SparseEpoch: [47][1/398]	Time 0.609	Data 0.000	Loss 2.0492	
SparseEpoch: [47][101/398]	Time 0.626	Data 0.000	Loss 2.4043	
SparseEpoch: [47][201/398]	Time 0.627	Data 0.000	Loss 2.1843	
SparseEpoch: [47][301/398]	Time 0.626	Data 0.000	Loss 2.8866	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 2.2790	
Epoch(adapt):{0} Loss 1.6156	
Epoch(adapt):{0} Loss 1.8691	
Epoch(adapt):{0} Loss 1.5836	
------------------the total time cost:1216.108153104782
>>>>>meta updating
Epoch: 0047 | TRAIN: 0.9412 0.4161 0.6826 | 0.4870 0.4870 0.2309 | 0.1742 28.9742 24.6982 0.2124 0.4633 0.6003 ||TEST: 1.1461 0.3392 0.6226 | 0.5848 0.5848 0.2280 | 0.1707 28.7822 24.9062 0.2144 0.4593 0.5947 | 115.4911
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.0233153  1.02330884 1.02329295 1.02325828 1.02318857 1.02311612
 1.02307663 1.02310629 1.02306964 1.02300066 1.02294214 1.02285699
 1.02271633 1.02270253 1.02268431 1.02274932 1.02266066 1.02261608
 1.02256742 1.02255352]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.02287506 1.02288687 1.02290475 1.02292622 1.02295985 1.02292915
 1.02294894 1.02292616 1.02296443 1.02296975 1.02299065 1.02299106
 1.02301154 1.02298942 1.0230014  1.02299545 1.02300122 1.02303054
 1.02305877 1.02309266]
[0.  0.5 0. ]
-----------end of analyzing the loss ratio:74.27813744544983
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938753fd0>
---------------------------------
SparseEpoch: [48][1/398]	Time 0.616	Data 0.000	Loss 1.8087	
SparseEpoch: [48][101/398]	Time 0.623	Data 0.000	Loss 1.3676	
SparseEpoch: [48][201/398]	Time 0.621	Data 0.000	Loss 1.3244	
SparseEpoch: [48][301/398]	Time 0.622	Data 0.000	Loss 1.5358	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.51567111 0.51573193 0.51577793 0.5157712  0.51575762 0.51576658
 0.51588064 0.51591362 0.51594758 0.51593989 0.51601484 0.51599402
 0.51594642 0.51598378 0.51601754 0.51604488 0.5160666  0.51622856
 0.51624494 0.51630874]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.51596794 0.51596625 0.51596501 0.51594391 0.51595222 0.51596335
 0.51594627 0.51594507 0.51592854 0.51595231 0.51598041 0.51599489
 0.51598251 0.51598397 0.5159742  0.51598567 0.51598525 0.51598605
 0.51593383 0.5159307 ]
[0. 0. 0.]
-----------end of analyzing the loss ratio:74.2399320602417
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9389da950>
---------------------------------
SparseEpoch: [48][1/398]	Time 0.607	Data 0.000	Loss 0.3892	
SparseEpoch: [48][101/398]	Time 0.624	Data 0.000	Loss 1.2776	
SparseEpoch: [48][201/398]	Time 0.623	Data 0.000	Loss 1.0353	
SparseEpoch: [48][301/398]	Time 0.623	Data 0.000	Loss 0.4288	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.21927236 0.21922852 0.2191921  0.21918605 0.21915708 0.21915156
 0.21909182 0.21901413 0.21898497 0.21892215 0.21890442 0.21884368
 0.21880054 0.21882079 0.21878638 0.21875058 0.21869513 0.21863403
 0.21856866 0.21850939]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.21902542 0.2190258  0.2190182  0.21901349 0.21900261 0.21898041
 0.21895804 0.21893072 0.21892772 0.21891522 0.21890752 0.21887933
 0.21885722 0.21886194 0.2188346  0.2188355  0.21882396 0.21879542
 0.21877384 0.21876147]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:74.17391967773438
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938751ff0>
---------------------------------
SparseEpoch: [48][1/398]	Time 0.608	Data 0.000	Loss 1.8716	
SparseEpoch: [48][101/398]	Time 0.621	Data 0.000	Loss 2.5324	
SparseEpoch: [48][201/398]	Time 0.623	Data 0.000	Loss 4.0396	
SparseEpoch: [48][301/398]	Time 0.621	Data 0.000	Loss 3.1622	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.7849	
Epoch(adapt):{0} Loss 1.4668	
Epoch(adapt):{0} Loss 1.7083	
Epoch(adapt):{0} Loss 2.2004	
------------------the total time cost:1215.2860145568848
>>>>>meta updating
Epoch: 0048 | TRAIN: 0.9616 0.4002 0.6816 | 0.4668 0.4668 0.2203 | 0.1784 29.5003 25.5755 0.2038 0.4457 0.5837 ||TEST: 1.1406 0.3244 0.6228 | 0.5693 0.5693 0.2269 | 0.1754 29.2736 25.5833 0.2095 0.4478 0.5818 | 115.2882
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.91100784 0.91101704 0.91096664 0.91100605 0.91100644 0.91107059
 0.91110513 0.91112174 0.91106754 0.91104008 0.91106701 0.91109724
 0.91111419 0.91114091 0.91112924 0.91114802 0.9110954  0.91116514
 0.91114581 0.9111858 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.91105893 0.91106699 0.91105884 0.91105638 0.91106901 0.91105859
 0.91106478 0.91107046 0.91104394 0.9110619  0.91105669 0.91105347
 0.91105382 0.91103026 0.91102649 0.91103396 0.91104343 0.91105952
 0.91107038 0.91107462]
[0.         0.         0.23684211]
-----------end of analyzing the loss ratio:74.2681314945221
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938fc7400>
---------------------------------
SparseEpoch: [49][1/398]	Time 0.605	Data 0.000	Loss 1.1341	
SparseEpoch: [49][101/398]	Time 0.617	Data 0.000	Loss 1.4088	
SparseEpoch: [49][201/398]	Time 0.624	Data 0.000	Loss 1.4208	
SparseEpoch: [49][301/398]	Time 0.625	Data 0.000	Loss 1.3739	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.07814195 1.0779871  1.07788392 1.07785578 1.07775545 1.0776805
 1.07774348 1.07759575 1.07745546 1.07740486 1.07729392 1.077241
 1.0771152  1.07710357 1.07719951 1.07718573 1.07703162 1.07696273
 1.07694656 1.07687393]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.07741199 1.07736298 1.07740886 1.07737563 1.07735655 1.07735603
 1.07738348 1.07739915 1.07734134 1.07733385 1.07734429 1.07735529
 1.07736427 1.07735952 1.07734686 1.07737207 1.07737579 1.07742514
 1.07742325 1.07735238]
[0.5 0.  0. ]
-----------end of analyzing the loss ratio:74.35028743743896
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9384a5030>
---------------------------------
SparseEpoch: [49][1/398]	Time 0.608	Data 0.000	Loss 0.8221	
SparseEpoch: [49][101/398]	Time 0.625	Data 0.000	Loss 1.1320	
SparseEpoch: [49][201/398]	Time 0.621	Data 0.000	Loss 1.2992	
SparseEpoch: [49][301/398]	Time 0.621	Data 0.000	Loss 0.9375	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.18243806 0.18245699 0.18238669 0.18243946 0.18244352 0.18242695
 0.18238748 0.18230146 0.182256   0.18220397 0.18213933 0.18214425
 0.18210502 0.18208015 0.1820939  0.18204471 0.18197699 0.18196666
 0.18191623 0.18190278]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.1822621  0.18225719 0.182229   0.1822267  0.18219138 0.18221543
 0.1821952  0.18219954 0.18218886 0.1821803  0.18214507 0.18214545
 0.18213055 0.1821098  0.18210418 0.18211277 0.18209252 0.18209763
 0.18211354 0.18211513]
[0.5        0.34210526 0.        ]
-----------end of analyzing the loss ratio:74.6118848323822
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938505870>
---------------------------------
SparseEpoch: [49][1/398]	Time 0.605	Data 0.000	Loss 2.3804	
SparseEpoch: [49][101/398]	Time 0.624	Data 0.000	Loss 2.5891	
SparseEpoch: [49][201/398]	Time 0.622	Data 0.000	Loss 2.0795	
SparseEpoch: [49][301/398]	Time 0.623	Data 0.000	Loss 2.5280	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.6773	
Epoch(adapt):{0} Loss 1.3029	
Epoch(adapt):{0} Loss 1.4781	
Epoch(adapt):{0} Loss 1.9769	
------------------the total time cost:1214.8790428638458
>>>>>meta updating
Epoch: 0049 | TRAIN: 0.9372 0.4167 0.6879 | 0.4591 0.4591 0.2227 | 0.1728 28.8712 24.6935 0.2118 0.4623 0.6005 ||TEST: 1.1286 0.3399 0.6288 | 0.5617 0.5617 0.2287 | 0.1686 28.5432 24.6362 0.2184 0.4643 0.5993 | 115.4226
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.98941893 0.98948631 0.98952183 0.98952944 0.98958072 0.98961502
 0.98964747 0.98975887 0.98979105 0.98984122 0.98984559 0.98983226
 0.98977517 0.9898013  0.98978857 0.98983454 0.98987135 0.98992516
 0.98992441 0.98992048]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.98988023 0.98988011 0.98984556 0.98985114 0.98982334 0.98983299
 0.98983825 0.98984522 0.98985329 0.98983171 0.98983029 0.98982087
 0.9898199  0.98980935 0.98980305 0.9898066  0.98981712 0.98981256
 0.98980695 0.9898343 ]
[0.         0.         0.23684211]
-----------end of analyzing the loss ratio:74.43966937065125
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cca5e4f4a00>
---------------------------------
SparseEpoch: [50][1/398]	Time 0.620	Data 0.000	Loss 1.3392	
SparseEpoch: [50][101/398]	Time 0.622	Data 0.000	Loss 1.8018	
SparseEpoch: [50][201/398]	Time 0.624	Data 0.000	Loss 1.6858	
SparseEpoch: [50][301/398]	Time 0.626	Data 0.000	Loss 1.4992	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.7710037  0.77098069 0.77110938 0.77108702 0.77110964 0.77129236
 0.7714554  0.77161102 0.77170292 0.77185894 0.77193623 0.77188794
 0.7719706  0.77208384 0.77213905 0.77229775 0.77232347 0.77243565
 0.77249436 0.77249989]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.7718648  0.77184724 0.77184762 0.77185304 0.77186214 0.77187732
 0.7718654  0.77187677 0.77189351 0.77185392 0.77187637 0.77186714
 0.77185556 0.77182476 0.77182466 0.77179719 0.77182234 0.77184929
 0.77185851 0.77186141]
[0.         0.         0.28947368]
-----------end of analyzing the loss ratio:74.30005502700806
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cca5e213400>
---------------------------------
SparseEpoch: [50][1/398]	Time 0.616	Data 0.000	Loss 1.4012	
SparseEpoch: [50][101/398]	Time 0.623	Data 0.000	Loss 0.7923	
SparseEpoch: [50][201/398]	Time 0.624	Data 0.000	Loss 1.0215	
SparseEpoch: [50][301/398]	Time 0.623	Data 0.000	Loss 0.8269	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.18216361 0.18214289 0.1821178  0.18213792 0.18213414 0.18213435
 0.18213283 0.18210856 0.18210196 0.18208752 0.18205959 0.18206668
 0.18204232 0.18204789 0.18201709 0.1820117  0.18199168 0.18198609
 0.18196648 0.18195975]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.18210412 0.18209024 0.18209903 0.18209597 0.18208857 0.18208512
 0.18208447 0.18208723 0.18208156 0.18207567 0.18207386 0.18207088
 0.18206645 0.18206275 0.18205318 0.1820654  0.18205606 0.18204374
 0.18204044 0.18204285]
[0.5        0.44736842 0.        ]
-----------end of analyzing the loss ratio:74.25607061386108
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938a8c940>
---------------------------------
SparseEpoch: [50][1/398]	Time 0.605	Data 0.000	Loss 2.9092	
SparseEpoch: [50][101/398]	Time 0.624	Data 0.000	Loss 2.5019	
SparseEpoch: [50][201/398]	Time 0.623	Data 0.000	Loss 2.5178	
SparseEpoch: [50][301/398]	Time 0.624	Data 0.000	Loss 2.6640	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.8699	
Epoch(adapt):{0} Loss 1.6122	
Epoch(adapt):{0} Loss 1.6064	
Epoch(adapt):{0} Loss 1.7396	
------------------the total time cost:1216.052580833435
>>>>>meta updating
Epoch: 0050 | TRAIN: 0.9505 0.4133 0.6837 | 0.4836 0.4836 0.2274 | 0.1702 28.5348 24.0426 0.2154 0.4754 0.6132 ||TEST: 1.1369 0.3356 0.6262 | 0.5838 0.5838 0.2290 | 0.1669 28.2961 24.1010 0.2206 0.4750 0.6103 | 115.5262
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.92968462 0.92969209 0.92965449 0.92967309 0.92948744 0.92942545
 0.92928059 0.92921121 0.9290867  0.9289872  0.92895188 0.92886626
 0.92876275 0.9288314  0.92871459 0.92876992 0.92882044 0.92878347
 0.92875788 0.92868124]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.92898624 0.92898291 0.92899845 0.92900624 0.92899264 0.92897261
 0.92897397 0.92895398 0.92892662 0.92892941 0.92893858 0.92894703
 0.92893978 0.92894389 0.92894003 0.92893275 0.92891728 0.92891892
 0.92891894 0.92894658]
[0.         0.5        0.34210526]
-----------end of analyzing the loss ratio:74.30193209648132
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc93997c850>
---------------------------------
SparseEpoch: [51][1/398]	Time 0.609	Data 0.000	Loss 1.8634	
SparseEpoch: [51][101/398]	Time 0.625	Data 0.000	Loss 2.6142	
SparseEpoch: [51][201/398]	Time 0.626	Data 0.000	Loss 1.6143	
SparseEpoch: [51][301/398]	Time 0.626	Data 0.000	Loss 3.0346	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.61477839 0.614701   0.61468504 0.61488407 0.61488007 0.61485748
 0.61491475 0.61487315 0.61485893 0.61486947 0.61483048 0.61486578
 0.61490397 0.61487209 0.61485191 0.61499741 0.61501729 0.61495168
 0.61490054 0.61495268]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.61484997 0.61487778 0.61485984 0.61486447 0.61487928 0.61486995
 0.61486924 0.6148727  0.61484208 0.61482669 0.61487157 0.61484022
 0.61485351 0.61485564 0.61483871 0.61488271 0.61487288 0.61486193
 0.61485567 0.6148646 ]
[0. 0. 0.]
-----------end of analyzing the loss ratio:74.32463717460632
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9384fd4e0>
---------------------------------
SparseEpoch: [51][1/398]	Time 0.606	Data 0.000	Loss 0.5579	
SparseEpoch: [51][101/398]	Time 0.624	Data 0.000	Loss 0.7168	
SparseEpoch: [51][201/398]	Time 0.623	Data 0.000	Loss 0.4580	
SparseEpoch: [51][301/398]	Time 0.623	Data 0.000	Loss 0.4909	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.22192668 0.22180733 0.22173811 0.22168197 0.2216065  0.22156544
 0.22153566 0.22148473 0.2213847  0.22138654 0.2213533  0.22125034
 0.22116785 0.22107301 0.22102365 0.22095354 0.22088425 0.22081264
 0.22066325 0.22060836]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.22148398 0.22148393 0.22149992 0.22148104 0.22145512 0.22141593
 0.22137898 0.22134659 0.22136027 0.22139478 0.22139196 0.22133558
 0.22128751 0.22128497 0.22124615 0.22120203 0.22117389 0.2211457
 0.22112209 0.22109976]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:74.5798225402832
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938dd8940>
---------------------------------
SparseEpoch: [51][1/398]	Time 0.606	Data 0.000	Loss 2.5044	
SparseEpoch: [51][101/398]	Time 0.621	Data 0.000	Loss 2.2335	
SparseEpoch: [51][201/398]	Time 0.621	Data 0.000	Loss 3.3803	
SparseEpoch: [51][301/398]	Time 0.623	Data 0.000	Loss 2.9565	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.4133	
Epoch(adapt):{0} Loss 1.3957	
Epoch(adapt):{0} Loss 1.8999	
Epoch(adapt):{0} Loss 1.4036	
------------------the total time cost:1215.4879825115204
>>>>>meta updating
Epoch: 0051 | TRAIN: 0.9326 0.4211 0.6934 | 0.4661 0.4661 0.2212 | 0.1718 28.7483 24.5842 0.2155 0.4650 0.6024 ||TEST: 1.1313 0.3340 0.6268 | 0.5672 0.5672 0.2247 | 0.1690 28.5588 24.6262 0.2201 0.4647 0.5993 | 115.2653
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.8300199  0.83005792 0.83013385 0.83015128 0.83015402 0.83018422
 0.83016309 0.83021643 0.83022303 0.83023367 0.83024556 0.83021691
 0.83017519 0.83019119 0.83021119 0.83021518 0.83020335 0.83022014
 0.83023967 0.83027835]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.83022227 0.83023007 0.83025042 0.83025118 0.83022783 0.83022512
 0.83021964 0.83022988 0.83024912 0.8302485  0.83024515 0.83024102
 0.83024803 0.83024496 0.83024514 0.83023032 0.83022378 0.83020093
 0.83020758 0.83021707]
[0.         0.         0.39473684]
-----------end of analyzing the loss ratio:74.23987793922424
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938a49ba0>
---------------------------------
SparseEpoch: [52][1/398]	Time 0.604	Data 0.000	Loss 1.5593	
SparseEpoch: [52][101/398]	Time 0.625	Data 0.000	Loss 1.4933	
SparseEpoch: [52][201/398]	Time 0.623	Data 0.000	Loss 1.5178	
SparseEpoch: [52][301/398]	Time 0.625	Data 0.000	Loss 1.4917	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.6991842  0.69911398 0.69910447 0.69911618 0.69915894 0.69920458
 0.69916056 0.69915057 0.6990769  0.69900811 0.69907752 0.69906123
 0.6991334  0.69909056 0.69906601 0.69911119 0.69914136 0.69918298
 0.6992144  0.69922149]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.69906372 0.6990806  0.69906988 0.69903781 0.69905789 0.69905735
 0.69905693 0.69905707 0.69899278 0.69897149 0.69901502 0.69901551
 0.69901831 0.69908702 0.69908781 0.69910268 0.69912137 0.69910775
 0.69910268 0.69907817]
[0. 0. 0.]
-----------end of analyzing the loss ratio:74.38018226623535
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938b15d80>
---------------------------------
SparseEpoch: [52][1/398]	Time 0.603	Data 0.000	Loss 0.7446	
SparseEpoch: [52][101/398]	Time 0.626	Data 0.000	Loss 0.4358	
SparseEpoch: [52][201/398]	Time 0.624	Data 0.000	Loss 0.4300	
SparseEpoch: [52][301/398]	Time 0.623	Data 0.000	Loss 0.4755	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.22319331 0.22308325 0.22293594 0.22274842 0.22255911 0.22238544
 0.22224035 0.2221469  0.22199944 0.22186906 0.22174802 0.22152092
 0.22136252 0.22131726 0.22111696 0.22091914 0.22078335 0.22062597
 0.2204196  0.22024139]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.22204217 0.22204278 0.22202503 0.22199581 0.2219548  0.22196171
 0.2219003  0.22187792 0.22184566 0.22183399 0.22177282 0.22177374
 0.22174979 0.22170637 0.22166035 0.22160931 0.2216082  0.22156547
 0.22150758 0.22145967]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:74.2688684463501
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938dd8c70>
---------------------------------
SparseEpoch: [52][1/398]	Time 0.605	Data 0.000	Loss 2.7156	
SparseEpoch: [52][101/398]	Time 0.623	Data 0.000	Loss 2.8895	
SparseEpoch: [52][201/398]	Time 0.624	Data 0.000	Loss 2.3791	
SparseEpoch: [52][301/398]	Time 0.623	Data 0.000	Loss 1.9406	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.7086	
Epoch(adapt):{0} Loss 2.1092	
Epoch(adapt):{0} Loss 2.3440	
Epoch(adapt):{0} Loss 1.1066	
------------------the total time cost:1214.9752190113068
>>>>>meta updating
Epoch: 0052 | TRAIN: 0.9321 0.4311 0.6884 | 0.4517 0.4517 0.2086 | 0.1726 28.8402 24.6042 0.2130 0.4639 0.6013 ||TEST: 1.1247 0.3496 0.6271 | 0.5686 0.5686 0.2202 | 0.1672 28.4183 24.5284 0.2202 0.4658 0.6015 | 115.3315
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.83312543 0.83306887 0.83306174 0.8329747  0.83294262 0.83287106
 0.83278595 0.83278815 0.83267741 0.8326305  0.83255134 0.83250543
 0.83241466 0.83230485 0.83232069 0.83231923 0.83229904 0.8323555
 0.8323325  0.83233744]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.83259385 0.83259489 0.83255323 0.83254448 0.83254563 0.83254687
 0.83259174 0.83260772 0.83261594 0.83259629 0.83260081 0.83260485
 0.83258778 0.83257856 0.83258425 0.83257947 0.83257817 0.8325565
 0.83257138 0.83257087]
[0.         0.34210526 0.        ]
-----------end of analyzing the loss ratio:74.17768454551697
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cca5e3b4880>
---------------------------------
SparseEpoch: [53][1/398]	Time 0.605	Data 0.000	Loss 0.8886	
SparseEpoch: [53][101/398]	Time 0.629	Data 0.000	Loss 1.2451	
SparseEpoch: [53][201/398]	Time 0.627	Data 0.000	Loss 1.2244	
SparseEpoch: [53][301/398]	Time 0.626	Data 0.000	Loss 1.0459	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.60760976 0.60764123 0.60778417 0.60795608 0.60800236 0.60801468
 0.60802585 0.60803231 0.60815896 0.6082424  0.60800201 0.6079701
 0.60800468 0.60795139 0.60791628 0.60783144 0.60804347 0.60816854
 0.60832597 0.60842922]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.6081342  0.60812637 0.60815626 0.60816407 0.60817033 0.60817744
 0.60816061 0.60816156 0.60814317 0.60816646 0.60815209 0.60818908
 0.60819874 0.60819323 0.60817586 0.60810601 0.60808245 0.6080489
 0.60806906 0.60806178]
[0.         0.         0.39473684]
-----------end of analyzing the loss ratio:74.27802205085754
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938b69180>
---------------------------------
SparseEpoch: [53][1/398]	Time 0.608	Data 0.000	Loss 1.5227	
SparseEpoch: [53][101/398]	Time 0.620	Data 0.000	Loss 1.5121	
SparseEpoch: [53][201/398]	Time 0.622	Data 0.000	Loss 1.2295	
SparseEpoch: [53][301/398]	Time 0.622	Data 0.000	Loss 1.2025	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.21199247 0.21197642 0.21196036 0.21198843 0.21195819 0.21192512
 0.21192157 0.21189782 0.21186708 0.21183757 0.21183178 0.21184795
 0.21182014 0.21180508 0.21178986 0.21177517 0.21178045 0.21176214
 0.21174912 0.21171964]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.2119205  0.21192262 0.21190842 0.21190051 0.21188647 0.21187367
 0.21186648 0.21185699 0.21185877 0.211838   0.21183418 0.21183484
 0.21182726 0.21182685 0.21181971 0.21180868 0.21180876 0.21180004
 0.21180214 0.21179886]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:74.44239711761475
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938627310>
---------------------------------
SparseEpoch: [53][1/398]	Time 0.609	Data 0.000	Loss 2.1089	
SparseEpoch: [53][101/398]	Time 0.621	Data 0.000	Loss 2.8104	
SparseEpoch: [53][201/398]	Time 0.621	Data 0.000	Loss 2.9434	
SparseEpoch: [53][301/398]	Time 0.622	Data 0.000	Loss 2.3442	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.6502	
Epoch(adapt):{0} Loss 1.0798	
Epoch(adapt):{0} Loss 1.0511	
Epoch(adapt):{0} Loss 1.8886	
------------------the total time cost:1215.0177688598633
>>>>>meta updating
Epoch: 0053 | TRAIN: 0.9197 0.4293 0.6970 | 0.4672 0.4672 0.2183 | 0.1695 28.5178 24.2071 0.2169 0.4719 0.6092 ||TEST: 1.1193 0.3458 0.6316 | 0.5745 0.5745 0.2254 | 0.1665 28.2989 24.2617 0.2212 0.4717 0.6067 | 115.9519
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.8586396  0.85865275 0.85875209 0.85873584 0.85875727 0.85881543
 0.85876293 0.85875208 0.85879849 0.85881752 0.85884055 0.85884934
 0.85891496 0.85888669 0.85883861 0.85887257 0.85886247 0.85893296
 0.85890663 0.85889583]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.85878398 0.85877067 0.85878896 0.85877558 0.85880166 0.85880408
 0.85880261 0.85883372 0.85880144 0.85879543 0.85881171 0.85878848
 0.85878387 0.85875025 0.85875835 0.85875086 0.85878338 0.85883241
 0.85884556 0.85888407]
[0.         0.         0.18421053]
-----------end of analyzing the loss ratio:74.34610152244568
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938397670>
---------------------------------
SparseEpoch: [54][1/398]	Time 0.604	Data 0.000	Loss 1.1721	
SparseEpoch: [54][101/398]	Time 0.625	Data 0.000	Loss 0.8124	
SparseEpoch: [54][201/398]	Time 0.626	Data 0.000	Loss 1.2013	
SparseEpoch: [54][301/398]	Time 0.625	Data 0.000	Loss 1.1720	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.69811545 0.69912211 0.69991614 0.70100768 0.70194309 0.70261136
 0.70373139 0.70457875 0.70531764 0.70633873 0.70721261 0.70820087
 0.70899029 0.70989288 0.71090419 0.71139817 0.71227438 0.7132408
 0.71384024 0.71442503]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.70648445 0.70655296 0.70658882 0.70656283 0.70651283 0.70654657
 0.70655153 0.70656154 0.70653919 0.70656848 0.70655164 0.70659803
 0.70662746 0.70662594 0.70663793 0.70685079 0.70693218 0.70706763
 0.70711083 0.70714045]
[0. 0. 0.]
-----------end of analyzing the loss ratio:74.18372201919556
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9383977f0>
---------------------------------
SparseEpoch: [54][1/398]	Time 0.603	Data 0.000	Loss 0.4188	
SparseEpoch: [54][101/398]	Time 0.621	Data 0.000	Loss 0.3044	
SparseEpoch: [54][201/398]	Time 0.623	Data 0.000	Loss 0.5655	
SparseEpoch: [54][301/398]	Time 0.622	Data 0.000	Loss 0.7110	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.20052522 0.20048618 0.20043099 0.20036047 0.20031713 0.20024092
 0.20013977 0.2000102  0.19998056 0.1999222  0.1998841  0.19984653
 0.19983757 0.19980982 0.19980918 0.19980674 0.19976729 0.19975758
 0.19970765 0.19967754]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.1999723  0.19996169 0.19993599 0.19993291 0.19993062 0.19992042
 0.19990707 0.19990835 0.19990544 0.1999198  0.199924   0.19991857
 0.19991174 0.19988347 0.19988351 0.19988697 0.19986843 0.19985233
 0.19983878 0.19984261]
[0.5        0.44736842 0.        ]
-----------end of analyzing the loss ratio:74.3064911365509
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938d4d870>
---------------------------------
SparseEpoch: [54][1/398]	Time 0.605	Data 0.000	Loss 2.1912	
SparseEpoch: [54][101/398]	Time 0.624	Data 0.000	Loss 2.5339	
SparseEpoch: [54][201/398]	Time 0.624	Data 0.000	Loss 2.1633	
SparseEpoch: [54][301/398]	Time 0.625	Data 0.000	Loss 2.3345	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 2.0614	
Epoch(adapt):{0} Loss 2.1888	
Epoch(adapt):{0} Loss 1.4919	
Epoch(adapt):{0} Loss 1.6402	
------------------the total time cost:1216.4945216178894
>>>>>meta updating
Epoch: 0054 | TRAIN: 0.9312 0.4210 0.6895 | 0.4559 0.4559 0.2195 | 0.1698 28.4194 23.9815 0.2227 0.4787 0.6138 ||TEST: 1.1263 0.3397 0.6276 | 0.5691 0.5691 0.2252 | 0.1663 28.1951 24.0218 0.2262 0.4764 0.6108 | 115.6015
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.7731118  0.77311872 0.77313678 0.77309994 0.77310039 0.77311191
 0.77306151 0.77305329 0.77304399 0.77305518 0.7730073  0.77301424
 0.77300429 0.77297488 0.77302503 0.77305024 0.77308236 0.77308335
 0.77306163 0.77305006]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.77307256 0.77305182 0.77305179 0.77304882 0.77306237 0.77306131
 0.77305893 0.77305099 0.77304416 0.77304203 0.77303637 0.77301872
 0.77300444 0.77301783 0.77302254 0.77303212 0.77303059 0.7730338
 0.77303219 0.77303339]
[0.         0.18421053 0.13157895]
-----------end of analyzing the loss ratio:74.45952892303467
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938ce3df0>
---------------------------------
SparseEpoch: [55][1/398]	Time 0.608	Data 0.000	Loss 1.4266	
SparseEpoch: [55][101/398]	Time 0.624	Data 0.000	Loss 1.6022	
SparseEpoch: [55][201/398]	Time 0.627	Data 0.000	Loss 1.2752	
SparseEpoch: [55][301/398]	Time 0.627	Data 0.000	Loss 1.4316	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.51055098 0.51034313 0.51016028 0.51001739 0.5098124  0.50966026
 0.50946487 0.50941945 0.50932866 0.5092999  0.50908114 0.50894077
 0.50884165 0.50867631 0.50844035 0.50840388 0.50843489 0.50854188
 0.50842332 0.50829448]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.50923889 0.50922036 0.50920814 0.50923803 0.50923785 0.509231
 0.50923825 0.50922623 0.50924275 0.50923734 0.50925401 0.50924393
 0.5092209  0.50919716 0.50917544 0.50915481 0.50911956 0.50910462
 0.5091071  0.50912901]
[0.5        0.         0.39473684]
-----------end of analyzing the loss ratio:74.27144026756287
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938835ed0>
---------------------------------
SparseEpoch: [55][1/398]	Time 0.606	Data 0.000	Loss 2.1787	
SparseEpoch: [55][101/398]	Time 0.623	Data 0.000	Loss 1.4228	
SparseEpoch: [55][201/398]	Time 0.623	Data 0.000	Loss 2.0313	
SparseEpoch: [55][301/398]	Time 0.622	Data 0.000	Loss 1.2266	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.19107912 0.19107426 0.19107562 0.19104648 0.19107754 0.19106474
 0.19105334 0.19107449 0.19104368 0.19102088 0.19101476 0.19100897
 0.19097251 0.19098598 0.19098655 0.19098917 0.19098756 0.19095937
 0.19095039 0.19092212]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.19108381 0.19107637 0.19107152 0.19106278 0.1910535  0.19104478
 0.19103065 0.19102696 0.19102885 0.19102155 0.19101803 0.19101275
 0.19101242 0.19100578 0.19101341 0.19099702 0.19099077 0.1909907
 0.19098551 0.19098194]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:74.51597833633423
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938e59450>
---------------------------------
SparseEpoch: [55][1/398]	Time 0.609	Data 0.000	Loss 2.2109	
SparseEpoch: [55][101/398]	Time 0.629	Data 0.000	Loss 2.6628	
SparseEpoch: [55][201/398]	Time 0.627	Data 0.000	Loss 2.7312	
SparseEpoch: [55][301/398]	Time 0.624	Data 0.000	Loss 1.7846	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.5127	
Epoch(adapt):{0} Loss 1.4471	
Epoch(adapt):{0} Loss 1.7571	
Epoch(adapt):{0} Loss 1.7651	
------------------the total time cost:1216.8976261615753
>>>>>meta updating
Epoch: 0055 | TRAIN: 0.8929 0.4350 0.7007 | 0.4577 0.4577 0.2111 | 0.1669 28.2036 23.8165 0.2229 0.4801 0.6165 ||TEST: 1.1231 0.3461 0.6298 | 0.5701 0.5701 0.2218 | 0.1641 28.0515 24.0052 0.2250 0.4763 0.6117 | 115.8596
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.84268036 0.84250491 0.84253152 0.84247729 0.84235362 0.84214995
 0.84216083 0.84206355 0.84201403 0.84211372 0.84208781 0.84229426
 0.84233908 0.8425459  0.84244257 0.84248489 0.8424421  0.84239393
 0.84221895 0.84212177]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.84210269 0.84209101 0.84217119 0.84211668 0.84207858 0.84214606
 0.84218077 0.84215908 0.84217761 0.84220134 0.84210998 0.84203394
 0.8420454  0.84207556 0.84205681 0.84204175 0.84211711 0.84211957
 0.84215373 0.84227547]
[0.         0.         0.07894737]
-----------end of analyzing the loss ratio:74.44440293312073
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9398d2830>
---------------------------------
SparseEpoch: [56][1/398]	Time 0.615	Data 0.000	Loss 0.8647	
SparseEpoch: [56][101/398]	Time 0.624	Data 0.000	Loss 0.9719	
SparseEpoch: [56][201/398]	Time 0.624	Data 0.000	Loss 0.9559	
SparseEpoch: [56][301/398]	Time 0.624	Data 0.000	Loss 1.2423	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.78324282 0.78314433 0.7829441  0.7829655  0.78282847 0.78295686
 0.7827841  0.78269311 0.78261144 0.78247356 0.78241503 0.78253806
 0.7826807  0.78275638 0.78263921 0.78250458 0.78232661 0.78209569
 0.78209504 0.78211307]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.7825222  0.7825069  0.78249608 0.7824957  0.78246928 0.78245522
 0.78247576 0.78248935 0.78251675 0.78249185 0.78247285 0.78245685
 0.78245516 0.78245741 0.78245952 0.78244818 0.78250287 0.78250225
 0.78255471 0.78256946]
[0.44736842 0.         0.28947368]
-----------end of analyzing the loss ratio:74.51140260696411
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938394670>
---------------------------------
SparseEpoch: [56][1/398]	Time 0.606	Data 0.000	Loss 1.8803	
SparseEpoch: [56][101/398]	Time 0.623	Data 0.000	Loss 2.1371	
SparseEpoch: [56][201/398]	Time 0.624	Data 0.000	Loss 1.1959	
SparseEpoch: [56][301/398]	Time 0.624	Data 0.000	Loss 1.1564	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.18340741 0.18338746 0.18336815 0.1833038  0.18329991 0.18328399
 0.18327428 0.18328442 0.18325064 0.18325802 0.18326977 0.18322494
 0.18316999 0.18314806 0.18311155 0.18306693 0.18300999 0.18302156
 0.18300411 0.18300279]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.18322287 0.18323084 0.18323703 0.18323733 0.1832476  0.18326519
 0.18325174 0.18325595 0.18326235 0.18326409 0.18328468 0.1832878
 0.18327969 0.18326756 0.18327588 0.18325646 0.1832512  0.18322906
 0.18323458 0.18322043]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:74.44860911369324
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9384a4d00>
---------------------------------
SparseEpoch: [56][1/398]	Time 0.608	Data 0.000	Loss 2.1234	
SparseEpoch: [56][101/398]	Time 0.625	Data 0.000	Loss 2.3544	
SparseEpoch: [56][201/398]	Time 0.624	Data 0.000	Loss 3.3501	
SparseEpoch: [56][301/398]	Time 0.622	Data 0.000	Loss 1.8805	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 2.0250	
Epoch(adapt):{0} Loss 1.3935	
Epoch(adapt):{0} Loss 1.5325	
Epoch(adapt):{0} Loss 1.4700	
------------------the total time cost:1214.12424826622
>>>>>meta updating
Epoch: 0056 | TRAIN: 0.8704 0.4450 0.7051 | 0.4488 0.4488 0.2186 | 0.1645 27.8618 23.3016 0.2309 0.4899 0.6252 ||TEST: 1.1207 0.3530 0.6336 | 0.5577 0.5577 0.2252 | 0.1623 27.7417 23.4985 0.2342 0.4866 0.6203 | 115.4070
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.85789576 0.85776056 0.85777276 0.85772564 0.85765137 0.85759457
 0.85767238 0.85763941 0.85758991 0.85751085 0.8574173  0.85742988
 0.85739644 0.85736005 0.85741661 0.85742544 0.85723012 0.85720754
 0.85713118 0.85725028]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.85749432 0.85750296 0.8575223  0.85749374 0.85751073 0.85750188
 0.8575247  0.85751922 0.85751302 0.85746307 0.85743904 0.85743135
 0.85743869 0.85742295 0.85743386 0.85743086 0.8574426  0.8574528
 0.85746693 0.85745538]
[0.         0.44736842 0.18421053]
-----------end of analyzing the loss ratio:74.28817892074585
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc93992d840>
---------------------------------
SparseEpoch: [57][1/398]	Time 0.620	Data 0.000	Loss 1.2760	
SparseEpoch: [57][101/398]	Time 0.627	Data 0.000	Loss 1.2212	
SparseEpoch: [57][201/398]	Time 0.624	Data 0.000	Loss 1.1576	
SparseEpoch: [57][301/398]	Time 0.624	Data 0.000	Loss 1.8518	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.4878878  0.48796573 0.48788593 0.48781393 0.48778486 0.48784715
 0.48774023 0.48767326 0.48750176 0.48740025 0.48737201 0.48745649
 0.48744645 0.48732329 0.48720509 0.487279   0.48720927 0.48720532
 0.48709393 0.4870549 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.48748906 0.48745737 0.48745413 0.48744455 0.48741374 0.48740649
 0.48739481 0.48741979 0.48739187 0.48734211 0.48734414 0.48735743
 0.48736269 0.48736202 0.48735172 0.4873633  0.48730727 0.4873164
 0.48732554 0.48733286]
[0.5        0.         0.34210526]
-----------end of analyzing the loss ratio:74.40027403831482
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cca5e212d70>
---------------------------------
SparseEpoch: [57][1/398]	Time 0.627	Data 0.000	Loss 1.4649	
SparseEpoch: [57][101/398]	Time 0.624	Data 0.000	Loss 1.3034	
SparseEpoch: [57][201/398]	Time 0.623	Data 0.000	Loss 2.2936	
SparseEpoch: [57][301/398]	Time 0.622	Data 0.000	Loss 1.3483	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.19462168 0.19443892 0.19424504 0.19405998 0.1938921  0.19377595
 0.19364468 0.19346375 0.19325202 0.19305754 0.19290423 0.19277397
 0.19257467 0.19233577 0.19221223 0.19203241 0.19187506 0.1917487
 0.19165564 0.19145305]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.19319844 0.19319414 0.19314255 0.1931127  0.19306968 0.19306551
 0.19308831 0.19300896 0.19299654 0.19296302 0.19295151 0.19296156
 0.19292127 0.19291193 0.19288294 0.19281554 0.19277875 0.1927601
 0.19270698 0.19269952]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:74.1926908493042
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938a1bee0>
---------------------------------
SparseEpoch: [57][1/398]	Time 0.619	Data 0.000	Loss 2.1705	
SparseEpoch: [57][101/398]	Time 0.631	Data 0.000	Loss 2.9089	
SparseEpoch: [57][201/398]	Time 0.629	Data 0.000	Loss 2.2330	
SparseEpoch: [57][301/398]	Time 0.627	Data 0.000	Loss 2.0154	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.5675	
Epoch(adapt):{0} Loss 1.4715	
Epoch(adapt):{0} Loss 2.8853	
Epoch(adapt):{0} Loss 1.8502	
------------------the total time cost:1216.8352570533752
>>>>>meta updating
Epoch: 0057 | TRAIN: 0.8610 0.4601 0.7148 | 0.4452 0.4452 0.2110 | 0.1623 27.7129 23.1483 0.2275 0.4924 0.6302 ||TEST: 1.1079 0.3569 0.6380 | 0.5600 0.5600 0.2222 | 0.1611 27.6929 23.4036 0.2292 0.4876 0.6233 | 115.3180
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.89753905 0.89755914 0.89755953 0.89753639 0.89756691 0.89753116
 0.89746572 0.89737529 0.89739851 0.89743174 0.89746413 0.89751335
 0.89755196 0.89757514 0.89769171 0.89771287 0.89777861 0.89774348
 0.89774752 0.89774029]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.89750565 0.89749766 0.89746503 0.8974931  0.89746059 0.89746112
 0.89745144 0.89743686 0.89745249 0.89743572 0.897427   0.89742942
 0.89742305 0.89741724 0.89741017 0.89743571 0.89744969 0.89742575
 0.89741377 0.89741369]
[0.         0.         0.23684211]
-----------end of analyzing the loss ratio:74.50097823143005
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9390316f0>
---------------------------------
SparseEpoch: [58][1/398]	Time 0.608	Data 0.000	Loss 1.1324	
SparseEpoch: [58][101/398]	Time 0.627	Data 0.000	Loss 0.9519	
SparseEpoch: [58][201/398]	Time 0.628	Data 0.000	Loss 1.0537	
SparseEpoch: [58][301/398]	Time 0.626	Data 0.000	Loss 2.0824	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.65064083 0.65045379 0.65024227 0.65009669 0.65004492 0.64958473
 0.64952679 0.64925508 0.64897369 0.64870541 0.64837228 0.6479804
 0.64754618 0.64735866 0.64678138 0.64673283 0.6464283  0.64615918
 0.64593037 0.6457244 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.64895097 0.64884778 0.64880944 0.64877304 0.64879164 0.64864276
 0.64860694 0.6485578  0.64853047 0.64861808 0.64864336 0.64850522
 0.64853492 0.64846883 0.64843453 0.64834927 0.6482589  0.64815811
 0.64816784 0.64815983]
[0.5        0.         0.39473684]
-----------end of analyzing the loss ratio:74.37592792510986
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cca5e306620>
---------------------------------
SparseEpoch: [58][1/398]	Time 0.614	Data 0.000	Loss 2.3051	
SparseEpoch: [58][101/398]	Time 0.627	Data 0.000	Loss 1.5211	
SparseEpoch: [58][201/398]	Time 0.626	Data 0.000	Loss 1.4480	
SparseEpoch: [58][301/398]	Time 0.626	Data 0.000	Loss 1.6603	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.18856023 0.18854014 0.18855585 0.18853796 0.18851108 0.18845561
 0.1884361  0.18837603 0.18835559 0.18834838 0.18834825 0.18832889
 0.18831173 0.18833572 0.18830283 0.18828367 0.18827087 0.18826127
 0.1882445  0.1882686 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.18833122 0.18833126 0.18830729 0.18832471 0.18834517 0.1883347
 0.1883381  0.18834412 0.18835271 0.18836787 0.18836511 0.18836423
 0.18834307 0.18835223 0.18836368 0.18835967 0.18836278 0.188383
 0.18837447 0.18837559]
[0.44736842 0.         0.        ]
-----------end of analyzing the loss ratio:74.69114232063293
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9398f95d0>
---------------------------------
SparseEpoch: [58][1/398]	Time 0.604	Data 0.000	Loss 1.9129	
SparseEpoch: [58][101/398]	Time 0.617	Data 0.000	Loss 2.9226	
SparseEpoch: [58][201/398]	Time 0.620	Data 0.000	Loss 2.5741	
SparseEpoch: [58][301/398]	Time 0.622	Data 0.000	Loss 2.6820	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.4822	
Epoch(adapt):{0} Loss 1.1760	
Epoch(adapt):{0} Loss 2.0485	
Epoch(adapt):{0} Loss 1.4109	
------------------the total time cost:1216.961526632309
>>>>>meta updating
Epoch: 0058 | TRAIN: 0.8473 0.4608 0.7171 | 0.4617 0.4617 0.2021 | 0.1606 27.4803 22.9166 0.2335 0.4976 0.6353 ||TEST: 1.0921 0.3574 0.6407 | 0.5907 0.5907 0.2241 | 0.1606 27.6007 23.3694 0.2328 0.4891 0.6248 | 116.3425
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.79493886 0.79488549 0.79485044 0.79485676 0.79485241 0.79485846
 0.79481948 0.7947573  0.79472243 0.79466277 0.79457331 0.7945085
 0.79448605 0.79442514 0.79435439 0.79437094 0.794301   0.79425749
 0.79428311 0.79423446]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.79450374 0.79448952 0.79453444 0.79453679 0.79454885 0.79455044
 0.79457271 0.7945733  0.79460012 0.79462395 0.79464678 0.79462808
 0.79462274 0.79463685 0.7946453  0.7945842  0.79455631 0.79455963
 0.79453791 0.79455244]
[0.  0.5 0. ]
-----------end of analyzing the loss ratio:74.36203598976135
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938dd9660>
---------------------------------
SparseEpoch: [59][1/398]	Time 0.606	Data 0.000	Loss 0.8278	
SparseEpoch: [59][101/398]	Time 0.623	Data 0.000	Loss 1.7723	
SparseEpoch: [59][201/398]	Time 0.621	Data 0.000	Loss 1.1059	
SparseEpoch: [59][301/398]	Time 0.622	Data 0.000	Loss 1.0651	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.51749884 0.51756874 0.51751967 0.51754373 0.51754791 0.51748842
 0.51757887 0.51767014 0.51776015 0.5178373  0.517876   0.51800034
 0.51804752 0.51810179 0.51813175 0.51810778 0.51813359 0.51815901
 0.51813754 0.51817806]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.5178844  0.51789691 0.51789662 0.51790259 0.51790406 0.5179147
 0.5179014  0.51787353 0.51783673 0.51781943 0.51781422 0.51782219
 0.51780963 0.51781305 0.51782259 0.51780754 0.51784444 0.51783071
 0.51787611 0.51786622]
[0.         0.         0.28947368]
-----------end of analyzing the loss ratio:74.46250200271606
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc93901ea70>
---------------------------------
SparseEpoch: [59][1/398]	Time 0.607	Data 0.000	Loss 1.1609	
SparseEpoch: [59][101/398]	Time 0.627	Data 0.000	Loss 1.0813	
SparseEpoch: [59][201/398]	Time 0.622	Data 0.000	Loss 0.5950	
SparseEpoch: [59][301/398]	Time 0.623	Data 0.000	Loss 0.8211	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.17486287 0.17484782 0.17483507 0.17477105 0.17475222 0.17473282
 0.17467165 0.17462184 0.17459828 0.17455042 0.17449543 0.17446071
 0.17442241 0.17438765 0.17436802 0.17433084 0.17432261 0.17429023
 0.17425318 0.17424558]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.1746518  0.17461143 0.17460451 0.17458169 0.17457168 0.17457538
 0.17454988 0.17455806 0.17453802 0.17453294 0.17450055 0.17448545
 0.17446972 0.17444642 0.17446685 0.17445687 0.17444203 0.17443705
 0.17442175 0.17442056]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:74.3288505077362
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9384a4280>
---------------------------------
SparseEpoch: [59][1/398]	Time 0.608	Data 0.000	Loss 1.8812	
SparseEpoch: [59][101/398]	Time 0.625	Data 0.000	Loss 2.7905	
SparseEpoch: [59][201/398]	Time 0.627	Data 0.000	Loss 2.4780	
SparseEpoch: [59][301/398]	Time 0.626	Data 0.000	Loss 3.5707	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 3.1714	
Epoch(adapt):{0} Loss 1.4480	
Epoch(adapt):{0} Loss 2.0517	
Epoch(adapt):{0} Loss 1.9123	
------------------the total time cost:1215.604152917862
>>>>>meta updating
Epoch: 0059 | TRAIN: 0.8574 0.4560 0.7160 | 0.4509 0.4509 0.2087 | 0.1636 27.8875 23.4926 0.2249 0.4868 0.6242 ||TEST: 1.1063 0.3505 0.6379 | 0.5695 0.5695 0.2211 | 0.1632 27.9362 23.8201 0.2273 0.4800 0.6150 | 115.3804
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.7755432  0.77556981 0.77556109 0.77551473 0.77555964 0.77551014
 0.77555104 0.77548303 0.77554705 0.77554521 0.77558179 0.77557462
 0.77555468 0.77552602 0.77551278 0.77550477 0.77549798 0.77548297
 0.77546307 0.77546037]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.77551367 0.77554207 0.77551725 0.77551705 0.7755307  0.775525
 0.77553148 0.77554605 0.7755476  0.7755308  0.77554687 0.77555941
 0.7755606  0.77557567 0.77558855 0.7756268  0.77563688 0.77563314
 0.77564264 0.7756301 ]
[0.  0.5 0. ]
-----------end of analyzing the loss ratio:74.26994824409485
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc93997fac0>
---------------------------------
SparseEpoch: [60][1/398]	Time 0.605	Data 0.000	Loss 1.0333	
SparseEpoch: [60][101/398]	Time 0.623	Data 0.000	Loss 1.1167	
SparseEpoch: [60][201/398]	Time 0.621	Data 0.000	Loss 1.2814	
SparseEpoch: [60][301/398]	Time 0.622	Data 0.000	Loss 1.8956	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.49210114 0.49161744 0.49139964 0.4908292  0.49057673 0.49031779
 0.4900358  0.48967269 0.48939519 0.48923191 0.48909214 0.48887194
 0.48880874 0.48840499 0.48822773 0.48814185 0.48757995 0.48718699
 0.48687647 0.48661589]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.48915333 0.4891302  0.48915526 0.4891378  0.48919248 0.48923174
 0.48928233 0.48927652 0.48926668 0.48926593 0.48922348 0.4891846
 0.4891636  0.48919031 0.48917182 0.4891295  0.4890555  0.48904341
 0.4890204  0.48904499]
[0.5        0.         0.44736842]
-----------end of analyzing the loss ratio:74.24716258049011
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cca5e466b60>
---------------------------------
SparseEpoch: [60][1/398]	Time 0.604	Data 0.000	Loss 1.8316	
SparseEpoch: [60][101/398]	Time 0.625	Data 0.000	Loss 1.8446	
SparseEpoch: [60][201/398]	Time 0.627	Data 0.000	Loss 1.5610	
SparseEpoch: [60][301/398]	Time 0.629	Data 0.000	Loss 3.1273	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.18969401 0.18969127 0.18969874 0.18968671 0.18967629 0.18968914
 0.18963069 0.18960392 0.18955684 0.18953022 0.18952922 0.1895671
 0.18950202 0.18945585 0.18943357 0.18945674 0.18943334 0.18942409
 0.18938121 0.18937528]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.18958355 0.18957858 0.18956793 0.18956433 0.18955868 0.18954539
 0.18953773 0.18953601 0.18952554 0.18951814 0.18952056 0.18950874
 0.18950492 0.18952051 0.18949829 0.18950334 0.18950633 0.18949152
 0.18949258 0.1894789 ]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:74.4575080871582
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9398f97e0>
---------------------------------
SparseEpoch: [60][1/398]	Time 0.612	Data 0.000	Loss 1.9267	
SparseEpoch: [60][101/398]	Time 0.621	Data 0.000	Loss 2.5042	
SparseEpoch: [60][201/398]	Time 0.622	Data 0.000	Loss 3.7296	
SparseEpoch: [60][301/398]	Time 0.622	Data 0.000	Loss 2.1179	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.5221	
Epoch(adapt):{0} Loss 1.3355	
Epoch(adapt):{0} Loss 1.3785	
Epoch(adapt):{0} Loss 1.5960	
------------------the total time cost:1215.4533433914185
>>>>>meta updating
Epoch: 0060 | TRAIN: 0.8289 0.4697 0.7229 | 0.4374 0.4374 0.2157 | 0.1627 27.7443 23.2386 0.2288 0.4914 0.6278 ||TEST: 1.1049 0.3612 0.6427 | 0.5466 0.5466 0.2240 | 0.1615 27.6796 23.3757 0.2334 0.4886 0.6226 | 115.5288
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.80683776 0.80676577 0.8067165  0.80677012 0.80667164 0.80668394
 0.8067578  0.80676154 0.80684613 0.80680157 0.80672002 0.80666172
 0.80664312 0.8065141  0.80648816 0.80646288 0.8065552  0.80657169
 0.80649456 0.80651291]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.80665693 0.80664639 0.80661554 0.80662466 0.8066899  0.80666418
 0.80664964 0.80661742 0.80671179 0.80675051 0.8068128  0.80681713
 0.8067997  0.80683574 0.80679685 0.80681466 0.80683008 0.80685154
 0.80682448 0.80680746]
[0.         0.28947368 0.        ]
-----------end of analyzing the loss ratio:74.25532555580139
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9398f8a30>
---------------------------------
SparseEpoch: [61][1/398]	Time 0.606	Data 0.000	Loss 0.7692	
SparseEpoch: [61][101/398]	Time 0.621	Data 0.000	Loss 0.9643	
SparseEpoch: [61][201/398]	Time 0.621	Data 0.000	Loss 1.5678	
SparseEpoch: [61][301/398]	Time 0.621	Data 0.000	Loss 1.3429	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.59897319 0.59904124 0.59901346 0.5990964  0.59903698 0.59896114
 0.59885603 0.5988547  0.59885228 0.59875537 0.59873591 0.59886194
 0.59887017 0.59873735 0.59866133 0.59853603 0.59848677 0.59839598
 0.59814019 0.59796144]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.59880686 0.59880917 0.59880979 0.59879022 0.59877402 0.59879645
 0.59880187 0.59881653 0.59880797 0.59879251 0.59877927 0.59878856
 0.59880165 0.59881748 0.59881478 0.59879085 0.59876942 0.59878544
 0.59876591 0.59878311]
[0.5        0.         0.44736842]
-----------end of analyzing the loss ratio:74.68246126174927
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc93992d960>
---------------------------------
SparseEpoch: [61][1/398]	Time 0.605	Data 0.000	Loss 1.8771	
SparseEpoch: [61][101/398]	Time 0.626	Data 0.000	Loss 2.3066	
SparseEpoch: [61][201/398]	Time 0.626	Data 0.000	Loss 1.7401	
SparseEpoch: [61][301/398]	Time 0.626	Data 0.000	Loss 1.8585	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.19045752 0.19040025 0.19039065 0.19030136 0.19025853 0.19030004
 0.1903258  0.19027483 0.19023806 0.19021974 0.19019842 0.19015834
 0.19011252 0.19006492 0.19002022 0.18994911 0.18987228 0.18985153
 0.18985217 0.18975008]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.19043792 0.19041577 0.19037639 0.19031772 0.19026974 0.19027422
 0.1903166  0.19028692 0.19027258 0.19022511 0.19020014 0.19013972
 0.19012015 0.19005067 0.18996853 0.18989781 0.18983243 0.18980137
 0.18974859 0.18971065]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:74.51146006584167
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc93866aef0>
---------------------------------
SparseEpoch: [61][1/398]	Time 0.608	Data 0.000	Loss 2.0969	
SparseEpoch: [61][101/398]	Time 0.623	Data 0.000	Loss 2.4757	
SparseEpoch: [61][201/398]	Time 0.623	Data 0.000	Loss 4.0811	
SparseEpoch: [61][301/398]	Time 0.623	Data 0.000	Loss 1.9906	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.2339	
Epoch(adapt):{0} Loss 1.7902	
Epoch(adapt):{0} Loss 2.1203	
Epoch(adapt):{0} Loss 1.4885	
------------------the total time cost:1215.8144936561584
>>>>>meta updating
Epoch: 0061 | TRAIN: 0.8272 0.4740 0.7263 | 0.4491 0.4491 0.2102 | 0.1635 27.9181 23.6399 0.2225 0.4837 0.6226 ||TEST: 1.0875 0.3599 0.6416 | 0.5679 0.5679 0.2232 | 0.1632 27.9656 23.9227 0.2257 0.4777 0.6136 | 116.0246
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.89267547 0.89264424 0.89270599 0.89262705 0.89266403 0.89272649
 0.89271448 0.89276148 0.89277164 0.89268003 0.89271114 0.8926177
 0.89252006 0.89255555 0.89248102 0.89245088 0.89241085 0.89241971
 0.89234259 0.8923156 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.89262652 0.89260925 0.89263177 0.89264481 0.89266763 0.89267847
 0.89264561 0.89264771 0.89269553 0.89270966 0.8927339  0.89268134
 0.89266192 0.8926643  0.89267893 0.89269714 0.8926967  0.89269198
 0.89270208 0.89270861]
[0.  0.5 0. ]
-----------end of analyzing the loss ratio:74.22486233711243
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938509f60>
---------------------------------
SparseEpoch: [62][1/398]	Time 0.607	Data 0.000	Loss 0.9106	
SparseEpoch: [62][101/398]	Time 0.623	Data 0.000	Loss 1.2264	
SparseEpoch: [62][201/398]	Time 0.622	Data 0.000	Loss 1.2013	
SparseEpoch: [62][301/398]	Time 0.621	Data 0.000	Loss 0.9143	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.44902151 0.44882681 0.4484035  0.44804032 0.4479653  0.44774867
 0.44756454 0.44722203 0.44706039 0.44686801 0.44665255 0.44664629
 0.44651489 0.44616587 0.44584116 0.44563136 0.44541309 0.44499044
 0.44480741 0.44468717]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.44678709 0.446733   0.44673639 0.44677218 0.44678472 0.44677291
 0.44678334 0.44678533 0.44679985 0.44681569 0.44680937 0.44679567
 0.44683789 0.44684752 0.44684187 0.44683627 0.44684746 0.44686637
 0.44684923 0.44682315]
[0.5 0.  0. ]
-----------end of analyzing the loss ratio:74.65755534172058
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938a4c310>
---------------------------------
SparseEpoch: [62][1/398]	Time 0.605	Data 0.000	Loss 0.8869	
SparseEpoch: [62][101/398]	Time 0.618	Data 0.000	Loss 1.3782	
SparseEpoch: [62][201/398]	Time 0.620	Data 0.000	Loss 0.9578	
SparseEpoch: [62][301/398]	Time 0.620	Data 0.000	Loss 0.8329	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.198759   0.19869389 0.19863646 0.19865231 0.19855911 0.19850856
 0.19850925 0.19842509 0.19836541 0.19828317 0.19821    0.19816789
 0.19809731 0.19804918 0.19808422 0.19804624 0.1980087  0.19801748
 0.19794977 0.19793377]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.19849717 0.19850217 0.19851444 0.19849232 0.19843453 0.19841523
 0.19839287 0.19835529 0.19832518 0.19826977 0.19822548 0.19821296
 0.19813935 0.19814484 0.19812493 0.19810374 0.19805716 0.19803452
 0.19800802 0.1980102 ]
[0.5        0.44736842 0.        ]
-----------end of analyzing the loss ratio:74.63450074195862
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9387c6d70>
---------------------------------
SparseEpoch: [62][1/398]	Time 0.615	Data 0.000	Loss 1.9407	
SparseEpoch: [62][101/398]	Time 0.625	Data 0.000	Loss 2.3262	
SparseEpoch: [62][201/398]	Time 0.625	Data 0.000	Loss 3.7418	
SparseEpoch: [62][301/398]	Time 0.625	Data 0.000	Loss 3.0035	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.0727	
Epoch(adapt):{0} Loss 1.3826	
Epoch(adapt):{0} Loss 1.1842	
Epoch(adapt):{0} Loss 1.4108	
------------------the total time cost:1214.471269607544
>>>>>meta updating
Epoch: 0062 | TRAIN: 0.8262 0.4755 0.7213 | 0.4208 0.4208 0.1994 | 0.1653 28.0755 23.7350 0.2221 0.4815 0.6198 ||TEST: 1.1240 0.3617 0.6332 | 0.5501 0.5501 0.2178 | 0.1644 28.0876 24.0796 0.2242 0.4749 0.6107 | 115.6922
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.82678904 0.82681655 0.82676586 0.82673244 0.82671432 0.82668954
 0.82662024 0.82653161 0.82648737 0.82650822 0.82637846 0.82633423
 0.8263308  0.82628286 0.82623484 0.82618403 0.82612313 0.82606611
 0.82602067 0.82606525]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.82644045 0.82646775 0.8264556  0.82646055 0.8264721  0.82649935
 0.82646872 0.82650826 0.82647419 0.82647671 0.82633952 0.82639561
 0.82638664 0.82633365 0.82636463 0.82634696 0.82630478 0.82631831
 0.82631707 0.82636511]
[0.         0.44736842 0.34210526]
-----------end of analyzing the loss ratio:74.44642114639282
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9386c8f40>
---------------------------------
SparseEpoch: [63][1/398]	Time 0.605	Data 0.000	Loss 1.7012	
SparseEpoch: [63][101/398]	Time 0.621	Data 0.000	Loss 1.5543	
SparseEpoch: [63][201/398]	Time 0.622	Data 0.000	Loss 1.8723	
SparseEpoch: [63][301/398]	Time 0.623	Data 0.000	Loss 2.2156	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.51368998 0.51368989 0.51370553 0.51372904 0.51378983 0.51381711
 0.51386178 0.51389447 0.51391008 0.51392793 0.51388855 0.51391274
 0.51391215 0.51389479 0.51392348 0.51395198 0.51398664 0.51400719
 0.51403    0.5139976 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.51393329 0.51392635 0.51393918 0.51394027 0.51393561 0.51393339
 0.51393388 0.51392331 0.51389201 0.51390354 0.51389402 0.51388307
 0.51388896 0.51388828 0.51388287 0.51388849 0.51388344 0.51389141
 0.51388709 0.51388475]
[0.         0.         0.23684211]
-----------end of analyzing the loss ratio:74.34797239303589
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938d65ba0>
---------------------------------
SparseEpoch: [63][1/398]	Time 0.605	Data 0.000	Loss 0.9548	
SparseEpoch: [63][101/398]	Time 0.623	Data 0.000	Loss 1.0481	
SparseEpoch: [63][201/398]	Time 0.623	Data 0.000	Loss 1.1072	
SparseEpoch: [63][301/398]	Time 0.623	Data 0.000	Loss 0.9631	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.19610956 0.19610893 0.19610167 0.19607792 0.19607521 0.19609257
 0.19607701 0.19606671 0.19607366 0.19606606 0.19604759 0.19603329
 0.196029   0.19601792 0.19601204 0.19599631 0.19597836 0.19597629
 0.19597899 0.19594585]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.19611669 0.19608736 0.19609057 0.19608437 0.19608575 0.19608606
 0.19606236 0.19605044 0.19605778 0.19605622 0.19605159 0.19604894
 0.19604434 0.19603213 0.19602916 0.1960283  0.19603762 0.19604308
 0.19603885 0.19604506]
[0.5        0.28947368 0.        ]
-----------end of analyzing the loss ratio:74.39905047416687
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc939030430>
---------------------------------
SparseEpoch: [63][1/398]	Time 0.605	Data 0.000	Loss 2.7348	
SparseEpoch: [63][101/398]	Time 0.623	Data 0.000	Loss 2.3616	
SparseEpoch: [63][201/398]	Time 0.620	Data 0.000	Loss 3.2004	
SparseEpoch: [63][301/398]	Time 0.623	Data 0.000	Loss 2.9483	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.3963	
Epoch(adapt):{0} Loss 1.1057	
Epoch(adapt):{0} Loss 1.5015	
Epoch(adapt):{0} Loss 1.3757	
------------------the total time cost:1215.555074930191
>>>>>meta updating
Epoch: 0063 | TRAIN: 0.8013 0.4859 0.7353 | 0.4210 0.4210 0.1945 | 0.1586 27.3253 22.8567 0.2328 0.4994 0.6378 ||TEST: 1.0844 0.3685 0.6456 | 0.5470 0.5470 0.2166 | 0.1584 27.3941 23.1267 0.2347 0.4938 0.6291 | 115.6862
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.8141847  0.81400679 0.81384354 0.8137803  0.81371887 0.81371852
 0.81351695 0.81374673 0.81364897 0.81339396 0.8134036  0.81322265
 0.81302071 0.81301976 0.81294817 0.81278965 0.81258591 0.81276054
 0.81266637 0.8125135 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.81355196 0.81351732 0.81350625 0.81351603 0.81347314 0.81346195
 0.81343608 0.81346121 0.81343466 0.8134099  0.81340588 0.81337453
 0.81337328 0.81334485 0.81336454 0.81334696 0.81337091 0.81336336
 0.81337531 0.81336663]
[0.         0.5        0.18421053]
-----------end of analyzing the loss ratio:74.51492953300476
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc93856faf0>
---------------------------------
SparseEpoch: [64][1/398]	Time 0.605	Data 0.000	Loss 1.4676	
SparseEpoch: [64][101/398]	Time 0.626	Data 0.000	Loss 1.6147	
SparseEpoch: [64][201/398]	Time 0.624	Data 0.000	Loss 1.8821	
SparseEpoch: [64][301/398]	Time 0.624	Data 0.000	Loss 1.4745	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.5465434  0.5466211  0.54653929 0.54654204 0.54662973 0.54656242
 0.5465526  0.54660729 0.54670213 0.54668646 0.54668575 0.54676123
 0.54692284 0.54698946 0.54699994 0.54709164 0.54726939 0.54739495
 0.54737448 0.54738809]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.54667588 0.54667716 0.54666661 0.54668625 0.54668127 0.5466796
 0.54668501 0.5466849  0.54667654 0.54666931 0.5466695  0.54667173
 0.54665029 0.54664457 0.54662151 0.54662833 0.54663602 0.54664374
 0.54663553 0.5466484 ]
[0.         0.         0.23684211]
-----------end of analyzing the loss ratio:74.403724193573
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cca5e467a90>
---------------------------------
SparseEpoch: [64][1/398]	Time 0.609	Data 0.000	Loss 0.6466	
SparseEpoch: [64][101/398]	Time 0.622	Data 0.000	Loss 1.5713	
SparseEpoch: [64][201/398]	Time 0.623	Data 0.000	Loss 0.9490	
SparseEpoch: [64][301/398]	Time 0.624	Data 0.000	Loss 0.8148	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.17345647 0.17345006 0.1734273  0.17341086 0.17340927 0.17341564
 0.17341097 0.17341832 0.17341776 0.17342329 0.17343104 0.17342833
 0.17341709 0.17344828 0.17343982 0.17345167 0.17346742 0.1734771
 0.17353948 0.17353113]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.17345523 0.1734642  0.17347676 0.17342104 0.17339978 0.17340239
 0.17338263 0.17337629 0.17340335 0.17344025 0.17343193 0.17341974
 0.17343004 0.17345124 0.1734319  0.17342814 0.17342866 0.17343969
 0.17342449 0.17344419]
[0. 0. 0.]
-----------end of analyzing the loss ratio:74.45174407958984
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc93856f820>
---------------------------------
SparseEpoch: [64][1/398]	Time 0.603	Data 0.000	Loss 2.4990	
SparseEpoch: [64][101/398]	Time 0.622	Data 0.000	Loss 1.9466	
SparseEpoch: [64][201/398]	Time 0.625	Data 0.000	Loss 1.9386	
SparseEpoch: [64][301/398]	Time 0.625	Data 0.000	Loss 1.2182	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.6484	
Epoch(adapt):{0} Loss 1.3666	
Epoch(adapt):{0} Loss 1.5839	
Epoch(adapt):{0} Loss 1.6765	
------------------the total time cost:1216.8835973739624
>>>>>meta updating
Epoch: 0064 | TRAIN: 0.8355 0.4730 0.7247 | 0.4272 0.4272 0.2075 | 0.1603 27.4887 22.9663 0.2309 0.4969 0.6354 ||TEST: 1.0959 0.3607 0.6399 | 0.5567 0.5567 0.2220 | 0.1601 27.5285 23.2200 0.2350 0.4920 0.6269 | 115.7191
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.78825706 0.78823143 0.78820582 0.78812925 0.78815629 0.78803394
 0.78798896 0.78797281 0.78799331 0.78788518 0.78794079 0.78790283
 0.78794655 0.78800132 0.78797161 0.78796552 0.78800785 0.78800288
 0.78800632 0.78798321]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.78804777 0.78803286 0.78798194 0.78792786 0.78792806 0.78792654
 0.78792272 0.78793638 0.78791143 0.7878831  0.78788384 0.7878928
 0.78789689 0.78794404 0.78797179 0.78800221 0.78793742 0.78793539
 0.78795031 0.78796333]
[0. 0. 0.]
-----------end of analyzing the loss ratio:74.37566065788269
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9384a51b0>
---------------------------------
SparseEpoch: [65][1/398]	Time 0.608	Data 0.000	Loss 0.6627	
SparseEpoch: [65][101/398]	Time 0.625	Data 0.000	Loss 0.8275	
SparseEpoch: [65][201/398]	Time 0.623	Data 0.000	Loss 0.5330	
SparseEpoch: [65][301/398]	Time 0.622	Data 0.000	Loss 0.9756	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.76860574 0.76865223 0.76871549 0.76872367 0.76870294 0.76866627
 0.76871017 0.76877685 0.76883394 0.76885405 0.76882223 0.7688733
 0.76892497 0.76892924 0.76893348 0.76900061 0.76900645 0.76901996
 0.76903744 0.76915695]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.76888679 0.76881576 0.76880776 0.76880852 0.76885985 0.76892605
 0.76893741 0.76889834 0.76888431 0.7688522  0.76883362 0.76881543
 0.76877846 0.7687805  0.76879566 0.76881801 0.76882402 0.76876318
 0.7687106  0.76870905]
[0.  0.  0.5]
-----------end of analyzing the loss ratio:74.37598633766174
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938b16c50>
---------------------------------
SparseEpoch: [65][1/398]	Time 0.605	Data 0.000	Loss 1.2374	
SparseEpoch: [65][101/398]	Time 0.621	Data 0.000	Loss 1.0252	
SparseEpoch: [65][201/398]	Time 0.622	Data 0.000	Loss 1.4328	
SparseEpoch: [65][301/398]	Time 0.620	Data 0.000	Loss 1.2426	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.22905259 0.22900704 0.22897751 0.22895759 0.22890502 0.22887968
 0.22886732 0.22887195 0.22886652 0.22880813 0.22877098 0.22875951
 0.2286919  0.22867048 0.22866967 0.22862807 0.22860286 0.22854931
 0.22854888 0.22849828]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.22896636 0.22895136 0.22893507 0.22891913 0.22891089 0.22887847
 0.22889774 0.22886729 0.2288254  0.22881793 0.22878651 0.2287471
 0.22873425 0.22870775 0.22868863 0.22866744 0.22861161 0.22858742
 0.22858906 0.22857672]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:74.66673064231873
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9388c6c20>
---------------------------------
SparseEpoch: [65][1/398]	Time 0.619	Data 0.000	Loss 3.1443	
SparseEpoch: [65][101/398]	Time 0.623	Data 0.000	Loss 2.0672	
SparseEpoch: [65][201/398]	Time 0.624	Data 0.000	Loss 1.7534	
SparseEpoch: [65][301/398]	Time 0.624	Data 0.000	Loss 2.5867	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.1053	
Epoch(adapt):{0} Loss 1.5289	
Epoch(adapt):{0} Loss 1.2698	
Epoch(adapt):{0} Loss 1.5309	
------------------the total time cost:1213.2509920597076
>>>>>meta updating
Epoch: 0065 | TRAIN: 0.8032 0.4898 0.7384 | 0.4448 0.4448 0.2001 | 0.1593 27.4908 23.0422 0.2255 0.4946 0.6343 ||TEST: 1.0751 0.3641 0.6441 | 0.5715 0.5715 0.2195 | 0.1611 27.7503 23.6114 0.2263 0.4837 0.6208 | 115.7201
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.80063834 0.80049089 0.80050359 0.80046757 0.800497   0.80031775
 0.80029049 0.80012434 0.80016856 0.80029312 0.80015285 0.80016967
 0.80013952 0.80011435 0.80002908 0.79990714 0.79998305 0.79985042
 0.79964004 0.79963181]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.80004565 0.80006403 0.80011991 0.8000751  0.80012484 0.80010059
 0.80017973 0.8002039  0.8002359  0.80022674 0.80019977 0.80013457
 0.80016382 0.80015381 0.80018592 0.80018032 0.80023299 0.80025944
 0.80028095 0.80029371]
[0.  0.5 0. ]
-----------end of analyzing the loss ratio:74.4610025882721
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9399468f0>
---------------------------------
SparseEpoch: [66][1/398]	Time 0.605	Data 0.000	Loss 1.3333	
SparseEpoch: [66][101/398]	Time 0.624	Data 0.000	Loss 1.0911	
SparseEpoch: [66][201/398]	Time 0.624	Data 0.000	Loss 1.2290	
SparseEpoch: [66][301/398]	Time 0.624	Data 0.000	Loss 1.6949	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.54229018 0.54209694 0.54208421 0.54190591 0.54155681 0.54177944
 0.54168522 0.5417748  0.54176776 0.5417141  0.54158245 0.54153043
 0.54174214 0.54209127 0.5419967  0.54185553 0.54177555 0.54191186
 0.54190754 0.54196361]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.54171289 0.54169647 0.54168291 0.54168949 0.54169921 0.54168249
 0.54168657 0.54167778 0.54166098 0.54163859 0.54162534 0.54165904
 0.54166094 0.54163204 0.54157202 0.54158626 0.54158952 0.54159003
 0.54160389 0.54164013]
[0.07894737 0.         0.23684211]
-----------end of analyzing the loss ratio:74.71270799636841
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9398d1480>
---------------------------------
SparseEpoch: [66][1/398]	Time 0.606	Data 0.000	Loss 1.0019	
SparseEpoch: [66][101/398]	Time 0.626	Data 0.000	Loss 1.0200	
SparseEpoch: [66][201/398]	Time 0.625	Data 0.000	Loss 0.8769	
SparseEpoch: [66][301/398]	Time 0.627	Data 0.000	Loss 1.1477	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.18855714 0.18842131 0.18831196 0.18822399 0.18811423 0.18800904
 0.18792284 0.18785342 0.18775285 0.18772952 0.18759051 0.18745831
 0.18734046 0.18726492 0.18717521 0.18708064 0.18702279 0.18695549
 0.18686787 0.18683867]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.18772038 0.18773878 0.18774616 0.18776844 0.18770486 0.18770379
 0.18771879 0.18771666 0.18767191 0.18765272 0.18761625 0.18760305
 0.18760505 0.18758637 0.18754435 0.18753262 0.18752768 0.18750128
 0.18747849 0.18745543]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:74.48548221588135
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9398d1f00>
---------------------------------
SparseEpoch: [66][1/398]	Time 0.609	Data 0.000	Loss 1.9435	
SparseEpoch: [66][101/398]	Time 0.620	Data 0.000	Loss 2.2242	
SparseEpoch: [66][201/398]	Time 0.623	Data 0.000	Loss 1.6300	
SparseEpoch: [66][301/398]	Time 0.624	Data 0.000	Loss 2.5768	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.5261	
Epoch(adapt):{0} Loss 1.3685	
Epoch(adapt):{0} Loss 2.0299	
Epoch(adapt):{0} Loss 1.1364	
------------------the total time cost:1217.241945028305
>>>>>meta updating
Epoch: 0066 | TRAIN: 0.8230 0.4745 0.7292 | 0.4646 0.4646 0.2016 | 0.1607 27.5732 23.1340 0.2282 0.4940 0.6325 ||TEST: 1.0797 0.3575 0.6455 | 0.6024 0.6024 0.2246 | 0.1607 27.6245 23.3688 0.2321 0.4889 0.6237 | 115.7124
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.70389879 0.70384659 0.70382835 0.70383329 0.70388613 0.70386827
 0.7038598  0.70388804 0.70390934 0.70393285 0.70400814 0.70399002
 0.70395555 0.70400211 0.70394324 0.70389866 0.70397078 0.70393363
 0.70389582 0.70390918]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.70391325 0.70391269 0.70392077 0.70392919 0.70394409 0.70394462
 0.70393153 0.70392892 0.70394672 0.7039711  0.70396127 0.70396051
 0.70397485 0.70397384 0.70398378 0.70398821 0.70399316 0.70400823
 0.70400316 0.70401761]
[0. 0. 0.]
-----------end of analyzing the loss ratio:74.54313087463379
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cca5e213550>
---------------------------------
SparseEpoch: [67][1/398]	Time 0.612	Data 0.000	Loss 0.9189	
SparseEpoch: [67][101/398]	Time 0.625	Data 0.000	Loss 1.2799	
SparseEpoch: [67][201/398]	Time 0.626	Data 0.000	Loss 0.8374	
SparseEpoch: [67][301/398]	Time 0.626	Data 0.000	Loss 0.7072	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.67225239 0.67224784 0.67229837 0.67229598 0.67233293 0.67239677
 0.67232679 0.67237276 0.67240543 0.67242098 0.67253276 0.67262387
 0.6728018  0.67282692 0.67286471 0.67284984 0.67281102 0.6728162
 0.67281053 0.67292842]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.67245647 0.672456   0.6724456  0.67245601 0.67246071 0.67247394
 0.67247767 0.67247914 0.67247517 0.67246782 0.67247528 0.67249599
 0.67248192 0.67248623 0.67248721 0.67248812 0.67249947 0.6724911
 0.67247748 0.67247763]
[0. 0. 0.]
-----------end of analyzing the loss ratio:74.5588493347168
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cca5df80970>
---------------------------------
SparseEpoch: [67][1/398]	Time 0.604	Data 0.000	Loss 0.4623	
SparseEpoch: [67][101/398]	Time 0.627	Data 0.000	Loss 0.3460	
SparseEpoch: [67][201/398]	Time 0.626	Data 0.000	Loss 0.4500	
SparseEpoch: [67][301/398]	Time 0.625	Data 0.000	Loss 0.5052	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.17310213 0.17311558 0.17302965 0.17299004 0.17295351 0.1728795
 0.17287111 0.172914   0.1728973  0.17282776 0.17277131 0.17266738
 0.17267017 0.17261206 0.17265168 0.17262223 0.17258872 0.17251292
 0.17246354 0.1724575 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.17295997 0.17296041 0.17297656 0.17295673 0.17293244 0.17288664
 0.17286901 0.17285401 0.1728282  0.17279683 0.17280462 0.17277412
 0.17276056 0.17276508 0.17271785 0.17268639 0.17266123 0.17266064
 0.17265188 0.17264326]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:74.46219277381897
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9385e6a10>
---------------------------------
SparseEpoch: [67][1/398]	Time 0.606	Data 0.000	Loss 2.7264	
SparseEpoch: [67][101/398]	Time 0.625	Data 0.000	Loss 2.4306	
SparseEpoch: [67][201/398]	Time 0.625	Data 0.000	Loss 3.6540	
SparseEpoch: [67][301/398]	Time 0.624	Data 0.000	Loss 2.2250	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.2051	
Epoch(adapt):{0} Loss 1.8009	
Epoch(adapt):{0} Loss 1.5607	
Epoch(adapt):{0} Loss 1.2133	
------------------the total time cost:1216.7535860538483
>>>>>meta updating
Epoch: 0067 | TRAIN: 0.8109 0.4817 0.7340 | 0.4518 0.4518 0.2000 | 0.1618 27.7533 23.4162 0.2233 0.4868 0.6270 ||TEST: 1.0897 0.3607 0.6402 | 0.5826 0.5826 0.2189 | 0.1633 27.9620 23.8769 0.2252 0.4788 0.6148 | 115.6954
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.7787302  0.77874565 0.77870982 0.77869717 0.7786561  0.7786266
 0.77852865 0.77850968 0.7783919  0.77849251 0.77844507 0.77846388
 0.77851236 0.77859419 0.77861853 0.77866644 0.77870719 0.77876419
 0.77858589 0.77859361]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.77857288 0.77854671 0.77856939 0.77854698 0.77855411 0.77851911
 0.7785145  0.77853389 0.77851291 0.77849056 0.77849376 0.77848259
 0.77847487 0.77848696 0.77847326 0.77844141 0.77842069 0.77844833
 0.77845665 0.77844211]
[0.         0.         0.34210526]
-----------end of analyzing the loss ratio:74.6047534942627
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cca5e4f5540>
---------------------------------
SparseEpoch: [68][1/398]	Time 0.604	Data 0.000	Loss 1.4608	
SparseEpoch: [68][101/398]	Time 0.625	Data 0.000	Loss 1.4186	
SparseEpoch: [68][201/398]	Time 0.620	Data 0.000	Loss 1.4281	
SparseEpoch: [68][301/398]	Time 0.620	Data 0.000	Loss 1.1363	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.55744736 0.55740519 0.55735658 0.55734048 0.55732684 0.55728587
 0.55711083 0.55693914 0.55670346 0.55669741 0.55673502 0.55669104
 0.55652579 0.55646197 0.55643817 0.556385   0.55634587 0.5562759
 0.55630412 0.55637284]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.55667034 0.55669259 0.55671193 0.55670735 0.55668133 0.55666672
 0.55665259 0.55664787 0.55670579 0.55672881 0.55669978 0.55667225
 0.55667804 0.55671624 0.55674189 0.55674964 0.55676299 0.55676531
 0.55677212 0.55676512]
[0.39473684 0.         0.        ]
-----------end of analyzing the loss ratio:74.60052227973938
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9383d3310>
---------------------------------
SparseEpoch: [68][1/398]	Time 0.604	Data 0.000	Loss 0.7144	
SparseEpoch: [68][101/398]	Time 0.622	Data 0.000	Loss 1.2491	
SparseEpoch: [68][201/398]	Time 0.626	Data 0.000	Loss 0.9885	
SparseEpoch: [68][301/398]	Time 0.625	Data 0.000	Loss 1.0110	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.17946631 0.17943761 0.17945735 0.1794036  0.17935289 0.17931125
 0.1793393  0.17930752 0.17937527 0.17941611 0.17937312 0.17939525
 0.17941803 0.17938637 0.17936949 0.17929654 0.17928106 0.17932509
 0.17929683 0.17921669]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.17941592 0.17942229 0.17939805 0.17939865 0.17943237 0.1794202
 0.17941808 0.17938566 0.17940726 0.17939686 0.17938232 0.17937039
 0.17936576 0.17933388 0.17932676 0.17933818 0.17934617 0.17935878
 0.17940043 0.17930902]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:74.42028975486755
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938f6dcc0>
---------------------------------
SparseEpoch: [68][1/398]	Time 0.617	Data 0.000	Loss 2.4466	
SparseEpoch: [68][101/398]	Time 0.622	Data 0.000	Loss 3.5438	
SparseEpoch: [68][201/398]	Time 0.621	Data 0.000	Loss 2.7282	
SparseEpoch: [68][301/398]	Time 0.621	Data 0.000	Loss 2.8928	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.3599	
Epoch(adapt):{0} Loss 1.4192	
Epoch(adapt):{0} Loss 1.7785	
Epoch(adapt):{0} Loss 1.2231	
------------------the total time cost:1214.1938219070435
>>>>>meta updating
Epoch: 0068 | TRAIN: 0.7938 0.4858 0.7342 | 0.4171 0.4171 0.1981 | 0.1569 27.0711 22.4325 0.2402 0.5090 0.6440 ||TEST: 1.1304 0.3622 0.6348 | 0.5430 0.5430 0.2179 | 0.1588 27.4070 23.0470 0.2343 0.4958 0.6308 | 115.4727
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.65339678 0.65348293 0.65351307 0.65359058 0.65363843 0.65358047
 0.65368608 0.65378835 0.65384734 0.65384356 0.65383194 0.65386034
 0.65390513 0.65393178 0.65393768 0.65393196 0.65400818 0.65402993
 0.65408156 0.65403154]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.65399759 0.65395778 0.65392872 0.65391846 0.65388296 0.65385906
 0.65389973 0.65389036 0.65387029 0.65380322 0.65383331 0.65379098
 0.65376801 0.6537991  0.65381284 0.6537995  0.65374134 0.65371284
 0.65363705 0.65362493]
[0.  0.  0.5]
-----------end of analyzing the loss ratio:74.79151368141174
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc93881d900>
---------------------------------
SparseEpoch: [69][1/398]	Time 0.606	Data 0.000	Loss 0.9320	
SparseEpoch: [69][101/398]	Time 0.622	Data 0.000	Loss 2.3207	
SparseEpoch: [69][201/398]	Time 0.624	Data 0.000	Loss 2.0848	
SparseEpoch: [69][301/398]	Time 0.624	Data 0.000	Loss 2.2818	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.63785935 0.63781491 0.63788049 0.63807267 0.63819114 0.63835427
 0.63845767 0.63856557 0.63877791 0.6389522  0.63903697 0.63927257
 0.63932122 0.6392767  0.63918459 0.63959225 0.63963143 0.63978338
 0.64002063 0.64001598]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.63893999 0.63894154 0.6389458  0.63896978 0.63896244 0.63896227
 0.63900128 0.63896951 0.63896316 0.63897423 0.63896326 0.6389686
 0.63895088 0.63895891 0.63897508 0.63897202 0.63895135 0.63897788
 0.63899057 0.63901436]
[0. 0. 0.]
-----------end of analyzing the loss ratio:74.54984140396118
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938a8aef0>
---------------------------------
SparseEpoch: [69][1/398]	Time 0.606	Data 0.000	Loss 0.5255	
SparseEpoch: [69][101/398]	Time 0.623	Data 0.000	Loss 0.6412	
SparseEpoch: [69][201/398]	Time 0.624	Data 0.000	Loss 0.6235	
SparseEpoch: [69][301/398]	Time 0.625	Data 0.000	Loss 0.6864	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.18830162 0.1882544  0.18819296 0.18811007 0.18801284 0.18793934
 0.18785947 0.18779132 0.18774105 0.187678   0.1876208  0.18760989
 0.18762182 0.18759171 0.18762014 0.18755715 0.18756812 0.18765331
 0.18760527 0.18750381]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.18764802 0.18765869 0.18764669 0.18762547 0.18761342 0.18761839
 0.18763687 0.18761919 0.18763044 0.18764385 0.1876598  0.18765604
 0.18764649 0.1876915  0.18774045 0.1877418  0.1877893  0.18782179
 0.18781021 0.18785857]
[0.5 0.  0. ]
-----------end of analyzing the loss ratio:74.35150361061096
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9398d1150>
---------------------------------
SparseEpoch: [69][1/398]	Time 0.606	Data 0.000	Loss 1.6479	
SparseEpoch: [69][101/398]	Time 0.620	Data 0.000	Loss 2.0801	
SparseEpoch: [69][201/398]	Time 0.625	Data 0.000	Loss 2.3672	
SparseEpoch: [69][301/398]	Time 0.624	Data 0.000	Loss 1.9115	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.7480	
Epoch(adapt):{0} Loss 1.6941	
Epoch(adapt):{0} Loss 1.0788	
Epoch(adapt):{0} Loss 1.3013	
------------------the total time cost:1216.7900183200836
>>>>>meta updating
Epoch: 0069 | TRAIN: 0.7763 0.5019 0.7430 | 0.4187 0.4187 0.2115 | 0.1565 27.1117 22.6260 0.2354 0.5028 0.6422 ||TEST: 1.0918 0.3672 0.6456 | 0.5440 0.5440 0.2287 | 0.1596 27.4697 23.2401 0.2376 0.4920 0.6264 | 115.8607
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.88859313 0.88848928 0.88849486 0.88853156 0.88854216 0.88844276
 0.88846754 0.88853057 0.88862106 0.88869731 0.88876482 0.88880668
 0.88879524 0.88885645 0.88891618 0.88890373 0.88895075 0.88898737
 0.88904596 0.88912151]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.88876463 0.8887755  0.88874749 0.88873367 0.88873965 0.88870771
 0.88872355 0.88872427 0.88872559 0.88874373 0.88875597 0.88874512
 0.8887237  0.8886978  0.88867025 0.88869969 0.88866223 0.88863713
 0.88863043 0.8886304 ]
[0.  0.  0.5]
-----------end of analyzing the loss ratio:74.34446787834167
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938dda2f0>
---------------------------------
SparseEpoch: [70][1/398]	Time 0.605	Data 0.000	Loss 1.7844	
SparseEpoch: [70][101/398]	Time 0.625	Data 0.000	Loss 2.6950	
SparseEpoch: [70][201/398]	Time 0.626	Data 0.000	Loss 1.1334	
SparseEpoch: [70][301/398]	Time 0.626	Data 0.000	Loss 1.6411	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.87614596 0.87614627 0.87613433 0.87618007 0.87624686 0.87624073
 0.87609636 0.87600256 0.87591676 0.87586738 0.8759093  0.87590429
 0.87588578 0.87600933 0.8761095  0.876247   0.87614799 0.87606602
 0.87611624 0.8760334 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.87584063 0.87585995 0.87586008 0.8758213  0.87580887 0.87582017
 0.87584397 0.87585126 0.87584541 0.8758556  0.87587134 0.87589302
 0.87588391 0.87587528 0.87585596 0.87582268 0.87581778 0.87584669
 0.87584373 0.87586997]
[0. 0. 0.]
-----------end of analyzing the loss ratio:74.44010162353516
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9383977f0>
---------------------------------
SparseEpoch: [70][1/398]	Time 0.606	Data 0.000	Loss 0.7212	
SparseEpoch: [70][101/398]	Time 0.623	Data 0.000	Loss 0.3302	
SparseEpoch: [70][201/398]	Time 0.623	Data 0.000	Loss 0.3634	
SparseEpoch: [70][301/398]	Time 0.622	Data 0.000	Loss 0.5760	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.19420104 0.19409804 0.19412299 0.19413686 0.19415632 0.1941543
 0.19416544 0.19412914 0.19413521 0.19405484 0.19402164 0.19397468
 0.1939213  0.19388567 0.19384689 0.1937757  0.19374789 0.19368774
 0.19368221 0.19364766]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.19401783 0.19404407 0.19401898 0.19402374 0.19402962 0.19402968
 0.19401017 0.19402112 0.19401203 0.19403667 0.19405667 0.19408024
 0.19405277 0.19402333 0.1940237  0.19402755 0.19402498 0.19402253
 0.19400501 0.1939869 ]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:74.76723599433899
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cca5e4f5720>
---------------------------------
SparseEpoch: [70][1/398]	Time 0.605	Data 0.000	Loss 2.7777	
SparseEpoch: [70][101/398]	Time 0.622	Data 0.000	Loss 1.3718	
SparseEpoch: [70][201/398]	Time 0.624	Data 0.000	Loss 2.3325	
SparseEpoch: [70][301/398]	Time 0.625	Data 0.000	Loss 2.4119	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.4626	
Epoch(adapt):{0} Loss 1.3377	
Epoch(adapt):{0} Loss 0.9132	
Epoch(adapt):{0} Loss 1.5060	
------------------the total time cost:1215.7019329071045
>>>>>meta updating
Epoch: 0070 | TRAIN: 0.7981 0.4844 0.7390 | 0.4371 0.4371 0.2053 | 0.1585 27.3171 22.9129 0.2331 0.4998 0.6378 ||TEST: 1.0880 0.3591 0.6451 | 0.5612 0.5612 0.2173 | 0.1600 27.5100 23.2412 0.2370 0.4916 0.6258 | 115.4692
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.7047458  0.70467536 0.70456253 0.7045493  0.70452911 0.70454259
 0.70464294 0.70463824 0.70462276 0.70472483 0.70467497 0.70470617
 0.70464647 0.70459094 0.70458138 0.70462973 0.70469904 0.70462495
 0.70456978 0.70458053]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.70466979 0.70468673 0.70467587 0.70469503 0.70469566 0.70470561
 0.70469455 0.70467597 0.70466705 0.70471098 0.7047297  0.70469117
 0.70468717 0.70469408 0.70467949 0.70460419 0.70459168 0.70458397
 0.70457214 0.7045987 ]
[0.         0.         0.44736842]
-----------end of analyzing the loss ratio:74.82002782821655
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938508820>
---------------------------------
SparseEpoch: [71][1/398]	Time 0.678	Data 0.000	Loss 1.1346	
SparseEpoch: [71][101/398]	Time 0.629	Data 0.000	Loss 1.2034	
SparseEpoch: [71][201/398]	Time 0.625	Data 0.000	Loss 1.6425	
SparseEpoch: [71][301/398]	Time 0.625	Data 0.000	Loss 2.2860	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.91613721 0.91628116 0.91621983 0.91633662 0.91654325 0.91662827
 0.91669576 0.91674657 0.91684121 0.91697167 0.9170702  0.91710577
 0.91717895 0.91728839 0.91735911 0.91735848 0.91742474 0.917527
 0.91763453 0.91781161]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.91690363 0.91693271 0.91687461 0.91688859 0.91694134 0.91695186
 0.9169256  0.91697341 0.91699107 0.91706222 0.91707414 0.91706685
 0.91706974 0.91706476 0.91708986 0.91704522 0.91712627 0.91715505
 0.917163   0.91717134]
[0. 0. 0.]
-----------end of analyzing the loss ratio:74.51866173744202
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cca5e465d50>
---------------------------------
SparseEpoch: [71][1/398]	Time 0.604	Data 0.000	Loss 0.4261	
SparseEpoch: [71][101/398]	Time 0.624	Data 0.000	Loss 0.3322	
SparseEpoch: [71][201/398]	Time 0.623	Data 0.000	Loss 0.2769	
SparseEpoch: [71][301/398]	Time 0.622	Data 0.000	Loss 0.2586	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.19580715 0.19569364 0.1955301  0.1954733  0.19543739 0.19526576
 0.19518291 0.1951614  0.19506788 0.19496818 0.1948733  0.1947965
 0.19473856 0.19461323 0.19458671 0.19448345 0.19438562 0.19427898
 0.19421117 0.19416666]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.19517347 0.19517003 0.19512709 0.19509822 0.19507531 0.19509069
 0.19508396 0.19505516 0.19497378 0.19492642 0.1949218  0.19487062
 0.19483613 0.19481539 0.19477151 0.19477522 0.1947453  0.19468886
 0.19468989 0.19463869]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:74.61776685714722
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938f16710>
---------------------------------
SparseEpoch: [71][1/398]	Time 0.624	Data 0.000	Loss 1.7338	
SparseEpoch: [71][101/398]	Time 0.626	Data 0.000	Loss 2.5290	
SparseEpoch: [71][201/398]	Time 0.623	Data 0.000	Loss 2.4222	
SparseEpoch: [71][301/398]	Time 0.622	Data 0.000	Loss 2.0224	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.5047	
Epoch(adapt):{0} Loss 1.5857	
Epoch(adapt):{0} Loss 1.1220	
Epoch(adapt):{0} Loss 1.3911	
------------------the total time cost:1216.1944961547852
>>>>>meta updating
Epoch: 0071 | TRAIN: 0.7808 0.5032 0.7431 | 0.4261 0.4261 0.1952 | 0.1576 27.1845 22.6153 0.2348 0.5050 0.6426 ||TEST: 1.0783 0.3718 0.6471 | 0.5608 0.5608 0.2150 | 0.1577 27.2639 22.8959 0.2383 0.4982 0.6331 | 115.5748
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.74945589 0.74948008 0.74951835 0.74945102 0.74951547 0.74952368
 0.7495997  0.74954221 0.74956352 0.74963731 0.74973642 0.74984244
 0.74991689 0.74989547 0.74991143 0.74984781 0.74988725 0.74992976
 0.74984687 0.74990692]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.74954607 0.74956714 0.74957842 0.74958971 0.74961979 0.74965484
 0.74965215 0.74965989 0.74970221 0.74973136 0.74970709 0.749691
 0.74970097 0.74972316 0.74970956 0.749764   0.74977515 0.74977576
 0.74980417 0.74982895]
[0. 0. 0.]
-----------end of analyzing the loss ratio:74.62302470207214
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc93866b310>
---------------------------------
SparseEpoch: [72][1/398]	Time 0.604	Data 0.000	Loss 0.6514	
SparseEpoch: [72][101/398]	Time 0.629	Data 0.000	Loss 1.1621	
SparseEpoch: [72][201/398]	Time 0.626	Data 0.000	Loss 1.0385	
SparseEpoch: [72][301/398]	Time 0.626	Data 0.000	Loss 1.2406	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.85644704 0.8565157  0.85662995 0.85666987 0.85700114 0.85712964
 0.85717498 0.85741926 0.8575226  0.85785141 0.85795604 0.85815176
 0.85838657 0.85882112 0.85919141 0.85885611 0.85898479 0.85902944
 0.85892925 0.85891156]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.85787189 0.8578699  0.85786409 0.85784209 0.85784606 0.85787331
 0.85789078 0.85788997 0.85789526 0.85794817 0.85790818 0.85789772
 0.85791053 0.85794864 0.85792928 0.85790561 0.85785106 0.85786603
 0.85786902 0.85781807]
[0.  0.  0.5]
-----------end of analyzing the loss ratio:74.53144478797913
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938b6b7c0>
---------------------------------
SparseEpoch: [72][1/398]	Time 0.606	Data 0.000	Loss 1.4563	
SparseEpoch: [72][101/398]	Time 0.621	Data 0.000	Loss 1.3153	
SparseEpoch: [72][201/398]	Time 0.624	Data 0.000	Loss 1.5286	
SparseEpoch: [72][301/398]	Time 0.625	Data 0.000	Loss 0.8990	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.17856987 0.17857127 0.17857623 0.17858188 0.17859665 0.17860298
 0.17860264 0.17860738 0.17865567 0.17865423 0.17868252 0.1786775
 0.17868781 0.17869259 0.17868792 0.17867997 0.17872244 0.17870654
 0.17872283 0.17871335]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.17865026 0.1786666  0.17866432 0.17865915 0.17865237 0.17865407
 0.17864684 0.1786611  0.17866773 0.17868977 0.17867934 0.17868569
 0.17868576 0.17866996 0.17868657 0.17868266 0.17868071 0.17869164
 0.17869048 0.17868452]
[0. 0. 0.]
-----------end of analyzing the loss ratio:74.6866385936737
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9385e6aa0>
---------------------------------
SparseEpoch: [72][1/398]	Time 0.605	Data 0.000	Loss 1.4409	
SparseEpoch: [72][101/398]	Time 0.626	Data 0.000	Loss 0.9804	
SparseEpoch: [72][201/398]	Time 0.626	Data 0.000	Loss 2.0287	
SparseEpoch: [72][301/398]	Time 0.625	Data 0.000	Loss 1.1992	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.1101	
Epoch(adapt):{0} Loss 0.8649	
Epoch(adapt):{0} Loss 1.3065	
Epoch(adapt):{0} Loss 1.5814	
------------------the total time cost:1218.5041596889496
>>>>>meta updating
Epoch: 0072 | TRAIN: 0.7826 0.4938 0.7421 | 0.4178 0.4178 0.2000 | 0.1568 27.1124 22.5818 0.2360 0.5064 0.6437 ||TEST: 1.0878 0.3664 0.6440 | 0.5536 0.5536 0.2182 | 0.1579 27.3465 23.0651 0.2338 0.4949 0.6310 | 115.6846
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.60962909 0.60966079 0.60968033 0.60944217 0.60942418 0.60942146
 0.60939467 0.60949236 0.60954192 0.60940738 0.60942602 0.60938199
 0.60934022 0.60928663 0.60922162 0.60926524 0.60926274 0.60922256
 0.60929431 0.60926651]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.60931963 0.6093341  0.60932604 0.6093391  0.60933316 0.60935777
 0.60938921 0.60943263 0.60937715 0.60940461 0.60940515 0.60942094
 0.60938305 0.6093743  0.60937265 0.60935871 0.6093673  0.60936736
 0.6094123  0.60940005]
[0.         0.23684211 0.        ]
-----------end of analyzing the loss ratio:74.70992016792297
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc93901ec20>
---------------------------------
SparseEpoch: [73][1/398]	Time 0.607	Data 0.000	Loss 0.6047	
SparseEpoch: [73][101/398]	Time 0.624	Data 0.000	Loss 0.8787	
SparseEpoch: [73][201/398]	Time 0.622	Data 0.000	Loss 1.2262	
SparseEpoch: [73][301/398]	Time 0.623	Data 0.000	Loss 1.4895	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.7329985  0.73274926 0.73254133 0.73240924 0.73237571 0.73224211
 0.73209329 0.73199019 0.73184735 0.73183094 0.73160714 0.73164403
 0.7314252  0.73103388 0.730861   0.73081528 0.73044858 0.73050348
 0.73046382 0.73044407]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.7317075  0.73183267 0.7318284  0.73176181 0.73181267 0.73179055
 0.73187177 0.73185335 0.73188951 0.73181529 0.73177378 0.73174736
 0.73173814 0.73168513 0.73160149 0.73160332 0.73155377 0.7315227
 0.73153424 0.73151621]
[0.5 0.  0.5]
-----------end of analyzing the loss ratio:74.5327582359314
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc93992de10>
---------------------------------
SparseEpoch: [73][1/398]	Time 0.607	Data 0.000	Loss 1.7281	
SparseEpoch: [73][101/398]	Time 0.626	Data 0.000	Loss 2.0548	
SparseEpoch: [73][201/398]	Time 0.628	Data 0.000	Loss 1.1345	
SparseEpoch: [73][301/398]	Time 0.626	Data 0.000	Loss 1.2636	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.14252645 0.14244189 0.14236525 0.14227666 0.14218758 0.14211071
 0.14208245 0.14201093 0.14192753 0.14180496 0.14170552 0.14162636
 0.1415415  0.14152269 0.14143275 0.14138485 0.14130602 0.14124359
 0.14124093 0.14119512]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.14198999 0.14197323 0.14195589 0.14193819 0.14193725 0.1419234
 0.14188878 0.14183972 0.14182322 0.14179918 0.14178089 0.14175048
 0.14173588 0.14170728 0.14169666 0.14167458 0.14164559 0.14162483
 0.14159529 0.14158256]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:74.51143431663513
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938fc63b0>
---------------------------------
SparseEpoch: [73][1/398]	Time 0.605	Data 0.000	Loss 1.8113	
SparseEpoch: [73][101/398]	Time 0.623	Data 0.000	Loss 2.1632	
SparseEpoch: [73][201/398]	Time 0.622	Data 0.000	Loss 2.3504	
SparseEpoch: [73][301/398]	Time 0.625	Data 0.000	Loss 1.6545	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.9298	
Epoch(adapt):{0} Loss 1.5429	
Epoch(adapt):{0} Loss 1.2101	
Epoch(adapt):{0} Loss 1.3971	
------------------the total time cost:1217.4204008579254
>>>>>meta updating
Epoch: 0073 | TRAIN: 0.7502 0.5165 0.7500 | 0.4108 0.4108 0.1983 | 0.1550 26.8852 22.2449 0.2400 0.5127 0.6499 ||TEST: 1.1002 0.3750 0.6492 | 0.5480 0.5480 0.2205 | 0.1572 27.2126 22.7891 0.2372 0.5009 0.6363 | 115.7736
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.79254162 0.79268655 0.79276587 0.79269234 0.7926743  0.79281961
 0.79295975 0.79303569 0.79305183 0.79303598 0.7929544  0.79286581
 0.79284678 0.79299057 0.79303125 0.79303438 0.79318611 0.7932236
 0.79322581 0.79335643]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.79290907 0.79291606 0.79292446 0.79291021 0.79291316 0.79289752
 0.79290229 0.79292114 0.79292902 0.79292603 0.79293395 0.7929103
 0.79289533 0.79289222 0.79291786 0.79291822 0.79295186 0.79292364
 0.79292319 0.79289787]
[0.         0.         0.18421053]
-----------end of analyzing the loss ratio:74.84408187866211
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9382c4880>
---------------------------------
SparseEpoch: [74][1/398]	Time 0.605	Data 0.000	Loss 1.2804	
SparseEpoch: [74][101/398]	Time 0.627	Data 0.000	Loss 1.2271	
SparseEpoch: [74][201/398]	Time 0.627	Data 0.000	Loss 0.9951	
SparseEpoch: [74][301/398]	Time 0.626	Data 0.000	Loss 1.4039	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.70162001 0.7018021  0.70168975 0.70187367 0.70218728 0.70207229
 0.70218919 0.70231736 0.70227528 0.70238439 0.70204318 0.70189645
 0.7016303  0.70153261 0.70156479 0.70152624 0.70145995 0.70133797
 0.70140099 0.70153754]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.70234598 0.70230859 0.70234112 0.70229752 0.70224142 0.70223684
 0.70220207 0.70219112 0.70219814 0.70225673 0.7021036  0.7021219
 0.70211736 0.70210158 0.70207903 0.70208156 0.7020462  0.70205182
 0.70208847 0.702088  ]
[0.39473684 0.         0.34210526]
-----------end of analyzing the loss ratio:74.70026063919067
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9388effa0>
---------------------------------
SparseEpoch: [74][1/398]	Time 0.606	Data 0.000	Loss 1.3153	
SparseEpoch: [74][101/398]	Time 0.619	Data 0.000	Loss 1.1170	
SparseEpoch: [74][201/398]	Time 0.621	Data 0.000	Loss 1.4955	
SparseEpoch: [74][301/398]	Time 0.623	Data 0.000	Loss 1.0930	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.18097013 0.18090789 0.18084707 0.18078296 0.1807655  0.18070806
 0.18066629 0.18063016 0.18057998 0.18054941 0.18044289 0.1803767
 0.18034456 0.18031036 0.18028827 0.18024129 0.18018517 0.18010105
 0.18005007 0.18001533]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.18061678 0.18060303 0.18059719 0.18058192 0.18059418 0.18057235
 0.18054956 0.18053548 0.18052926 0.18049216 0.18048539 0.18044987
 0.18045797 0.1804465  0.1804419  0.18043276 0.18041791 0.18043038
 0.18040493 0.1803888 ]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:74.62465643882751
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cca5e465210>
---------------------------------
SparseEpoch: [74][1/398]	Time 0.612	Data 0.000	Loss 2.4405	
SparseEpoch: [74][101/398]	Time 0.630	Data 0.000	Loss 2.0709	
SparseEpoch: [74][201/398]	Time 0.626	Data 0.000	Loss 1.9906	
SparseEpoch: [74][301/398]	Time 0.624	Data 0.000	Loss 3.4981	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.9303	
Epoch(adapt):{0} Loss 0.9381	
Epoch(adapt):{0} Loss 1.4484	
Epoch(adapt):{0} Loss 1.2258	
------------------the total time cost:1216.584676027298
>>>>>meta updating
Epoch: 0074 | TRAIN: 0.7103 0.5332 0.7645 | 0.4111 0.4111 0.1941 | 0.1522 26.5016 21.6384 0.2481 0.5252 0.6601 ||TEST: 1.0868 0.3802 0.6511 | 0.5461 0.5461 0.2194 | 0.1562 27.0054 22.4074 0.2438 0.5088 0.6429 | 115.8247
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.70450897 0.70436865 0.70443301 0.70442975 0.70452311 0.70462763
 0.70469815 0.70477945 0.70474809 0.70474767 0.70488678 0.70496381
 0.70507764 0.70509833 0.70524722 0.70522575 0.70534896 0.70539733
 0.70542782 0.70558041]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.70495607 0.70494769 0.70490879 0.70490316 0.70490359 0.70494172
 0.704912   0.70488344 0.70482453 0.7048014  0.70476719 0.70476366
 0.7047898  0.70477201 0.70479988 0.70479732 0.70479518 0.70478908
 0.70479221 0.7047716 ]
[0.         0.         0.07894737]
-----------end of analyzing the loss ratio:74.64034342765808
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cca5e1fbf10>
---------------------------------
SparseEpoch: [75][1/398]	Time 0.608	Data 0.000	Loss 1.6179	
SparseEpoch: [75][101/398]	Time 0.626	Data 0.000	Loss 0.9629	
SparseEpoch: [75][201/398]	Time 0.628	Data 0.000	Loss 0.6951	
SparseEpoch: [75][301/398]	Time 0.627	Data 0.000	Loss 1.1990	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.72431674 0.72409917 0.72388197 0.72369672 0.72347268 0.72352024
 0.72346456 0.72314773 0.72308708 0.72311851 0.72310901 0.72302353
 0.72256529 0.72238232 0.72224157 0.72212185 0.72191265 0.72172135
 0.72161499 0.72160993]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.72313198 0.72311917 0.72314402 0.72311047 0.72313834 0.72311161
 0.72313424 0.72312711 0.72309729 0.72307817 0.72307187 0.72303323
 0.7230139  0.72306107 0.72307316 0.72309374 0.72317462 0.72315368
 0.72310897 0.72308434]
[0.5        0.         0.13157895]
-----------end of analyzing the loss ratio:74.7144992351532
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938c05870>
---------------------------------
SparseEpoch: [75][1/398]	Time 0.606	Data 0.000	Loss 1.0939	
SparseEpoch: [75][101/398]	Time 0.631	Data 0.000	Loss 0.8875	
SparseEpoch: [75][201/398]	Time 0.627	Data 0.000	Loss 1.3481	
SparseEpoch: [75][301/398]	Time 0.627	Data 0.000	Loss 1.0664	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.19195339 0.19194192 0.19189672 0.19186977 0.19177573 0.19176456
 0.19173313 0.19168746 0.19167113 0.19168451 0.19169459 0.19170256
 0.19170041 0.19166241 0.19162526 0.19162512 0.19157325 0.19146741
 0.19147736 0.19142753]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.19171897 0.19170772 0.19170968 0.19169557 0.19169064 0.19166238
 0.19166131 0.19165558 0.19168882 0.191707   0.19170845 0.19169213
 0.19170034 0.19171866 0.1917192  0.19171119 0.19167939 0.19166353
 0.19166817 0.19168255]
[0.5 0.  0. ]
-----------end of analyzing the loss ratio:74.61064124107361
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938f6dea0>
---------------------------------
SparseEpoch: [75][1/398]	Time 0.606	Data 0.000	Loss 1.6102	
SparseEpoch: [75][101/398]	Time 0.622	Data 0.000	Loss 2.6701	
SparseEpoch: [75][201/398]	Time 0.624	Data 0.000	Loss 1.5021	
SparseEpoch: [75][301/398]	Time 0.625	Data 0.000	Loss 1.7468	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.4965	
Epoch(adapt):{0} Loss 1.3012	
Epoch(adapt):{0} Loss 1.1382	
Epoch(adapt):{0} Loss 1.2714	
------------------the total time cost:1218.3671538829803
>>>>>meta updating
Epoch: 0075 | TRAIN: 0.7405 0.5178 0.7536 | 0.4196 0.4196 0.1928 | 0.1539 26.7848 22.0935 0.2403 0.5149 0.6525 ||TEST: 1.1060 0.3801 0.6466 | 0.5579 0.5579 0.2162 | 0.1560 27.1122 22.7132 0.2380 0.5019 0.6378 | 115.8629
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.68623501 0.68619761 0.68626263 0.6862327  0.68624174 0.68625047
 0.6862039  0.68614612 0.68613926 0.6862145  0.68620271 0.68625118
 0.68622478 0.68614787 0.68617482 0.68619797 0.68615386 0.68616914
 0.68619192 0.68617051]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.68613772 0.68616054 0.68615894 0.68612072 0.68613747 0.68615599
 0.68614219 0.68616779 0.68619874 0.68621876 0.68622386 0.68622055
 0.68622441 0.68617827 0.68622189 0.68620793 0.68621156 0.68618479
 0.68621522 0.68620788]
[0. 0. 0.]
-----------end of analyzing the loss ratio:74.58332419395447
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938a8e1d0>
---------------------------------
SparseEpoch: [76][1/398]	Time 0.612	Data 0.000	Loss 0.5901	
SparseEpoch: [76][101/398]	Time 0.621	Data 0.000	Loss 1.1952	
SparseEpoch: [76][201/398]	Time 0.620	Data 0.000	Loss 0.5913	
SparseEpoch: [76][301/398]	Time 0.621	Data 0.000	Loss 0.8103	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.53432197 0.53434643 0.53441365 0.53448833 0.53448355 0.5345692
 0.53465282 0.53483981 0.53481518 0.53477734 0.5348121  0.53495514
 0.53500364 0.53505469 0.5351084  0.53520924 0.53525704 0.53533992
 0.53532905 0.53553261]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.534718   0.53469574 0.5346884  0.53469431 0.53474222 0.5347439
 0.53478994 0.5348211  0.5348288  0.53481064 0.53481711 0.53481962
 0.53482684 0.53482986 0.53481929 0.53482144 0.53480611 0.53479473
 0.53481867 0.53482598]
[0. 0. 0.]
-----------end of analyzing the loss ratio:74.6723563671112
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9389db520>
---------------------------------
SparseEpoch: [76][1/398]	Time 0.609	Data 0.000	Loss 0.4671	
SparseEpoch: [76][101/398]	Time 0.626	Data 0.000	Loss 0.5055	
SparseEpoch: [76][201/398]	Time 0.625	Data 0.000	Loss 0.5488	
SparseEpoch: [76][301/398]	Time 0.626	Data 0.000	Loss 0.5181	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.16315597 0.16314865 0.16313608 0.16314343 0.16312001 0.1630949
 0.16310412 0.1630932  0.16311027 0.16310905 0.16308731 0.16308135
 0.16307393 0.16304813 0.1630435  0.16303813 0.16303936 0.16304512
 0.16302761 0.16303318]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.16306539 0.16304594 0.16304525 0.16304334 0.16304856 0.16306376
 0.16307971 0.1630905  0.16309494 0.16309289 0.16310295 0.16310692
 0.16309497 0.16309431 0.1631004  0.16309612 0.16310918 0.16311283
 0.16311324 0.16310123]
[0.44736842 0.         0.        ]
-----------end of analyzing the loss ratio:74.84889340400696
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938504580>
---------------------------------
SparseEpoch: [76][1/398]	Time 0.611	Data 0.000	Loss 2.0998	
SparseEpoch: [76][101/398]	Time 0.622	Data 0.000	Loss 1.8154	
SparseEpoch: [76][201/398]	Time 0.623	Data 0.000	Loss 1.8996	
SparseEpoch: [76][301/398]	Time 0.624	Data 0.000	Loss 2.0412	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 2.0822	
Epoch(adapt):{0} Loss 1.3658	
Epoch(adapt):{0} Loss 1.8606	
Epoch(adapt):{0} Loss 1.4700	
------------------the total time cost:1216.0448806285858
>>>>>meta updating
Epoch: 0076 | TRAIN: 0.7485 0.5186 0.7541 | 0.4068 0.4068 0.1973 | 0.1574 27.2878 22.7854 0.2281 0.4997 0.6401 ||TEST: 1.0867 0.3789 0.6463 | 0.5446 0.5446 0.2159 | 0.1600 27.6408 23.4966 0.2286 0.4858 0.6222 | 116.1224
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.67042468 0.6704608  0.67051407 0.67040285 0.6704802  0.67048676
 0.6705402  0.67056409 0.67056232 0.67050898 0.6705191  0.67057077
 0.67063058 0.67063819 0.67058293 0.67066161 0.67071236 0.67082455
 0.6708261  0.67085544]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.67052114 0.67049465 0.67048604 0.67044769 0.67046782 0.67050065
 0.67050221 0.67047101 0.67045977 0.67047802 0.67048737 0.67052204
 0.67055843 0.6705793  0.67059971 0.67058148 0.67055889 0.67053905
 0.67052081 0.67056306]
[0. 0. 0.]
-----------end of analyzing the loss ratio:74.78087139129639
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc93881f550>
---------------------------------
SparseEpoch: [77][1/398]	Time 0.617	Data 0.000	Loss 0.8153	
SparseEpoch: [77][101/398]	Time 0.624	Data 0.000	Loss 0.5391	
SparseEpoch: [77][201/398]	Time 0.621	Data 0.000	Loss 0.8097	
SparseEpoch: [77][301/398]	Time 0.621	Data 0.000	Loss 0.5175	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.59208399 0.59206142 0.59202097 0.591961   0.59198147 0.59193045
 0.59203124 0.59209032 0.59213586 0.59218078 0.59208255 0.59188091
 0.59197853 0.59192897 0.59199797 0.59196528 0.59196821 0.59192478
 0.59194449 0.59190208]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.59213486 0.59215145 0.59215424 0.59215737 0.59214777 0.59215357
 0.59213504 0.59212468 0.59212535 0.59215208 0.59211754 0.59211055
 0.59209236 0.5920904  0.59206085 0.59203398 0.59202649 0.59199679
 0.59195111 0.5919389 ]
[0.07894737 0.         0.5       ]
-----------end of analyzing the loss ratio:74.79946398735046
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938d67d60>
---------------------------------
SparseEpoch: [77][1/398]	Time 0.619	Data 0.000	Loss 1.3085	
SparseEpoch: [77][101/398]	Time 0.624	Data 0.000	Loss 1.2252	
SparseEpoch: [77][201/398]	Time 0.622	Data 0.000	Loss 1.1954	
SparseEpoch: [77][301/398]	Time 0.621	Data 0.000	Loss 1.2363	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.2104029  0.2103434  0.21024385 0.21020859 0.2101268  0.21003802
 0.21002532 0.21005924 0.20999177 0.20991353 0.20988697 0.20983532
 0.20977066 0.20972725 0.20975178 0.20970116 0.20965673 0.20963406
 0.20953892 0.20955708]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.21000706 0.21000413 0.2099883  0.20996251 0.20994786 0.209951
 0.20990686 0.20991507 0.20989042 0.20989493 0.20987598 0.20986978
 0.20989274 0.20988895 0.20988647 0.20983719 0.2098367  0.20983353
 0.2098682  0.20986338]
[0.44736842 0.39473684 0.        ]
-----------end of analyzing the loss ratio:74.77149081230164
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9384fdba0>
---------------------------------
SparseEpoch: [77][1/398]	Time 0.606	Data 0.000	Loss 1.6269	
SparseEpoch: [77][101/398]	Time 0.621	Data 0.000	Loss 3.1197	
SparseEpoch: [77][201/398]	Time 0.625	Data 0.000	Loss 2.6636	
SparseEpoch: [77][301/398]	Time 0.624	Data 0.000	Loss 1.7538	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.1705	
Epoch(adapt):{0} Loss 2.2589	
Epoch(adapt):{0} Loss 1.0459	
Epoch(adapt):{0} Loss 1.2091	
------------------the total time cost:1216.448683977127
>>>>>meta updating
Epoch: 0077 | TRAIN: 0.7027 0.5411 0.7706 | 0.4085 0.4085 0.2001 | 0.1526 26.7059 22.1458 0.2388 0.5141 0.6532 ||TEST: 1.0809 0.3872 0.6531 | 0.5364 0.5364 0.2182 | 0.1566 27.2193 22.9048 0.2352 0.4978 0.6339 | 115.6882
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.65867094 0.65862159 0.65855553 0.65863584 0.65860163 0.658485
 0.65854768 0.65854592 0.6584696  0.65846995 0.65843768 0.65831628
 0.65814156 0.6581628  0.6581944  0.65809262 0.65811375 0.65811427
 0.65809037 0.65810984]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.65822521 0.6582805  0.65832188 0.65835013 0.65834465 0.65836572
 0.65838483 0.65838932 0.65842512 0.65844807 0.65846084 0.65844818
 0.65844625 0.6584558  0.65846033 0.65837831 0.6584289  0.65840345
 0.65844834 0.65841221]
[0.         0.44736842 0.        ]
-----------end of analyzing the loss ratio:74.52522087097168
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc93856f760>
---------------------------------
SparseEpoch: [78][1/398]	Time 0.606	Data 0.000	Loss 0.9545	
SparseEpoch: [78][101/398]	Time 0.618	Data 0.000	Loss 0.9942	
SparseEpoch: [78][201/398]	Time 0.620	Data 0.000	Loss 0.8575	
SparseEpoch: [78][301/398]	Time 0.623	Data 0.000	Loss 1.2233	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.60682341 0.60672196 0.6067105  0.60661873 0.60639349 0.6062922
 0.6061934  0.6059447  0.60589999 0.60596349 0.60598216 0.60616484
 0.60612488 0.60617704 0.60614991 0.60605296 0.60608707 0.60601391
 0.60590065 0.60584636]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.60594822 0.60593451 0.60591388 0.60594614 0.60592048 0.6058991
 0.60589231 0.60588813 0.60590525 0.60589793 0.60591274 0.60592598
 0.60594456 0.60594761 0.60594405 0.60593988 0.60593934 0.60594861
 0.60596823 0.60606574]
[0.5 0.  0. ]
-----------end of analyzing the loss ratio:74.86807155609131
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc93875de70>
---------------------------------
SparseEpoch: [78][1/398]	Time 0.605	Data 0.000	Loss 0.6549	
SparseEpoch: [78][101/398]	Time 0.620	Data 0.000	Loss 0.9005	
SparseEpoch: [78][201/398]	Time 0.622	Data 0.000	Loss 0.9340	
SparseEpoch: [78][301/398]	Time 0.622	Data 0.000	Loss 1.0166	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.17692175 0.17692427 0.17685187 0.17685008 0.17679482 0.1767456
 0.17671658 0.17672158 0.17671821 0.17666057 0.17662488 0.1766016
 0.17660334 0.17661496 0.17658731 0.1766113  0.1766093  0.17657758
 0.17650403 0.17647799]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.17674234 0.1767289  0.17672009 0.17669722 0.17671058 0.17671774
 0.17673222 0.17672133 0.17668517 0.17664979 0.17665756 0.17663935
 0.1766093  0.17659881 0.17657753 0.17656384 0.17656928 0.17658462
 0.17659169 0.1765711 ]
[0.5        0.28947368 0.        ]
-----------end of analyzing the loss ratio:74.57489943504333
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc939ee7760>
---------------------------------
SparseEpoch: [78][1/398]	Time 0.606	Data 0.000	Loss 2.6226	
SparseEpoch: [78][101/398]	Time 0.623	Data 0.000	Loss 2.1895	
SparseEpoch: [78][201/398]	Time 0.625	Data 0.000	Loss 2.0233	
SparseEpoch: [78][301/398]	Time 0.626	Data 0.000	Loss 2.1497	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.3207	
Epoch(adapt):{0} Loss 1.0248	
Epoch(adapt):{0} Loss 1.1032	
Epoch(adapt):{0} Loss 1.1978	
------------------the total time cost:1216.3982427120209
>>>>>meta updating
Epoch: 0078 | TRAIN: 0.7283 0.5244 0.7607 | 0.4137 0.4137 0.1875 | 0.1587 27.3249 22.8495 0.2332 0.4999 0.6389 ||TEST: 1.0804 0.3788 0.6487 | 0.5612 0.5612 0.2145 | 0.1594 27.5467 23.3743 0.2302 0.4884 0.6251 | 115.7663
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.63680179 0.63678519 0.63676453 0.63674814 0.63680472 0.6367827
 0.63668673 0.636672   0.63665952 0.63655665 0.63661893 0.63662043
 0.63668173 0.63672625 0.63670874 0.63663721 0.63651101 0.63644657
 0.63641027 0.63645267]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.63661958 0.63659102 0.63658977 0.63660602 0.6365762  0.63655958
 0.63656108 0.63659249 0.63659444 0.63659137 0.63657886 0.63660492
 0.63659378 0.63658496 0.63656444 0.6365766  0.63657191 0.63657853
 0.63655004 0.6365785 ]
[0.         0.44736842 0.44736842]
-----------end of analyzing the loss ratio:75.10221099853516
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cca5e354af0>
---------------------------------
SparseEpoch: [79][1/398]	Time 0.605	Data 0.000	Loss 4.3254	
SparseEpoch: [79][101/398]	Time 0.622	Data 0.000	Loss 1.1356	
SparseEpoch: [79][201/398]	Time 0.621	Data 0.000	Loss 1.9392	
SparseEpoch: [79][301/398]	Time 0.623	Data 0.000	Loss 1.6174	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.602833   0.60277679 0.60270126 0.6027847  0.6027096  0.60261037
 0.60262904 0.60254279 0.60247084 0.60254683 0.6025626  0.60279298
 0.60288773 0.60292397 0.60276455 0.60272031 0.60263928 0.60261815
 0.60254495 0.60265296]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.60255162 0.60256553 0.6025989  0.60258358 0.60259623 0.60257687
 0.60256749 0.60254807 0.60257905 0.60254555 0.60252706 0.60252674
 0.60251944 0.60252532 0.60252624 0.60250262 0.60250134 0.60252229
 0.60255857 0.60254842]
[0.         0.         0.34210526]
-----------end of analyzing the loss ratio:74.78285217285156
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938395120>
---------------------------------
SparseEpoch: [79][1/398]	Time 0.604	Data 0.000	Loss 0.7403	
SparseEpoch: [79][101/398]	Time 0.623	Data 0.000	Loss 0.8826	
SparseEpoch: [79][201/398]	Time 0.624	Data 0.000	Loss 0.9561	
SparseEpoch: [79][301/398]	Time 0.626	Data 0.000	Loss 0.7967	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.18790732 0.18785279 0.18782504 0.18780994 0.18776814 0.18776531
 0.18776071 0.18774741 0.18774196 0.18774098 0.18773033 0.1877275
 0.18770946 0.18770176 0.18768088 0.18767945 0.18768396 0.18767974
 0.18765397 0.18763992]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.18773025 0.18771974 0.18772459 0.18773451 0.18771739 0.18772359
 0.18773173 0.18775166 0.18773894 0.187749   0.1877355  0.1877338
 0.18771866 0.18774203 0.1877407  0.1877525  0.18776705 0.18778595
 0.18775823 0.18775245]
[0.5 0.  0. ]
-----------end of analyzing the loss ratio:74.69489789009094
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938c432e0>
---------------------------------
SparseEpoch: [79][1/398]	Time 0.610	Data 0.000	Loss 3.0973	
SparseEpoch: [79][101/398]	Time 0.628	Data 0.000	Loss 1.4170	
SparseEpoch: [79][201/398]	Time 0.626	Data 0.000	Loss 2.5594	
SparseEpoch: [79][301/398]	Time 0.624	Data 0.000	Loss 1.9502	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.5227	
Epoch(adapt):{0} Loss 1.2660	
Epoch(adapt):{0} Loss 1.5999	
Epoch(adapt):{0} Loss 0.8710	
------------------the total time cost:1215.4351253509521
>>>>>meta updating
Epoch: 0079 | TRAIN: 0.7027 0.5430 0.7700 | 0.4109 0.4109 0.1902 | 0.1474 26.0606 21.2351 0.2504 0.5349 0.6709 ||TEST: 1.0780 0.3799 0.6523 | 0.5490 0.5490 0.2156 | 0.1541 26.8402 22.2491 0.2423 0.5120 0.6477 | 115.6782
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.72600239 0.72597283 0.72591543 0.72585047 0.72579198 0.72576696
 0.72580706 0.72573434 0.72566096 0.72566763 0.72564313 0.72570376
 0.72569658 0.72548618 0.72543937 0.72534395 0.72538114 0.72527573
 0.72523037 0.72536617]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.72559833 0.72562524 0.72564065 0.72563491 0.72562916 0.72564788
 0.72567402 0.72565334 0.72563171 0.72562164 0.72562368 0.72560802
 0.72559831 0.72560676 0.72560664 0.72555481 0.72560443 0.72559178
 0.72559125 0.72557797]
[0.         0.44736842 0.28947368]
-----------end of analyzing the loss ratio:74.63625931739807
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc93875d900>
---------------------------------
SparseEpoch: [80][1/398]	Time 0.608	Data 0.000	Loss 2.2625	
SparseEpoch: [80][101/398]	Time 0.622	Data 0.000	Loss 1.6184	
SparseEpoch: [80][201/398]	Time 0.625	Data 0.000	Loss 1.3548	
SparseEpoch: [80][301/398]	Time 0.624	Data 0.000	Loss 1.3925	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.80077394 0.80082219 0.80038694 0.80008437 0.79993246 0.7996594
 0.79909279 0.79891515 0.7989049  0.79861723 0.79859198 0.79861091
 0.79829803 0.79812741 0.79797105 0.79775188 0.79772403 0.79752254
 0.79742218 0.7969891 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.79869256 0.79873178 0.79866878 0.79864075 0.7986791  0.798716
 0.79869637 0.79862213 0.79859812 0.79856446 0.79849428 0.79851263
 0.79848978 0.79853169 0.79854054 0.79851828 0.79853241 0.79860502
 0.79859192 0.79853876]
[0.5        0.         0.13157895]
-----------end of analyzing the loss ratio:74.54660820960999
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938376bc0>
---------------------------------
SparseEpoch: [80][1/398]	Time 0.604	Data 0.000	Loss 0.9297	
SparseEpoch: [80][101/398]	Time 0.624	Data 0.000	Loss 1.3913	
SparseEpoch: [80][201/398]	Time 0.622	Data 0.000	Loss 1.1317	
SparseEpoch: [80][301/398]	Time 0.623	Data 0.000	Loss 0.9817	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.18073013 0.18061626 0.18049964 0.18039982 0.18030016 0.18026938
 0.18009483 0.18002383 0.17997664 0.17984267 0.17978731 0.17971588
 0.1796626  0.17951065 0.17944816 0.17937817 0.17930839 0.17930187
 0.17923547 0.17904503]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.17988388 0.17988432 0.17988716 0.17988198 0.17987071 0.17986264
 0.17986713 0.17985521 0.17986168 0.17986221 0.17984983 0.17984114
 0.17982164 0.17982038 0.17981452 0.1798108  0.17979266 0.17978883
 0.17976807 0.179765  ]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:74.51653122901917
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938752620>
---------------------------------
SparseEpoch: [80][1/398]	Time 0.606	Data 0.000	Loss 1.1324	
SparseEpoch: [80][101/398]	Time 0.625	Data 0.000	Loss 1.3374	
SparseEpoch: [80][201/398]	Time 0.624	Data 0.000	Loss 2.2626	
SparseEpoch: [80][301/398]	Time 0.622	Data 0.000	Loss 2.0290	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 2.1612	
Epoch(adapt):{0} Loss 0.8337	
Epoch(adapt):{0} Loss 0.9582	
Epoch(adapt):{0} Loss 1.0497	
------------------the total time cost:1214.7566163539886
>>>>>meta updating
Epoch: 0080 | TRAIN: 0.7067 0.5266 0.7667 | 0.4045 0.4045 0.1933 | 0.1516 26.4538 21.6988 0.2485 0.5247 0.6609 ||TEST: 1.0865 0.3788 0.6529 | 0.5427 0.5427 0.2195 | 0.1541 26.7865 22.1810 0.2476 0.5132 0.6469 | 115.9636
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.71111175 0.71099665 0.7110045  0.71095445 0.71097972 0.7109129
 0.71086039 0.71069644 0.71069772 0.7107334  0.7107504  0.71073755
 0.71069587 0.71060686 0.71059298 0.71050854 0.71048292 0.71049998
 0.71036429 0.71022136]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.71080818 0.71080988 0.71073928 0.71072859 0.71080061 0.71084097
 0.71079726 0.71071057 0.71073773 0.71071368 0.71071995 0.71068534
 0.71074575 0.71081215 0.71082468 0.71081507 0.71082541 0.71082203
 0.71083896 0.71078842]
[0.         0.5        0.07894737]
-----------end of analyzing the loss ratio:74.53305101394653
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938ce1510>
---------------------------------
SparseEpoch: [81][1/398]	Time 0.606	Data 0.000	Loss 0.9802	
SparseEpoch: [81][101/398]	Time 0.632	Data 0.000	Loss 0.9613	
SparseEpoch: [81][201/398]	Time 0.629	Data 0.000	Loss 0.9525	
SparseEpoch: [81][301/398]	Time 0.628	Data 0.000	Loss 1.2705	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.65249974 0.65238237 0.65253933 0.6524979  0.65245028 0.65228162
 0.65237622 0.65242828 0.65226246 0.65229152 0.65245662 0.65248814
 0.65248559 0.65236338 0.6521172  0.65220266 0.65210358 0.65194917
 0.652032   0.65205772]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.65235196 0.65232586 0.6523193  0.65231242 0.6523333  0.65231055
 0.65234719 0.65235586 0.65240446 0.65242878 0.65243751 0.65242861
 0.65242026 0.65242203 0.65245328 0.65243053 0.65239913 0.65242153
 0.65242201 0.65240791]
[0.39473684 0.         0.        ]
-----------end of analyzing the loss ratio:74.53687238693237
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc93856d840>
---------------------------------
SparseEpoch: [81][1/398]	Time 0.606	Data 0.000	Loss 0.8478	
SparseEpoch: [81][101/398]	Time 0.619	Data 0.000	Loss 1.0669	
SparseEpoch: [81][201/398]	Time 0.621	Data 0.000	Loss 0.8388	
SparseEpoch: [81][301/398]	Time 0.622	Data 0.000	Loss 0.6571	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.18737715 0.18736835 0.18734522 0.18734625 0.18729507 0.18728225
 0.18722631 0.18719007 0.18718809 0.18716826 0.18717878 0.18718671
 0.18713363 0.18705483 0.18709505 0.18705458 0.18704993 0.18701611
 0.18702407 0.1869808 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.18699315 0.18704469 0.18706698 0.18710469 0.18712248 0.1871245
 0.18709604 0.18712043 0.18716308 0.18716525 0.18714223 0.18719462
 0.18719279 0.18722764 0.18723477 0.18723158 0.18724049 0.18728472
 0.18727038 0.1872201 ]
[0.5 0.  0. ]
-----------end of analyzing the loss ratio:74.5241289138794
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc93882c7c0>
---------------------------------
SparseEpoch: [81][1/398]	Time 0.605	Data 0.000	Loss 1.9906	
SparseEpoch: [81][101/398]	Time 0.630	Data 0.000	Loss 1.6293	
SparseEpoch: [81][201/398]	Time 0.628	Data 0.000	Loss 2.4477	
SparseEpoch: [81][301/398]	Time 0.627	Data 0.000	Loss 1.9569	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.9973	
Epoch(adapt):{0} Loss 1.2543	
Epoch(adapt):{0} Loss 1.3530	
Epoch(adapt):{0} Loss 1.5283	
------------------the total time cost:1217.2879309654236
>>>>>meta updating
Epoch: 0081 | TRAIN: 0.6781 0.5558 0.7794 | 0.4033 0.4033 0.1920 | 0.1544 26.8602 22.2893 0.2404 0.5107 0.6488 ||TEST: 1.0761 0.3880 0.6574 | 0.5441 0.5441 0.2134 | 0.1574 27.2039 22.8481 0.2416 0.4997 0.6338 | 115.8014
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.73645632 0.73643735 0.73647935 0.7364521  0.73642866 0.73641725
 0.73631271 0.73629596 0.73633972 0.73635356 0.73632607 0.7363123
 0.7362772  0.73633586 0.73637295 0.73636442 0.73641136 0.73642054
 0.73649277 0.73654397]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.73640509 0.73636685 0.73633549 0.73633069 0.73631798 0.73629687
 0.73629233 0.7362947  0.73629197 0.73630756 0.73632205 0.73634328
 0.73633013 0.73632325 0.7363128  0.7363179  0.73632963 0.73630265
 0.73633503 0.73635564]
[0.         0.13157895 0.        ]
-----------end of analyzing the loss ratio:74.478520154953
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938e17280>
---------------------------------
SparseEpoch: [82][1/398]	Time 0.606	Data 0.000	Loss 0.6131	
SparseEpoch: [82][101/398]	Time 0.624	Data 0.000	Loss 0.6837	
SparseEpoch: [82][201/398]	Time 0.621	Data 0.000	Loss 0.8375	
SparseEpoch: [82][301/398]	Time 0.621	Data 0.000	Loss 1.7869	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.6408063  0.64077332 0.64071237 0.64075373 0.64083825 0.64060746
 0.64046985 0.64048852 0.64046588 0.64047887 0.64036683 0.64013558
 0.64012004 0.64007821 0.63997204 0.63979469 0.63968101 0.63966779
 0.6395788  0.63968866]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.64043628 0.64046824 0.64030745 0.64038857 0.64037879 0.6404128
 0.64035684 0.64039649 0.64045075 0.64048414 0.64041991 0.64051603
 0.64047888 0.64046339 0.64040907 0.64038213 0.64044861 0.64040142
 0.64036759 0.64038346]
[0.44736842 0.         0.        ]
-----------end of analyzing the loss ratio:74.5677809715271
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938308580>
---------------------------------
SparseEpoch: [82][1/398]	Time 0.626	Data 0.000	Loss 0.6631	
SparseEpoch: [82][101/398]	Time 0.622	Data 0.000	Loss 0.8459	
SparseEpoch: [82][201/398]	Time 0.623	Data 0.000	Loss 0.9976	
SparseEpoch: [82][301/398]	Time 0.624	Data 0.000	Loss 1.2935	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.21857437 0.21856276 0.21851684 0.21850732 0.21853254 0.21840177
 0.21826966 0.21818901 0.21810909 0.21806449 0.21805906 0.21814445
 0.218169   0.21810033 0.21811047 0.21818393 0.21822836 0.21824119
 0.21825311 0.21821142]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.21821529 0.21824919 0.21822662 0.21813895 0.21806127 0.21807101
 0.21808891 0.21805325 0.21805581 0.21803618 0.21805187 0.21807105
 0.2181294  0.21817591 0.21816072 0.2181482  0.21820496 0.21818691
 0.21817874 0.21816261]
[0.02631579 0.         0.        ]
-----------end of analyzing the loss ratio:74.74732565879822
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cca5df80df0>
---------------------------------
SparseEpoch: [82][1/398]	Time 0.608	Data 0.000	Loss 1.6008	
SparseEpoch: [82][101/398]	Time 0.625	Data 0.000	Loss 2.1090	
SparseEpoch: [82][201/398]	Time 0.623	Data 0.000	Loss 1.2506	
SparseEpoch: [82][301/398]	Time 0.623	Data 0.000	Loss 2.3004	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.7863	
Epoch(adapt):{0} Loss 1.7611	
Epoch(adapt):{0} Loss 1.1971	
Epoch(adapt):{0} Loss 1.5687	
------------------the total time cost:1215.4739830493927
>>>>>meta updating
Epoch: 0082 | TRAIN: 0.6507 0.5698 0.7874 | 0.4073 0.4073 0.1951 | 0.1559 27.0715 22.5650 0.2333 0.5047 0.6444 ||TEST: 1.0645 0.3943 0.6618 | 0.5419 0.5419 0.2138 | 0.1574 27.2992 23.1034 0.2351 0.4943 0.6312 | 116.4284
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.7225572  0.72261873 0.72258902 0.72266793 0.72258749 0.72261477
 0.72266324 0.7225019  0.72259804 0.72272047 0.72283517 0.72292221
 0.72299663 0.7229203  0.72285062 0.7230515  0.72302905 0.72307918
 0.72295994 0.72292189]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.72280399 0.72280393 0.72280786 0.72280261 0.72276835 0.72279728
 0.72281332 0.7227976  0.72284244 0.72282798 0.72282963 0.72283084
 0.72283576 0.72281242 0.72280461 0.72279983 0.72278382 0.72276676
 0.72278099 0.72271723]
[0.  0.  0.5]
-----------end of analyzing the loss ratio:74.65051746368408
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938b7e920>
---------------------------------
SparseEpoch: [83][1/398]	Time 0.605	Data 0.000	Loss 1.9093	
SparseEpoch: [83][101/398]	Time 0.624	Data 0.000	Loss 1.6506	
SparseEpoch: [83][201/398]	Time 0.621	Data 0.000	Loss 1.3724	
SparseEpoch: [83][301/398]	Time 0.623	Data 0.000	Loss 2.2071	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.64959009 0.64944896 0.64948743 0.64939887 0.64938738 0.64945647
 0.6492803  0.64917041 0.64896313 0.64879095 0.64851489 0.64848456
 0.64831323 0.64839694 0.64837966 0.64805323 0.64790588 0.64790223
 0.64785717 0.64787548]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.64880199 0.64877359 0.64879849 0.64881477 0.64877364 0.64877801
 0.64873071 0.64877165 0.64875356 0.64873133 0.64870256 0.64873822
 0.64870586 0.64868345 0.64866185 0.64862059 0.64859213 0.64856097
 0.64849328 0.64846735]
[0.44736842 0.         0.5       ]
-----------end of analyzing the loss ratio:74.59621453285217
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9398a9420>
---------------------------------
SparseEpoch: [83][1/398]	Time 0.607	Data 0.000	Loss 1.9433	
SparseEpoch: [83][101/398]	Time 0.624	Data 0.000	Loss 1.4950	
SparseEpoch: [83][201/398]	Time 0.624	Data 0.000	Loss 1.8515	
SparseEpoch: [83][301/398]	Time 0.625	Data 0.000	Loss 1.9503	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.19418056 0.19418235 0.19417388 0.19416589 0.19412561 0.19412642
 0.19410299 0.19404132 0.19398179 0.19398417 0.19397247 0.19393853
 0.19387722 0.19386392 0.19382608 0.19381382 0.19380017 0.19376316
 0.19377424 0.19372848]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.19407846 0.19406592 0.19402346 0.1940066  0.19400477 0.19400194
 0.19400066 0.19397932 0.19398416 0.19397407 0.19398058 0.19396808
 0.19395455 0.19390368 0.19389418 0.19388239 0.1938684  0.19381754
 0.19382641 0.19381475]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:74.68684434890747
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938902410>
---------------------------------
SparseEpoch: [83][1/398]	Time 0.605	Data 0.000	Loss 2.3435	
SparseEpoch: [83][101/398]	Time 0.631	Data 0.000	Loss 2.3420	
SparseEpoch: [83][201/398]	Time 0.627	Data 0.000	Loss 2.7046	
SparseEpoch: [83][301/398]	Time 0.627	Data 0.000	Loss 1.5356	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.9133	
Epoch(adapt):{0} Loss 1.0395	
Epoch(adapt):{0} Loss 1.1892	
Epoch(adapt):{0} Loss 1.1523	
------------------the total time cost:1218.5252842903137
>>>>>meta updating
Epoch: 0083 | TRAIN: 0.6797 0.5549 0.7763 | 0.3853 0.3853 0.1838 | 0.1481 26.1312 21.3544 0.2514 0.5308 0.6677 ||TEST: 1.1015 0.3860 0.6462 | 0.5368 0.5368 0.2146 | 0.1525 26.7355 22.2899 0.2420 0.5114 0.6473 | 115.9978
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.65728237 0.65725374 0.65720163 0.65716985 0.65715464 0.65715114
 0.65705504 0.65709184 0.65707722 0.65710002 0.65710628 0.65714355
 0.65708026 0.65704397 0.6569879  0.65682915 0.65672064 0.65678753
 0.65681236 0.65687412]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.65713114 0.65713193 0.65713168 0.65709606 0.65708394 0.65708124
 0.65710252 0.65705388 0.65711275 0.65710254 0.65709146 0.65708315
 0.65707422 0.65711134 0.65707047 0.65704058 0.65701384 0.65698181
 0.65698716 0.65698046]
[0.         0.34210526 0.5       ]
-----------end of analyzing the loss ratio:75.17058515548706
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc93882dc90>
---------------------------------
SparseEpoch: [84][1/398]	Time 0.607	Data 0.000	Loss 1.7135	
SparseEpoch: [84][101/398]	Time 0.624	Data 0.000	Loss 1.6063	
SparseEpoch: [84][201/398]	Time 0.624	Data 0.000	Loss 1.6243	
SparseEpoch: [84][301/398]	Time 0.624	Data 0.000	Loss 1.5158	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.57432875 0.57449276 0.57459313 0.57460137 0.57465818 0.57491704
 0.57501859 0.57500249 0.57487017 0.57505714 0.57516873 0.57512549
 0.57529121 0.57552178 0.57575059 0.57593921 0.57635459 0.5764779
 0.57675579 0.57663385]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.57510448 0.57509721 0.57510872 0.57510362 0.57505409 0.57505436
 0.57502061 0.57502283 0.57501767 0.57506298 0.57506258 0.5750586
 0.57506825 0.57507341 0.57506579 0.57510186 0.57510657 0.57510458
 0.57509752 0.57511534]
[0. 0. 0.]
-----------end of analyzing the loss ratio:74.78180575370789
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc93901f640>
---------------------------------
SparseEpoch: [84][1/398]	Time 0.604	Data 0.000	Loss 0.2588	
SparseEpoch: [84][101/398]	Time 0.626	Data 0.000	Loss 0.2961	
SparseEpoch: [84][201/398]	Time 0.626	Data 0.000	Loss 0.4249	
SparseEpoch: [84][301/398]	Time 0.626	Data 0.000	Loss 0.2605	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.19372105 0.1936161  0.19351544 0.19342298 0.19331442 0.19322503
 0.19312652 0.19316998 0.19308136 0.19301739 0.19300345 0.19293653
 0.1928635  0.19287151 0.19282938 0.19283434 0.19281023 0.19273899
 0.19277886 0.19276215]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.19316283 0.19313032 0.19316346 0.19314229 0.19312966 0.19311292
 0.19306004 0.19306904 0.19302887 0.19302283 0.19298076 0.19299068
 0.19298568 0.19297256 0.1929514  0.19293596 0.1928848  0.19286526
 0.19288414 0.19283234]
[0.39473684 0.5        0.        ]
-----------end of analyzing the loss ratio:74.84776091575623
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc93830a5f0>
---------------------------------
SparseEpoch: [84][1/398]	Time 0.604	Data 0.000	Loss 2.1119	
SparseEpoch: [84][101/398]	Time 0.628	Data 0.000	Loss 2.0407	
SparseEpoch: [84][201/398]	Time 0.627	Data 0.000	Loss 1.3392	
SparseEpoch: [84][301/398]	Time 0.626	Data 0.000	Loss 2.0142	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.0988	
Epoch(adapt):{0} Loss 1.2894	
Epoch(adapt):{0} Loss 1.6974	
Epoch(adapt):{0} Loss 1.2004	
------------------the total time cost:1217.6549470424652
>>>>>meta updating
Epoch: 0084 | TRAIN: 0.6709 0.5636 0.7798 | 0.3940 0.3940 0.1885 | 0.1500 26.4041 21.8045 0.2448 0.5211 0.6590 ||TEST: 1.1086 0.3871 0.6503 | 0.5338 0.5338 0.2142 | 0.1548 27.0019 22.7242 0.2402 0.5021 0.6384 | 116.0007
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.71846219 0.71843218 0.71857529 0.71857859 0.71861979 0.71837184
 0.71836891 0.71832932 0.71830104 0.71810962 0.71815236 0.71814595
 0.71815247 0.71808947 0.71811636 0.71811331 0.71781061 0.71785766
 0.71790432 0.7176985 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.71814526 0.71815288 0.71818894 0.71818    0.71814812 0.71812789
 0.71813344 0.71814339 0.71810348 0.71809151 0.71806518 0.71810171
 0.71811054 0.71809854 0.7181056  0.71809335 0.7181083  0.71807488
 0.71805706 0.71807849]
[0.         0.5        0.44736842]
-----------end of analyzing the loss ratio:74.72315192222595
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc939031f30>
---------------------------------
SparseEpoch: [85][1/398]	Time 0.605	Data 0.000	Loss 1.8126	
SparseEpoch: [85][101/398]	Time 0.624	Data 0.000	Loss 2.1747	
SparseEpoch: [85][201/398]	Time 0.622	Data 0.000	Loss 1.9918	
SparseEpoch: [85][301/398]	Time 0.622	Data 0.000	Loss 1.9651	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.60546309 0.60545048 0.60537772 0.60532303 0.60529985 0.60536542
 0.60537871 0.60529137 0.60524426 0.60514724 0.60505569 0.60503268
 0.6050519  0.60501085 0.60505462 0.60496913 0.60493105 0.60504191
 0.60497323 0.6049549 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.6051475  0.60513048 0.6050961  0.6050668  0.60507272 0.60508439
 0.60510257 0.60509675 0.60510255 0.60510737 0.60507704 0.60509216
 0.60508422 0.60506176 0.60510333 0.60512486 0.60511692 0.60512808
 0.60511586 0.60515149]
[0.34210526 0.         0.18421053]
-----------end of analyzing the loss ratio:74.75773501396179
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938b14a60>
---------------------------------
SparseEpoch: [85][1/398]	Time 0.607	Data 0.000	Loss 1.3226	
SparseEpoch: [85][101/398]	Time 0.621	Data 0.000	Loss 1.2750	
SparseEpoch: [85][201/398]	Time 0.621	Data 0.000	Loss 0.7561	
SparseEpoch: [85][301/398]	Time 0.623	Data 0.000	Loss 1.0975	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.1662143  0.16600272 0.16582873 0.16563073 0.16542304 0.16513304
 0.16494057 0.16465257 0.16440578 0.16423398 0.16402507 0.16376102
 0.16352625 0.16331837 0.16312562 0.16291267 0.1627108  0.16258246
 0.16252431 0.16236587]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.16467036 0.16460805 0.16456953 0.164498   0.16443254 0.16434725
 0.16429032 0.16428072 0.16420547 0.16413023 0.16408516 0.16402743
 0.1639567  0.1638922  0.16383969 0.16374799 0.16365526 0.16360202
 0.16357538 0.16352303]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:74.57665753364563
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938373310>
---------------------------------
SparseEpoch: [85][1/398]	Time 0.605	Data 0.000	Loss 1.9112	
SparseEpoch: [85][101/398]	Time 0.617	Data 0.000	Loss 1.9249	
SparseEpoch: [85][201/398]	Time 0.619	Data 0.000	Loss 2.1692	
SparseEpoch: [85][301/398]	Time 0.620	Data 0.000	Loss 2.6616	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.5367	
Epoch(adapt):{0} Loss 2.0291	
Epoch(adapt):{0} Loss 1.5146	
Epoch(adapt):{0} Loss 0.7781	
------------------the total time cost:1214.897723197937
>>>>>meta updating
Epoch: 0085 | TRAIN: 0.6707 0.5609 0.7785 | 0.3913 0.3913 0.1871 | 0.1499 26.3131 21.4956 0.2497 0.5284 0.6625 ||TEST: 1.1127 0.3870 0.6499 | 0.5402 0.5402 0.2164 | 0.1554 26.9863 22.4356 0.2412 0.5081 0.6427 | 116.1821
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.54428927 0.54442264 0.54441828 0.54448891 0.54447676 0.54444878
 0.54448249 0.54448784 0.54448735 0.54430747 0.54424294 0.54428987
 0.54417374 0.54416629 0.54419676 0.54409939 0.54407225 0.54399312
 0.54403709 0.54398609]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.54437354 0.54440786 0.54443578 0.54432595 0.54428877 0.54423574
 0.54423952 0.54423828 0.54425506 0.54429013 0.54433493 0.54432749
 0.54439158 0.54433859 0.54432397 0.54435348 0.54432887 0.54430722
 0.5442873  0.54428484]
[0.  0.5 0. ]
-----------end of analyzing the loss ratio:74.8127989768982
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938ce0bb0>
---------------------------------
SparseEpoch: [86][1/398]	Time 0.606	Data 0.000	Loss 1.1277	
SparseEpoch: [86][101/398]	Time 0.625	Data 0.000	Loss 0.9864	
SparseEpoch: [86][201/398]	Time 0.624	Data 0.000	Loss 1.1379	
SparseEpoch: [86][301/398]	Time 0.623	Data 0.000	Loss 1.0181	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.48432247 0.48455404 0.4844468  0.4845789  0.48456822 0.48457691
 0.48453429 0.48460304 0.48482166 0.48494161 0.48507327 0.48516015
 0.48512599 0.48514765 0.48532387 0.48550892 0.48539515 0.48540317
 0.48548619 0.48558005]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.48495823 0.48492784 0.48492243 0.48493054 0.48493271 0.48495894
 0.48494528 0.48495391 0.48494759 0.48491765 0.4849766  0.48495998
 0.4849757  0.48498502 0.48503236 0.48504254 0.48505219 0.4850577
 0.48501511 0.48500724]
[0. 0. 0.]
-----------end of analyzing the loss ratio:74.76830172538757
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938dd9b70>
---------------------------------
SparseEpoch: [86][1/398]	Time 0.605	Data 0.000	Loss 0.3261	
SparseEpoch: [86][101/398]	Time 0.620	Data 0.000	Loss 0.3778	
SparseEpoch: [86][201/398]	Time 0.623	Data 0.000	Loss 0.3755	
SparseEpoch: [86][301/398]	Time 0.624	Data 0.000	Loss 0.4860	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.19347646 0.19350163 0.19344329 0.19335767 0.19322473 0.1931492
 0.19305109 0.19299939 0.19290765 0.1928321  0.19280317 0.1926459
 0.19248543 0.1924291  0.19232739 0.19221506 0.19210746 0.19203046
 0.19195464 0.19179164]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.19302422 0.19298596 0.1929567  0.19292515 0.1928882  0.19288407
 0.19285516 0.19282455 0.19283673 0.19278728 0.19281032 0.19281039
 0.19280575 0.19273221 0.19267237 0.19262875 0.19253348 0.19250698
 0.19250609 0.19250243]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:74.67608451843262
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9398fa7d0>
---------------------------------
SparseEpoch: [86][1/398]	Time 0.607	Data 0.000	Loss 2.2597	
SparseEpoch: [86][101/398]	Time 0.625	Data 0.000	Loss 2.5701	
SparseEpoch: [86][201/398]	Time 0.625	Data 0.000	Loss 1.8144	
SparseEpoch: [86][301/398]	Time 0.625	Data 0.000	Loss 2.7538	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.6140	
Epoch(adapt):{0} Loss 1.1201	
Epoch(adapt):{0} Loss 1.0146	
Epoch(adapt):{0} Loss 0.9632	
------------------the total time cost:1218.041852235794
>>>>>meta updating
Epoch: 0086 | TRAIN: 0.6620 0.5671 0.7848 | 0.3838 0.3838 0.1830 | 0.1524 26.6821 22.1912 0.2406 0.5136 0.6523 ||TEST: 1.0920 0.3870 0.6522 | 0.5396 0.5396 0.2153 | 0.1569 27.2252 22.9572 0.2362 0.4976 0.6340 | 116.1550
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.71643577 0.71644959 0.71641213 0.71643225 0.71645235 0.71643964
 0.71639714 0.71636361 0.71639087 0.71635742 0.7163366  0.7162946
 0.71620663 0.71620979 0.71617448 0.7161843  0.71618994 0.71623993
 0.71625093 0.71632179]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.71632954 0.7163473  0.71635368 0.71637757 0.71636133 0.71635671
 0.71635646 0.71637075 0.71637719 0.71637043 0.71639945 0.7163679
 0.71630442 0.71628693 0.71628367 0.71632183 0.7162759  0.71626068
 0.71626661 0.71625845]
[0.         0.23684211 0.5       ]
-----------end of analyzing the loss ratio:74.82459354400635
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9388c5f90>
---------------------------------
SparseEpoch: [87][1/398]	Time 0.608	Data 0.000	Loss 2.1011	
SparseEpoch: [87][101/398]	Time 0.630	Data 0.000	Loss 1.2812	
SparseEpoch: [87][201/398]	Time 0.628	Data 0.000	Loss 1.4995	
SparseEpoch: [87][301/398]	Time 0.627	Data 0.000	Loss 2.2489	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.44245136 0.4424986  0.44245908 0.44236139 0.44239084 0.44226411
 0.44245422 0.44235456 0.44240232 0.44232937 0.44231675 0.44234134
 0.44234649 0.44234392 0.44250038 0.44256824 0.44250316 0.44260764
 0.44261772 0.44256845]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.44228598 0.44230238 0.44230006 0.44229867 0.44232634 0.44231744
 0.44233767 0.44233334 0.44229939 0.44231356 0.44232123 0.44231891
 0.44232101 0.44233945 0.44230173 0.44233907 0.44228765 0.44227203
 0.44229318 0.44229396]
[0.         0.         0.39473684]
-----------end of analyzing the loss ratio:74.69075131416321
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938a1afb0>
---------------------------------
SparseEpoch: [87][1/398]	Time 0.609	Data 0.000	Loss 0.9721	
SparseEpoch: [87][101/398]	Time 0.622	Data 0.000	Loss 0.9619	
SparseEpoch: [87][201/398]	Time 0.626	Data 0.000	Loss 1.3326	
SparseEpoch: [87][301/398]	Time 0.625	Data 0.000	Loss 1.2365	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.18367674 0.18361338 0.18344266 0.18336392 0.18332192 0.18326852
 0.18314232 0.18297954 0.1829253  0.18285725 0.18280196 0.18272462
 0.18261994 0.18249415 0.18241989 0.18234228 0.18229294 0.18218849
 0.18219438 0.18209196]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.18300589 0.18297082 0.18292849 0.182905   0.18286482 0.18287221
 0.18285306 0.18286495 0.18283561 0.1828208  0.1828324  0.18281584
 0.18282711 0.18279424 0.182771   0.18275989 0.18273203 0.18268805
 0.18267914 0.18265127]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:74.867751121521
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938a4c2b0>
---------------------------------
SparseEpoch: [87][1/398]	Time 0.614	Data 0.000	Loss 2.1243	
SparseEpoch: [87][101/398]	Time 0.621	Data 0.000	Loss 2.8549	
SparseEpoch: [87][201/398]	Time 0.623	Data 0.000	Loss 2.0297	
SparseEpoch: [87][301/398]	Time 0.624	Data 0.000	Loss 2.6845	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.2588	
Epoch(adapt):{0} Loss 0.7855	
Epoch(adapt):{0} Loss 0.8834	
Epoch(adapt):{0} Loss 1.4304	
------------------the total time cost:1217.4666047096252
>>>>>meta updating
Epoch: 0087 | TRAIN: 0.6410 0.5769 0.7944 | 0.3827 0.3827 0.1825 | 0.1460 25.7995 20.9137 0.2638 0.5395 0.6736 ||TEST: 1.0799 0.3870 0.6607 | 0.5376 0.5376 0.2152 | 0.1519 26.5018 21.8757 0.2556 0.5194 0.6518 | 116.0035
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.63417524 0.63402493 0.63403767 0.63400748 0.63399806 0.63397701
 0.63396276 0.63395023 0.6338785  0.63383091 0.63379255 0.63377057
 0.63386609 0.6338137  0.63377909 0.63372649 0.63375702 0.6337348
 0.63371134 0.63390268]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.63398013 0.63392276 0.63387321 0.633896   0.63385799 0.63383418
 0.63378808 0.63376346 0.63378837 0.63380676 0.63381055 0.63381677
 0.63382074 0.6338001  0.63383202 0.63387554 0.63392117 0.63389315
 0.63393355 0.63393065]
[0.         0.44736842 0.        ]
-----------end of analyzing the loss ratio:74.772390127182
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc939e6fd90>
---------------------------------
SparseEpoch: [88][1/398]	Time 0.628	Data 0.000	Loss 1.0918	
SparseEpoch: [88][101/398]	Time 0.624	Data 0.000	Loss 0.8182	
SparseEpoch: [88][201/398]	Time 0.624	Data 0.000	Loss 1.5252	
SparseEpoch: [88][301/398]	Time 0.623	Data 0.000	Loss 1.0453	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.75171306 0.75056607 0.74930104 0.7485674  0.7471633  0.74606968
 0.74481789 0.74360039 0.74235165 0.74147171 0.74016278 0.73895681
 0.73803358 0.73649274 0.73545946 0.73398808 0.73283373 0.73163809
 0.73071079 0.72908472]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.7414566  0.74133195 0.74121349 0.74120053 0.74126256 0.74111683
 0.74104505 0.74107351 0.74101297 0.74099928 0.7409987  0.74082301
 0.7408569  0.74073727 0.74063297 0.74051271 0.74043608 0.74042899
 0.74035808 0.74026765]
[0.5 0.  0.5]
-----------end of analyzing the loss ratio:74.71718144416809
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cca5e2f2140>
---------------------------------
SparseEpoch: [88][1/398]	Time 0.604	Data 0.000	Loss 1.8145	
SparseEpoch: [88][101/398]	Time 0.622	Data 0.000	Loss 2.0479	
SparseEpoch: [88][201/398]	Time 0.621	Data 0.000	Loss 2.0900	
SparseEpoch: [88][301/398]	Time 0.623	Data 0.000	Loss 1.9813	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.18406594 0.18404288 0.18400602 0.18400389 0.1839941  0.18394781
 0.18390228 0.18387495 0.18382478 0.18376566 0.18373052 0.18370227
 0.18367628 0.18363198 0.18362728 0.18361237 0.18357067 0.18353515
 0.18353061 0.18351471]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.18381164 0.18381035 0.18380782 0.18379014 0.18377835 0.1837745
 0.18377327 0.18376443 0.1837471  0.18374805 0.18375935 0.18376269
 0.18377233 0.18376514 0.18374345 0.18373046 0.18372881 0.18372865
 0.18370082 0.18370225]
[0.5        0.44736842 0.        ]
-----------end of analyzing the loss ratio:74.78274583816528
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938c6cf70>
---------------------------------
SparseEpoch: [88][1/398]	Time 0.605	Data 0.000	Loss 2.1394	
SparseEpoch: [88][101/398]	Time 0.628	Data 0.000	Loss 1.8980	
SparseEpoch: [88][201/398]	Time 0.627	Data 0.000	Loss 2.4285	
SparseEpoch: [88][301/398]	Time 0.627	Data 0.000	Loss 1.9521	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.0019	
Epoch(adapt):{0} Loss 1.4346	
Epoch(adapt):{0} Loss 1.0619	
Epoch(adapt):{0} Loss 1.0570	
------------------the total time cost:1216.8763620853424
>>>>>meta updating
Epoch: 0088 | TRAIN: 0.6279 0.5868 0.7964 | 0.3821 0.3821 0.1897 | 0.1484 26.1663 21.4851 0.2511 0.5296 0.6662 ||TEST: 1.0982 0.3994 0.6601 | 0.5334 0.5334 0.2188 | 0.1523 26.6667 22.1608 0.2466 0.5134 0.6482 | 116.0847
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.53694774 0.53700336 0.5370533  0.537088   0.53706916 0.53700484
 0.53701571 0.53707265 0.53708979 0.53714203 0.53709788 0.53712844
 0.5371254  0.53718593 0.53720902 0.53715822 0.53715366 0.53721212
 0.53725857 0.53723056]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.53716848 0.53715881 0.53714209 0.53711513 0.53711632 0.53709781
 0.53710548 0.53709911 0.53711086 0.53707445 0.5370632  0.53708137
 0.53706728 0.53705178 0.53705515 0.53703068 0.53701966 0.53702794
 0.53701629 0.53702415]
[0.         0.         0.44736842]
-----------end of analyzing the loss ratio:74.82651162147522
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938505ea0>
---------------------------------
SparseEpoch: [89][1/398]	Time 0.605	Data 0.000	Loss 1.4473	
SparseEpoch: [89][101/398]	Time 0.627	Data 0.000	Loss 1.3511	
SparseEpoch: [89][201/398]	Time 0.623	Data 0.000	Loss 1.6614	
SparseEpoch: [89][301/398]	Time 0.624	Data 0.000	Loss 1.4142	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.68121085 0.68154879 0.68191118 0.68233373 0.68267838 0.68302103
 0.68326167 0.68343825 0.68371393 0.6840852  0.6843827  0.68483487
 0.68511315 0.6854259  0.68572519 0.68606072 0.68642976 0.68687028
 0.68703764 0.68727106]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.6839808  0.68399702 0.68399826 0.68398719 0.68401274 0.68402383
 0.68402173 0.68402181 0.68411536 0.68414329 0.68414781 0.68419724
 0.68423375 0.68422345 0.68419156 0.68423087 0.68423733 0.68430222
 0.68432882 0.68431564]
[0. 0. 0.]
-----------end of analyzing the loss ratio:74.61623311042786
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938374880>
---------------------------------
SparseEpoch: [89][1/398]	Time 0.603	Data 0.000	Loss 0.3879	
SparseEpoch: [89][101/398]	Time 0.619	Data 0.000	Loss 0.5315	
SparseEpoch: [89][201/398]	Time 0.623	Data 0.000	Loss 0.3420	
SparseEpoch: [89][301/398]	Time 0.624	Data 0.000	Loss 0.5426	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.15130326 0.15123788 0.15123368 0.15119698 0.15115838 0.15109435
 0.15105468 0.15102622 0.15091732 0.15083162 0.15075358 0.15067353
 0.15058357 0.1505259  0.15046717 0.15039451 0.15037572 0.15035582
 0.15028652 0.15025969]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.15099639 0.15100055 0.15101146 0.15100858 0.15097539 0.1509055
 0.15089051 0.15086215 0.1508197  0.15078035 0.15078238 0.1507549
 0.15073264 0.15069465 0.15069268 0.15063807 0.15060469 0.15058827
 0.15059095 0.15059346]
[0.5        0.39473684 0.        ]
-----------end of analyzing the loss ratio:74.79123878479004
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc93882e860>
---------------------------------
SparseEpoch: [89][1/398]	Time 0.605	Data 0.000	Loss 2.5413	
SparseEpoch: [89][101/398]	Time 0.623	Data 0.000	Loss 1.8554	
SparseEpoch: [89][201/398]	Time 0.624	Data 0.000	Loss 1.6851	
SparseEpoch: [89][301/398]	Time 0.624	Data 0.000	Loss 2.4171	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.2440	
Epoch(adapt):{0} Loss 1.3131	
Epoch(adapt):{0} Loss 1.0577	
Epoch(adapt):{0} Loss 1.2269	
------------------the total time cost:1215.1994256973267
>>>>>meta updating
Epoch: 0089 | TRAIN: 0.6477 0.5671 0.7880 | 0.3857 0.3857 0.1961 | 0.1475 26.0908 21.4857 0.2517 0.5289 0.6664 ||TEST: 1.1126 0.3854 0.6483 | 0.5256 0.5256 0.2200 | 0.1524 26.6774 22.2529 0.2474 0.5119 0.6467 | 116.0111
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.81732734 0.817154   0.8169903  0.81694064 0.81672879 0.81654419
 0.81673293 0.81645754 0.81632732 0.81630013 0.8164253  0.81644942
 0.81654292 0.8167488  0.81681487 0.8169173  0.81710078 0.81728037
 0.81733131 0.81748677]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.81637528 0.8164014  0.81642025 0.81638495 0.81637885 0.81640205
 0.81640131 0.81642118 0.81636901 0.81635978 0.81634513 0.8163172
 0.8163588  0.81636482 0.81636994 0.81636931 0.81637917 0.81637606
 0.81638255 0.8164116 ]
[0.         0.         0.07894737]
-----------end of analyzing the loss ratio:74.89232039451599
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9383961d0>
---------------------------------
SparseEpoch: [90][1/398]	Time 0.627	Data 0.000	Loss 1.0995	
SparseEpoch: [90][101/398]	Time 0.621	Data 0.000	Loss 0.7836	
SparseEpoch: [90][201/398]	Time 0.623	Data 0.000	Loss 0.7067	
SparseEpoch: [90][301/398]	Time 0.622	Data 0.000	Loss 1.6420	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.14054719 1.14056842 1.14032279 1.14000576 1.13981715 1.13946453
 1.1392679  1.13924544 1.13902987 1.13888891 1.13842113 1.13807516
 1.1376482  1.13762586 1.13724223 1.1374878  1.13673216 1.1367443
 1.1360561  1.13545319]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.13885005 1.138833   1.13875716 1.13876944 1.13866645 1.13864445
 1.13869656 1.13869929 1.13866833 1.13854994 1.13860556 1.13856101
 1.13854288 1.13856995 1.13857943 1.13855763 1.13846702 1.1384498
 1.13845357 1.13850285]
[0.5        0.         0.39473684]
-----------end of analyzing the loss ratio:74.69310021400452
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938e00790>
---------------------------------
SparseEpoch: [90][1/398]	Time 0.606	Data 0.000	Loss 1.1334	
SparseEpoch: [90][101/398]	Time 0.624	Data 0.000	Loss 1.3336	
SparseEpoch: [90][201/398]	Time 0.625	Data 0.000	Loss 1.5848	
SparseEpoch: [90][301/398]	Time 0.625	Data 0.000	Loss 2.2870	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.15271128 0.15261785 0.15253097 0.1523853  0.15229867 0.15224825
 0.15221929 0.15218351 0.15207337 0.15201827 0.15189523 0.15186702
 0.15180174 0.15171719 0.15168542 0.15163771 0.15158597 0.15145299
 0.15143086 0.1513777 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.15208172 0.15209277 0.15209063 0.15206225 0.15205861 0.15205248
 0.15203869 0.15202318 0.1520017  0.15196809 0.15195827 0.1519389
 0.15191019 0.15189121 0.15188183 0.15185826 0.15185117 0.15185747
 0.15181999 0.15180916]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:74.65812993049622
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc93997e860>
---------------------------------
SparseEpoch: [90][1/398]	Time 0.607	Data 0.000	Loss 1.7316	
SparseEpoch: [90][101/398]	Time 0.625	Data 0.000	Loss 2.0383	
SparseEpoch: [90][201/398]	Time 0.623	Data 0.000	Loss 2.7722	
SparseEpoch: [90][301/398]	Time 0.623	Data 0.000	Loss 2.1749	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.9891	
Epoch(adapt):{0} Loss 0.8753	
Epoch(adapt):{0} Loss 1.3604	
Epoch(adapt):{0} Loss 1.1051	
------------------the total time cost:1218.0291833877563
>>>>>meta updating
Epoch: 0090 | TRAIN: 0.6441 0.5716 0.7901 | 0.4024 0.4024 0.1850 | 0.1462 25.8888 21.0425 0.2566 0.5382 0.6738 ||TEST: 1.0641 0.3924 0.6588 | 0.5549 0.5549 0.2140 | 0.1510 26.4421 21.7504 0.2519 0.5227 0.6557 | 116.2649
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.71273952 0.71281287 0.71281705 0.71275442 0.71274477 0.71268723
 0.71246189 0.71257713 0.71257463 0.71247136 0.71260192 0.71268124
 0.71265051 0.71257009 0.71258042 0.71242651 0.71247941 0.71252906
 0.7124355  0.71253336]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.71256439 0.71255161 0.71255568 0.71259477 0.71257342 0.7125612
 0.71258568 0.71257271 0.71255999 0.71256905 0.71259137 0.71257295
 0.71258225 0.71256217 0.71257668 0.712574   0.71257391 0.71258338
 0.71260751 0.71261096]
[0.         0.28947368 0.        ]
-----------end of analyzing the loss ratio:74.90301156044006
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cca5df839a0>
---------------------------------
SparseEpoch: [91][1/398]	Time 0.605	Data 0.000	Loss 0.6903	
SparseEpoch: [91][101/398]	Time 0.618	Data 0.000	Loss 0.7405	
SparseEpoch: [91][201/398]	Time 0.622	Data 0.000	Loss 0.7762	
SparseEpoch: [91][301/398]	Time 0.622	Data 0.000	Loss 0.7670	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.51647294 0.5164286  0.51618269 0.51632887 0.51627072 0.51615928
 0.51613565 0.51625153 0.51617862 0.51630921 0.51645124 0.51653881
 0.51656868 0.51674989 0.5167344  0.51676572 0.51684672 0.51687476
 0.51685878 0.51708252]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.51632394 0.51630566 0.51629684 0.51626673 0.51625766 0.51627739
 0.5163088  0.51636474 0.51638559 0.51637993 0.51643757 0.51643691
 0.51641906 0.51640856 0.51642533 0.51642733 0.51641541 0.51642344
 0.51639906 0.51639702]
[0. 0. 0.]
-----------end of analyzing the loss ratio:74.78241515159607
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9384ffc70>
---------------------------------
SparseEpoch: [91][1/398]	Time 0.604	Data 0.000	Loss 0.2238	
SparseEpoch: [91][101/398]	Time 0.622	Data 0.000	Loss 0.3462	
SparseEpoch: [91][201/398]	Time 0.623	Data 0.000	Loss 0.2354	
SparseEpoch: [91][301/398]	Time 0.623	Data 0.000	Loss 0.3296	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.16291599 0.1628967  0.16288578 0.16283605 0.16283904 0.16278753
 0.1628084  0.16278976 0.16279656 0.16271456 0.1627511  0.16271187
 0.16265915 0.16260995 0.16257375 0.16255537 0.16256234 0.16255069
 0.16256973 0.16259637]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.1628867  0.16285225 0.16281648 0.16279119 0.16277422 0.16275987
 0.16275    0.16274629 0.16273435 0.162726   0.16272528 0.16271268
 0.16270126 0.16268504 0.16266518 0.16265867 0.16264252 0.16264482
 0.1626237  0.16260399]
[0.39473684 0.5        0.        ]
-----------end of analyzing the loss ratio:74.66881561279297
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938377f70>
---------------------------------
SparseEpoch: [91][1/398]	Time 0.608	Data 0.000	Loss 2.1410	
SparseEpoch: [91][101/398]	Time 0.626	Data 0.000	Loss 2.1112	
SparseEpoch: [91][201/398]	Time 0.627	Data 0.000	Loss 1.8217	
SparseEpoch: [91][301/398]	Time 0.625	Data 0.000	Loss 2.6017	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.8767	
Epoch(adapt):{0} Loss 1.2003	
Epoch(adapt):{0} Loss 1.3564	
Epoch(adapt):{0} Loss 0.8539	
------------------the total time cost:1217.048971414566
>>>>>meta updating
Epoch: 0091 | TRAIN: 0.6110 0.5976 0.7990 | 0.3933 0.3933 0.1808 | 0.1476 26.0790 21.3460 0.2515 0.5323 0.6694 ||TEST: 1.1197 0.3944 0.6533 | 0.5557 0.5557 0.2107 | 0.1530 26.7634 22.3007 0.2438 0.5105 0.6470 | 116.1167
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.60189753 0.60192395 0.60183813 0.60178815 0.60170676 0.60166953
 0.60173599 0.60171745 0.60169319 0.60169526 0.60177553 0.6018025
 0.60171002 0.60167446 0.60173293 0.6017846  0.6019038  0.60184596
 0.6019413  0.60190066]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.60173424 0.60176152 0.60179166 0.60171918 0.60171591 0.60174993
 0.60177017 0.60175855 0.60174252 0.60173256 0.60173283 0.60168683
 0.60168828 0.60167065 0.6016903  0.60169149 0.60169783 0.60175138
 0.60173347 0.60171465]
[0.         0.         0.18421053]
-----------end of analyzing the loss ratio:74.921226978302
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938626680>
---------------------------------
SparseEpoch: [92][1/398]	Time 0.605	Data 0.000	Loss 1.1747	
SparseEpoch: [92][101/398]	Time 0.624	Data 0.000	Loss 1.0927	
SparseEpoch: [92][201/398]	Time 0.627	Data 0.000	Loss 1.0724	
SparseEpoch: [92][301/398]	Time 0.626	Data 0.000	Loss 1.0005	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.50268569 0.50285491 0.50281787 0.50273494 0.5026809  0.50264633
 0.5026471  0.50273532 0.50239673 0.50238257 0.50257009 0.50249011
 0.50245411 0.50228657 0.50215206 0.50220189 0.50246704 0.50233371
 0.50229211 0.50244026]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.50240953 0.50239959 0.50241763 0.5023929  0.5024302  0.50242339
 0.50246588 0.50250824 0.50253311 0.5025077  0.50245063 0.50245387
 0.50251673 0.50251358 0.5025588  0.50255698 0.50256266 0.50255611
 0.50250951 0.50248194]
[0.23684211 0.         0.        ]
-----------end of analyzing the loss ratio:74.66558408737183
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9398d1ea0>
---------------------------------
SparseEpoch: [92][1/398]	Time 0.606	Data 0.000	Loss 0.4030	
SparseEpoch: [92][101/398]	Time 0.621	Data 0.000	Loss 0.7885	
SparseEpoch: [92][201/398]	Time 0.622	Data 0.000	Loss 0.6202	
SparseEpoch: [92][301/398]	Time 0.623	Data 0.000	Loss 0.6866	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.18102342 0.18103948 0.18101497 0.18096495 0.1809433  0.18091018
 0.18090402 0.18089607 0.18086731 0.1808266  0.18078661 0.1807723
 0.1807715  0.18076953 0.18075215 0.18072568 0.18072766 0.18069787
 0.18069211 0.18067784]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.18075422 0.18074743 0.1807449  0.1806983  0.18066545 0.18066931
 0.18072467 0.18073094 0.18078378 0.18081554 0.18081712 0.18084388
 0.18084897 0.18083082 0.18085176 0.18086513 0.18093761 0.18092674
 0.18093778 0.1809266 ]
[0.5 0.  0. ]
-----------end of analyzing the loss ratio:74.63851857185364
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938a8feb0>
---------------------------------
SparseEpoch: [92][1/398]	Time 0.606	Data 0.000	Loss 2.0976	
SparseEpoch: [92][101/398]	Time 0.622	Data 0.000	Loss 1.8210	
SparseEpoch: [92][201/398]	Time 0.622	Data 0.000	Loss 1.2068	
SparseEpoch: [92][301/398]	Time 0.622	Data 0.000	Loss 1.9413	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.8602	
Epoch(adapt):{0} Loss 1.6572	
Epoch(adapt):{0} Loss 1.3538	
Epoch(adapt):{0} Loss 0.8714	
------------------the total time cost:1216.2161502838135
>>>>>meta updating
Epoch: 0092 | TRAIN: 0.5850 0.6108 0.8110 | 0.3759 0.3759 0.1883 | 0.1452 25.7369 20.9196 0.2613 0.5414 0.6761 ||TEST: 1.0794 0.4036 0.6639 | 0.5291 0.5291 0.2181 | 0.1514 26.4888 21.9308 0.2537 0.5190 0.6521 | 116.2339
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.50039687 0.50043313 0.50036939 0.50043603 0.50039325 0.50043732
 0.50046608 0.50048549 0.50044635 0.50042883 0.50045715 0.50048022
 0.50051671 0.50044568 0.50041057 0.50046333 0.50047821 0.50048507
 0.50051199 0.50053765]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.50050867 0.50051704 0.50049851 0.50050287 0.50048886 0.50051196
 0.50052449 0.50045672 0.50045525 0.50045687 0.50044619 0.5004434
 0.50043436 0.50042061 0.50041308 0.50042587 0.50041075 0.5004235
 0.50041714 0.50039682]
[0.  0.  0.5]
-----------end of analyzing the loss ratio:75.09619688987732
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9384a7040>
---------------------------------
SparseEpoch: [93][1/398]	Time 0.604	Data 0.000	Loss 1.7328	
SparseEpoch: [93][101/398]	Time 0.628	Data 0.000	Loss 1.9945	
SparseEpoch: [93][201/398]	Time 0.622	Data 0.000	Loss 1.6496	
SparseEpoch: [93][301/398]	Time 0.622	Data 0.000	Loss 2.1386	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.93959454 0.93931182 0.939103   0.93881003 0.93850298 0.93816392
 0.93780532 0.93745854 0.93731895 0.93709335 0.93688592 0.93676273
 0.93661307 0.93634862 0.9361429  0.93591079 0.93598543 0.93562928
 0.93541563 0.93505527]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.93730128 0.93729323 0.93721266 0.93711914 0.93715243 0.93707925
 0.93708792 0.93707563 0.93705922 0.93703224 0.93701581 0.93701993
 0.93701977 0.93685794 0.93683239 0.9368549  0.93681626 0.93683775
 0.93678743 0.93672817]
[0.5 0.  0.5]
-----------end of analyzing the loss ratio:74.84617352485657
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938e14c70>
---------------------------------
SparseEpoch: [93][1/398]	Time 0.606	Data 0.000	Loss 1.4469	
SparseEpoch: [93][101/398]	Time 0.627	Data 0.000	Loss 1.7112	
SparseEpoch: [93][201/398]	Time 0.625	Data 0.000	Loss 1.7163	
SparseEpoch: [93][301/398]	Time 0.624	Data 0.000	Loss 1.5718	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.18682833 0.1868067  0.18677657 0.18674333 0.18673531 0.18671361
 0.18671036 0.18667344 0.1866373  0.18662397 0.18661008 0.186584
 0.18658747 0.18653755 0.18652359 0.18648456 0.18649109 0.18646858
 0.18645712 0.18644242]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.18667397 0.18667338 0.18666182 0.18664532 0.18663289 0.1866387
 0.18664857 0.18665175 0.18664396 0.18662236 0.18659101 0.1865803
 0.18657379 0.18657445 0.18657342 0.18655067 0.18654096 0.18655232
 0.18653951 0.18651226]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:74.94354104995728
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938b6a950>
---------------------------------
SparseEpoch: [93][1/398]	Time 0.606	Data 0.000	Loss 1.9789	
SparseEpoch: [93][101/398]	Time 0.622	Data 0.000	Loss 2.4776	
SparseEpoch: [93][201/398]	Time 0.621	Data 0.000	Loss 1.8229	
SparseEpoch: [93][301/398]	Time 0.623	Data 0.000	Loss 1.9868	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.8320	
Epoch(adapt):{0} Loss 1.2426	
Epoch(adapt):{0} Loss 1.3328	
Epoch(adapt):{0} Loss 1.2341	
------------------the total time cost:1218.22394323349
>>>>>meta updating
Epoch: 0093 | TRAIN: 0.6193 0.5886 0.7991 | 0.3986 0.3986 0.1788 | 0.1451 25.7476 20.8971 0.2603 0.5415 0.6755 ||TEST: 1.0747 0.3929 0.6572 | 0.5598 0.5598 0.2133 | 0.1504 26.4076 21.7968 0.2521 0.5219 0.6552 | 116.1444
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.62048802 0.62037928 0.62015124 0.6200322  0.61997204 0.61984546
 0.61959899 0.61962431 0.61925839 0.61924445 0.61926469 0.61920614
 0.61922944 0.61935825 0.61937982 0.6193175  0.61915838 0.61908118
 0.61917525 0.61930952]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.61924373 0.61923885 0.61923504 0.61923359 0.61922585 0.61921901
 0.61925518 0.61926046 0.61928286 0.61929192 0.61927765 0.61927725
 0.61927967 0.61929166 0.61929611 0.61930568 0.61930606 0.61931837
 0.61932772 0.61934283]
[0.         0.39473684 0.        ]
-----------end of analyzing the loss ratio:74.64056944847107
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9382c7b50>
---------------------------------
SparseEpoch: [94][1/398]	Time 0.608	Data 0.000	Loss 0.8279	
SparseEpoch: [94][101/398]	Time 0.623	Data 0.000	Loss 0.9940	
SparseEpoch: [94][201/398]	Time 0.622	Data 0.000	Loss 0.8660	
SparseEpoch: [94][301/398]	Time 0.622	Data 0.000	Loss 0.6571	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.47433623 0.47435521 0.47445477 0.4741372  0.47403438 0.47415949
 0.47420522 0.47411613 0.47392986 0.4738623  0.47373254 0.4736938
 0.4737394  0.47391095 0.47380325 0.47341702 0.47340318 0.47329996
 0.47339447 0.47347651]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.47388645 0.47390219 0.47390122 0.47388541 0.47383411 0.47377267
 0.47378654 0.47377839 0.47378781 0.47376783 0.47372056 0.47373852
 0.4737244  0.47370501 0.47373229 0.47374429 0.47370377 0.47373227
 0.47373145 0.47374047]
[0.39473684 0.         0.34210526]
-----------end of analyzing the loss ratio:74.99237823486328
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9384a75e0>
---------------------------------
SparseEpoch: [94][1/398]	Time 0.627	Data 0.000	Loss 0.7736	
SparseEpoch: [94][101/398]	Time 0.626	Data 0.000	Loss 1.2035	
SparseEpoch: [94][201/398]	Time 0.625	Data 0.000	Loss 1.2468	
SparseEpoch: [94][301/398]	Time 0.626	Data 0.000	Loss 1.2013	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.16726652 0.16728339 0.16725869 0.16723334 0.16720463 0.16724722
 0.16728094 0.1672719  0.16724454 0.16727637 0.16731583 0.16731545
 0.16731722 0.16734245 0.16737145 0.1673931  0.16736996 0.16736248
 0.16734964 0.16738994]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.16734641 0.16733547 0.1673377  0.16733912 0.16733085 0.16732015
 0.1673215  0.16732491 0.16732301 0.16731331 0.16729107 0.16729016
 0.16727877 0.16727103 0.16727654 0.16729136 0.1672967  0.1672913
 0.16728987 0.16728382]
[0.         0.18421053 0.        ]
-----------end of analyzing the loss ratio:74.9993965625763
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9385e5d50>
---------------------------------
SparseEpoch: [94][1/398]	Time 0.604	Data 0.000	Loss 2.1292	
SparseEpoch: [94][101/398]	Time 0.627	Data 0.000	Loss 1.6208	
SparseEpoch: [94][201/398]	Time 0.621	Data 0.000	Loss 1.4096	
SparseEpoch: [94][301/398]	Time 0.622	Data 0.000	Loss 1.3202	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.9796	
Epoch(adapt):{0} Loss 1.1385	
Epoch(adapt):{0} Loss 1.4485	
Epoch(adapt):{0} Loss 1.2438	
------------------the total time cost:1215.5571644306183
>>>>>meta updating
Epoch: 0094 | TRAIN: 0.5952 0.5939 0.8058 | 0.3738 0.3738 0.1834 | 0.1476 26.0607 21.2608 0.2523 0.5336 0.6700 ||TEST: 1.1029 0.3934 0.6616 | 0.5346 0.5346 0.2145 | 0.1529 26.7389 22.2357 0.2446 0.5126 0.6477 | 116.1531
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.51863435 0.51852694 0.51860102 0.51848191 0.51852545 0.51844096
 0.51829534 0.5184204  0.51864632 0.51872469 0.51874836 0.51880348
 0.51888902 0.51922933 0.51927414 0.51915618 0.51920575 0.51903501
 0.51910916 0.51922126]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.51863342 0.51868138 0.51865687 0.51866984 0.51868147 0.51867993
 0.51867316 0.51864358 0.5186738  0.51868464 0.51871286 0.51872301
 0.51873606 0.51873415 0.51872326 0.51870878 0.51875685 0.51878561
 0.5187586  0.51878812]
[0. 0. 0.]
-----------end of analyzing the loss ratio:74.98240280151367
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9382c4130>
---------------------------------
SparseEpoch: [95][1/398]	Time 0.604	Data 0.000	Loss 0.8301	
SparseEpoch: [95][101/398]	Time 0.623	Data 0.000	Loss 0.7151	
SparseEpoch: [95][201/398]	Time 0.623	Data 0.000	Loss 0.3956	
SparseEpoch: [95][301/398]	Time 0.623	Data 0.000	Loss 1.3058	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.84378185 0.84349907 0.84344178 0.84335832 0.84336466 0.84308666
 0.84304899 0.84320626 0.84325736 0.84307409 0.84305459 0.84288439
 0.84266059 0.84255762 0.842656   0.84229945 0.84216554 0.84205782
 0.84188385 0.84177201]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.8429964  0.84298337 0.84300058 0.8430039  0.84300544 0.84300358
 0.84301404 0.8430364  0.84307972 0.8431224  0.84312836 0.84313583
 0.84310929 0.84307839 0.84308795 0.84310526 0.84310587 0.84305037
 0.84302508 0.84297037]
[0.5 0.  0.5]
-----------end of analyzing the loss ratio:74.80012536048889
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9398fa0b0>
---------------------------------
SparseEpoch: [95][1/398]	Time 0.609	Data 0.000	Loss 1.6035	
SparseEpoch: [95][101/398]	Time 0.624	Data 0.000	Loss 1.5445	
SparseEpoch: [95][201/398]	Time 0.624	Data 0.000	Loss 1.6301	
SparseEpoch: [95][301/398]	Time 0.625	Data 0.000	Loss 1.3319	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.16698907 0.16688289 0.16681812 0.16671665 0.16659438 0.16654993
 0.16647946 0.16638993 0.16631415 0.16619297 0.16608096 0.16595058
 0.16582975 0.1657334  0.16565548 0.16560178 0.16555731 0.16554755
 0.16547707 0.16540141]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.16663157 0.16657927 0.16651136 0.16651897 0.16646287 0.16642279
 0.1663688  0.16629755 0.16624034 0.16620206 0.1661115  0.16604398
 0.16596413 0.16590247 0.16583971 0.16575633 0.16570134 0.16564576
 0.1656009  0.16556683]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:75.0416910648346
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc939031030>
---------------------------------
SparseEpoch: [95][1/398]	Time 0.686	Data 0.000	Loss 1.8685	
SparseEpoch: [95][101/398]	Time 0.624	Data 0.000	Loss 2.0201	
SparseEpoch: [95][201/398]	Time 0.625	Data 0.000	Loss 2.6379	
SparseEpoch: [95][301/398]	Time 0.625	Data 0.000	Loss 2.0550	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.9452	
Epoch(adapt):{0} Loss 1.0321	
Epoch(adapt):{0} Loss 0.9247	
Epoch(adapt):{0} Loss 1.1642	
------------------the total time cost:1218.6022567749023
>>>>>meta updating
Epoch: 0095 | TRAIN: 0.5837 0.6088 0.8112 | 0.3732 0.3732 0.1751 | 0.1438 25.6275 20.7689 0.2621 0.5434 0.6782 ||TEST: 1.0890 0.4044 0.6622 | 0.5347 0.5347 0.2112 | 0.1512 26.5238 21.9686 0.2492 0.5180 0.6521 | 115.8081
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.57654577 0.5765244  0.57628308 0.57629619 0.5762444  0.57631133
 0.5761592  0.57641846 0.57640662 0.57609914 0.57616884 0.57620571
 0.57594574 0.57581471 0.57590417 0.57588463 0.57576516 0.57591238
 0.57573353 0.57568648]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.576222   0.57622345 0.57622055 0.57626085 0.57627089 0.57621155
 0.5761999  0.57621408 0.57622164 0.576228   0.57621116 0.57620492
 0.57622818 0.57623036 0.57621333 0.57620884 0.57621929 0.57619941
 0.57620002 0.5761925 ]
[0.  0.5 0.5]
-----------end of analyzing the loss ratio:74.87597465515137
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9398ab520>
---------------------------------
SparseEpoch: [96][1/398]	Time 0.605	Data 0.000	Loss 1.3034	
SparseEpoch: [96][101/398]	Time 0.625	Data 0.000	Loss 1.4832	
SparseEpoch: [96][201/398]	Time 0.623	Data 0.000	Loss 1.8393	
SparseEpoch: [96][301/398]	Time 0.623	Data 0.000	Loss 1.3481	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.62524577 0.62481956 0.62461294 0.62428703 0.62385536 0.62385396
 0.62367182 0.62342812 0.62307079 0.62258697 0.62236876 0.62212565
 0.62175014 0.62152271 0.62132188 0.62100465 0.62074267 0.6203584
 0.62026703 0.6200141 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.62291658 0.62288891 0.62286217 0.62264594 0.62258599 0.62254692
 0.62254533 0.62256631 0.62257182 0.6226127  0.62247985 0.62246734
 0.6223899  0.62236011 0.6222256  0.62211652 0.62207797 0.62215517
 0.62214504 0.62214803]
[0.5        0.         0.34210526]
-----------end of analyzing the loss ratio:74.92456340789795
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9387926b0>
---------------------------------
SparseEpoch: [96][1/398]	Time 0.609	Data 0.000	Loss 1.5217	
SparseEpoch: [96][101/398]	Time 0.621	Data 0.000	Loss 1.2747	
SparseEpoch: [96][201/398]	Time 0.620	Data 0.000	Loss 1.5935	
SparseEpoch: [96][301/398]	Time 0.622	Data 0.000	Loss 0.9295	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.15180279 0.15181125 0.1518271  0.15183077 0.151793   0.15179399
 0.15176248 0.15171744 0.15168242 0.15166827 0.15165069 0.15164282
 0.15162174 0.15157768 0.15151101 0.15148048 0.15144129 0.15141603
 0.15141737 0.15137988]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.15179572 0.15180501 0.15178146 0.15177398 0.15176318 0.15172886
 0.15170758 0.1516611  0.15163862 0.15165201 0.15166581 0.15165546
 0.15164229 0.15165293 0.15162487 0.15161321 0.1515809  0.15155603
 0.15155889 0.15151967]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:75.04027581214905
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938751060>
---------------------------------
SparseEpoch: [96][1/398]	Time 0.606	Data 0.000	Loss 1.5970	
SparseEpoch: [96][101/398]	Time 0.622	Data 0.000	Loss 2.6969	
SparseEpoch: [96][201/398]	Time 0.622	Data 0.000	Loss 1.9204	
SparseEpoch: [96][301/398]	Time 0.622	Data 0.000	Loss 3.6288	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.3032	
Epoch(adapt):{0} Loss 1.1088	
Epoch(adapt):{0} Loss 0.6563	
Epoch(adapt):{0} Loss 0.9348	
------------------the total time cost:1215.8372476100922
>>>>>meta updating
Epoch: 0096 | TRAIN: 0.5693 0.6145 0.8158 | 0.3642 0.3642 0.1770 | 0.1427 25.4048 20.3357 0.2671 0.5537 0.6873 ||TEST: 1.1222 0.4043 0.6633 | 0.5245 0.5245 0.2119 | 0.1492 26.2380 21.5027 0.2546 0.5282 0.6611 | 116.1053
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.55312593 0.5531522  0.55307319 0.55297065 0.55291862 0.55293444
 0.55298847 0.55311813 0.55315672 0.5530922  0.55317031 0.55313352
 0.55318875 0.55325734 0.55329087 0.55331485 0.55330176 0.55342154
 0.5535354  0.55356511]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.5534424  0.55344517 0.55353082 0.55347713 0.55346287 0.55335025
 0.55330274 0.55325775 0.55318843 0.55315068 0.55314443 0.5531275
 0.55319618 0.55319673 0.55313639 0.55314347 0.5531473  0.55310778
 0.55311365 0.55315329]
[0.         0.         0.39473684]
-----------end of analyzing the loss ratio:74.71956610679626
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938792020>
---------------------------------
SparseEpoch: [97][1/398]	Time 0.607	Data 0.000	Loss 1.5476	
SparseEpoch: [97][101/398]	Time 0.625	Data 0.000	Loss 1.2059	
SparseEpoch: [97][201/398]	Time 0.621	Data 0.000	Loss 1.8135	
SparseEpoch: [97][301/398]	Time 0.622	Data 0.000	Loss 2.0121	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.38786725 0.38802562 0.38789466 0.38789724 0.3879581  0.38782477
 0.38779966 0.38789137 0.38781952 0.38780347 0.38768429 0.38769426
 0.38763627 0.38760578 0.38761436 0.38763753 0.38762161 0.387778
 0.3879073  0.38797137]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.38775444 0.3877787  0.38778152 0.38779339 0.38781812 0.38779709
 0.38778194 0.38777687 0.38775638 0.38776033 0.38774028 0.38772192
 0.38775357 0.38771898 0.3877113  0.38772283 0.38772205 0.38771755
 0.3877432  0.38771982]
[0.18421053 0.         0.23684211]
-----------end of analyzing the loss ratio:74.82720112800598
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938c057b0>
---------------------------------
SparseEpoch: [97][1/398]	Time 0.605	Data 0.000	Loss 0.8739	
SparseEpoch: [97][101/398]	Time 0.622	Data 0.000	Loss 0.8825	
SparseEpoch: [97][201/398]	Time 0.621	Data 0.000	Loss 0.8536	
SparseEpoch: [97][301/398]	Time 0.621	Data 0.000	Loss 0.8836	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.16650105 0.16643767 0.16636928 0.16633695 0.16630204 0.16624939
 0.16623752 0.16618914 0.16615537 0.1661134  0.16605634 0.16600752
 0.16595775 0.16593743 0.16586214 0.1658     0.16576812 0.16577203
 0.16572607 0.16572858]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.16626008 0.16622842 0.16619178 0.16619326 0.16615511 0.16614918
 0.16615884 0.16614216 0.16611355 0.16608037 0.16607672 0.16604231
 0.16602796 0.16602703 0.16600363 0.16598666 0.16596735 0.16593476
 0.16591988 0.16589955]
[0.44736842 0.5        0.        ]
-----------end of analyzing the loss ratio:75.01791214942932
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938b47430>
---------------------------------
SparseEpoch: [97][1/398]	Time 0.604	Data 0.000	Loss 2.6154	
SparseEpoch: [97][101/398]	Time 0.618	Data 0.000	Loss 2.4497	
SparseEpoch: [97][201/398]	Time 0.623	Data 0.000	Loss 1.9078	
SparseEpoch: [97][301/398]	Time 0.624	Data 0.000	Loss 1.9706	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.1152	
Epoch(adapt):{0} Loss 0.8073	
Epoch(adapt):{0} Loss 0.8535	
Epoch(adapt):{0} Loss 1.4593	
------------------the total time cost:1215.8621900081635
>>>>>meta updating
Epoch: 0097 | TRAIN: 0.5606 0.6277 0.8211 | 0.3702 0.3702 0.1776 | 0.1429 25.4582 20.4886 0.2657 0.5513 0.6843 ||TEST: 1.0954 0.4030 0.6638 | 0.5345 0.5345 0.2113 | 0.1499 26.2885 21.5312 0.2561 0.5274 0.6599 | 116.2131
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.64181643 0.64190835 0.64201218 0.64197612 0.64203673 0.64206249
 0.64211517 0.64215131 0.64218739 0.64216822 0.64206222 0.64214544
 0.64212638 0.64214653 0.64209755 0.64216222 0.64201092 0.64203974
 0.64198658 0.64197944]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.64213611 0.64218013 0.64218999 0.64217094 0.64214193 0.64219282
 0.64211769 0.64218556 0.64216482 0.64211099 0.64208942 0.64208054
 0.64209821 0.6420958  0.64207881 0.64205059 0.64199871 0.6420415
 0.64206598 0.64205008]
[0.         0.         0.34210526]
-----------end of analyzing the loss ratio:74.845463514328
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938d64820>
---------------------------------
SparseEpoch: [98][1/398]	Time 0.608	Data 0.000	Loss 1.2185	
SparseEpoch: [98][101/398]	Time 0.627	Data 0.000	Loss 1.3392	
SparseEpoch: [98][201/398]	Time 0.625	Data 0.000	Loss 1.2269	
SparseEpoch: [98][301/398]	Time 0.626	Data 0.000	Loss 1.2842	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.74165215 0.74168265 0.74172269 0.74156669 0.74144281 0.74157304
 0.74154232 0.74161238 0.74175698 0.7418557  0.74190959 0.7418758
 0.74190437 0.74183797 0.74187779 0.74183577 0.74190285 0.74182032
 0.74187264 0.74192164]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.74183089 0.74185145 0.74183709 0.74187042 0.7418769  0.74183549
 0.7418434  0.74184318 0.74183859 0.74186776 0.74183508 0.74186217
 0.74185553 0.74188063 0.74186276 0.74185009 0.74185216 0.74183707
 0.7418544  0.74185298]
[0. 0. 0.]
-----------end of analyzing the loss ratio:74.90571475028992
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938d4c6d0>
---------------------------------
SparseEpoch: [98][1/398]	Time 0.604	Data 0.000	Loss 0.5413	
SparseEpoch: [98][101/398]	Time 0.620	Data 0.000	Loss 0.2942	
SparseEpoch: [98][201/398]	Time 0.621	Data 0.000	Loss 0.4714	
SparseEpoch: [98][301/398]	Time 0.622	Data 0.000	Loss 0.6180	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.15808522 0.15808498 0.15804853 0.15805314 0.1580592  0.15803092
 0.15802431 0.15799995 0.15799628 0.1579599  0.15794216 0.1579377
 0.15793455 0.15793055 0.15795934 0.15797126 0.15798543 0.15799456
 0.15800778 0.15803325]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.15817112 0.15814388 0.15811728 0.15810773 0.1581009  0.15808517
 0.15806569 0.158031   0.15799451 0.15795585 0.15794781 0.15793685
 0.15794703 0.15795121 0.15793906 0.15793616 0.15792724 0.15795074
 0.15793622 0.15793946]
[0.18421053 0.34210526 0.        ]
-----------end of analyzing the loss ratio:74.99163150787354
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938a1b100>
---------------------------------
SparseEpoch: [98][1/398]	Time 0.605	Data 0.000	Loss 1.3471	
SparseEpoch: [98][101/398]	Time 0.627	Data 0.000	Loss 2.3310	
SparseEpoch: [98][201/398]	Time 0.622	Data 0.000	Loss 1.6692	
SparseEpoch: [98][301/398]	Time 0.621	Data 0.000	Loss 2.1691	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.9164	
Epoch(adapt):{0} Loss 1.1864	
Epoch(adapt):{0} Loss 0.7916	
Epoch(adapt):{0} Loss 1.5829	
------------------the total time cost:1216.6118273735046
>>>>>meta updating
Epoch: 0098 | TRAIN: 0.6031 0.5959 0.8044 | 0.3713 0.3713 0.1767 | 0.1413 25.2345 20.1890 0.2710 0.5570 0.6900 ||TEST: 1.1116 0.3937 0.6530 | 0.5364 0.5364 0.2094 | 0.1493 26.2413 21.5725 0.2563 0.5266 0.6600 | 116.2226
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.49718142 0.49714468 0.49716805 0.49721677 0.49719143 0.49717661
 0.49715504 0.4972031  0.49723407 0.49728326 0.49729624 0.49725102
 0.49722979 0.49731027 0.49728441 0.49725346 0.49724028 0.49718832
 0.49714419 0.49719455]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.49736525 0.49734859 0.49733821 0.49734184 0.49733026 0.49733181
 0.49733748 0.49730145 0.49729978 0.49730547 0.49729211 0.49726311
 0.49729538 0.49730657 0.4972737  0.49726396 0.49726881 0.49728583
 0.49726858 0.49723485]
[0.         0.44736842 0.5       ]
-----------end of analyzing the loss ratio:74.8688132762909
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938791f90>
---------------------------------
SparseEpoch: [99][1/398]	Time 0.606	Data 0.000	Loss 1.3972	
SparseEpoch: [99][101/398]	Time 0.625	Data 0.000	Loss 1.5955	
SparseEpoch: [99][201/398]	Time 0.626	Data 0.000	Loss 2.2946	
SparseEpoch: [99][301/398]	Time 0.624	Data 0.000	Loss 1.8848	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.52771368 0.52733253 0.52720617 0.52672029 0.52647642 0.5260442
 0.52572259 0.52559009 0.52527567 0.5249988  0.52432698 0.52388747
 0.52381565 0.52361309 0.52349624 0.52343634 0.52340272 0.52316628
 0.52301542 0.52308037]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.52510325 0.52503244 0.52506146 0.52502187 0.52506164 0.52498957
 0.52500743 0.52488514 0.52473068 0.52466528 0.52460842 0.52457034
 0.52447083 0.52436561 0.52433649 0.52437658 0.52432112 0.52416979
 0.52415026 0.52410757]
[0.44736842 0.         0.5       ]
-----------end of analyzing the loss ratio:74.87024402618408
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9386c9ab0>
---------------------------------
SparseEpoch: [99][1/398]	Time 0.606	Data 0.000	Loss 1.2156	
SparseEpoch: [99][101/398]	Time 0.624	Data 0.000	Loss 1.4757	
SparseEpoch: [99][201/398]	Time 0.624	Data 0.000	Loss 1.5253	
SparseEpoch: [99][301/398]	Time 0.624	Data 0.000	Loss 1.9656	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.16592557 0.16587248 0.16581537 0.1656539  0.16560444 0.16546344
 0.1653967  0.1653055  0.16519818 0.16508385 0.16505961 0.16502246
 0.16500132 0.16499692 0.16489551 0.16487421 0.16473662 0.16470417
 0.16469327 0.16459497]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.1651181  0.16509846 0.16508501 0.16507329 0.16506996 0.16506711
 0.16506242 0.16506704 0.16507391 0.16506117 0.16505648 0.16506264
 0.16505945 0.16506777 0.16507046 0.16507061 0.16508619 0.16507185
 0.16507056 0.16506473]
[0.5        0.02631579 0.        ]
-----------end of analyzing the loss ratio:74.76171088218689
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938c06da0>
---------------------------------
SparseEpoch: [99][1/398]	Time 0.674	Data 0.000	Loss 2.1745	
SparseEpoch: [99][101/398]	Time 0.628	Data 0.000	Loss 1.3064	
SparseEpoch: [99][201/398]	Time 0.625	Data 0.000	Loss 1.8717	
SparseEpoch: [99][301/398]	Time 0.624	Data 0.000	Loss 2.1308	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.6815	
Epoch(adapt):{0} Loss 0.8131	
Epoch(adapt):{0} Loss 1.3053	
Epoch(adapt):{0} Loss 0.9296	
------------------the total time cost:1218.414231300354
>>>>>meta updating
Epoch: 0099 | TRAIN: 0.5711 0.6202 0.8166 | 0.3845 0.3845 0.1756 | 0.1417 25.3675 20.4816 0.2662 0.5510 0.6854 ||TEST: 1.1021 0.3983 0.6589 | 0.5445 0.5445 0.2109 | 0.1501 26.3549 21.7178 0.2545 0.5233 0.6566 | 116.1926
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.5120916  0.51208783 0.51207428 0.51200509 0.51198234 0.51197029
 0.5119638  0.51197609 0.51189434 0.5118538  0.51181927 0.51179553
 0.5117571  0.51173314 0.51167208 0.51164279 0.51164638 0.51163207
 0.51161229 0.51162013]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.51194493 0.51200663 0.51196505 0.51194322 0.51191277 0.51189025
 0.51188987 0.51187671 0.51184267 0.51184632 0.51184159 0.51184771
 0.51186398 0.51183479 0.51183037 0.51185783 0.5118543  0.51184746
 0.51184682 0.51179357]
[0.         0.44736842 0.5       ]
-----------end of analyzing the loss ratio:74.90736842155457
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938c6df60>
---------------------------------
SparseEpoch: [100][1/398]	Time 0.578	Data 0.000	Loss 1.5466	
SparseEpoch: [100][101/398]	Time 0.580	Data 0.000	Loss 1.9745	
SparseEpoch: [100][201/398]	Time 0.580	Data 0.000	Loss 2.2932	
SparseEpoch: [100][301/398]	Time 0.580	Data 0.000	Loss 2.0717	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.40400812 0.4040142  0.40406798 0.40409499 0.40410541 0.40411041
 0.40410294 0.40408764 0.40410682 0.40412016 0.40412319 0.40407924
 0.40406863 0.404103   0.40414797 0.40415178 0.40418089 0.40418672
 0.40420735 0.40419244]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.40411761 0.40411881 0.4041153  0.4041146  0.40410716 0.40411153
 0.40411031 0.40410323 0.40412147 0.40412075 0.40409169 0.40410298
 0.40411503 0.40410489 0.40410215 0.40409881 0.40410632 0.40409352
 0.40410833 0.40410657]
[0.         0.         0.02631579]
-----------end of analyzing the loss ratio:74.74693727493286
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9398fb7f0>
---------------------------------
SparseEpoch: [100][1/398]	Time 0.578	Data 0.000	Loss 0.3958	
SparseEpoch: [100][101/398]	Time 0.579	Data 0.000	Loss 0.4991	
SparseEpoch: [100][201/398]	Time 0.580	Data 0.000	Loss 0.6648	
SparseEpoch: [100][301/398]	Time 0.580	Data 0.000	Loss 0.3770	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.13451627 0.13451321 0.13448796 0.13442924 0.13441597 0.13443572
 0.13445393 0.1344244  0.13442193 0.13442029 0.13441426 0.13440313
 0.13441899 0.13440857 0.13440242 0.13440467 0.13440903 0.13440902
 0.13439094 0.13439831]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.13439592 0.1344106  0.13440827 0.13437637 0.13439943 0.13440322
 0.13438791 0.13438492 0.13439216 0.13441638 0.1344124  0.13440549
 0.13441284 0.13443527 0.13444998 0.13445258 0.13444979 0.13445187
 0.13447691 0.13450192]
[0.44736842 0.         0.        ]
-----------end of analyzing the loss ratio:74.75449657440186
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc93837a980>
---------------------------------
SparseEpoch: [100][1/398]	Time 0.578	Data 0.000	Loss 2.0064	
SparseEpoch: [100][101/398]	Time 0.580	Data 0.000	Loss 1.5889	
SparseEpoch: [100][201/398]	Time 0.580	Data 0.000	Loss 2.3916	
SparseEpoch: [100][301/398]	Time 0.580	Data 0.000	Loss 1.1431	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.3404	
Epoch(adapt):{0} Loss 1.1477	
Epoch(adapt):{0} Loss 1.0893	
Epoch(adapt):{0} Loss 1.1419	
------------------the total time cost:1164.1194932460785
>>>>>meta updating
Epoch: 0100 | TRAIN: 0.6085 0.5955 0.8009 | 0.3857 0.3857 0.1805 | 0.1360 24.5900 19.5068 0.2858 0.5733 0.7022 ||TEST: 1.0931 0.3934 0.6521 | 0.5365 0.5365 0.2084 | 0.1456 25.7692 20.9886 0.2671 0.5388 0.6703 | 116.0818
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.63061983 0.63071131 0.63072381 0.63068781 0.63067427 0.63074681
 0.63075861 0.63074889 0.630838   0.63077302 0.63078516 0.63073088
 0.6307263  0.63070826 0.63064833 0.6307872  0.63071445 0.6307342
 0.63062366 0.63062271]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.63078645 0.63078549 0.63077365 0.63076097 0.63082684 0.63083634
 0.63076927 0.6306921  0.63077042 0.63079642 0.63074928 0.63075149
 0.63075561 0.63074256 0.63075723 0.63072011 0.63062528 0.63064625
 0.63063961 0.63061227]
[0.  0.  0.5]
-----------end of analyzing the loss ratio:74.97137546539307
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cca5e305bd0>
---------------------------------
SparseEpoch: [101][1/398]	Time 0.578	Data 0.000	Loss 1.4387	
SparseEpoch: [101][101/398]	Time 0.580	Data 0.000	Loss 1.0875	
SparseEpoch: [101][201/398]	Time 0.580	Data 0.000	Loss 1.5173	
SparseEpoch: [101][301/398]	Time 0.580	Data 0.000	Loss 1.2794	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.44716609 0.44714505 0.44712402 0.44713095 0.44705433 0.44704178
 0.44699636 0.44697756 0.44702746 0.44696365 0.4470211  0.44700007
 0.44703411 0.44697776 0.44693956 0.44695262 0.4469226  0.44683726
 0.44677809 0.44683245]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.44701538 0.44700569 0.44699635 0.44699355 0.44699265 0.44700837
 0.4470006  0.4470012  0.44699395 0.44699276 0.4470024  0.44701467
 0.44701363 0.44698784 0.44697007 0.44695481 0.44694197 0.44692145
 0.44692318 0.44690786]
[0.44736842 0.         0.5       ]
-----------end of analyzing the loss ratio:74.67618560791016
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cca5e305360>
---------------------------------
SparseEpoch: [101][1/398]	Time 0.582	Data 0.000	Loss 1.2710	
SparseEpoch: [101][101/398]	Time 0.581	Data 0.000	Loss 1.0612	
SparseEpoch: [101][201/398]	Time 0.581	Data 0.000	Loss 1.6063	
SparseEpoch: [101][301/398]	Time 0.581	Data 0.000	Loss 1.1030	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.13879811 0.13878464 0.13878872 0.13878496 0.13879243 0.13880869
 0.13881315 0.13880778 0.13880363 0.1387985  0.13880195 0.13880205
 0.13880225 0.13879488 0.13878924 0.13879097 0.1387899  0.13879692
 0.1387984  0.13880562]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.13890693 0.13890363 0.13890344 0.13890037 0.13887706 0.13887013
 0.13883414 0.13881613 0.1388292  0.1388133  0.13881553 0.13876909
 0.1387885  0.13878101 0.13878701 0.13878598 0.13880084 0.13878663
 0.13876516 0.13879151]
[0.         0.44736842 0.        ]
-----------end of analyzing the loss ratio:74.83804130554199
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9386a5f00>
---------------------------------
SparseEpoch: [101][1/398]	Time 0.578	Data 0.000	Loss 1.4411	
SparseEpoch: [101][101/398]	Time 0.580	Data 0.000	Loss 1.3074	
SparseEpoch: [101][201/398]	Time 0.580	Data 0.000	Loss 1.5918	
SparseEpoch: [101][301/398]	Time 0.580	Data 0.000	Loss 1.2516	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.7634	
Epoch(adapt):{0} Loss 1.7321	
Epoch(adapt):{0} Loss 0.9129	
Epoch(adapt):{0} Loss 1.1698	
------------------the total time cost:1164.9914932250977
>>>>>meta updating
Epoch: 0101 | TRAIN: 0.5681 0.6216 0.8178 | 0.3779 0.3779 0.1770 | 0.1385 24.8420 19.7963 0.2834 0.5662 0.6969 ||TEST: 1.0869 0.4065 0.6659 | 0.5442 0.5442 0.2120 | 0.1455 25.6944 20.8781 0.2730 0.5411 0.6709 | 116.2215
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.61055171 0.6105858  0.6105753  0.61062972 0.61063298 0.61060649
 0.61060892 0.61061264 0.61059329 0.61054043 0.61059391 0.61059446
 0.61057758 0.61059581 0.61062395 0.61065805 0.61065465 0.6106924
 0.61069409 0.61072515]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.61060637 0.61060889 0.61061554 0.61059256 0.61060723 0.61056633
 0.61056656 0.61055813 0.61056784 0.61057434 0.61057245 0.61057796
 0.61057099 0.61055891 0.61056101 0.61055862 0.61054913 0.61056451
 0.61055554 0.61056919]
[0.         0.         0.34210526]
-----------end of analyzing the loss ratio:75.1221866607666
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938e17df0>
---------------------------------
SparseEpoch: [102][1/398]	Time 0.578	Data 0.000	Loss 0.8561	
SparseEpoch: [102][101/398]	Time 0.580	Data 0.000	Loss 1.1865	
SparseEpoch: [102][201/398]	Time 0.580	Data 0.000	Loss 1.5892	
SparseEpoch: [102][301/398]	Time 0.579	Data 0.000	Loss 1.9205	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.72820383 0.72787961 0.72768441 0.72731382 0.726916   0.72674206
 0.72682244 0.72672042 0.72662436 0.72638609 0.72630375 0.72591734
 0.72564267 0.72540247 0.72518967 0.72497439 0.72470283 0.72448332
 0.72414263 0.72384617]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.72636741 0.72637382 0.72631698 0.72631768 0.7263143  0.72628935
 0.7263011  0.72628626 0.72625844 0.72626157 0.72624514 0.72625694
 0.72623692 0.72625207 0.72627044 0.7262526  0.72630832 0.72629054
 0.72628051 0.72628696]
[0.5        0.         0.13157895]
-----------end of analyzing the loss ratio:75.08539319038391
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938372530>
---------------------------------
SparseEpoch: [102][1/398]	Time 0.578	Data 0.000	Loss 0.7997	
SparseEpoch: [102][101/398]	Time 0.580	Data 0.000	Loss 0.9773	
SparseEpoch: [102][201/398]	Time 0.580	Data 0.000	Loss 0.8461	
SparseEpoch: [102][301/398]	Time 0.580	Data 0.000	Loss 0.9736	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.13146808 0.13144946 0.13144792 0.13143412 0.13143045 0.13142409
 0.13143676 0.13143874 0.13145669 0.13144658 0.13143692 0.13144946
 0.13145995 0.13143584 0.13139658 0.13139587 0.13142333 0.13143306
 0.13141661 0.13140938]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.13152767 0.13155144 0.13153923 0.13154199 0.13150255 0.13146415
 0.13144242 0.13144596 0.13146956 0.13145826 0.13143611 0.13142143
 0.13140062 0.1313666  0.13133792 0.13132538 0.13131146 0.13131267
 0.13132271 0.13128244]
[0.28947368 0.5        0.        ]
-----------end of analyzing the loss ratio:74.92617106437683
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9386ca560>
---------------------------------
SparseEpoch: [102][1/398]	Time 0.587	Data 0.000	Loss 1.5996	
SparseEpoch: [102][101/398]	Time 0.581	Data 0.000	Loss 1.5522	
SparseEpoch: [102][201/398]	Time 0.581	Data 0.000	Loss 2.0216	
SparseEpoch: [102][301/398]	Time 0.581	Data 0.000	Loss 1.5375	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.2924	
Epoch(adapt):{0} Loss 1.0204	
Epoch(adapt):{0} Loss 1.4276	
Epoch(adapt):{0} Loss 1.3590	
------------------the total time cost:1164.4681944847107
>>>>>meta updating
Epoch: 0102 | TRAIN: 0.5513 0.6308 0.8205 | 0.3740 0.3740 0.1857 | 0.1325 24.0984 18.8310 0.2980 0.5884 0.7151 ||TEST: 1.1129 0.4067 0.6621 | 0.5273 0.5273 0.2110 | 0.1435 25.4069 20.3851 0.2789 0.5513 0.6794 | 115.8018
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.50608565 0.50615157 0.50612326 0.50623732 0.50626287 0.50622212
 0.5062713  0.50630857 0.50617157 0.50615493 0.50622726 0.50630336
 0.50633675 0.50628401 0.5062627  0.50643866 0.50648541 0.50633737
 0.50642802 0.50632191]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.50635439 0.50632444 0.50637272 0.50634636 0.50634964 0.50632821
 0.50624382 0.50623403 0.50620611 0.50619302 0.50616348 0.50613975
 0.50615018 0.50615753 0.50616058 0.50611477 0.50610779 0.50619471
 0.50620314 0.50620947]
[0.         0.         0.34210526]
-----------end of analyzing the loss ratio:74.9660177230835
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938d3d060>
---------------------------------
SparseEpoch: [103][1/398]	Time 0.577	Data 0.000	Loss 1.0450	
SparseEpoch: [103][101/398]	Time 0.580	Data 0.000	Loss 1.5276	
SparseEpoch: [103][201/398]	Time 0.581	Data 0.000	Loss 1.3079	
SparseEpoch: [103][301/398]	Time 0.580	Data 0.000	Loss 1.3689	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.43051107 0.430546   0.43050491 0.43052715 0.43049028 0.4304846
 0.43057352 0.43060167 0.43060642 0.43053821 0.43063716 0.43075068
 0.43078282 0.43069712 0.43074699 0.43065854 0.43054229 0.43050312
 0.43049    0.43048715]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.43054633 0.43056205 0.43056298 0.43058407 0.43058494 0.43059106
 0.43059713 0.43059614 0.43058977 0.43058811 0.43058489 0.43057772
 0.4305724  0.43057311 0.43057676 0.4305739  0.43056591 0.43056027
 0.43057301 0.43058532]
[0. 0. 0.]
-----------end of analyzing the loss ratio:74.9130322933197
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9389da5f0>
---------------------------------
SparseEpoch: [103][1/398]	Time 0.577	Data 0.000	Loss 0.3656	
SparseEpoch: [103][101/398]	Time 0.578	Data 0.000	Loss 0.3631	
SparseEpoch: [103][201/398]	Time 0.579	Data 0.000	Loss 0.4474	
SparseEpoch: [103][301/398]	Time 0.579	Data 0.000	Loss 0.3650	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.15275117 0.15277275 0.15277044 0.1527369  0.15273655 0.15271342
 0.15268851 0.15270103 0.15265281 0.15263662 0.15262971 0.15264373
 0.15261613 0.15262042 0.15259913 0.15259839 0.15262383 0.15263021
 0.15261375 0.15259981]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.15278593 0.15275511 0.15274302 0.15273048 0.15269927 0.15270071
 0.1526971  0.15269173 0.15266661 0.15264689 0.1526307  0.15262576
 0.15261861 0.15260724 0.15259121 0.15258961 0.15258806 0.15258593
 0.15257324 0.15256726]
[0.28947368 0.5        0.        ]
-----------end of analyzing the loss ratio:74.94920611381531
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938e5ae60>
---------------------------------
SparseEpoch: [103][1/398]	Time 0.579	Data 0.000	Loss 1.3884	
SparseEpoch: [103][101/398]	Time 0.582	Data 0.000	Loss 1.8942	
SparseEpoch: [103][201/398]	Time 0.581	Data 0.000	Loss 1.9105	
SparseEpoch: [103][301/398]	Time 0.581	Data 0.000	Loss 1.8896	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.2032	
Epoch(adapt):{0} Loss 1.3693	
Epoch(adapt):{0} Loss 0.9998	
Epoch(adapt):{0} Loss 0.8650	
------------------the total time cost:1162.9629204273224
>>>>>meta updating
Epoch: 0103 | TRAIN: 0.5901 0.5895 0.8042 | 0.3813 0.3813 0.1925 | 0.1341 24.3978 19.3434 0.2870 0.5779 0.7082 ||TEST: 1.1260 0.3889 0.6540 | 0.5306 0.5306 0.2156 | 0.1457 25.7342 20.9489 0.2707 0.5397 0.6709 | 116.4276
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.59896684 0.59897025 0.59894279 0.59905186 0.59904102 0.59902039
 0.59905216 0.59906787 0.59910724 0.59900434 0.59900864 0.5990701
 0.59907613 0.59909764 0.59906985 0.59902257 0.59893266 0.59888342
 0.59887668 0.59898998]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.59904416 0.59905142 0.59904098 0.59903815 0.59904343 0.59905259
 0.59901392 0.599012   0.59903846 0.59902642 0.59902158 0.5990122
 0.59899553 0.59895585 0.59895917 0.5989719  0.59900115 0.59898904
 0.59899744 0.59903999]
[0.         0.44736842 0.18421053]
-----------end of analyzing the loss ratio:75.04998898506165
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9384fe110>
---------------------------------
SparseEpoch: [104][1/398]	Time 0.579	Data 0.000	Loss 1.2867	
SparseEpoch: [104][101/398]	Time 0.581	Data 0.000	Loss 1.1703	
SparseEpoch: [104][201/398]	Time 0.581	Data 0.000	Loss 1.1905	
SparseEpoch: [104][301/398]	Time 0.580	Data 0.000	Loss 1.2409	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.42619898 0.42631231 0.42628756 0.42629581 0.42630968 0.42636534
 0.42639015 0.42647217 0.42648219 0.42647962 0.42652166 0.42661588
 0.42657007 0.42656709 0.42651615 0.42649573 0.42652857 0.42655176
 0.42657167 0.42660496]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.42658768 0.42657247 0.42655949 0.42656922 0.42657009 0.42654839
 0.42654442 0.4265374  0.4265519  0.42655846 0.42655446 0.42651679
 0.4265018  0.42648588 0.42647105 0.4264361  0.42644217 0.42644494
 0.42646053 0.42643642]
[0.         0.         0.28947368]
-----------end of analyzing the loss ratio:75.26226806640625
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938ce2560>
---------------------------------
SparseEpoch: [104][1/398]	Time 0.578	Data 0.000	Loss 0.5820	
SparseEpoch: [104][101/398]	Time 0.580	Data 0.000	Loss 0.5654	
SparseEpoch: [104][201/398]	Time 0.580	Data 0.000	Loss 0.7294	
SparseEpoch: [104][301/398]	Time 0.581	Data 0.000	Loss 0.9019	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.13437155 0.13433449 0.13431623 0.13430314 0.13424314 0.13424549
 0.13422778 0.13420581 0.13418408 0.13417118 0.13412712 0.13413413
 0.13409559 0.13412498 0.13411293 0.13413016 0.1340852  0.13406217
 0.13404887 0.13402264]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.13422143 0.13423796 0.13421124 0.1341871  0.1342021  0.13419008
 0.13418657 0.13416166 0.13416618 0.13417473 0.1341482  0.13414374
 0.13413305 0.13412864 0.13414431 0.13412593 0.13411421 0.13409904
 0.13411238 0.13411375]
[0.5        0.39473684 0.        ]
-----------end of analyzing the loss ratio:74.81966996192932
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9387c70d0>
---------------------------------
SparseEpoch: [104][1/398]	Time 0.578	Data 0.000	Loss 1.8021	
SparseEpoch: [104][101/398]	Time 0.581	Data 0.000	Loss 1.8078	
SparseEpoch: [104][201/398]	Time 0.581	Data 0.000	Loss 2.0687	
SparseEpoch: [104][301/398]	Time 0.581	Data 0.000	Loss 2.5610	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.0956	
Epoch(adapt):{0} Loss 1.1301	
Epoch(adapt):{0} Loss 1.4553	
Epoch(adapt):{0} Loss 0.8646	
------------------the total time cost:1164.0150504112244
>>>>>meta updating
Epoch: 0104 | TRAIN: 0.5412 0.6315 0.8252 | 0.3651 0.3651 0.1772 | 0.1313 23.9851 18.7619 0.2989 0.5909 0.7177 ||TEST: 1.0907 0.4030 0.6644 | 0.5268 0.5268 0.2117 | 0.1437 25.4346 20.4555 0.2778 0.5508 0.6794 | 116.1360
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.49737755 0.49731512 0.49715224 0.49696926 0.49692938 0.4968614
 0.49684288 0.49678903 0.4965498  0.49660974 0.49650045 0.49640491
 0.49618819 0.49624709 0.49616393 0.49619021 0.49612503 0.49625295
 0.49616044 0.4961299 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.49645883 0.49646766 0.49649562 0.49653738 0.49654339 0.49655022
 0.49655541 0.49652953 0.49655185 0.4965361  0.49650326 0.49655371
 0.49652815 0.49654967 0.49658198 0.49659877 0.49659279 0.49656371
 0.49658236 0.49657024]
[0.         0.34210526 0.        ]
-----------end of analyzing the loss ratio:74.9629557132721
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cca5e213190>
---------------------------------
SparseEpoch: [105][1/398]	Time 0.578	Data 0.000	Loss 0.6316	
SparseEpoch: [105][101/398]	Time 0.579	Data 0.000	Loss 0.3379	
SparseEpoch: [105][201/398]	Time 0.579	Data 0.000	Loss 0.7802	
SparseEpoch: [105][301/398]	Time 0.580	Data 0.000	Loss 0.6303	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.4912608  0.49131077 0.49133012 0.49129642 0.49118886 0.49111054
 0.49104306 0.49108548 0.49105641 0.49101684 0.49104267 0.49107707
 0.49103726 0.49099423 0.49094534 0.49093585 0.49085853 0.4908839
 0.4908882  0.49082305]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.49104726 0.49106155 0.49105952 0.49105925 0.49105597 0.49105147
 0.49102541 0.49105461 0.49105437 0.49104618 0.49105079 0.49105342
 0.49105957 0.4910688  0.49105691 0.49104795 0.49103469 0.49100226
 0.4910051  0.4909921 ]
[0.5 0.  0.5]
-----------end of analyzing the loss ratio:74.95275521278381
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938668c10>
---------------------------------
SparseEpoch: [105][1/398]	Time 0.578	Data 0.000	Loss 1.3389	
SparseEpoch: [105][101/398]	Time 0.580	Data 0.000	Loss 1.6600	
SparseEpoch: [105][201/398]	Time 0.580	Data 0.000	Loss 1.5440	
SparseEpoch: [105][301/398]	Time 0.581	Data 0.000	Loss 1.4710	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.16708373 0.16706526 0.16705654 0.16706066 0.16704814 0.16700221
 0.16699973 0.16698682 0.16697856 0.16696643 0.16697079 0.16698468
 0.16699041 0.16697848 0.16697668 0.16696551 0.16696448 0.16698211
 0.16696856 0.16698099]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.16700239 0.16699331 0.16698408 0.16698435 0.16698441 0.16699034
 0.16698455 0.16697604 0.16697561 0.16697803 0.1669749  0.1669645
 0.16697021 0.16697005 0.16697671 0.16698161 0.16699256 0.16697717
 0.16698771 0.16698446]
[0.34210526 0.07894737 0.        ]
-----------end of analyzing the loss ratio:75.22704696655273
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc93830b670>
---------------------------------
SparseEpoch: [105][1/398]	Time 0.579	Data 0.000	Loss 1.3346	
SparseEpoch: [105][101/398]	Time 0.580	Data 0.000	Loss 1.9449	
SparseEpoch: [105][201/398]	Time 0.580	Data 0.000	Loss 1.6537	
SparseEpoch: [105][301/398]	Time 0.580	Data 0.000	Loss 1.4777	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.8426	
Epoch(adapt):{0} Loss 0.9441	
Epoch(adapt):{0} Loss 0.7152	
Epoch(adapt):{0} Loss 0.8686	
------------------the total time cost:1164.5701203346252
>>>>>meta updating
Epoch: 0105 | TRAIN: 0.5727 0.6058 0.8099 | 0.3642 0.3642 0.1696 | 0.1340 24.5054 19.6889 0.2805 0.5702 0.7040 ||TEST: 1.1340 0.3944 0.6522 | 0.5366 0.5366 0.2092 | 0.1448 25.7497 21.1171 0.2665 0.5363 0.6687 | 116.5340
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.51063704 0.51062827 0.51065424 0.51061048 0.51064272 0.51071799
 0.5107624  0.51073941 0.51074812 0.51069856 0.51072268 0.51075572
 0.51081907 0.51091475 0.51094577 0.5109137  0.51093118 0.51091737
 0.5108304  0.51087375]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.51075535 0.51077492 0.51077875 0.5107635  0.51073673 0.5107428
 0.51073338 0.51073011 0.51071412 0.51071029 0.5107027  0.51068805
 0.51069076 0.5106912  0.51068448 0.51069028 0.51069734 0.51070806
 0.5107151  0.51069828]
[0.         0.         0.23684211]
-----------end of analyzing the loss ratio:74.78021025657654
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9387917e0>
---------------------------------
SparseEpoch: [106][1/398]	Time 0.577	Data 0.000	Loss 0.7786	
SparseEpoch: [106][101/398]	Time 0.579	Data 0.000	Loss 0.9064	
SparseEpoch: [106][201/398]	Time 0.579	Data 0.000	Loss 1.1600	
SparseEpoch: [106][301/398]	Time 0.580	Data 0.000	Loss 1.4593	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.52991872 0.52979423 0.52975208 0.52958777 0.52958544 0.5295417
 0.52950926 0.5294993  0.52936894 0.52936919 0.52927363 0.52926059
 0.52919852 0.52915306 0.52913038 0.52902349 0.52895396 0.52882999
 0.52873289 0.52860039]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.52934755 0.52934605 0.52937209 0.52937953 0.52937382 0.52935449
 0.52934807 0.52931061 0.52930215 0.52931387 0.52930582 0.52929331
 0.52929128 0.52926989 0.52926484 0.52926153 0.52924518 0.52926982
 0.52925042 0.52925557]
[0.5        0.         0.34210526]
-----------end of analyzing the loss ratio:75.11926102638245
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9390608e0>
---------------------------------
SparseEpoch: [106][1/398]	Time 0.591	Data 0.000	Loss 1.1755	
SparseEpoch: [106][101/398]	Time 0.580	Data 0.000	Loss 0.8007	
SparseEpoch: [106][201/398]	Time 0.581	Data 0.000	Loss 1.2787	
SparseEpoch: [106][301/398]	Time 0.581	Data 0.000	Loss 1.1339	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.13403783 0.1340467  0.13403801 0.1340647  0.13405917 0.13405169
 0.13400368 0.13394617 0.13397087 0.13397534 0.13395823 0.13397078
 0.13396832 0.13399994 0.13397877 0.13396926 0.13397284 0.13402745
 0.13398035 0.13396972]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.1340394  0.13404089 0.13403461 0.13400874 0.13399069 0.13399167
 0.13399078 0.13398237 0.13397377 0.13397846 0.13395588 0.13395854
 0.13396694 0.13397732 0.13396055 0.13394211 0.13393669 0.13395208
 0.13395218 0.13395325]
[0.         0.34210526 0.        ]
-----------end of analyzing the loss ratio:74.93721413612366
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938a89390>
---------------------------------
SparseEpoch: [106][1/398]	Time 0.578	Data 0.000	Loss 1.9244	
SparseEpoch: [106][101/398]	Time 0.580	Data 0.000	Loss 1.6706	
SparseEpoch: [106][201/398]	Time 0.580	Data 0.000	Loss 2.1733	
SparseEpoch: [106][301/398]	Time 0.580	Data 0.000	Loss 1.8910	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.8001	
Epoch(adapt):{0} Loss 0.8226	
Epoch(adapt):{0} Loss 1.5701	
Epoch(adapt):{0} Loss 0.9211	
------------------the total time cost:1164.7540519237518
>>>>>meta updating
Epoch: 0106 | TRAIN: 0.5216 0.6435 0.8314 | 0.3689 0.3689 0.1706 | 0.1322 24.1962 19.1707 0.2891 0.5829 0.7138 ||TEST: 1.0905 0.4089 0.6642 | 0.5475 0.5475 0.2078 | 0.1439 25.5904 20.7713 0.2682 0.5444 0.6759 | 116.7048
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.46238254 0.46241486 0.462431   0.46240982 0.46243022 0.46246214
 0.4624307  0.46245414 0.46247045 0.46246646 0.46247889 0.46253099
 0.46250412 0.46250018 0.46244401 0.46241533 0.46244391 0.46246138
 0.46248157 0.46249428]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.46246359 0.46248414 0.46250691 0.46250771 0.46250572 0.46253052
 0.46249256 0.46250289 0.4625193  0.46249093 0.46248593 0.46247953
 0.46247208 0.46245398 0.46244882 0.46244532 0.46244756 0.46246796
 0.46247161 0.46243954]
[0.  0.  0.5]
-----------end of analyzing the loss ratio:75.02285051345825
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938504a00>
---------------------------------
SparseEpoch: [107][1/398]	Time 0.578	Data 0.000	Loss 0.8262	
SparseEpoch: [107][101/398]	Time 0.579	Data 0.000	Loss 1.2424	
SparseEpoch: [107][201/398]	Time 0.579	Data 0.000	Loss 1.1123	
SparseEpoch: [107][301/398]	Time 0.580	Data 0.000	Loss 1.2959	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.58338101 0.58314723 0.58310805 0.58279403 0.58249697 0.58225548
 0.58187141 0.5819983  0.58216338 0.58211036 0.58190376 0.58170634
 0.58144277 0.58121344 0.5809559  0.58093723 0.58079485 0.58086089
 0.5807319  0.58059263]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.58225067 0.5822498  0.5821961  0.58219204 0.58216597 0.58218855
 0.58213925 0.58215213 0.58214592 0.5821505  0.58214403 0.58215498
 0.58214603 0.58212131 0.58209615 0.58208729 0.58207204 0.58207024
 0.58207087 0.58208253]
[0.5        0.         0.39473684]
-----------end of analyzing the loss ratio:75.02242517471313
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938d4d420>
---------------------------------
SparseEpoch: [107][1/398]	Time 0.579	Data 0.000	Loss 1.0457	
SparseEpoch: [107][101/398]	Time 0.581	Data 0.000	Loss 1.9642	
SparseEpoch: [107][201/398]	Time 0.581	Data 0.000	Loss 1.1768	
SparseEpoch: [107][301/398]	Time 0.581	Data 0.000	Loss 1.0595	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.13502071 0.13503446 0.13504843 0.13504897 0.13503957 0.13503607
 0.13501523 0.13502593 0.13502503 0.1350022  0.13500711 0.13499912
 0.1350055  0.13499711 0.13500247 0.13499088 0.1349981  0.13500047
 0.13499815 0.13500828]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.13503231 0.13503117 0.13502427 0.13502725 0.13502821 0.1350261
 0.13501596 0.1350072  0.13500883 0.13500381 0.13500603 0.13500004
 0.13500385 0.13500878 0.13500431 0.1350013  0.13500295 0.1350037
 0.13501602 0.13501275]
[0.28947368 0.07894737 0.        ]
-----------end of analyzing the loss ratio:75.15147471427917
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9383738e0>
---------------------------------
SparseEpoch: [107][1/398]	Time 0.587	Data 0.000	Loss 1.2572	
SparseEpoch: [107][101/398]	Time 0.580	Data 0.000	Loss 1.2394	
SparseEpoch: [107][201/398]	Time 0.581	Data 0.000	Loss 1.5262	
SparseEpoch: [107][301/398]	Time 0.581	Data 0.000	Loss 1.2123	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.5043	
Epoch(adapt):{0} Loss 1.0751	
Epoch(adapt):{0} Loss 1.3121	
Epoch(adapt):{0} Loss 1.5233	
------------------the total time cost:1164.9509720802307
>>>>>meta updating
Epoch: 0107 | TRAIN: 0.5140 0.6515 0.8343 | 0.3699 0.3699 0.1717 | 0.1304 24.0224 18.9121 0.2922 0.5872 0.7167 ||TEST: 1.1071 0.4072 0.6640 | 0.5426 0.5426 0.2100 | 0.1438 25.6234 20.8402 0.2662 0.5426 0.6738 | 116.4627
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.59645741 0.59645674 0.59650317 0.59642884 0.59641119 0.5964044
 0.59639599 0.59641108 0.59639649 0.59636503 0.59634389 0.59630983
 0.59626365 0.59626653 0.59624675 0.59626844 0.59630189 0.59626645
 0.59626623 0.59626732]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.59632545 0.59632902 0.59633455 0.59632831 0.59633364 0.59633345
 0.5963348  0.59633117 0.59634106 0.59635141 0.59633779 0.59633654
 0.59634037 0.59635753 0.59634214 0.59632827 0.59636297 0.59638131
 0.59634431 0.59637751]
[0.         0.23684211 0.        ]
-----------end of analyzing the loss ratio:74.86771035194397
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9382d1de0>
---------------------------------
SparseEpoch: [108][1/398]	Time 0.578	Data 0.000	Loss 0.4814	
SparseEpoch: [108][101/398]	Time 0.580	Data 0.000	Loss 0.6473	
SparseEpoch: [108][201/398]	Time 0.579	Data 0.000	Loss 0.4284	
SparseEpoch: [108][301/398]	Time 0.580	Data 0.000	Loss 0.4730	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.39940809 0.39945792 0.39946479 0.39946041 0.39950319 0.39945286
 0.39946139 0.39944602 0.39941898 0.39939505 0.39937683 0.39937512
 0.39934669 0.39934743 0.39934918 0.39931217 0.399329   0.39941376
 0.39937581 0.3993216 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.39935307 0.3993471  0.39937382 0.39935784 0.39938128 0.39938652
 0.39939616 0.39940223 0.39940245 0.39940104 0.39939119 0.39939891
 0.39940056 0.39939535 0.39940663 0.39943119 0.39943663 0.3994351
 0.39942984 0.39943575]
[0.28947368 0.         0.        ]
-----------end of analyzing the loss ratio:74.79430484771729
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9398fab30>
---------------------------------
SparseEpoch: [108][1/398]	Time 0.578	Data 0.000	Loss 0.3169	
SparseEpoch: [108][101/398]	Time 0.580	Data 0.000	Loss 0.3986	
SparseEpoch: [108][201/398]	Time 0.580	Data 0.000	Loss 0.4158	
SparseEpoch: [108][301/398]	Time 0.580	Data 0.000	Loss 0.3748	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.13352185 0.13351893 0.1335026  0.13350915 0.1335154  0.13350937
 0.13350537 0.13351632 0.13353251 0.13353221 0.13354098 0.13352167
 0.13351204 0.13352556 0.13353065 0.13352901 0.1335389  0.13355941
 0.13355986 0.13355855]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.13351207 0.1335165  0.13354151 0.13355166 0.13352945 0.13355228
 0.13356824 0.13354065 0.13354172 0.13353053 0.13353454 0.13354425
 0.13353199 0.13353167 0.13350782 0.13352104 0.1335395  0.13354411
 0.13351105 0.13352129]
[0.         0.23684211 0.        ]
-----------end of analyzing the loss ratio:75.10417556762695
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9384fe110>
---------------------------------
SparseEpoch: [108][1/398]	Time 0.579	Data 0.000	Loss 1.0802	
SparseEpoch: [108][101/398]	Time 0.580	Data 0.000	Loss 1.1303	
SparseEpoch: [108][201/398]	Time 0.580	Data 0.000	Loss 1.2765	
SparseEpoch: [108][301/398]	Time 0.580	Data 0.000	Loss 1.3169	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.9678	
Epoch(adapt):{0} Loss 0.7878	
Epoch(adapt):{0} Loss 1.0291	
Epoch(adapt):{0} Loss 0.8543	
------------------the total time cost:1165.1823406219482
>>>>>meta updating
Epoch: 0108 | TRAIN: 0.5297 0.6410 0.8249 | 0.3549 0.3549 0.1654 | 0.1336 24.4594 19.6735 0.2840 0.5689 0.7018 ||TEST: 1.1298 0.3963 0.6585 | 0.5333 0.5333 0.2116 | 0.1478 26.0692 21.5325 0.2634 0.5272 0.6591 | 115.9778
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.55301086 0.55292929 0.55286404 0.55284303 0.55279644 0.5527868
 0.5527911  0.55268755 0.55276566 0.55275523 0.55277615 0.55283435
 0.55283673 0.55279114 0.55264486 0.55256604 0.55252251 0.5525248
 0.55250092 0.55245521]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.55273197 0.55271593 0.55275958 0.55277735 0.55277971 0.55278506
 0.55274342 0.5527419  0.55274599 0.55274826 0.55272837 0.55275691
 0.5527616  0.55275162 0.55276782 0.55279603 0.55283786 0.55283549
 0.5528354  0.55284683]
[0.  0.5 0. ]
-----------end of analyzing the loss ratio:75.06733846664429
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cca5e307a90>
---------------------------------
SparseEpoch: [109][1/398]	Time 0.578	Data 0.000	Loss 0.8020	
SparseEpoch: [109][101/398]	Time 0.580	Data 0.000	Loss 0.5675	
SparseEpoch: [109][201/398]	Time 0.580	Data 0.000	Loss 0.5431	
SparseEpoch: [109][301/398]	Time 0.580	Data 0.000	Loss 0.6498	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.34007343 0.34005203 0.34008594 0.34005985 0.34000032 0.33994613
 0.33996088 0.34004134 0.34005934 0.34004097 0.34007278 0.34008873
 0.34010303 0.34008111 0.34004978 0.34001346 0.34003854 0.33997614
 0.33993274 0.33992081]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.34008381 0.34009072 0.34009537 0.34009435 0.3401083  0.3401075
 0.34007709 0.34008981 0.34006845 0.34007134 0.34005665 0.34005037
 0.34006813 0.34006082 0.34007438 0.34008208 0.34009661 0.34009199
 0.3400842  0.3400765 ]
[0.5        0.         0.07894737]
-----------end of analyzing the loss ratio:74.88362979888916
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938790370>
---------------------------------
SparseEpoch: [109][1/398]	Time 0.580	Data 0.000	Loss 0.5130	
SparseEpoch: [109][101/398]	Time 0.580	Data 0.000	Loss 0.8098	
SparseEpoch: [109][201/398]	Time 0.581	Data 0.000	Loss 0.6647	
SparseEpoch: [109][301/398]	Time 0.581	Data 0.000	Loss 0.8426	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.12066237 0.12066074 0.12066945 0.12066534 0.12065693 0.12064426
 0.12065333 0.12067285 0.120679   0.12067321 0.12066622 0.1206633
 0.12065256 0.12065368 0.12065754 0.12065619 0.12066205 0.12065117
 0.12066802 0.1206708 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.12069514 0.12069991 0.12069034 0.12069479 0.12067165 0.12067161
 0.12066642 0.1206746  0.12067486 0.12067243 0.12066353 0.12065458
 0.12065672 0.12065622 0.12064085 0.12064492 0.12063985 0.12062171
 0.12062891 0.12062267]
[0.         0.39473684 0.        ]
-----------end of analyzing the loss ratio:74.98370456695557
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9386a60b0>
---------------------------------
SparseEpoch: [109][1/398]	Time 0.577	Data 0.000	Loss 1.2867	
SparseEpoch: [109][101/398]	Time 0.579	Data 0.000	Loss 2.2268	
SparseEpoch: [109][201/398]	Time 0.579	Data 0.000	Loss 1.8840	
SparseEpoch: [109][301/398]	Time 0.579	Data 0.000	Loss 1.5654	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.9173	
Epoch(adapt):{0} Loss 1.5965	
Epoch(adapt):{0} Loss 0.8638	
Epoch(adapt):{0} Loss 0.5568	
------------------the total time cost:1163.8257567882538
>>>>>meta updating
Epoch: 0109 | TRAIN: 0.5026 0.6474 0.8351 | 0.3529 0.3529 0.1674 | 0.1324 24.2679 19.3297 0.2879 0.5778 0.7093 ||TEST: 1.1472 0.3986 0.6594 | 0.5291 0.5291 0.2100 | 0.1447 25.7068 21.0318 0.2680 0.5380 0.6694 | 116.4836
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.52261458 0.52264013 0.52268825 0.52260237 0.52254477 0.52256751
 0.5224957  0.52253451 0.52250621 0.52244611 0.52238771 0.52234319
 0.5222986  0.52226341 0.52241877 0.52238153 0.5223905  0.52236497
 0.52243817 0.52239981]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.52236414 0.52236341 0.52237479 0.52238487 0.52241278 0.52245251
 0.52240144 0.52245205 0.52240829 0.5224271  0.52239632 0.52238094
 0.52234504 0.52237683 0.52239469 0.52241529 0.522413   0.52241969
 0.52241875 0.52242288]
[0.         0.18421053 0.13157895]
-----------end of analyzing the loss ratio:75.18661499023438
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cca5dec8c10>
---------------------------------
SparseEpoch: [110][1/398]	Time 0.578	Data 0.000	Loss 1.0974	
SparseEpoch: [110][101/398]	Time 0.580	Data 0.000	Loss 0.7352	
SparseEpoch: [110][201/398]	Time 0.580	Data 0.000	Loss 1.1064	
SparseEpoch: [110][301/398]	Time 0.580	Data 0.000	Loss 0.6290	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.40927969 0.40923224 0.40918094 0.40912039 0.4091492  0.40912528
 0.40912359 0.40919742 0.40914466 0.40905188 0.40913732 0.40902258
 0.40892972 0.40894726 0.40896441 0.40893686 0.4089818  0.40899131
 0.409025   0.4089994 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.40906985 0.40905708 0.40906155 0.40906377 0.40907071 0.40906415
 0.40905265 0.40903391 0.40904045 0.40903639 0.40904198 0.40902995
 0.4090078  0.40901042 0.40911838 0.40912645 0.40913829 0.40914359
 0.4091285  0.40910321]
[0.13157895 0.         0.13157895]
-----------end of analyzing the loss ratio:75.18684768676758
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938141300>
---------------------------------
SparseEpoch: [110][1/398]	Time 0.579	Data 0.000	Loss 0.6672	
SparseEpoch: [110][101/398]	Time 0.581	Data 0.000	Loss 0.7694	
SparseEpoch: [110][201/398]	Time 0.581	Data 0.000	Loss 0.6900	
SparseEpoch: [110][301/398]	Time 0.581	Data 0.000	Loss 0.6872	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.13913158 0.13911831 0.13907314 0.13904229 0.13901647 0.13895917
 0.13895357 0.13888745 0.13887271 0.13889058 0.13885818 0.13882335
 0.13880645 0.13875669 0.13873707 0.13869604 0.13869149 0.1386279
 0.13862544 0.13862587]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.13893144 0.138915   0.13889824 0.13887868 0.1388792  0.13887691
 0.13888289 0.13888437 0.13888311 0.13887372 0.13887108 0.13886191
 0.13884566 0.13884751 0.1388157  0.13882029 0.13880995 0.13881294
 0.13880681 0.13880966]
[0.44736842 0.44736842 0.        ]
-----------end of analyzing the loss ratio:75.1460428237915
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938b6bf40>
---------------------------------
SparseEpoch: [110][1/398]	Time 0.579	Data 0.000	Loss 1.3728	
SparseEpoch: [110][101/398]	Time 0.581	Data 0.000	Loss 1.8729	
SparseEpoch: [110][201/398]	Time 0.581	Data 0.000	Loss 2.2426	
SparseEpoch: [110][301/398]	Time 0.581	Data 0.000	Loss 1.4095	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.7898	
Epoch(adapt):{0} Loss 1.2121	
Epoch(adapt):{0} Loss 1.0229	
Epoch(adapt):{0} Loss 0.9084	
------------------the total time cost:1166.4911193847656
>>>>>meta updating
Epoch: 0110 | TRAIN: 0.4856 0.6613 0.8430 | 0.3448 0.3448 0.1691 | 0.1290 23.6871 18.5105 0.3070 0.5970 0.7231 ||TEST: 1.1507 0.4051 0.6630 | 0.5182 0.5182 0.2098 | 0.1435 25.4206 20.4685 0.2774 0.5504 0.6794 | 116.5111
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.47710945 0.47712676 0.47710823 0.47712916 0.47707327 0.47710276
 0.47710756 0.47713115 0.47706843 0.47697285 0.47696558 0.47696995
 0.47697109 0.47693669 0.47689589 0.4768359  0.4768667  0.47689945
 0.47690225 0.47696245]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.47704013 0.47705135 0.4770505  0.47702181 0.47700344 0.47702778
 0.47698403 0.47699774 0.476983   0.47695595 0.47693799 0.47697301
 0.47695804 0.47696205 0.47699502 0.47699568 0.47700036 0.47699488
 0.47700653 0.47700645]
[0.         0.28947368 0.02631579]
-----------end of analyzing the loss ratio:75.25080490112305
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc93875fa60>
---------------------------------
SparseEpoch: [111][1/398]	Time 0.595	Data 0.000	Loss 1.1290	
SparseEpoch: [111][101/398]	Time 0.581	Data 0.000	Loss 0.8000	
SparseEpoch: [111][201/398]	Time 0.581	Data 0.000	Loss 0.5484	
SparseEpoch: [111][301/398]	Time 0.581	Data 0.000	Loss 0.4970	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.41547591 0.41553042 0.41567849 0.41570879 0.41577867 0.41587267
 0.41584493 0.41587807 0.41584622 0.41597637 0.4160159  0.41590025
 0.41592946 0.41596097 0.41598983 0.41594658 0.41602793 0.41605873
 0.41604711 0.41599231]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.41601023 0.41603813 0.41600664 0.41599471 0.41597855 0.41599053
 0.41601404 0.41600639 0.416014   0.4160137  0.41598779 0.41598471
 0.41598069 0.41599592 0.4160051  0.4159974  0.41599019 0.41598
 0.41596437 0.41596414]
[0.  0.  0.5]
-----------end of analyzing the loss ratio:75.10388994216919
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cca5e306cb0>
---------------------------------
SparseEpoch: [111][1/398]	Time 0.580	Data 0.000	Loss 0.6592	
SparseEpoch: [111][101/398]	Time 0.580	Data 0.000	Loss 1.3933	
SparseEpoch: [111][201/398]	Time 0.580	Data 0.000	Loss 1.0082	
SparseEpoch: [111][301/398]	Time 0.580	Data 0.000	Loss 1.1189	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.14238286 0.14238989 0.14235775 0.14231679 0.14225277 0.1422205
 0.14220208 0.1421853  0.14216954 0.14217564 0.14215361 0.14212499
 0.14210509 0.14208121 0.14205282 0.1420239  0.1420471  0.14198404
 0.14193538 0.14188747]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.14219843 0.14219809 0.1421978  0.14222294 0.14220046 0.14216488
 0.14218408 0.14219677 0.14218759 0.1421833  0.14216483 0.14212979
 0.14214256 0.14213337 0.14212204 0.14208031 0.14203589 0.14203735
 0.14203477 0.14203177]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:75.07490062713623
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938778f70>
---------------------------------
SparseEpoch: [111][1/398]	Time 0.578	Data 0.000	Loss 1.9243	
SparseEpoch: [111][101/398]	Time 0.581	Data 0.000	Loss 1.3365	
SparseEpoch: [111][201/398]	Time 0.580	Data 0.000	Loss 1.6398	
SparseEpoch: [111][301/398]	Time 0.581	Data 0.000	Loss 1.3968	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.8140	
Epoch(adapt):{0} Loss 0.9279	
Epoch(adapt):{0} Loss 0.9038	
Epoch(adapt):{0} Loss 0.7918	
------------------the total time cost:1164.9968180656433
>>>>>meta updating
Epoch: 0111 | TRAIN: 0.5264 0.6356 0.8280 | 0.3630 0.3630 0.1657 | 0.1308 24.0795 19.0946 0.2914 0.5834 0.7138 ||TEST: 1.1387 0.3956 0.6576 | 0.5447 0.5447 0.2113 | 0.1455 25.7323 20.9290 0.2694 0.5405 0.6707 | 116.3174
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.49822817 0.49827299 0.49826511 0.49829916 0.49833054 0.49828136
 0.49829856 0.49830266 0.49831182 0.49834676 0.4983478  0.49835812
 0.49838709 0.49839858 0.49841552 0.49840069 0.49839537 0.49840162
 0.49838925 0.49837486]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.49827835 0.49830128 0.49833475 0.49831143 0.49831703 0.4983268
 0.49836318 0.49838163 0.49835509 0.49834778 0.49834894 0.49833598
 0.49835697 0.49833306 0.4983526  0.49833583 0.498311   0.49832712
 0.49833258 0.49833513]
[0. 0. 0.]
-----------end of analyzing the loss ratio:75.08179974555969
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938c05480>
---------------------------------
SparseEpoch: [112][1/398]	Time 0.576	Data 0.000	Loss 0.5656	
SparseEpoch: [112][101/398]	Time 0.579	Data 0.000	Loss 0.3982	
SparseEpoch: [112][201/398]	Time 0.579	Data 0.000	Loss 0.6072	
SparseEpoch: [112][301/398]	Time 0.579	Data 0.000	Loss 0.5392	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.7056666  0.70539117 0.70516787 0.70486926 0.7046781  0.70451355
 0.7043743  0.70438206 0.7043479  0.70414954 0.70418919 0.70393682
 0.70367537 0.70335485 0.70345469 0.70311844 0.70297568 0.70286632
 0.70254801 0.70247376]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.70421044 0.70418643 0.70417383 0.70417635 0.70417328 0.70411323
 0.70416093 0.70411537 0.70409222 0.704057   0.70407051 0.70405058
 0.7040415  0.70406606 0.70406625 0.70404457 0.70409598 0.7041244
 0.70416024 0.70415568]
[0.5        0.         0.13157895]
-----------end of analyzing the loss ratio:75.10048460960388
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938309ba0>
---------------------------------
SparseEpoch: [112][1/398]	Time 0.579	Data 0.000	Loss 0.8952	
SparseEpoch: [112][101/398]	Time 0.582	Data 0.000	Loss 0.7090	
SparseEpoch: [112][201/398]	Time 0.581	Data 0.000	Loss 0.7526	
SparseEpoch: [112][301/398]	Time 0.581	Data 0.000	Loss 1.0848	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11932231 0.1193141  0.11930811 0.11930047 0.11929746 0.11930394
 0.11930349 0.1192914  0.11929905 0.11928412 0.11925179 0.11924126
 0.11924354 0.11924105 0.11923858 0.11924597 0.1192354  0.11923007
 0.11922262 0.11920506]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11926822 0.11926253 0.11927595 0.11925882 0.11925862 0.11928384
 0.11927757 0.11926678 0.11926069 0.1192504  0.11928156 0.11928269
 0.11927128 0.11927549 0.11927213 0.1192758  0.1192789  0.119266
 0.11926473 0.11927607]
[0.5 0.  0. ]
-----------end of analyzing the loss ratio:74.92969918251038
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9386c8850>
---------------------------------
SparseEpoch: [112][1/398]	Time 0.578	Data 0.000	Loss 2.2881	
SparseEpoch: [112][101/398]	Time 0.581	Data 0.000	Loss 2.4505	
SparseEpoch: [112][201/398]	Time 0.581	Data 0.000	Loss 1.5051	
SparseEpoch: [112][301/398]	Time 0.580	Data 0.000	Loss 1.0988	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.7011	
Epoch(adapt):{0} Loss 0.9000	
Epoch(adapt):{0} Loss 0.8043	
Epoch(adapt):{0} Loss 1.2214	
------------------the total time cost:1164.4897210597992
>>>>>meta updating
Epoch: 0112 | TRAIN: 0.4711 0.6723 0.8477 | 0.3498 0.3498 0.1746 | 0.1303 23.9610 18.8947 0.2971 0.5864 0.7155 ||TEST: 1.1210 0.4160 0.6680 | 0.5183 0.5183 0.2089 | 0.1446 25.6501 20.8875 0.2713 0.5405 0.6711 | 115.9523
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.43069944 0.43070569 0.43065436 0.43065729 0.43065072 0.43061191
 0.43063187 0.43062591 0.43063717 0.4306679  0.4307002  0.43068114
 0.43064386 0.43065973 0.4306379  0.43065255 0.43066099 0.43061626
 0.43067786 0.43069129]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.43070068 0.43069052 0.43072536 0.43071308 0.43072253 0.43069898
 0.4306912  0.43068643 0.43065826 0.43067374 0.43067666 0.4306647
 0.43065798 0.43065835 0.43067607 0.43069224 0.43068493 0.4306984
 0.43068573 0.43067347]
[0.         0.         0.13157895]
-----------end of analyzing the loss ratio:75.0548963546753
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938de9990>
---------------------------------
SparseEpoch: [113][1/398]	Time 0.582	Data 0.000	Loss 0.5739	
SparseEpoch: [113][101/398]	Time 0.581	Data 0.000	Loss 1.0449	
SparseEpoch: [113][201/398]	Time 0.581	Data 0.000	Loss 0.7505	
SparseEpoch: [113][301/398]	Time 0.580	Data 0.000	Loss 0.9136	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.34934684 0.34932701 0.34935098 0.34930366 0.34928778 0.34927837
 0.34925366 0.34922159 0.34923474 0.34920924 0.34920562 0.34920018
 0.34924784 0.34931569 0.34929146 0.34932108 0.34931999 0.34927334
 0.34932985 0.34931763]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.34926316 0.34925998 0.34925769 0.34924635 0.34923532 0.34923735
 0.3492356  0.34923268 0.34923525 0.34922839 0.34922153 0.34920442
 0.34919317 0.34920269 0.34919905 0.34920122 0.3492069  0.34921097
 0.34921733 0.34921811]
[0.07894737 0.         0.13157895]
-----------end of analyzing the loss ratio:74.96577048301697
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938c6d810>
---------------------------------
SparseEpoch: [113][1/398]	Time 0.579	Data 0.000	Loss 0.6123	
SparseEpoch: [113][101/398]	Time 0.580	Data 0.000	Loss 0.5097	
SparseEpoch: [113][201/398]	Time 0.581	Data 0.000	Loss 0.4255	
SparseEpoch: [113][301/398]	Time 0.581	Data 0.000	Loss 0.6073	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.13812563 0.13811278 0.13811674 0.13812013 0.13809317 0.13810658
 0.1381124  0.13808419 0.13806243 0.13801998 0.13803056 0.13800262
 0.13795928 0.13795468 0.13792371 0.13793323 0.13792837 0.1379162
 0.13789811 0.13789608]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.13798332 0.13799905 0.13799012 0.13798628 0.13798702 0.13798956
 0.1380133  0.13802922 0.13802171 0.13802512 0.13801588 0.13801882
 0.13801998 0.1380318  0.1380385  0.13805673 0.13805667 0.13805374
 0.13804188 0.1380592 ]
[0.5 0.  0. ]
-----------end of analyzing the loss ratio:75.08596301078796
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9387c5db0>
---------------------------------
SparseEpoch: [113][1/398]	Time 0.596	Data 0.000	Loss 1.8144	
SparseEpoch: [113][101/398]	Time 0.580	Data 0.000	Loss 1.9391	
SparseEpoch: [113][201/398]	Time 0.580	Data 0.000	Loss 1.8001	
SparseEpoch: [113][301/398]	Time 0.580	Data 0.000	Loss 1.8817	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.3627	
Epoch(adapt):{0} Loss 1.2809	
Epoch(adapt):{0} Loss 0.9344	
Epoch(adapt):{0} Loss 1.0085	
------------------the total time cost:1165.3785407543182
>>>>>meta updating
Epoch: 0113 | TRAIN: 0.5034 0.6490 0.8352 | 0.3544 0.3544 0.1755 | 0.1290 23.7742 18.6574 0.3001 0.5939 0.7219 ||TEST: 1.1422 0.4019 0.6571 | 0.5263 0.5263 0.2106 | 0.1430 25.3793 20.3940 0.2778 0.5512 0.6801 | 116.2368
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.48104007 0.4810662  0.48108068 0.48110394 0.48112313 0.48111074
 0.48114764 0.48120906 0.48121999 0.48122035 0.48117366 0.4812001
 0.48119053 0.48120319 0.48122465 0.48124618 0.4812249  0.48119474
 0.48123792 0.4811995 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.48128025 0.48130188 0.4812744  0.48125996 0.48123707 0.48121882
 0.48120276 0.48118013 0.48118258 0.4811893  0.48118927 0.48117
 0.48120584 0.48113329 0.48114014 0.48109457 0.48107819 0.48104912
 0.48105778 0.48103742]
[0.  0.  0.5]
-----------end of analyzing the loss ratio:75.19744753837585
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938373400>
---------------------------------
SparseEpoch: [114][1/398]	Time 0.583	Data 0.000	Loss 1.4985	
SparseEpoch: [114][101/398]	Time 0.581	Data 0.000	Loss 0.8514	
SparseEpoch: [114][201/398]	Time 0.580	Data 0.000	Loss 1.0607	
SparseEpoch: [114][301/398]	Time 0.580	Data 0.000	Loss 1.0231	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.45979519 0.4598604  0.45990597 0.45994999 0.46002203 0.46006229
 0.46007922 0.46011776 0.46011789 0.46012484 0.46017966 0.46025341
 0.46024586 0.46026556 0.46026994 0.46029301 0.46029913 0.46027023
 0.46016979 0.46014684]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.46011304 0.4601194  0.46012795 0.46012602 0.4601502  0.46013069
 0.46012886 0.46012856 0.46013987 0.46015492 0.46012258 0.46012471
 0.46014716 0.46014442 0.46014473 0.46012553 0.46013477 0.46015201
 0.4601528  0.46013926]
[0. 0. 0.]
-----------end of analyzing the loss ratio:74.94663619995117
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc939062830>
---------------------------------
SparseEpoch: [114][1/398]	Time 0.577	Data 0.000	Loss 0.2813	
SparseEpoch: [114][101/398]	Time 0.579	Data 0.000	Loss 0.3290	
SparseEpoch: [114][201/398]	Time 0.579	Data 0.000	Loss 0.4961	
SparseEpoch: [114][301/398]	Time 0.579	Data 0.000	Loss 0.5649	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.13056134 0.13053316 0.13051209 0.13053808 0.13053262 0.13051775
 0.13050062 0.13049516 0.13045    0.13041919 0.13038955 0.13038126
 0.13038404 0.13037278 0.13037564 0.13036126 0.13034859 0.13033444
 0.13034999 0.13035024]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.13052168 0.1305171  0.13052049 0.1305208  0.13050826 0.13048826
 0.1305046  0.13048933 0.13044325 0.1304161  0.13038793 0.13038339
 0.13038868 0.13038481 0.13038154 0.13036505 0.1303544  0.13034866
 0.13033959 0.13033559]
[0.39473684 0.5        0.        ]
-----------end of analyzing the loss ratio:75.14038157463074
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9382d3a60>
---------------------------------
SparseEpoch: [114][1/398]	Time 0.579	Data 0.000	Loss 2.1665	
SparseEpoch: [114][101/398]	Time 0.581	Data 0.000	Loss 1.7648	
SparseEpoch: [114][201/398]	Time 0.581	Data 0.000	Loss 1.6537	
SparseEpoch: [114][301/398]	Time 0.581	Data 0.000	Loss 2.4018	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.6050	
Epoch(adapt):{0} Loss 0.7257	
Epoch(adapt):{0} Loss 0.8818	
Epoch(adapt):{0} Loss 1.0940	
------------------the total time cost:1165.7147817611694
>>>>>meta updating
Epoch: 0114 | TRAIN: 0.4815 0.6698 0.8438 | 0.3482 0.3482 0.1672 | 0.1286 23.7935 18.7980 0.2986 0.5905 0.7197 ||TEST: 1.1445 0.4143 0.6654 | 0.5227 0.5227 0.2089 | 0.1437 25.5139 20.7149 0.2746 0.5451 0.6751 | 116.4024
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.4625569  0.46256113 0.46252638 0.46254799 0.46249219 0.46248081
 0.46247728 0.46251854 0.46249858 0.46250442 0.46258663 0.46259341
 0.46261625 0.46262745 0.46256694 0.46256457 0.46253104 0.46248965
 0.46247052 0.46242661]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.46268393 0.46266661 0.4626715  0.46264284 0.46267752 0.46263945
 0.46262978 0.46261724 0.46260203 0.46258375 0.46255067 0.46250798
 0.46251955 0.46253073 0.46256121 0.46255018 0.46251226 0.4625021
 0.46250253 0.46252764]
[0.         0.5        0.39473684]
-----------end of analyzing the loss ratio:75.50549340248108
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9398f9960>
---------------------------------
SparseEpoch: [115][1/398]	Time 0.579	Data 0.000	Loss 0.9605	
SparseEpoch: [115][101/398]	Time 0.581	Data 0.000	Loss 0.9341	
SparseEpoch: [115][201/398]	Time 0.581	Data 0.000	Loss 1.0950	
SparseEpoch: [115][301/398]	Time 0.581	Data 0.000	Loss 1.2212	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.50146601 0.50141556 0.50114164 0.50123503 0.50122985 0.50131893
 0.50125526 0.5012849  0.50109842 0.50101935 0.50096965 0.50102486
 0.50088441 0.50081171 0.5006202  0.50045906 0.50040541 0.50014909
 0.50009727 0.49992517]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.50097105 0.50099646 0.50100124 0.50100605 0.50099905 0.5009831
 0.50098746 0.5009808  0.50097966 0.50096993 0.50094886 0.50094961
 0.50094422 0.50091067 0.50089468 0.50089917 0.50091944 0.50089785
 0.50091316 0.50091869]
[0.5        0.         0.23684211]
-----------end of analyzing the loss ratio:75.06244826316833
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc93820aa40>
---------------------------------
SparseEpoch: [115][1/398]	Time 0.579	Data 0.000	Loss 0.9560	
SparseEpoch: [115][101/398]	Time 0.581	Data 0.000	Loss 0.7742	
SparseEpoch: [115][201/398]	Time 0.581	Data 0.000	Loss 1.2924	
SparseEpoch: [115][301/398]	Time 0.581	Data 0.000	Loss 0.8066	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11986865 0.11986092 0.11985984 0.11985115 0.11984514 0.11984174
 0.11981487 0.11982738 0.1198275  0.11983862 0.11981843 0.11983569
 0.11983729 0.11983115 0.11983284 0.11983805 0.11981037 0.11978422
 0.11978161 0.1197903 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11983176 0.11982849 0.11981914 0.11981846 0.11981929 0.11982854
 0.11983441 0.11982335 0.11982512 0.11982063 0.11982586 0.1198332
 0.1198211  0.11981642 0.1198161  0.11981301 0.1198141  0.11980965
 0.11981339 0.11980822]
[0.44736842 0.5        0.        ]
-----------end of analyzing the loss ratio:74.87461471557617
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc93830bee0>
---------------------------------
SparseEpoch: [115][1/398]	Time 0.578	Data 0.000	Loss 1.5134	
SparseEpoch: [115][101/398]	Time 0.580	Data 0.000	Loss 1.5107	
SparseEpoch: [115][201/398]	Time 0.580	Data 0.000	Loss 1.4734	
SparseEpoch: [115][301/398]	Time 0.580	Data 0.000	Loss 2.1460	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.8552	
Epoch(adapt):{0} Loss 0.8231	
Epoch(adapt):{0} Loss 0.6727	
Epoch(adapt):{0} Loss 1.0143	
------------------the total time cost:1164.6572086811066
>>>>>meta updating
Epoch: 0115 | TRAIN: 0.4797 0.6610 0.8435 | 0.3447 0.3447 0.1669 | 0.1284 23.7401 18.7050 0.3006 0.5919 0.7212 ||TEST: 1.1605 0.4062 0.6651 | 0.5267 0.5267 0.2143 | 0.1440 25.5577 20.7745 0.2726 0.5435 0.6744 | 116.6070
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.42538835 0.42541238 0.42540028 0.42534875 0.42543492 0.42538745
 0.4253169  0.42529751 0.4253078  0.42535259 0.42536212 0.42539572
 0.42542791 0.42546466 0.42541577 0.42548287 0.42544956 0.42540532
 0.42538935 0.42534192]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.42534314 0.42534278 0.42540264 0.42541134 0.42540576 0.42542343
 0.42543307 0.42543922 0.4254205  0.42538944 0.42534962 0.42533922
 0.42534594 0.42534057 0.42532569 0.42534902 0.42534985 0.42535022
 0.42534291 0.4253459 ]
[0.         0.         0.23684211]
-----------end of analyzing the loss ratio:75.27751517295837
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938208ca0>
---------------------------------
SparseEpoch: [116][1/398]	Time 0.587	Data 0.000	Loss 0.7992	
SparseEpoch: [116][101/398]	Time 0.581	Data 0.000	Loss 0.9406	
SparseEpoch: [116][201/398]	Time 0.581	Data 0.000	Loss 0.7345	
SparseEpoch: [116][301/398]	Time 0.581	Data 0.000	Loss 0.8408	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.41977268 0.41936913 0.4189903  0.41867108 0.41836029 0.41820536
 0.41780411 0.41732986 0.41692629 0.41663742 0.41608199 0.41579772
 0.41547734 0.41519613 0.41477542 0.41445719 0.41416008 0.41398959
 0.41355384 0.41324221]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.41658148 0.41656924 0.41654314 0.41653943 0.41656008 0.41652637
 0.41645797 0.41642415 0.41642368 0.41640802 0.41638367 0.41636537
 0.41636669 0.4163226  0.41631039 0.41629882 0.41627301 0.41626937
 0.41625132 0.41623768]
[0.5 0.  0.5]
-----------end of analyzing the loss ratio:75.62322735786438
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938d4d0c0>
---------------------------------
SparseEpoch: [116][1/398]	Time 0.587	Data 0.000	Loss 1.3155	
SparseEpoch: [116][101/398]	Time 0.580	Data 0.000	Loss 1.2865	
SparseEpoch: [116][201/398]	Time 0.580	Data 0.000	Loss 1.0441	
SparseEpoch: [116][301/398]	Time 0.580	Data 0.000	Loss 0.9627	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.14057185 0.1405864  0.1406306  0.14061486 0.14056656 0.14060518
 0.14052319 0.1405086  0.14056184 0.14057279 0.14057159 0.14056804
 0.14052297 0.1404991  0.14046438 0.14045507 0.14038992 0.14035342
 0.14034081 0.14030976]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.14054462 0.14056332 0.14058166 0.14058992 0.14057866 0.14057178
 0.14055164 0.1405858  0.14056391 0.14055533 0.14056179 0.14058193
 0.14054809 0.14055951 0.140544   0.14053981 0.14053842 0.14053704
 0.14054542 0.14056373]
[0.5        0.39473684 0.        ]
-----------end of analyzing the loss ratio:75.23560309410095
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9386a6500>
---------------------------------
SparseEpoch: [116][1/398]	Time 0.579	Data 0.000	Loss 1.9983	
SparseEpoch: [116][101/398]	Time 0.580	Data 0.000	Loss 1.2290	
SparseEpoch: [116][201/398]	Time 0.580	Data 0.000	Loss 1.8940	
SparseEpoch: [116][301/398]	Time 0.580	Data 0.000	Loss 1.7364	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.7415	
Epoch(adapt):{0} Loss 0.9345	
Epoch(adapt):{0} Loss 1.1702	
Epoch(adapt):{0} Loss 1.1265	
------------------the total time cost:1165.5935244560242
>>>>>meta updating
Epoch: 0116 | TRAIN: 0.4489 0.6887 0.8554 | 0.3416 0.3416 0.1679 | 0.1274 23.5376 18.3549 0.3096 0.5989 0.7247 ||TEST: 1.1382 0.4137 0.6692 | 0.5190 0.5190 0.2078 | 0.1429 25.3385 20.4105 0.2818 0.5509 0.6792 | 116.2020
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.38403905 0.38407408 0.38404544 0.38413719 0.38404281 0.38409227
 0.38409431 0.38402129 0.38395491 0.38395403 0.3839417  0.38389379
 0.38395004 0.3839388  0.38398346 0.38401845 0.38399001 0.38389152
 0.38391782 0.38395958]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.38394092 0.38394299 0.3839428  0.38394461 0.38394552 0.38394168
 0.38394844 0.3839706  0.38396979 0.38397543 0.3839859  0.38399604
 0.38399969 0.38399846 0.38398735 0.38398302 0.38397852 0.38397525
 0.38398299 0.38398708]
[0.         0.39473684 0.        ]
-----------end of analyzing the loss ratio:75.13246560096741
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc89df1ef80>
---------------------------------
SparseEpoch: [117][1/398]	Time 0.578	Data 0.000	Loss 1.0839	
SparseEpoch: [117][101/398]	Time 0.580	Data 0.000	Loss 0.7002	
SparseEpoch: [117][201/398]	Time 0.580	Data 0.000	Loss 0.5504	
SparseEpoch: [117][301/398]	Time 0.580	Data 0.000	Loss 0.3746	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.45813946 0.45741003 0.45669968 0.45624362 0.45546682 0.45458657
 0.45384164 0.45314668 0.45279005 0.45218318 0.45158713 0.451172
 0.45084064 0.45088843 0.45054448 0.45005101 0.44997949 0.44972822
 0.44983143 0.44969151]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.45197194 0.45199037 0.45198709 0.45197652 0.45196624 0.45196955
 0.45195186 0.45196667 0.45195673 0.45192961 0.45193386 0.45193288
 0.45194098 0.45194196 0.45193329 0.45195684 0.45199151 0.45201927
 0.45195105 0.45190826]
[0.5 0.  0.5]
-----------end of analyzing the loss ratio:75.21153593063354
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc93882fdf0>
---------------------------------
SparseEpoch: [117][1/398]	Time 0.582	Data 0.000	Loss 1.3965	
SparseEpoch: [117][101/398]	Time 0.581	Data 0.000	Loss 0.8610	
SparseEpoch: [117][201/398]	Time 0.581	Data 0.000	Loss 1.1450	
SparseEpoch: [117][301/398]	Time 0.581	Data 0.000	Loss 1.2338	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.13781945 0.13780528 0.13779135 0.13779689 0.13781415 0.1378041
 0.1378159  0.13782946 0.13783694 0.13782205 0.13783022 0.1378341
 0.13783784 0.13783721 0.13782675 0.13781776 0.13779092 0.1377701
 0.13778189 0.13777627]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.13778157 0.13778023 0.13776738 0.13778208 0.1377934  0.13780109
 0.13778973 0.13781054 0.1378282  0.13782209 0.13781792 0.1378298
 0.13783183 0.13783134 0.13783376 0.13784987 0.13783512 0.13782792
 0.13782374 0.13780592]
[0.39473684 0.         0.        ]
-----------end of analyzing the loss ratio:74.95369672775269
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938d58cd0>
---------------------------------
SparseEpoch: [117][1/398]	Time 0.578	Data 0.000	Loss 1.7382	
SparseEpoch: [117][101/398]	Time 0.580	Data 0.000	Loss 1.6650	
SparseEpoch: [117][201/398]	Time 0.580	Data 0.000	Loss 1.7683	
SparseEpoch: [117][301/398]	Time 0.580	Data 0.000	Loss 2.1334	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.5827	
Epoch(adapt):{0} Loss 1.0639	
Epoch(adapt):{0} Loss 0.5864	
Epoch(adapt):{0} Loss 1.2642	
------------------the total time cost:1164.7949521541595
>>>>>meta updating
Epoch: 0117 | TRAIN: 0.4633 0.6727 0.8469 | 0.3414 0.3414 0.1633 | 0.1284 23.6909 18.5419 0.3019 0.5957 0.7237 ||TEST: 1.1613 0.4068 0.6626 | 0.5333 0.5333 0.2118 | 0.1439 25.5093 20.6488 0.2751 0.5463 0.6762 | 116.4369
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.46714976 0.46712899 0.46711552 0.46713026 0.46712485 0.46707844
 0.46707608 0.46705996 0.46708182 0.46702541 0.46704797 0.46706454
 0.4670848  0.46702574 0.46706086 0.46703464 0.46714212 0.46709505
 0.46707739 0.46711707]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.46708459 0.46709919 0.46709652 0.4671075  0.46706955 0.46707337
 0.4670833  0.46704936 0.46702525 0.46703306 0.46702452 0.4670219
 0.46702991 0.46704031 0.46702304 0.46702248 0.46704812 0.46705585
 0.46705526 0.46707067]
[0.         0.         0.07894737]
-----------end of analyzing the loss ratio:75.25909900665283
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938c6cbb0>
---------------------------------
SparseEpoch: [118][1/398]	Time 0.578	Data 0.000	Loss 0.6065	
SparseEpoch: [118][101/398]	Time 0.579	Data 0.000	Loss 0.4788	
SparseEpoch: [118][201/398]	Time 0.580	Data 0.000	Loss 0.9715	
SparseEpoch: [118][301/398]	Time 0.580	Data 0.000	Loss 0.8496	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.42872783 0.42872771 0.42866064 0.42866657 0.42868686 0.42866429
 0.42865423 0.42864753 0.42863044 0.42863197 0.42861472 0.42854289
 0.42845424 0.42844367 0.42843381 0.42843596 0.42838053 0.42834638
 0.42839246 0.42842979]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.42856604 0.4285619  0.42858111 0.42858818 0.42859688 0.4285757
 0.42858521 0.42856887 0.42856533 0.4286115  0.42863051 0.42859478
 0.42857446 0.42855555 0.42856694 0.42850619 0.42853693 0.42854664
 0.42853431 0.42857143]
[0.39473684 0.         0.28947368]
-----------end of analyzing the loss ratio:74.97105669975281
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9386c8be0>
---------------------------------
SparseEpoch: [118][1/398]	Time 0.578	Data 0.000	Loss 1.2343	
SparseEpoch: [118][101/398]	Time 0.581	Data 0.000	Loss 1.1327	
SparseEpoch: [118][201/398]	Time 0.581	Data 0.000	Loss 0.9030	
SparseEpoch: [118][301/398]	Time 0.581	Data 0.000	Loss 0.8757	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.12048252 0.12047083 0.12046159 0.12044872 0.12044226 0.12044481
 0.12047139 0.12045677 0.12045297 0.1204494  0.12048269 0.12048952
 0.12047714 0.12048491 0.1204832  0.12048596 0.12049608 0.12050393
 0.12050187 0.12051877]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.12048927 0.12050087 0.12050986 0.12053652 0.1205587  0.12053592
 0.12051706 0.1205022  0.1205052  0.12047948 0.12044644 0.12045224
 0.12045143 0.12046747 0.12046841 0.12049791 0.12050487 0.12050164
 0.12052096 0.12052115]
[0.         0.02631579 0.        ]
-----------end of analyzing the loss ratio:75.02240061759949
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc93866bbb0>
---------------------------------
SparseEpoch: [118][1/398]	Time 0.584	Data 0.000	Loss 1.7143	
SparseEpoch: [118][101/398]	Time 0.579	Data 0.000	Loss 1.3701	
SparseEpoch: [118][201/398]	Time 0.579	Data 0.000	Loss 1.2295	
SparseEpoch: [118][301/398]	Time 0.579	Data 0.000	Loss 2.0816	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.0727	
Epoch(adapt):{0} Loss 1.3691	
Epoch(adapt):{0} Loss 1.4067	
Epoch(adapt):{0} Loss 0.6969	
------------------the total time cost:1165.231912612915
>>>>>meta updating
Epoch: 0118 | TRAIN: 0.4571 0.6771 0.8511 | 0.3612 0.3612 0.1641 | 0.1254 23.4231 18.3179 0.3048 0.6014 0.7291 ||TEST: 1.1474 0.3995 0.6607 | 0.5520 0.5520 0.2102 | 0.1434 25.4429 20.5124 0.2765 0.5490 0.6782 | 116.1149
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.436784   0.43678699 0.43674353 0.43674397 0.43683491 0.43683938
 0.43688736 0.43690448 0.43696231 0.43698114 0.43704073 0.43709889
 0.43706235 0.43712008 0.43712133 0.43713794 0.43713189 0.43713347
 0.43716096 0.43719129]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.43700574 0.43701694 0.43701697 0.43702428 0.43702423 0.43702151
 0.43701473 0.43701623 0.43701505 0.43701    0.43703133 0.43702718
 0.43702942 0.43705215 0.43705929 0.43704861 0.4370499  0.43704638
 0.43704551 0.43705444]
[0. 0. 0.]
-----------end of analyzing the loss ratio:75.37326669692993
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9389d8d90>
---------------------------------
SparseEpoch: [119][1/398]	Time 0.577	Data 0.000	Loss 0.4229	
SparseEpoch: [119][101/398]	Time 0.580	Data 0.000	Loss 0.8779	
SparseEpoch: [119][201/398]	Time 0.579	Data 0.000	Loss 0.6875	
SparseEpoch: [119][301/398]	Time 0.579	Data 0.000	Loss 0.4140	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.41385598 0.41306072 0.41246372 0.41195296 0.41149554 0.41075447
 0.41022059 0.40957175 0.40882443 0.40827226 0.40758493 0.40686924
 0.40656215 0.40635312 0.40612804 0.40579269 0.40564942 0.40533367
 0.40465703 0.40417113]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.40801194 0.40802621 0.40804397 0.40801947 0.40801393 0.40800101
 0.40802891 0.40800787 0.40802777 0.40801122 0.40799587 0.40800228
 0.40800257 0.40801145 0.4079923  0.40795448 0.40793317 0.40790441
 0.40787943 0.40788116]
[0.5        0.         0.44736842]
-----------end of analyzing the loss ratio:75.1580228805542
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cca5e3b76a0>
---------------------------------
SparseEpoch: [119][1/398]	Time 0.583	Data 0.000	Loss 1.4141	
SparseEpoch: [119][101/398]	Time 0.581	Data 0.000	Loss 1.0562	
SparseEpoch: [119][201/398]	Time 0.582	Data 0.000	Loss 1.2040	
SparseEpoch: [119][301/398]	Time 0.581	Data 0.000	Loss 1.6786	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.1457317  0.14571844 0.14572341 0.14571514 0.14571124 0.14570349
 0.14568986 0.1456901  0.14570785 0.14566999 0.14565313 0.14562903
 0.14561623 0.1456349  0.14563697 0.14564191 0.14563677 0.14562204
 0.14559909 0.14558971]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.14567252 0.14568352 0.14568622 0.14569998 0.14568343 0.14567549
 0.14568016 0.14567249 0.14566925 0.14565915 0.14565579 0.14566236
 0.14565474 0.14565395 0.1456506  0.14564627 0.14562985 0.1456301
 0.14564051 0.14563147]
[0.5        0.34210526 0.        ]
-----------end of analyzing the loss ratio:75.15651750564575
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc93830b190>
---------------------------------
SparseEpoch: [119][1/398]	Time 0.580	Data 0.000	Loss 1.9097	
SparseEpoch: [119][101/398]	Time 0.580	Data 0.000	Loss 1.6400	
SparseEpoch: [119][201/398]	Time 0.580	Data 0.000	Loss 1.7555	
SparseEpoch: [119][301/398]	Time 0.580	Data 0.000	Loss 2.1040	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.7825	
Epoch(adapt):{0} Loss 0.7337	
Epoch(adapt):{0} Loss 0.6794	
Epoch(adapt):{0} Loss 1.5044	
------------------the total time cost:1165.9654326438904
>>>>>meta updating
Epoch: 0119 | TRAIN: 0.4727 0.6589 0.8409 | 0.3419 0.3419 0.1604 | 0.1281 23.7524 18.8311 0.2991 0.5891 0.7190 ||TEST: 1.1752 0.3975 0.6532 | 0.5297 0.5297 0.2075 | 0.1445 25.6502 20.9395 0.2723 0.5392 0.6698 | 116.4605
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.53173587 0.53170237 0.53168442 0.53172265 0.53176037 0.53164838
 0.53171044 0.53171379 0.53160262 0.53165473 0.5316457  0.5316687
 0.5317781  0.53176975 0.53176357 0.53175023 0.53170541 0.53166824
 0.53167486 0.5316149 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.53173345 0.53166941 0.53165494 0.53167896 0.53166826 0.53168643
 0.53166477 0.53166171 0.53165723 0.53166808 0.53163712 0.53161974
 0.53164935 0.53165104 0.53162428 0.53164298 0.53162377 0.53159875
 0.53160836 0.53160469]
[0.         0.         0.39473684]
-----------end of analyzing the loss ratio:75.23793911933899
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc89df1e7a0>
---------------------------------
SparseEpoch: [120][1/398]	Time 0.578	Data 0.000	Loss 0.8504	
SparseEpoch: [120][101/398]	Time 0.580	Data 0.000	Loss 0.9378	
SparseEpoch: [120][201/398]	Time 0.580	Data 0.000	Loss 0.9820	
SparseEpoch: [120][301/398]	Time 0.580	Data 0.000	Loss 1.2532	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.35163202 0.3514227  0.35124883 0.35122848 0.35131654 0.35125728
 0.35116065 0.35124495 0.35124398 0.35127935 0.35123445 0.3512914
 0.35138259 0.35150729 0.3515295  0.35138989 0.35149688 0.35143168
 0.35154207 0.35150919]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.35128231 0.35130862 0.35130592 0.35130312 0.35128925 0.35129277
 0.35129411 0.35127885 0.35125604 0.35124445 0.35125311 0.35124809
 0.3512326  0.35119364 0.35118164 0.35117879 0.35118532 0.35117709
 0.35117833 0.35118433]
[0.         0.         0.39473684]
-----------end of analyzing the loss ratio:75.1665267944336
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938627970>
---------------------------------
SparseEpoch: [120][1/398]	Time 0.580	Data 0.000	Loss 0.8924	
SparseEpoch: [120][101/398]	Time 0.580	Data 0.000	Loss 1.0152	
SparseEpoch: [120][201/398]	Time 0.580	Data 0.000	Loss 0.6678	
SparseEpoch: [120][301/398]	Time 0.580	Data 0.000	Loss 0.9197	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.13484131 0.13481008 0.13476048 0.13474077 0.13472763 0.13471217
 0.13469217 0.13468226 0.1346726  0.13466712 0.13465559 0.13464128
 0.13463141 0.13460187 0.13456832 0.13455923 0.13455191 0.1345323
 0.13453119 0.13453547]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.13470009 0.13467441 0.13467319 0.13466501 0.13465134 0.13466315
 0.13467692 0.13467359 0.13466988 0.13466467 0.13466869 0.13465666
 0.13463262 0.13463307 0.13462673 0.13461694 0.13462108 0.13461097
 0.13461516 0.13459522]
[0.44736842 0.5        0.        ]
-----------end of analyzing the loss ratio:75.19099545478821
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938d4fa30>
---------------------------------
SparseEpoch: [120][1/398]	Time 0.580	Data 0.000	Loss 2.3718	
SparseEpoch: [120][101/398]	Time 0.581	Data 0.000	Loss 1.5589	
SparseEpoch: [120][201/398]	Time 0.581	Data 0.000	Loss 1.2029	
SparseEpoch: [120][301/398]	Time 0.581	Data 0.000	Loss 1.2858	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.7004	
Epoch(adapt):{0} Loss 0.9020	
Epoch(adapt):{0} Loss 1.1305	
Epoch(adapt):{0} Loss 0.7273	
------------------the total time cost:1166.1891236305237
>>>>>meta updating
Epoch: 0120 | TRAIN: 0.4506 0.6886 0.8561 | 0.3540 0.3540 0.1694 | 0.1265 23.4895 18.3971 0.3065 0.6008 0.7275 ||TEST: 1.1728 0.4048 0.6606 | 0.5327 0.5327 0.2129 | 0.1431 25.4411 20.5715 0.2753 0.5481 0.6781 | 116.2121
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.52291546 0.52292012 0.522895   0.52288799 0.52288084 0.52289546
 0.52289745 0.52287828 0.52286028 0.52286741 0.52286349 0.52284894
 0.52284377 0.52281163 0.52281693 0.52282216 0.52280495 0.52276669
 0.52276266 0.52276986]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.5228196  0.5228191  0.52282714 0.5228345  0.52283672 0.52285962
 0.52286876 0.52286788 0.52284717 0.52285433 0.52285736 0.52283417
 0.52284448 0.52283501 0.52283152 0.52282873 0.52278892 0.5227794
 0.52276738 0.52275479]
[0.         0.44736842 0.5       ]
-----------end of analyzing the loss ratio:75.17729544639587
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938624b50>
---------------------------------
SparseEpoch: [121][1/398]	Time 0.579	Data 0.000	Loss 1.3291	
SparseEpoch: [121][101/398]	Time 0.580	Data 0.000	Loss 1.4879	
SparseEpoch: [121][201/398]	Time 0.580	Data 0.000	Loss 1.2342	
SparseEpoch: [121][301/398]	Time 0.581	Data 0.000	Loss 1.0406	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.40641231 0.4064018  0.40623786 0.40622507 0.40629307 0.40625388
 0.40627344 0.40623986 0.40633848 0.40645712 0.40657234 0.40656137
 0.40658874 0.40662435 0.4065955  0.40653521 0.40655659 0.40659518
 0.40659263 0.40645811]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.40656108 0.40653137 0.40654342 0.40656309 0.40657626 0.40657343
 0.40657713 0.40653621 0.40654308 0.40652575 0.40647904 0.40647513
 0.40638859 0.40639012 0.40643193 0.40643832 0.40642546 0.40642655
 0.40644048 0.40644597]
[0.         0.         0.13157895]
-----------end of analyzing the loss ratio:75.2221155166626
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9385b2320>
---------------------------------
SparseEpoch: [121][1/398]	Time 0.578	Data 0.000	Loss 0.5751	
SparseEpoch: [121][101/398]	Time 0.579	Data 0.000	Loss 0.5295	
SparseEpoch: [121][201/398]	Time 0.579	Data 0.000	Loss 0.5902	
SparseEpoch: [121][301/398]	Time 0.580	Data 0.000	Loss 0.4034	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.13224371 0.13220735 0.13220089 0.1322     0.13222688 0.13223711
 0.13224142 0.13222632 0.13223684 0.13223286 0.13220462 0.13221564
 0.13222945 0.1322188  0.13219236 0.13215229 0.13217067 0.13215894
 0.13215778 0.13216123]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.13221547 0.13221528 0.13220981 0.13221856 0.13221598 0.13221685
 0.13221316 0.13221638 0.13221089 0.13221453 0.1322185  0.13221967
 0.13221638 0.13221971 0.13223557 0.13224408 0.13223968 0.13223661
 0.13223338 0.13224085]
[0.28947368 0.         0.        ]
-----------end of analyzing the loss ratio:75.10590934753418
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938c6ead0>
---------------------------------
SparseEpoch: [121][1/398]	Time 0.578	Data 0.000	Loss 1.2207	
SparseEpoch: [121][101/398]	Time 0.580	Data 0.000	Loss 1.0262	
SparseEpoch: [121][201/398]	Time 0.580	Data 0.000	Loss 0.8050	
SparseEpoch: [121][301/398]	Time 0.580	Data 0.000	Loss 1.8011	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.9200	
Epoch(adapt):{0} Loss 0.8548	
Epoch(adapt):{0} Loss 0.5294	
Epoch(adapt):{0} Loss 0.8014	
------------------the total time cost:1165.872682094574
>>>>>meta updating
Epoch: 0121 | TRAIN: 0.4485 0.6789 0.8566 | 0.3407 0.3407 0.1665 | 0.1254 23.2804 18.0668 0.3138 0.6070 0.7325 ||TEST: 1.1643 0.4088 0.6633 | 0.5275 0.5275 0.2083 | 0.1419 25.1721 20.0656 0.2852 0.5587 0.6849 | 116.4472
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.43339767 0.43341269 0.43340492 0.43342415 0.43341535 0.43337813
 0.43336636 0.43335095 0.43345398 0.43348178 0.43353188 0.43348271
 0.4334009  0.43344978 0.4334692  0.43338567 0.43343447 0.43344458
 0.43342969 0.43344482]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.4335104  0.43353328 0.43352649 0.43354155 0.4335343  0.43354539
 0.43352082 0.43352521 0.43352004 0.4335001  0.43349707 0.43350257
 0.43346665 0.43347587 0.43345793 0.43345417 0.43344065 0.43342895
 0.43341768 0.43343455]
[0.         0.         0.44736842]
-----------end of analyzing the loss ratio:75.32038140296936
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938c6d750>
---------------------------------
SparseEpoch: [122][1/398]	Time 0.578	Data 0.000	Loss 1.5955	
SparseEpoch: [122][101/398]	Time 0.581	Data 0.000	Loss 0.9703	
SparseEpoch: [122][201/398]	Time 0.580	Data 0.000	Loss 0.8332	
SparseEpoch: [122][301/398]	Time 0.580	Data 0.000	Loss 1.0233	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.4070954  0.40702903 0.40704687 0.40711678 0.40712609 0.40710673
 0.40704473 0.40706657 0.40705864 0.40702962 0.40702127 0.40702476
 0.40701935 0.40691346 0.40683557 0.40672327 0.40666918 0.4065601
 0.40647926 0.40645169]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.40704835 0.40703759 0.40706706 0.40707341 0.40707088 0.40706009
 0.40704456 0.40701313 0.4070046  0.40701644 0.40698661 0.40702857
 0.40700414 0.40699376 0.40699075 0.40694694 0.40696305 0.40699013
 0.4069506  0.40695176]
[0.5        0.         0.28947368]
-----------end of analyzing the loss ratio:75.43292832374573
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cca5e402770>
---------------------------------
SparseEpoch: [122][1/398]	Time 0.588	Data 0.000	Loss 1.1301	
SparseEpoch: [122][101/398]	Time 0.581	Data 0.000	Loss 0.8779	
SparseEpoch: [122][201/398]	Time 0.581	Data 0.000	Loss 0.8518	
SparseEpoch: [122][301/398]	Time 0.581	Data 0.000	Loss 1.2031	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11720783 0.11722468 0.11721605 0.1171882  0.11718104 0.11718794
 0.11718537 0.11717123 0.11715807 0.11714251 0.11713042 0.11711878
 0.1171523  0.11714922 0.11713896 0.11712244 0.11710463 0.11711119
 0.11710781 0.11710213]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11719544 0.11718415 0.11715178 0.1171504  0.11715952 0.11715932
 0.11715    0.1171395  0.11714269 0.11713786 0.11713713 0.11716524
 0.11716012 0.11713443 0.11713784 0.11713289 0.11711709 0.11710032
 0.11710325 0.1171003 ]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:75.14953351020813
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9380d94b0>
---------------------------------
SparseEpoch: [122][1/398]	Time 0.579	Data 0.000	Loss 1.2358	
SparseEpoch: [122][101/398]	Time 0.580	Data 0.000	Loss 1.8854	
SparseEpoch: [122][201/398]	Time 0.580	Data 0.000	Loss 1.5635	
SparseEpoch: [122][301/398]	Time 0.580	Data 0.000	Loss 1.7807	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.0220	
Epoch(adapt):{0} Loss 0.7841	
Epoch(adapt):{0} Loss 0.7093	
Epoch(adapt):{0} Loss 0.6744	
------------------the total time cost:1166.748031616211
>>>>>meta updating
Epoch: 0122 | TRAIN: 0.4282 0.7023 0.8635 | 0.3388 0.3388 0.1668 | 0.1231 23.0263 17.7994 0.3185 0.6139 0.7377 ||TEST: 1.1699 0.4095 0.6657 | 0.5258 0.5258 0.2129 | 0.1416 25.1608 20.0742 0.2843 0.5588 0.6859 | 116.5245
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.35715093 0.35716035 0.35712761 0.35711024 0.35713823 0.35703327
 0.35699531 0.35696219 0.35697408 0.3569263  0.35695364 0.35689428
 0.35691143 0.35687755 0.35688013 0.35685572 0.35691618 0.35692696
 0.35689064 0.35678671]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.35694978 0.35695411 0.35694338 0.35694181 0.35694966 0.35693368
 0.35693574 0.35692782 0.3569207  0.35692553 0.356918   0.35690567
 0.35690479 0.35688482 0.3568862  0.35688367 0.35687863 0.35687659
 0.35686893 0.35686723]
[0.  0.5 0.5]
-----------end of analyzing the loss ratio:75.19423484802246
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938a8ccd0>
---------------------------------
SparseEpoch: [123][1/398]	Time 0.587	Data 0.000	Loss 1.4900	
SparseEpoch: [123][101/398]	Time 0.581	Data 0.000	Loss 1.2364	
SparseEpoch: [123][201/398]	Time 0.582	Data 0.000	Loss 1.6267	
SparseEpoch: [123][301/398]	Time 0.581	Data 0.000	Loss 1.8903	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.32699067 0.32694628 0.3268949  0.32687191 0.32674958 0.32666472
 0.32658392 0.32655541 0.32647067 0.3263924  0.32619291 0.32606669
 0.32601833 0.32597374 0.32589217 0.32597506 0.32593909 0.32582299
 0.32578525 0.32565296]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.3262691  0.32626618 0.32626672 0.32626523 0.32627088 0.32627136
 0.32626208 0.32626414 0.32626684 0.32625571 0.3262571  0.32625938
 0.32626104 0.32626917 0.32626165 0.32625837 0.32625632 0.32626411
 0.32626446 0.32625684]
[0.5 0.  0. ]
-----------end of analyzing the loss ratio:75.40052342414856
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cca5e304b80>
---------------------------------
SparseEpoch: [123][1/398]	Time 0.587	Data 0.000	Loss 0.4169	
SparseEpoch: [123][101/398]	Time 0.580	Data 0.000	Loss 0.5466	
SparseEpoch: [123][201/398]	Time 0.579	Data 0.000	Loss 0.6097	
SparseEpoch: [123][301/398]	Time 0.580	Data 0.000	Loss 1.6193	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11216233 0.11216131 0.11214734 0.11213755 0.1121014  0.11208817
 0.11211072 0.11210136 0.11209491 0.1121008  0.11209373 0.11210319
 0.11210137 0.11206897 0.11206293 0.11204822 0.11203701 0.11201944
 0.1120089  0.11201393]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11207072 0.11207447 0.11209531 0.11210782 0.1121062  0.11211649
 0.11211388 0.11211764 0.1121168  0.11210183 0.11210778 0.11210657
 0.11209711 0.11209615 0.1120968  0.11209357 0.11208287 0.11208022
 0.11208942 0.11207272]
[0.44736842 0.         0.        ]
-----------end of analyzing the loss ratio:75.17280697822571
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938d3f400>
---------------------------------
SparseEpoch: [123][1/398]	Time 0.578	Data 0.000	Loss 1.8309	
SparseEpoch: [123][101/398]	Time 0.582	Data 0.000	Loss 1.5347	
SparseEpoch: [123][201/398]	Time 0.581	Data 0.000	Loss 0.9739	
SparseEpoch: [123][301/398]	Time 0.581	Data 0.000	Loss 1.9946	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.8047	
Epoch(adapt):{0} Loss 0.9330	
Epoch(adapt):{0} Loss 0.9939	
Epoch(adapt):{0} Loss 0.8402	
------------------the total time cost:1166.2241265773773
>>>>>meta updating
Epoch: 0123 | TRAIN: 0.4208 0.7053 0.8646 | 0.3219 0.3219 0.1591 | 0.1233 22.9906 17.7590 0.3226 0.6135 0.7370 ||TEST: 1.1987 0.4148 0.6661 | 0.5183 0.5183 0.2101 | 0.1417 25.1277 20.1129 0.2883 0.5572 0.6845 | 116.6457
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.43446168 0.43444999 0.43453029 0.43453718 0.43453641 0.43452599
 0.43454399 0.43458572 0.43460826 0.43464415 0.43464568 0.43471029
 0.434696   0.43472955 0.43475288 0.43461109 0.43464856 0.43461062
 0.43459744 0.43456061]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.43465124 0.4346716  0.4346844  0.43467201 0.43467836 0.43467107
 0.43468291 0.43464994 0.43460225 0.43462237 0.43466745 0.43465619
 0.43464212 0.43456638 0.43453814 0.43458116 0.43455503 0.43453931
 0.43452365 0.43454375]
[0.         0.         0.44736842]
-----------end of analyzing the loss ratio:75.39385271072388
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cca5e356710>
---------------------------------
SparseEpoch: [124][1/398]	Time 0.578	Data 0.000	Loss 0.8993	
SparseEpoch: [124][101/398]	Time 0.580	Data 0.000	Loss 1.9407	
SparseEpoch: [124][201/398]	Time 0.580	Data 0.000	Loss 0.7808	
SparseEpoch: [124][301/398]	Time 0.580	Data 0.000	Loss 0.9766	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.50853869 0.50837562 0.50813866 0.50806447 0.50790434 0.507887
 0.50786722 0.50771304 0.50747889 0.50748529 0.50742294 0.50735351
 0.50728646 0.50724533 0.50726221 0.50704872 0.50689963 0.50677957
 0.50661855 0.50642354]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.50749227 0.50749499 0.50748243 0.50748907 0.50751598 0.5075129
 0.50750667 0.50750139 0.5074967  0.507488   0.50747315 0.50748281
 0.50748818 0.50746902 0.50746259 0.50746717 0.50745785 0.50743613
 0.50744623 0.5074183 ]
[0.5 0.  0.5]
-----------end of analyzing the loss ratio:75.26455807685852
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9389444c0>
---------------------------------
SparseEpoch: [124][1/398]	Time 0.579	Data 0.000	Loss 1.0484	
SparseEpoch: [124][101/398]	Time 0.581	Data 0.000	Loss 1.2353	
SparseEpoch: [124][201/398]	Time 0.581	Data 0.000	Loss 1.2709	
SparseEpoch: [124][301/398]	Time 0.581	Data 0.000	Loss 0.8572	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.14816968 0.14818644 0.14821188 0.14824526 0.14825597 0.14829751
 0.14833096 0.14835749 0.14836014 0.14838219 0.14838704 0.14844402
 0.14845093 0.14844524 0.14848766 0.14849296 0.14850683 0.14849896
 0.14855208 0.14858764]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.1483786  0.14837205 0.14837104 0.1483747  0.14837267 0.14837145
 0.14836793 0.14837352 0.14837577 0.14838004 0.14839228 0.14839526
 0.14839982 0.1483971  0.14839482 0.14840086 0.14839253 0.14840344
 0.14840494 0.1484082 ]
[0. 0. 0.]
-----------end of analyzing the loss ratio:75.21489810943604
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938933bb0>
---------------------------------
SparseEpoch: [124][1/398]	Time 0.578	Data 0.000	Loss 0.9101	
SparseEpoch: [124][101/398]	Time 0.580	Data 0.000	Loss 0.8989	
SparseEpoch: [124][201/398]	Time 0.579	Data 0.000	Loss 2.0811	
SparseEpoch: [124][301/398]	Time 0.579	Data 0.000	Loss 0.8246	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.8047	
Epoch(adapt):{0} Loss 1.6309	
Epoch(adapt):{0} Loss 0.9868	
Epoch(adapt):{0} Loss 0.5880	
------------------the total time cost:1165.2305591106415
>>>>>meta updating
Epoch: 0124 | TRAIN: 0.4276 0.6919 0.8612 | 0.3553 0.3553 0.1621 | 0.1238 23.1396 17.9478 0.3131 0.6107 0.7359 ||TEST: 1.1700 0.3988 0.6624 | 0.5469 0.5469 0.2091 | 0.1410 25.1484 20.2149 0.2826 0.5557 0.6844 | 116.5410
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.37038469 0.37037486 0.37035989 0.37032997 0.37032028 0.37027664
 0.37029363 0.37027157 0.37020902 0.3702186  0.3702306  0.37018318
 0.37013269 0.37009189 0.3701391  0.37012888 0.37018084 0.37016594
 0.37019454 0.37017317]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.37017252 0.3701737  0.37017342 0.37018352 0.37018643 0.37019608
 0.37022762 0.37023456 0.37021873 0.3701958  0.37019612 0.37020304
 0.37021472 0.37021556 0.37021252 0.37022698 0.37020927 0.37021028
 0.37019894 0.37019447]
[0.         0.18421053 0.        ]
-----------end of analyzing the loss ratio:75.26465082168579
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc93881fd00>
---------------------------------
SparseEpoch: [125][1/398]	Time 0.578	Data 0.000	Loss 0.2173	
SparseEpoch: [125][101/398]	Time 0.580	Data 0.000	Loss 1.3077	
SparseEpoch: [125][201/398]	Time 0.580	Data 0.000	Loss 0.8049	
SparseEpoch: [125][301/398]	Time 0.580	Data 0.000	Loss 0.6956	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.41808661 0.41797375 0.41792733 0.4177929  0.41751871 0.41750962
 0.41735281 0.41711834 0.41708101 0.41703148 0.4169396  0.41684962
 0.41669718 0.41666898 0.41658093 0.4163939  0.41641155 0.41630405
 0.4161195  0.41593146]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.41703838 0.41696984 0.41696494 0.41694575 0.41696903 0.41696932
 0.41701767 0.41702351 0.41701404 0.41702709 0.41703882 0.41703186
 0.41703354 0.41700569 0.4170076  0.41699933 0.41698699 0.41703306
 0.41704723 0.41701406]
[0.5 0.  0. ]
-----------end of analyzing the loss ratio:75.4748866558075
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938377e80>
---------------------------------
SparseEpoch: [125][1/398]	Time 0.578	Data 0.000	Loss 0.4831	
SparseEpoch: [125][101/398]	Time 0.581	Data 0.000	Loss 0.5483	
SparseEpoch: [125][201/398]	Time 0.580	Data 0.000	Loss 0.7002	
SparseEpoch: [125][301/398]	Time 0.581	Data 0.000	Loss 0.6162	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.1203698  0.12034032 0.12029021 0.1203193  0.12029318 0.12025678
 0.12017749 0.12017015 0.12016121 0.12016202 0.12011289 0.12009974
 0.12010279 0.12012261 0.12010422 0.12007582 0.1200613  0.12008502
 0.12002946 0.11999856]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.12022954 0.1201707  0.12016149 0.12015736 0.12015657 0.12013665
 0.12014819 0.12014719 0.12017171 0.12015079 0.12012144 0.12012372
 0.12012007 0.12012468 0.12013554 0.12010922 0.12014276 0.12013873
 0.12014539 0.12013676]
[0.5        0.28947368 0.        ]
-----------end of analyzing the loss ratio:75.09339594841003
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9383d06d0>
---------------------------------
SparseEpoch: [125][1/398]	Time 0.578	Data 0.000	Loss 1.4274	
SparseEpoch: [125][101/398]	Time 0.581	Data 0.000	Loss 2.0273	
SparseEpoch: [125][201/398]	Time 0.580	Data 0.000	Loss 0.9701	
SparseEpoch: [125][301/398]	Time 0.581	Data 0.000	Loss 1.7901	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.6506	
Epoch(adapt):{0} Loss 0.8461	
Epoch(adapt):{0} Loss 0.8642	
Epoch(adapt):{0} Loss 0.7204	
------------------the total time cost:1165.8366310596466
>>>>>meta updating
Epoch: 0125 | TRAIN: 0.4189 0.7004 0.8647 | 0.3309 0.3309 0.1663 | 0.1262 23.5302 18.5429 0.3026 0.5956 0.7253 ||TEST: 1.2096 0.4050 0.6647 | 0.5215 0.5215 0.2106 | 0.1435 25.5268 20.8009 0.2736 0.5430 0.6732 | 116.5230
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.4783623  0.47838337 0.47838131 0.47832363 0.47838936 0.47839695
 0.47835824 0.4783252  0.47828566 0.47836537 0.47831137 0.47826393
 0.47829841 0.47825539 0.47825612 0.47813176 0.47809441 0.47800048
 0.47796706 0.47791606]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.47839311 0.47835142 0.47838565 0.47836937 0.47838857 0.47838224
 0.47837197 0.47835106 0.47832554 0.47831327 0.47824793 0.47826172
 0.47827906 0.47828419 0.47830268 0.4782604  0.47827339 0.47828105
 0.47826587 0.47824966]
[0.         0.5        0.02631579]
-----------end of analyzing the loss ratio:75.59725737571716
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc93866a470>
---------------------------------
SparseEpoch: [126][1/398]	Time 0.579	Data 0.000	Loss 0.4437	
SparseEpoch: [126][101/398]	Time 0.581	Data 0.000	Loss 0.5901	
SparseEpoch: [126][201/398]	Time 0.581	Data 0.000	Loss 0.8973	
SparseEpoch: [126][301/398]	Time 0.580	Data 0.000	Loss 0.6770	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.31209942 0.31210534 0.31206715 0.31209268 0.31208612 0.3120483
 0.31206715 0.31209015 0.31206861 0.31207349 0.31206659 0.31201169
 0.3120317  0.31200473 0.31203586 0.31206662 0.31209275 0.31208346
 0.31205729 0.31205219]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.31208929 0.31208815 0.31211597 0.31211011 0.31208003 0.31208222
 0.31208839 0.3120784  0.3120791  0.31208974 0.31208457 0.31206175
 0.31205453 0.31204735 0.31202877 0.3120212  0.31202497 0.31200752
 0.31203876 0.31203154]
[0.18421053 0.         0.39473684]
-----------end of analyzing the loss ratio:75.27996563911438
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9386c9780>
---------------------------------
SparseEpoch: [126][1/398]	Time 0.589	Data 0.000	Loss 0.6527	
SparseEpoch: [126][101/398]	Time 0.581	Data 0.000	Loss 0.9070	
SparseEpoch: [126][201/398]	Time 0.581	Data 0.000	Loss 0.6016	
SparseEpoch: [126][301/398]	Time 0.581	Data 0.000	Loss 0.9645	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.13046533 0.13047633 0.13047283 0.13049248 0.13048946 0.13048968
 0.1305037  0.13048471 0.1304603  0.13044687 0.13046012 0.13046083
 0.13042945 0.13041225 0.13042066 0.13042946 0.1304372  0.13043077
 0.13045987 0.13044623]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.13045893 0.13044788 0.13045617 0.13047912 0.13046775 0.13047827
 0.13047527 0.13046836 0.13046658 0.13044289 0.13046592 0.13044882
 0.13045219 0.13043582 0.13042529 0.13042935 0.13042426 0.13042351
 0.13042682 0.13043543]
[0.18421053 0.39473684 0.        ]
-----------end of analyzing the loss ratio:75.15860748291016
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938e00460>
---------------------------------
SparseEpoch: [126][1/398]	Time 0.578	Data 0.000	Loss 0.9398	
SparseEpoch: [126][101/398]	Time 0.581	Data 0.000	Loss 1.5915	
SparseEpoch: [126][201/398]	Time 0.581	Data 0.000	Loss 1.3640	
SparseEpoch: [126][301/398]	Time 0.580	Data 0.000	Loss 2.2250	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.6959	
Epoch(adapt):{0} Loss 0.6370	
Epoch(adapt):{0} Loss 1.2143	
Epoch(adapt):{0} Loss 0.5914	
------------------the total time cost:1166.265756368637
>>>>>meta updating
Epoch: 0126 | TRAIN: 0.4293 0.6940 0.8600 | 0.3170 0.3170 0.1519 | 0.1244 23.2299 18.0828 0.3110 0.6079 0.7340 ||TEST: 1.2017 0.4030 0.6619 | 0.5206 0.5206 0.2058 | 0.1432 25.4247 20.5514 0.2765 0.5488 0.6791 | 116.4258
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.4403137  0.44033695 0.44035798 0.44032072 0.44033442 0.44029774
 0.44029435 0.44031274 0.44024167 0.44026299 0.44031912 0.44036284
 0.44036277 0.44035358 0.44032869 0.4403659  0.44039575 0.44038304
 0.44033311 0.44035019]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.44023053 0.44025079 0.44026231 0.44029556 0.440286   0.44027948
 0.44028783 0.44029564 0.44027842 0.44029912 0.44030363 0.44037289
 0.44037351 0.44038394 0.44038798 0.44039887 0.44042669 0.44043109
 0.44044634 0.44043425]
[0. 0. 0.]
-----------end of analyzing the loss ratio:75.18656945228577
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9388378b0>
---------------------------------
SparseEpoch: [127][1/398]	Time 0.578	Data 0.000	Loss 0.4918	
SparseEpoch: [127][101/398]	Time 0.578	Data 0.000	Loss 0.4305	
SparseEpoch: [127][201/398]	Time 0.579	Data 0.000	Loss 0.5202	
SparseEpoch: [127][301/398]	Time 0.579	Data 0.000	Loss 0.6926	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.37167512 0.37159315 0.37157624 0.37160175 0.37163261 0.37140387
 0.3713303  0.37128018 0.37123911 0.37113678 0.37113463 0.37107498
 0.37102221 0.37089452 0.37079483 0.37083724 0.37074163 0.37077044
 0.37077965 0.37065388]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.37114667 0.37114976 0.37115513 0.37115024 0.37114688 0.37114416
 0.37114324 0.37114655 0.37114048 0.37111941 0.37111214 0.37111304
 0.37113037 0.37113512 0.37113886 0.37113971 0.37114203 0.37113758
 0.3711184  0.37111899]
[0.5        0.         0.02631579]
-----------end of analyzing the loss ratio:75.36357045173645
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938b6b820>
---------------------------------
SparseEpoch: [127][1/398]	Time 0.579	Data 0.000	Loss 0.3106	
SparseEpoch: [127][101/398]	Time 0.580	Data 0.000	Loss 0.7227	
SparseEpoch: [127][201/398]	Time 0.580	Data 0.000	Loss 0.5994	
SparseEpoch: [127][301/398]	Time 0.581	Data 0.000	Loss 0.8107	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.12685244 0.12686012 0.12684696 0.12681577 0.12678235 0.12678425
 0.12677335 0.12676309 0.12675732 0.12676114 0.12675766 0.12675752
 0.12670563 0.12669665 0.12672151 0.1267181  0.126715   0.12669808
 0.12667685 0.12666321]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.12678061 0.12676923 0.12677194 0.12675514 0.12676309 0.12674314
 0.12675665 0.12676094 0.12674742 0.12675479 0.1267606  0.12676696
 0.12675254 0.12675983 0.12674554 0.12672836 0.12673956 0.12672696
 0.12673044 0.12675044]
[0.5        0.39473684 0.        ]
-----------end of analyzing the loss ratio:75.47862482070923
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc93881fc10>
---------------------------------
SparseEpoch: [127][1/398]	Time 0.578	Data 0.000	Loss 1.8420	
SparseEpoch: [127][101/398]	Time 0.580	Data 0.000	Loss 1.2509	
SparseEpoch: [127][201/398]	Time 0.581	Data 0.000	Loss 2.4406	
SparseEpoch: [127][301/398]	Time 0.581	Data 0.000	Loss 1.8580	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.9542	
Epoch(adapt):{0} Loss 0.9080	
Epoch(adapt):{0} Loss 0.9232	
Epoch(adapt):{0} Loss 0.7503	
------------------the total time cost:1166.4951014518738
>>>>>meta updating
Epoch: 0127 | TRAIN: 0.4087 0.7064 0.8675 | 0.3455 0.3455 0.1592 | 0.1245 23.3237 18.2754 0.3062 0.6030 0.7308 ||TEST: 1.1565 0.4081 0.6701 | 0.5490 0.5490 0.2108 | 0.1434 25.5220 20.7989 0.2727 0.5433 0.6747 | 116.6686
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.40679923 0.40679009 0.40681574 0.40683591 0.40681533 0.40688117
 0.4068795  0.40682217 0.40681032 0.40675561 0.4067992  0.40674821
 0.40677608 0.40673365 0.40680822 0.40681677 0.4068349  0.40689111
 0.40691788 0.40692791]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.40676657 0.40677333 0.40676845 0.40675413 0.40675861 0.40674186
 0.40676198 0.40673286 0.40672715 0.4067209  0.40674654 0.40674573
 0.40673552 0.40672106 0.40676757 0.40677395 0.40677163 0.40677576
 0.40677933 0.40678845]
[0.         0.18421053 0.        ]
-----------end of analyzing the loss ratio:75.22689604759216
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938d4f400>
---------------------------------
SparseEpoch: [128][1/398]	Time 0.579	Data 0.000	Loss 0.2593	
SparseEpoch: [128][101/398]	Time 0.580	Data 0.000	Loss 0.4062	
SparseEpoch: [128][201/398]	Time 0.581	Data 0.000	Loss 0.2926	
SparseEpoch: [128][301/398]	Time 0.580	Data 0.000	Loss 0.6710	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.37668893 0.37666439 0.37662758 0.37671224 0.37676638 0.37681289
 0.37682458 0.37678856 0.37666915 0.37667548 0.37671482 0.37667304
 0.3767673  0.37686082 0.3768157  0.37689461 0.37693725 0.3769321
 0.37696041 0.37695746]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.37673718 0.3767379  0.37672217 0.37673031 0.37674062 0.37673429
 0.37672837 0.37671886 0.37670637 0.37670755 0.37669092 0.37667517
 0.37666887 0.37667667 0.37667541 0.37669345 0.37668973 0.37668298
 0.37666518 0.37666116]
[0.  0.  0.5]
-----------end of analyzing the loss ratio:75.57608222961426
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938de8ac0>
---------------------------------
SparseEpoch: [128][1/398]	Time 0.578	Data 0.000	Loss 0.8772	
SparseEpoch: [128][101/398]	Time 0.579	Data 0.000	Loss 0.8085	
SparseEpoch: [128][201/398]	Time 0.579	Data 0.000	Loss 0.6815	
SparseEpoch: [128][301/398]	Time 0.579	Data 0.000	Loss 0.9591	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.13850639 0.13851723 0.13851653 0.13850238 0.1385075  0.13850669
 0.13849497 0.13847761 0.13846387 0.13845249 0.13844936 0.13846433
 0.1384699  0.13846312 0.13847269 0.13846396 0.13846753 0.13847983
 0.13848381 0.13849086]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.13849788 0.13849072 0.13848823 0.13847829 0.13847766 0.13846843
 0.13846931 0.13846152 0.1384637  0.13845083 0.13845205 0.13845947
 0.13846535 0.13847113 0.13847758 0.13845958 0.13846269 0.13846425
 0.1384748  0.13848775]
[0.02631579 0.         0.        ]
-----------end of analyzing the loss ratio:75.45799326896667
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938e5aa40>
---------------------------------
SparseEpoch: [128][1/398]	Time 0.580	Data 0.000	Loss 0.9554	
SparseEpoch: [128][101/398]	Time 0.581	Data 0.000	Loss 1.1307	
SparseEpoch: [128][201/398]	Time 0.580	Data 0.000	Loss 1.0095	
SparseEpoch: [128][301/398]	Time 0.580	Data 0.000	Loss 1.0712	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.7869	
Epoch(adapt):{0} Loss 0.7436	
Epoch(adapt):{0} Loss 0.7385	
Epoch(adapt):{0} Loss 0.9513	
------------------the total time cost:1166.6008310317993
>>>>>meta updating
Epoch: 0128 | TRAIN: 0.4152 0.7052 0.8663 | 0.3372 0.3372 0.1562 | 0.1227 23.0257 17.8975 0.3165 0.6125 0.7372 ||TEST: 1.1870 0.4067 0.6642 | 0.5392 0.5392 0.2095 | 0.1426 25.3625 20.5023 0.2774 0.5495 0.6799 | 116.1050
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.47736984 0.47736185 0.47737075 0.47738229 0.47738682 0.47745776
 0.47744995 0.47746164 0.47751413 0.47755637 0.47753232 0.47754108
 0.47756503 0.47755829 0.47752655 0.47751388 0.47756612 0.47757485
 0.47755197 0.47756618]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.47758415 0.47758405 0.47757861 0.47758378 0.4775941  0.47757505
 0.47756078 0.47753889 0.47753875 0.47752991 0.47753519 0.47753929
 0.47755297 0.4775433  0.47753648 0.47752987 0.47753331 0.47753289
 0.47753101 0.47751759]
[0.  0.  0.5]
-----------end of analyzing the loss ratio:75.62016177177429
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938a8ef50>
---------------------------------
SparseEpoch: [129][1/398]	Time 0.580	Data 0.000	Loss 0.9222	
SparseEpoch: [129][101/398]	Time 0.580	Data 0.000	Loss 1.3796	
SparseEpoch: [129][201/398]	Time 0.580	Data 0.000	Loss 1.3397	
SparseEpoch: [129][301/398]	Time 0.580	Data 0.000	Loss 1.5186	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.34238166 0.34246716 0.34237693 0.34237747 0.34230845 0.34234452
 0.3422058  0.34214699 0.34212087 0.34197678 0.34197843 0.34198765
 0.34193958 0.3418871  0.34181196 0.34174874 0.34166342 0.34166555
 0.34171558 0.3416291 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.34194424 0.34195115 0.34194669 0.34194154 0.34194273 0.34194188
 0.34194586 0.34195638 0.34195538 0.34196066 0.34196035 0.34195698
 0.3419638  0.34196324 0.34197271 0.34196588 0.34197455 0.34197144
 0.34196687 0.34197734]
[0.5 0.  0. ]
-----------end of analyzing the loss ratio:75.46875882148743
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938b6a230>
---------------------------------
SparseEpoch: [129][1/398]	Time 0.582	Data 0.000	Loss 0.7037	
SparseEpoch: [129][101/398]	Time 0.581	Data 0.000	Loss 0.3705	
SparseEpoch: [129][201/398]	Time 0.581	Data 0.000	Loss 0.6132	
SparseEpoch: [129][301/398]	Time 0.580	Data 0.000	Loss 0.6185	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.12477977 0.12476054 0.12472996 0.12470452 0.12466173 0.12460662
 0.12457696 0.12456709 0.12455901 0.12456473 0.12455139 0.12456241
 0.12454693 0.12456428 0.12457521 0.12452496 0.12449419 0.12446983
 0.1244364  0.12437435]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.12455323 0.12454254 0.12455462 0.1245751  0.12456108 0.12455387
 0.12455074 0.1245573  0.12455522 0.12454383 0.12454397 0.1245589
 0.12454845 0.12456609 0.1245704  0.12457083 0.12455077 0.12455207
 0.12454264 0.12453142]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:75.1865906715393
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938778ac0>
---------------------------------
SparseEpoch: [129][1/398]	Time 0.579	Data 0.000	Loss 1.2770	
SparseEpoch: [129][101/398]	Time 0.581	Data 0.000	Loss 2.7036	
SparseEpoch: [129][201/398]	Time 0.581	Data 0.000	Loss 1.8075	
SparseEpoch: [129][301/398]	Time 0.581	Data 0.000	Loss 2.2182	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.7293	
Epoch(adapt):{0} Loss 0.7083	
Epoch(adapt):{0} Loss 0.8513	
Epoch(adapt):{0} Loss 0.9239	
------------------the total time cost:1166.3082585334778
>>>>>meta updating
Epoch: 0129 | TRAIN: 0.4251 0.6931 0.8603 | 0.3250 0.3250 0.1564 | 0.1216 22.7960 17.5437 0.3254 0.6201 0.7429 ||TEST: 1.2076 0.4155 0.6634 | 0.5213 0.5213 0.2073 | 0.1419 25.1639 20.1079 0.2857 0.5579 0.6854 | 116.5645
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.39136567 0.39132597 0.39132112 0.39128129 0.3913074  0.39125467
 0.39123134 0.39124552 0.39121171 0.3912203  0.39123634 0.39122776
 0.3912282  0.39121788 0.39112462 0.39109904 0.39106728 0.39104678
 0.39102036 0.39098742]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.39115819 0.39116177 0.39121321 0.39123106 0.39122803 0.39122327
 0.3912091  0.39123903 0.39122002 0.39121654 0.39122818 0.39122995
 0.39124744 0.39124481 0.39125368 0.39127348 0.39125707 0.39122168
 0.39125558 0.39124807]
[0.  0.5 0. ]
-----------end of analyzing the loss ratio:75.35869288444519
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9380d85b0>
---------------------------------
SparseEpoch: [130][1/398]	Time 0.578	Data 0.000	Loss 0.6695	
SparseEpoch: [130][101/398]	Time 0.579	Data 0.000	Loss 0.8906	
SparseEpoch: [130][201/398]	Time 0.580	Data 0.000	Loss 0.4595	
SparseEpoch: [130][301/398]	Time 0.580	Data 0.000	Loss 0.7219	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.41788435 0.41792863 0.4179914  0.41797411 0.41791854 0.4179201
 0.41799088 0.41807876 0.41815412 0.418123   0.41821747 0.41831657
 0.41838293 0.41840914 0.41830393 0.41830783 0.41835604 0.41836671
 0.41837638 0.41834722]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.41816805 0.41816258 0.41813689 0.41812716 0.41814311 0.41814192
 0.41815468 0.41816295 0.41814282 0.41816493 0.41816968 0.41817187
 0.41817383 0.41817906 0.4181667  0.41817537 0.41817727 0.41817942
 0.41818501 0.41818049]
[0. 0. 0.]
-----------end of analyzing the loss ratio:75.77655243873596
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9386cbc70>
---------------------------------
SparseEpoch: [130][1/398]	Time 0.577	Data 0.000	Loss 0.5431	
SparseEpoch: [130][101/398]	Time 0.579	Data 0.000	Loss 0.3926	
SparseEpoch: [130][201/398]	Time 0.579	Data 0.000	Loss 0.3209	
SparseEpoch: [130][301/398]	Time 0.579	Data 0.000	Loss 0.3088	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.12915242 0.12903816 0.12894708 0.12884735 0.1287746  0.1286498
 0.12849011 0.12838764 0.12829738 0.1282355  0.12817543 0.12812519
 0.12807278 0.12800966 0.12793568 0.12781332 0.12771813 0.12766372
 0.12755593 0.12752754]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.12864035 0.12859043 0.12852784 0.12847952 0.12838086 0.12833893
 0.12830702 0.12827831 0.12824805 0.12822768 0.12821426 0.1281564
 0.128146   0.12816468 0.12814377 0.12809315 0.12811215 0.12808557
 0.12804881 0.12800047]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:75.48038220405579
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc93882f5e0>
---------------------------------
SparseEpoch: [130][1/398]	Time 0.579	Data 0.000	Loss 1.3616	
SparseEpoch: [130][101/398]	Time 0.581	Data 0.000	Loss 1.0012	
SparseEpoch: [130][201/398]	Time 0.581	Data 0.000	Loss 1.6654	
SparseEpoch: [130][301/398]	Time 0.581	Data 0.000	Loss 1.8584	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.8086	
Epoch(adapt):{0} Loss 0.7096	
Epoch(adapt):{0} Loss 0.7548	
Epoch(adapt):{0} Loss 0.9986	
------------------the total time cost:1166.5133950710297
>>>>>meta updating
Epoch: 0130 | TRAIN: 0.4476 0.6729 0.8508 | 0.3422 0.3422 0.1546 | 0.1241 23.3543 18.5213 0.3025 0.5985 0.7292 ||TEST: 1.1949 0.3975 0.6567 | 0.5367 0.5367 0.2061 | 0.1438 25.5669 20.8975 0.2732 0.5406 0.6720 | 116.5779
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.43664193 0.43649586 0.43644619 0.43641066 0.4364088  0.43642542
 0.43648272 0.43646183 0.43654372 0.43650747 0.43645906 0.43633233
 0.43629624 0.43620543 0.4359981  0.43595537 0.43589922 0.43587773
 0.4358555  0.43585848]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.43646825 0.43645344 0.43647945 0.43646687 0.43646318 0.43648332
 0.43648135 0.43647275 0.4364807  0.43645806 0.43640866 0.43641339
 0.43645361 0.43645768 0.43644676 0.4364452  0.43641518 0.43641441
 0.43638225 0.43637139]
[0.         0.44736842 0.5       ]
-----------end of analyzing the loss ratio:75.29348111152649
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc93822f880>
---------------------------------
SparseEpoch: [131][1/398]	Time 0.579	Data 0.000	Loss 1.3469	
SparseEpoch: [131][101/398]	Time 0.581	Data 0.000	Loss 1.4021	
SparseEpoch: [131][201/398]	Time 0.581	Data 0.000	Loss 1.3977	
SparseEpoch: [131][301/398]	Time 0.581	Data 0.000	Loss 1.2240	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.31609795 0.31612657 0.31614226 0.31617008 0.31616952 0.31618578
 0.3161897  0.31617668 0.31623049 0.31627995 0.31626538 0.31621868
 0.31619921 0.31620194 0.31618982 0.31623921 0.31627391 0.31626032
 0.31628691 0.31629705]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.31629444 0.31628505 0.31629666 0.31630176 0.31627985 0.31630864
 0.31630196 0.31630464 0.31628732 0.31627759 0.31628562 0.31624126
 0.3162404  0.31623253 0.31620301 0.31617936 0.31619406 0.31617601
 0.31618896 0.31618792]
[0.         0.         0.39473684]
-----------end of analyzing the loss ratio:75.29879188537598
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9383755a0>
---------------------------------
SparseEpoch: [131][1/398]	Time 0.578	Data 0.000	Loss 0.6776	
SparseEpoch: [131][101/398]	Time 0.579	Data 0.000	Loss 0.8830	
SparseEpoch: [131][201/398]	Time 0.579	Data 0.000	Loss 0.7235	
SparseEpoch: [131][301/398]	Time 0.580	Data 0.000	Loss 0.8018	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.12776169 0.12775159 0.12775182 0.12775093 0.1277608  0.12774494
 0.12775284 0.12776314 0.12777462 0.1277779  0.12777335 0.12777858
 0.12777078 0.12775708 0.12776123 0.1277703  0.1277725  0.12775959
 0.12777731 0.12775388]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.12773752 0.12774881 0.12773885 0.12772331 0.12771976 0.12773418
 0.12774608 0.12776564 0.12777187 0.1277783  0.12776019 0.12777041
 0.12778113 0.12778164 0.12777739 0.12776985 0.12779174 0.12777725
 0.12778178 0.12777467]
[0. 0. 0.]
-----------end of analyzing the loss ratio:75.35059762001038
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938508670>
---------------------------------
SparseEpoch: [131][1/398]	Time 0.578	Data 0.000	Loss 0.8960	
SparseEpoch: [131][101/398]	Time 0.579	Data 0.000	Loss 1.5486	
SparseEpoch: [131][201/398]	Time 0.580	Data 0.000	Loss 0.9294	
SparseEpoch: [131][301/398]	Time 0.580	Data 0.000	Loss 1.8075	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.7647	
Epoch(adapt):{0} Loss 1.0621	
Epoch(adapt):{0} Loss 0.6115	
Epoch(adapt):{0} Loss 1.1458	
------------------the total time cost:1167.078057050705
>>>>>meta updating
Epoch: 0131 | TRAIN: 0.4187 0.7055 0.8637 | 0.3405 0.3405 0.1522 | 0.1216 22.9850 17.9118 0.3116 0.6129 0.7396 ||TEST: 1.1950 0.4038 0.6584 | 0.5472 0.5472 0.2099 | 0.1415 25.3047 20.4263 0.2755 0.5512 0.6813 | 116.7045
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.52398357 0.52397524 0.5238796  0.52395799 0.52404264 0.52410933
 0.52411579 0.52421585 0.52425246 0.52424367 0.5243055  0.52432637
 0.52429871 0.52435309 0.52434312 0.52436419 0.52443324 0.52450999
 0.52454099 0.52447039]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.52422918 0.52422259 0.52421153 0.52421133 0.52420959 0.52423542
 0.52423088 0.52423482 0.52422825 0.52423539 0.52423475 0.52425361
 0.52423428 0.5242479  0.52427153 0.5242768  0.52425799 0.52426893
 0.52426772 0.52427524]
[0. 0. 0.]
-----------end of analyzing the loss ratio:75.31988477706909
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938dd91b0>
---------------------------------
SparseEpoch: [132][1/398]	Time 0.577	Data 0.000	Loss 0.2573	
SparseEpoch: [132][101/398]	Time 0.579	Data 0.000	Loss 0.4349	
SparseEpoch: [132][201/398]	Time 0.579	Data 0.000	Loss 0.5243	
SparseEpoch: [132][301/398]	Time 0.580	Data 0.000	Loss 0.2859	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.3840946  0.38417941 0.38428982 0.38430284 0.38432267 0.38434714
 0.38438145 0.38436001 0.38430228 0.38433879 0.38431081 0.38432563
 0.38427093 0.38424657 0.38422846 0.38423369 0.38416486 0.3841494
 0.38418931 0.38416465]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.38430218 0.38431355 0.3843262  0.38432055 0.38431151 0.38431881
 0.38433747 0.38434605 0.38434152 0.38432508 0.38431033 0.38432201
 0.38432254 0.3843382  0.38433225 0.38432869 0.38432737 0.38431794
 0.3843094  0.38432159]
[0. 0. 0.]
-----------end of analyzing the loss ratio:75.18047904968262
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9384a4640>
---------------------------------
SparseEpoch: [132][1/398]	Time 0.578	Data 0.000	Loss 0.2593	
SparseEpoch: [132][101/398]	Time 0.580	Data 0.000	Loss 0.4439	
SparseEpoch: [132][201/398]	Time 0.579	Data 0.000	Loss 0.2407	
SparseEpoch: [132][301/398]	Time 0.579	Data 0.000	Loss 0.3115	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11994345 0.11995209 0.11994634 0.1199677  0.11996795 0.11998146
 0.11996933 0.11998012 0.11997073 0.11997336 0.11996594 0.11996871
 0.1199651  0.11996434 0.11995759 0.11994579 0.11995055 0.11996647
 0.11998175 0.11998769]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11995354 0.11996059 0.11995676 0.11995878 0.11997063 0.11997085
 0.11996788 0.11997566 0.11996996 0.11996751 0.11996489 0.11998401
 0.11998652 0.11997383 0.11997319 0.11997197 0.11998203 0.11999742
 0.1199917  0.11999525]
[0. 0. 0.]
-----------end of analyzing the loss ratio:75.19264483451843
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9388c7910>
---------------------------------
SparseEpoch: [132][1/398]	Time 0.577	Data 0.000	Loss 0.8228	
SparseEpoch: [132][101/398]	Time 0.579	Data 0.000	Loss 1.1339	
SparseEpoch: [132][201/398]	Time 0.579	Data 0.000	Loss 1.2024	
SparseEpoch: [132][301/398]	Time 0.579	Data 0.000	Loss 1.0081	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.8814	
Epoch(adapt):{0} Loss 0.7407	
Epoch(adapt):{0} Loss 0.9568	
Epoch(adapt):{0} Loss 1.4465	
------------------the total time cost:1163.8039782047272
>>>>>meta updating
Epoch: 0132 | TRAIN: 0.4273 0.6964 0.8604 | 0.3303 0.3303 0.1578 | 0.1244 23.4843 18.7114 0.2947 0.5948 0.7272 ||TEST: 1.1681 0.4032 0.6630 | 0.5271 0.5271 0.2111 | 0.1445 25.7875 21.2596 0.2631 0.5335 0.6666 | 116.8509
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.4197877  0.41984186 0.4198274  0.41988128 0.41984875 0.41980114
 0.41979012 0.41981074 0.41976798 0.41981186 0.4198167  0.41988236
 0.41981456 0.41983541 0.41991801 0.41990475 0.41990782 0.41994211
 0.41997737 0.41994401]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.41975904 0.41976933 0.41977188 0.41979055 0.41978681 0.4197768
 0.41981274 0.41981638 0.41983702 0.41983107 0.41981886 0.41981667
 0.41982238 0.41982039 0.41981157 0.41980575 0.41981158 0.41981857
 0.41980224 0.41981918]
[0. 0. 0.]
-----------end of analyzing the loss ratio:75.27107787132263
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc93901f1c0>
---------------------------------
SparseEpoch: [133][1/398]	Time 0.577	Data 0.000	Loss 0.3766	
SparseEpoch: [133][101/398]	Time 0.579	Data 0.000	Loss 0.3824	
SparseEpoch: [133][201/398]	Time 0.580	Data 0.000	Loss 0.6752	
SparseEpoch: [133][301/398]	Time 0.579	Data 0.000	Loss 0.5374	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.62536004 0.625454   0.62548711 0.62563897 0.62565132 0.62569162
 0.6257242  0.6258512  0.62601839 0.62615103 0.6261878  0.62632302
 0.62640763 0.62640915 0.62650174 0.62651811 0.62659523 0.62677669
 0.62688687 0.6270995 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.62621002 0.62621844 0.62622667 0.6262248  0.62620375 0.62617435
 0.62616076 0.6261467  0.62612855 0.62613567 0.62611496 0.62615345
 0.62616    0.62616002 0.62615535 0.62614851 0.62612905 0.62614355
 0.62614215 0.62614316]
[0.         0.         0.02631579]
-----------end of analyzing the loss ratio:75.2953884601593
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9382c5690>
---------------------------------
SparseEpoch: [133][1/398]	Time 0.577	Data 0.000	Loss 0.4565	
SparseEpoch: [133][101/398]	Time 0.580	Data 0.000	Loss 0.2573	
SparseEpoch: [133][201/398]	Time 0.580	Data 0.000	Loss 0.3083	
SparseEpoch: [133][301/398]	Time 0.580	Data 0.000	Loss 0.2996	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.13972269 0.13969524 0.13962156 0.13954633 0.13947271 0.13934842
 0.13927528 0.13921213 0.1391265  0.13908181 0.1390538  0.13897881
 0.13888726 0.13884495 0.13879529 0.13866344 0.13859676 0.13852188
 0.13838339 0.13828558]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.13926947 0.13922901 0.13920194 0.13917559 0.13917282 0.13918205
 0.1391601  0.13910154 0.13911039 0.13907844 0.13907709 0.13904177
 0.13904188 0.13902181 0.13900245 0.13894162 0.13891943 0.13888102
 0.13884041 0.13881399]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:75.48176455497742
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938dd8040>
---------------------------------
SparseEpoch: [133][1/398]	Time 0.589	Data 0.000	Loss 1.4175	
SparseEpoch: [133][101/398]	Time 0.581	Data 0.000	Loss 1.4669	
SparseEpoch: [133][201/398]	Time 0.581	Data 0.000	Loss 2.9870	
SparseEpoch: [133][301/398]	Time 0.580	Data 0.000	Loss 1.3573	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.6065	
Epoch(adapt):{0} Loss 0.6993	
Epoch(adapt):{0} Loss 0.6267	
Epoch(adapt):{0} Loss 0.6069	
------------------the total time cost:1165.64670920372
>>>>>meta updating
Epoch: 0133 | TRAIN: 0.4087 0.7031 0.8653 | 0.3179 0.3179 0.1540 | 0.1225 23.0683 18.0329 0.3105 0.6116 0.7382 ||TEST: 1.2113 0.4015 0.6602 | 0.5228 0.5228 0.2082 | 0.1429 25.4113 20.6086 0.2767 0.5474 0.6782 | 116.4969
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.36680628 0.36680834 0.36681857 0.36684024 0.36678478 0.36679663
 0.36672412 0.36675026 0.36675057 0.36671522 0.36675444 0.36678009
 0.36681268 0.36676531 0.36677341 0.36677985 0.3667999  0.36681951
 0.3667845  0.36678224]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.36682526 0.36680975 0.36681391 0.36679278 0.36680345 0.36680564
 0.36678818 0.36677869 0.36673998 0.36672259 0.36670494 0.36671738
 0.3667251  0.36671276 0.36672227 0.3667202  0.36672344 0.36672346
 0.36673088 0.36671994]
[0.         0.         0.02631579]
-----------end of analyzing the loss ratio:75.37772583961487
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938792770>
---------------------------------
SparseEpoch: [134][1/398]	Time 0.582	Data 0.000	Loss 0.2987	
SparseEpoch: [134][101/398]	Time 0.580	Data 0.000	Loss 0.3357	
SparseEpoch: [134][201/398]	Time 0.580	Data 0.000	Loss 0.6111	
SparseEpoch: [134][301/398]	Time 0.580	Data 0.000	Loss 0.7047	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.30686869 0.30682965 0.30670801 0.30663522 0.30654588 0.30642958
 0.30635701 0.30628938 0.3062349  0.30622505 0.30601033 0.30594674
 0.30600185 0.30599961 0.30596043 0.30589692 0.30589639 0.30585903
 0.30571014 0.30555283]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.30619633 0.30620105 0.3061988  0.30617838 0.3061544  0.30614887
 0.3061029  0.30611539 0.30610126 0.30610293 0.30609546 0.30607179
 0.30607307 0.30605352 0.306061   0.30605    0.30604031 0.3060301
 0.30602968 0.30602577]
[0.5 0.  0.5]
-----------end of analyzing the loss ratio:75.30261039733887
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938c43040>
---------------------------------
SparseEpoch: [134][1/398]	Time 0.579	Data 0.000	Loss 1.0035	
SparseEpoch: [134][101/398]	Time 0.580	Data 0.000	Loss 0.7233	
SparseEpoch: [134][201/398]	Time 0.580	Data 0.000	Loss 0.9339	
SparseEpoch: [134][301/398]	Time 0.580	Data 0.000	Loss 1.3202	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.12335885 0.12334635 0.12331906 0.12331298 0.12331207 0.12328597
 0.12330412 0.1232884  0.12329314 0.12327634 0.12330164 0.12331352
 0.12330065 0.12329752 0.12328753 0.12328877 0.12330422 0.12330387
 0.12332085 0.12331131]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.12329581 0.12329743 0.12329451 0.12329633 0.12328199 0.12327409
 0.12327037 0.12327421 0.12327616 0.1232906  0.12329154 0.12329338
 0.1233074  0.12330825 0.12331455 0.12331362 0.1233364  0.12333483
 0.12332507 0.12332166]
[0. 0. 0.]
-----------end of analyzing the loss ratio:75.47788310050964
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9386a7100>
---------------------------------
SparseEpoch: [134][1/398]	Time 0.577	Data 0.000	Loss 1.2790	
SparseEpoch: [134][101/398]	Time 0.578	Data 0.000	Loss 0.9796	
SparseEpoch: [134][201/398]	Time 0.579	Data 0.000	Loss 0.8624	
SparseEpoch: [134][301/398]	Time 0.579	Data 0.000	Loss 1.1598	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.8016	
Epoch(adapt):{0} Loss 0.8172	
Epoch(adapt):{0} Loss 0.9159	
Epoch(adapt):{0} Loss 0.5676	
------------------the total time cost:1165.3406703472137
>>>>>meta updating
Epoch: 0134 | TRAIN: 0.4348 0.6774 0.8551 | 0.3256 0.3256 0.1588 | 0.1207 22.8410 17.7936 0.3186 0.6152 0.7410 ||TEST: 1.2325 0.3930 0.6531 | 0.5268 0.5268 0.2091 | 0.1418 25.2768 20.4283 0.2803 0.5508 0.6800 | 116.5610
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.66650844 0.66652227 0.6668058  0.66681595 0.66681331 0.66669941
 0.66680016 0.66674683 0.66694295 0.6668438  0.66681232 0.66675157
 0.66667361 0.66675063 0.66672604 0.66676918 0.66666201 0.66655643
 0.66659242 0.66684196]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.66685545 0.66683358 0.66680349 0.66686354 0.66684209 0.6668332
 0.66682796 0.66682942 0.66688888 0.66690041 0.66690322 0.66686159
 0.66686493 0.66686062 0.66688243 0.66689215 0.66684494 0.66682546
 0.66683455 0.66683472]
[0. 0. 0.]
-----------end of analyzing the loss ratio:75.5820415019989
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938309420>
---------------------------------
SparseEpoch: [135][1/398]	Time 0.577	Data 0.000	Loss 0.4328	
SparseEpoch: [135][101/398]	Time 0.579	Data 0.000	Loss 0.3838	
SparseEpoch: [135][201/398]	Time 0.579	Data 0.000	Loss 0.4921	
SparseEpoch: [135][301/398]	Time 0.579	Data 0.000	Loss 0.3757	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.34982542 0.34980802 0.34981075 0.34980835 0.34982162 0.34983704
 0.34985438 0.34987881 0.3498913  0.34989139 0.34994434 0.34998364
 0.35004649 0.35003389 0.34998549 0.34994871 0.34997528 0.34995621
 0.34994797 0.34995261]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.34991979 0.34992532 0.34991147 0.34990235 0.34992762 0.34992396
 0.34992408 0.34994229 0.34987564 0.34990217 0.34992472 0.34990369
 0.34993501 0.3499801  0.34996766 0.34997365 0.3499585  0.34994777
 0.34992081 0.34992304]
[0. 0. 0.]
-----------end of analyzing the loss ratio:75.46201419830322
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9390614e0>
---------------------------------
SparseEpoch: [135][1/398]	Time 0.577	Data 0.000	Loss 0.3078	
SparseEpoch: [135][101/398]	Time 0.579	Data 0.000	Loss 0.2029	
SparseEpoch: [135][201/398]	Time 0.580	Data 0.000	Loss 0.3456	
SparseEpoch: [135][301/398]	Time 0.579	Data 0.000	Loss 0.1839	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11870933 0.11872289 0.11872869 0.11871788 0.11870292 0.11869083
 0.11867282 0.11867771 0.11867    0.11866819 0.11866095 0.118651
 0.11864022 0.11863817 0.11861817 0.1186143  0.11863198 0.11863188
 0.11861972 0.11860835]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11860235 0.11859621 0.11864761 0.11866188 0.11865788 0.11866788
 0.11868235 0.11869552 0.11868066 0.11865868 0.11865315 0.11865697
 0.1186647  0.11866111 0.1186544  0.11866493 0.11867123 0.11867468
 0.11866549 0.11865577]
[0.5 0.  0. ]
-----------end of analyzing the loss ratio:75.55392479896545
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938a1b8e0>
---------------------------------
SparseEpoch: [135][1/398]	Time 0.578	Data 0.000	Loss 1.0602	
SparseEpoch: [135][101/398]	Time 0.580	Data 0.000	Loss 1.8287	
SparseEpoch: [135][201/398]	Time 0.580	Data 0.000	Loss 1.3711	
SparseEpoch: [135][301/398]	Time 0.580	Data 0.000	Loss 2.0787	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.7295	
Epoch(adapt):{0} Loss 0.6845	
Epoch(adapt):{0} Loss 1.0367	
Epoch(adapt):{0} Loss 0.5992	
------------------the total time cost:1164.9246575832367
>>>>>meta updating
Epoch: 0135 | TRAIN: 0.4122 0.6971 0.8615 | 0.3202 0.3202 0.1529 | 0.1213 22.9630 17.9362 0.3116 0.6129 0.7396 ||TEST: 1.2139 0.3994 0.6587 | 0.5241 0.5241 0.2065 | 0.1418 25.3385 20.5458 0.2754 0.5488 0.6796 | 116.5195
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.40587555 0.4058866  0.4058053  0.40579709 0.40581523 0.40569516
 0.40562803 0.40564387 0.40566886 0.40570847 0.4057144  0.4056948
 0.40568868 0.40570462 0.40569886 0.40568933 0.4057352  0.40577213
 0.40578495 0.40577368]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.4058175  0.40581358 0.40575805 0.40574517 0.40573671 0.405714
 0.40569373 0.40567499 0.4056999  0.40567323 0.40570113 0.40563653
 0.40562699 0.40561353 0.40566274 0.40559391 0.40563397 0.4057057
 0.4057074  0.40572605]
[0.         0.         0.28947368]
-----------end of analyzing the loss ratio:75.42767667770386
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938dead70>
---------------------------------
SparseEpoch: [136][1/398]	Time 0.578	Data 0.000	Loss 0.6115	
SparseEpoch: [136][101/398]	Time 0.580	Data 0.000	Loss 0.6114	
SparseEpoch: [136][201/398]	Time 0.580	Data 0.000	Loss 1.0321	
SparseEpoch: [136][301/398]	Time 0.581	Data 0.000	Loss 1.1041	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.4353951  0.43544271 0.43547263 0.43542221 0.43534913 0.43524899
 0.43521948 0.43514504 0.43518379 0.43512139 0.43495707 0.43487512
 0.43476342 0.43466995 0.43459477 0.43452801 0.43450829 0.43444265
 0.43443003 0.43439121]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.43523833 0.43517967 0.43516764 0.43517765 0.43514932 0.43512507
 0.43514105 0.43508306 0.43507489 0.43506925 0.43504439 0.43498633
 0.43497598 0.43492684 0.43490178 0.43487155 0.43484338 0.4348357
 0.43482284 0.43478957]
[0.5 0.  0.5]
-----------end of analyzing the loss ratio:75.59554028511047
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc93814b940>
---------------------------------
SparseEpoch: [136][1/398]	Time 0.578	Data 0.000	Loss 0.8094	
SparseEpoch: [136][101/398]	Time 0.580	Data 0.000	Loss 1.0438	
SparseEpoch: [136][201/398]	Time 0.580	Data 0.000	Loss 0.7791	
SparseEpoch: [136][301/398]	Time 0.580	Data 0.000	Loss 1.1026	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.12670484 0.12670757 0.12668965 0.1267109  0.12670022 0.12670509
 0.12669597 0.12669517 0.12668737 0.12666085 0.1266692  0.12667869
 0.12666965 0.12666876 0.12664186 0.12664725 0.12662365 0.12663105
 0.12662246 0.12660855]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.1266788  0.12667034 0.1266728  0.12667363 0.12668108 0.12668964
 0.12668695 0.12667759 0.12666833 0.12665645 0.12666314 0.12665837
 0.12665558 0.12665868 0.12664564 0.1266238  0.12661621 0.12660532
 0.12661445 0.12661169]
[0.5        0.39473684 0.        ]
-----------end of analyzing the loss ratio:75.38813042640686
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc89de13c40>
---------------------------------
SparseEpoch: [136][1/398]	Time 0.578	Data 0.000	Loss 1.0900	
SparseEpoch: [136][101/398]	Time 0.580	Data 0.000	Loss 1.3891	
SparseEpoch: [136][201/398]	Time 0.580	Data 0.000	Loss 3.2348	
SparseEpoch: [136][301/398]	Time 0.580	Data 0.000	Loss 1.3246	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.9652	
Epoch(adapt):{0} Loss 0.4829	
Epoch(adapt):{0} Loss 0.6344	
Epoch(adapt):{0} Loss 0.7598	
------------------the total time cost:1166.5934040546417
>>>>>meta updating
Epoch: 0136 | TRAIN: 0.3943 0.7068 0.8704 | 0.3243 0.3243 0.1564 | 0.1193 22.6136 17.3915 0.3234 0.6245 0.7480 ||TEST: 1.2102 0.4059 0.6647 | 0.5185 0.5185 0.2064 | 0.1411 25.1226 20.1105 0.2843 0.5578 0.6866 | 116.7627
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.37665538 0.37669498 0.37669996 0.37666549 0.37668974 0.37667417
 0.376631   0.37662918 0.37659733 0.37663105 0.37667005 0.37671844
 0.3767103  0.37673337 0.37671999 0.37674787 0.37680329 0.37682525
 0.37681461 0.37684135]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.37655568 0.37654384 0.37660379 0.37658202 0.37659835 0.37662171
 0.37662618 0.37664766 0.3766405  0.37664016 0.37665599 0.37666397
 0.37668591 0.37669053 0.37670956 0.37670489 0.37671684 0.37668903
 0.37670502 0.3767159 ]
[0. 0. 0.]
-----------end of analyzing the loss ratio:75.513112783432
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9382d19c0>
---------------------------------
SparseEpoch: [137][1/398]	Time 0.577	Data 0.000	Loss 0.1284	
SparseEpoch: [137][101/398]	Time 0.579	Data 0.000	Loss 0.2889	
SparseEpoch: [137][201/398]	Time 0.579	Data 0.000	Loss 0.5482	
SparseEpoch: [137][301/398]	Time 0.579	Data 0.000	Loss 0.1935	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.69021328 0.69011275 0.69004127 0.69004112 0.68990758 0.68986278
 0.68981166 0.68977171 0.68976291 0.68981438 0.68978713 0.68981511
 0.68971056 0.68968135 0.6894989  0.68950192 0.68937086 0.68934265
 0.6893295  0.6893622 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.68985304 0.68988978 0.68983998 0.68980446 0.68977976 0.68976916
 0.68978348 0.68975882 0.68977532 0.68981687 0.68981602 0.68981895
 0.68979812 0.68978258 0.68976587 0.6897827  0.68979915 0.68978869
 0.6898235  0.68985914]
[0.44736842 0.         0.        ]
-----------end of analyzing the loss ratio:75.49983716011047
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938d3d450>
---------------------------------
SparseEpoch: [137][1/398]	Time 0.580	Data 0.000	Loss 0.5694	
SparseEpoch: [137][101/398]	Time 0.580	Data 0.000	Loss 0.8061	
SparseEpoch: [137][201/398]	Time 0.580	Data 0.000	Loss 0.7849	
SparseEpoch: [137][301/398]	Time 0.580	Data 0.000	Loss 0.6005	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.1321557  0.13216748 0.13215984 0.13214217 0.1321416  0.13214388
 0.13216126 0.13219463 0.13219778 0.13220624 0.13219749 0.13214611
 0.13213952 0.13215697 0.13215531 0.13213645 0.13212384 0.13214982
 0.13215626 0.13215747]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.13221136 0.13221464 0.13220571 0.13220513 0.13221352 0.13221595
 0.13221249 0.13221133 0.13221705 0.13221856 0.13221231 0.1322091
 0.13219936 0.13219068 0.13218719 0.13218364 0.13217667 0.13216951
 0.13215843 0.13216621]
[0.34210526 0.44736842 0.        ]
-----------end of analyzing the loss ratio:75.42424178123474
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938944910>
---------------------------------
SparseEpoch: [137][1/398]	Time 0.586	Data 0.000	Loss 1.0057	
SparseEpoch: [137][101/398]	Time 0.580	Data 0.000	Loss 1.0759	
SparseEpoch: [137][201/398]	Time 0.581	Data 0.000	Loss 1.5822	
SparseEpoch: [137][301/398]	Time 0.581	Data 0.000	Loss 2.0066	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.1231	
Epoch(adapt):{0} Loss 0.7028	
Epoch(adapt):{0} Loss 0.5406	
Epoch(adapt):{0} Loss 0.5913	
------------------the total time cost:1166.227172613144
>>>>>meta updating
Epoch: 0137 | TRAIN: 0.4071 0.6986 0.8645 | 0.3087 0.3087 0.1450 | 0.1188 22.6137 17.5638 0.3227 0.6209 0.7459 ||TEST: 1.2475 0.3986 0.6551 | 0.5146 0.5146 0.2041 | 0.1422 25.2823 20.3841 0.2817 0.5515 0.6807 | 116.3221
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.36561235 0.36560645 0.36567563 0.36564517 0.36569651 0.36565953
 0.36558958 0.36558091 0.36546478 0.36556335 0.36548884 0.3655204
 0.36561417 0.3656633  0.36569002 0.36553146 0.3655658  0.36550583
 0.36560029 0.36560446]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.36549191 0.36548158 0.36548505 0.36544826 0.36547931 0.36546852
 0.36549778 0.36548796 0.36550105 0.36541477 0.36550145 0.36542949
 0.36545    0.36545829 0.36544528 0.36545159 0.36541862 0.36544862
 0.36548581 0.36546367]
[0. 0. 0.]
-----------end of analyzing the loss ratio:75.6802749633789
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc89de113c0>
---------------------------------
SparseEpoch: [138][1/398]	Time 0.577	Data 0.000	Loss 0.2993	
SparseEpoch: [138][101/398]	Time 0.579	Data 0.000	Loss 0.3677	
SparseEpoch: [138][201/398]	Time 0.579	Data 0.000	Loss 0.4974	
SparseEpoch: [138][301/398]	Time 0.579	Data 0.000	Loss 0.7910	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.35749361 0.35736948 0.35731118 0.35722553 0.35717166 0.35700457
 0.35707958 0.35709625 0.35713237 0.35711855 0.35713156 0.35721804
 0.35714738 0.35708487 0.35710246 0.35714949 0.35716118 0.35718162
 0.35711023 0.35710067]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.35711845 0.35710941 0.3571103  0.35711837 0.35711171 0.35710332
 0.35710252 0.35712498 0.3571261  0.35713421 0.35713866 0.3571225
 0.35710652 0.3571322  0.35713494 0.357161   0.35715198 0.35715089
 0.35715558 0.35714265]
[0. 0. 0.]
-----------end of analyzing the loss ratio:75.6362054347992
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938778f40>
---------------------------------
SparseEpoch: [138][1/398]	Time 0.577	Data 0.000	Loss 0.2451	
SparseEpoch: [138][101/398]	Time 0.580	Data 0.000	Loss 0.1930	
SparseEpoch: [138][201/398]	Time 0.580	Data 0.000	Loss 0.3529	
SparseEpoch: [138][301/398]	Time 0.580	Data 0.000	Loss 0.3576	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.13882031 0.13884757 0.13882048 0.13882882 0.13880835 0.13879753
 0.13874179 0.13871722 0.13872238 0.13872201 0.13873941 0.13878171
 0.13876797 0.13878593 0.13876173 0.13877243 0.138746   0.13875743
 0.13876246 0.13876584]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.13872516 0.13873146 0.13875402 0.13873985 0.13874143 0.1387068
 0.13872921 0.13874798 0.13873594 0.13872015 0.13874361 0.13875549
 0.13875662 0.13877738 0.1387778  0.13882595 0.1388372  0.13886661
 0.1388292  0.13886476]
[0. 0. 0.]
-----------end of analyzing the loss ratio:75.47245025634766
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cca5e2115d0>
---------------------------------
SparseEpoch: [138][1/398]	Time 0.578	Data 0.000	Loss 0.9139	
SparseEpoch: [138][101/398]	Time 0.579	Data 0.000	Loss 0.9728	
SparseEpoch: [138][201/398]	Time 0.579	Data 0.000	Loss 1.0337	
SparseEpoch: [138][301/398]	Time 0.579	Data 0.000	Loss 1.3748	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.9121	
Epoch(adapt):{0} Loss 0.6902	
Epoch(adapt):{0} Loss 0.5732	
Epoch(adapt):{0} Loss 0.6233	
------------------the total time cost:1166.1337671279907
>>>>>meta updating
Epoch: 0138 | TRAIN: 0.4073 0.7080 0.8665 | 0.3220 0.3220 0.1601 | 0.1243 23.3813 18.5151 0.3019 0.5973 0.7281 ||TEST: 1.2094 0.4014 0.6600 | 0.5175 0.5175 0.2081 | 0.1443 25.5811 20.8891 0.2764 0.5404 0.6709 | 116.7051
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.37512501 0.37520109 0.37520316 0.37521109 0.37518973 0.3752392
 0.37521303 0.37521807 0.37526071 0.37525277 0.37528225 0.37527326
 0.37525871 0.37520594 0.37516674 0.37516484 0.37520834 0.37524133
 0.37528133 0.37534628]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.37526855 0.37525804 0.37527274 0.37528344 0.37529797 0.37530034
 0.3752938  0.37529638 0.37528703 0.37527656 0.37528005 0.37526449
 0.37527072 0.37527903 0.3752747  0.37528395 0.3752733  0.37524825
 0.37524426 0.37526039]
[0.         0.         0.44736842]
-----------end of analyzing the loss ratio:75.56530928611755
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938e02350>
---------------------------------
SparseEpoch: [139][1/398]	Time 0.578	Data 0.000	Loss 0.9981	
SparseEpoch: [139][101/398]	Time 0.580	Data 0.000	Loss 1.0277	
SparseEpoch: [139][201/398]	Time 0.580	Data 0.000	Loss 1.1433	
SparseEpoch: [139][301/398]	Time 0.580	Data 0.000	Loss 1.1698	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.48055491 0.48071038 0.48090581 0.48106579 0.48120071 0.48134197
 0.48144479 0.48164497 0.48175766 0.48187611 0.48206627 0.48222433
 0.48233925 0.48245959 0.48256402 0.48263996 0.48280578 0.48296238
 0.48310848 0.48343805]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.48204708 0.48203106 0.48204154 0.48205057 0.48205716 0.48202579
 0.48200594 0.48198321 0.48197496 0.48197222 0.48196408 0.48194759
 0.48191673 0.48191681 0.48193586 0.48195933 0.48193476 0.48189898
 0.48189558 0.48185971]
[0.  0.  0.5]
-----------end of analyzing the loss ratio:75.3191728591919
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9382d0eb0>
---------------------------------
SparseEpoch: [139][1/398]	Time 0.579	Data 0.000	Loss 1.0627	
SparseEpoch: [139][101/398]	Time 0.581	Data 0.000	Loss 0.8029	
SparseEpoch: [139][201/398]	Time 0.580	Data 0.000	Loss 0.7478	
SparseEpoch: [139][301/398]	Time 0.580	Data 0.000	Loss 0.6894	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.13788059 0.13787964 0.13787468 0.13786095 0.13784208 0.13784505
 0.13782898 0.13781433 0.13780195 0.13781446 0.13781444 0.13781263
 0.13780075 0.13777069 0.13778474 0.13776854 0.13777843 0.13777886
 0.13779104 0.13777108]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.13784625 0.13784272 0.13783885 0.1378374  0.13783064 0.13783043
 0.13782853 0.13782518 0.13782884 0.13782135 0.13781612 0.13782233
 0.13782188 0.13781824 0.13781735 0.1378229  0.13782017 0.13781879
 0.13781714 0.13781653]
[0.28947368 0.02631579 0.        ]
-----------end of analyzing the loss ratio:75.38306617736816
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938a4a0e0>
---------------------------------
SparseEpoch: [139][1/398]	Time 0.579	Data 0.000	Loss 1.6008	
SparseEpoch: [139][101/398]	Time 0.581	Data 0.000	Loss 0.8212	
SparseEpoch: [139][201/398]	Time 0.581	Data 0.000	Loss 1.4524	
SparseEpoch: [139][301/398]	Time 0.581	Data 0.000	Loss 1.3029	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.7593	
Epoch(adapt):{0} Loss 0.5720	
Epoch(adapt):{0} Loss 0.9140	
Epoch(adapt):{0} Loss 0.9633	
------------------the total time cost:1166.879676103592
>>>>>meta updating
Epoch: 0139 | TRAIN: 0.3773 0.7324 0.8791 | 0.3255 0.3255 0.1700 | 0.1189 22.5008 17.2771 0.3309 0.6273 0.7481 ||TEST: 1.2111 0.4165 0.6660 | 0.5128 0.5128 0.2119 | 0.1404 25.0256 19.9498 0.2874 0.5605 0.6875 | 116.3778
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.35831094 0.35832985 0.35832945 0.35835937 0.35841569 0.35838419
 0.35833195 0.35833957 0.35833078 0.35827995 0.35834973 0.35841001
 0.35843555 0.35852631 0.3586028  0.35861148 0.35865115 0.35860943
 0.35864511 0.35876051]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.35835225 0.35834918 0.35833959 0.35835457 0.35836601 0.35836745
 0.35836507 0.35835217 0.35837156 0.35836385 0.35836521 0.35835086
 0.35835867 0.35835047 0.35835753 0.35832966 0.35832615 0.35831899
 0.35831851 0.35830033]
[0.  0.  0.5]
-----------end of analyzing the loss ratio:75.53898096084595
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938507d00>
---------------------------------
SparseEpoch: [140][1/398]	Time 0.578	Data 0.000	Loss 1.2883	
SparseEpoch: [140][101/398]	Time 0.580	Data 0.000	Loss 0.9142	
SparseEpoch: [140][201/398]	Time 0.580	Data 0.000	Loss 1.0914	
SparseEpoch: [140][301/398]	Time 0.580	Data 0.000	Loss 0.7589	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.59984504 0.59976918 0.59978768 0.59981606 0.59986063 0.59984778
 0.59976045 0.59983206 0.59992442 0.59980168 0.59971385 0.59963267
 0.59952495 0.5994934  0.59941764 0.59933884 0.59937285 0.59940395
 0.5994393  0.59945893]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.59982485 0.59981196 0.59978073 0.59979654 0.59979071 0.5997791
 0.5998049  0.59981171 0.59979972 0.59977027 0.59977632 0.59975878
 0.59973872 0.59968618 0.59964139 0.59965359 0.59958766 0.59961457
 0.59960065 0.59966133]
[0.28947368 0.         0.34210526]
-----------end of analyzing the loss ratio:75.42194938659668
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc93822fe50>
---------------------------------
SparseEpoch: [140][1/398]	Time 0.579	Data 0.000	Loss 1.0046	
SparseEpoch: [140][101/398]	Time 0.580	Data 0.000	Loss 0.6999	
SparseEpoch: [140][201/398]	Time 0.581	Data 0.000	Loss 0.7139	
SparseEpoch: [140][301/398]	Time 0.581	Data 0.000	Loss 0.6533	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.13330935 0.13324821 0.13315085 0.13312411 0.13315088 0.13310909
 0.13306196 0.13304395 0.13299529 0.13296736 0.13291157 0.13283872
 0.13278884 0.13274577 0.13271582 0.13268235 0.13261679 0.1326243
 0.13264024 0.13261438]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.13317201 0.13316855 0.13315741 0.13311908 0.13311351 0.13306607
 0.1330386  0.13300919 0.13298802 0.13295641 0.13287751 0.13287433
 0.13281312 0.13277441 0.13277463 0.1327822  0.13276865 0.13271602
 0.13270407 0.13263729]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:75.61954665184021
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938fa9150>
---------------------------------
SparseEpoch: [140][1/398]	Time 0.578	Data 0.000	Loss 1.6326	
SparseEpoch: [140][101/398]	Time 0.580	Data 0.000	Loss 1.5590	
SparseEpoch: [140][201/398]	Time 0.580	Data 0.000	Loss 1.0777	
SparseEpoch: [140][301/398]	Time 0.580	Data 0.000	Loss 1.6109	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.6754	
Epoch(adapt):{0} Loss 0.7532	
Epoch(adapt):{0} Loss 0.7390	
Epoch(adapt):{0} Loss 1.0030	
------------------the total time cost:1166.6439754962921
>>>>>meta updating
Epoch: 0140 | TRAIN: 0.3633 0.7396 0.8823 | 0.3070 0.3070 0.1510 | 0.1179 22.3549 17.1164 0.3326 0.6316 0.7533 ||TEST: 1.2613 0.4123 0.6632 | 0.5131 0.5131 0.2049 | 0.1410 25.0373 19.9398 0.2886 0.5612 0.6885 | 116.6386
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.31636037 0.31632689 0.31633105 0.31631681 0.31631063 0.31617605
 0.31614802 0.31614226 0.31609668 0.31594149 0.31590969 0.31590154
 0.31593649 0.31595404 0.31605177 0.31604131 0.31597176 0.31596847
 0.31604413 0.31605167]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.31593702 0.31594088 0.31594016 0.31594181 0.3159411  0.31593575
 0.31595976 0.31594547 0.3159403  0.31594986 0.31595227 0.31595758
 0.31595426 0.31594748 0.31595166 0.31593358 0.31593866 0.31594144
 0.31594898 0.31594792]
[0.         0.07894737 0.28947368]
-----------end of analyzing the loss ratio:75.4095549583435
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9389da830>
---------------------------------
SparseEpoch: [141][1/398]	Time 0.578	Data 0.000	Loss 0.7403	
SparseEpoch: [141][101/398]	Time 0.581	Data 0.000	Loss 1.1533	
SparseEpoch: [141][201/398]	Time 0.581	Data 0.000	Loss 0.6811	
SparseEpoch: [141][301/398]	Time 0.581	Data 0.000	Loss 0.7761	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.37922914 0.37926524 0.37912213 0.37915105 0.37904595 0.3789376
 0.37880826 0.37877425 0.37859334 0.37864513 0.37862742 0.37855788
 0.37855544 0.37861065 0.37860022 0.37858327 0.37838183 0.37832467
 0.37822659 0.3780785 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.37869086 0.37870509 0.3786721  0.37866591 0.37863992 0.37861115
 0.37862389 0.37863597 0.37862366 0.37861697 0.37860322 0.37860546
 0.37859152 0.3785905  0.3785933  0.37860462 0.37861169 0.37863002
 0.37861028 0.37861293]
[0.5        0.         0.18421053]
-----------end of analyzing the loss ratio:75.45686364173889
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc93890a170>
---------------------------------
SparseEpoch: [141][1/398]	Time 0.578	Data 0.000	Loss 0.5617	
SparseEpoch: [141][101/398]	Time 0.581	Data 0.000	Loss 0.7131	
SparseEpoch: [141][201/398]	Time 0.581	Data 0.000	Loss 0.7739	
SparseEpoch: [141][301/398]	Time 0.580	Data 0.000	Loss 0.5991	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11354207 0.11353778 0.11349914 0.11351705 0.11351565 0.11351174
 0.11350904 0.11350523 0.11350348 0.11351183 0.11351686 0.11349639
 0.11349912 0.11350207 0.113511   0.11348213 0.1134694  0.11345064
 0.11346637 0.11346323]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11352678 0.11353184 0.11352403 0.11352069 0.11352355 0.11352561
 0.11351447 0.11351717 0.11351566 0.11350677 0.11351686 0.11352386
 0.11350263 0.11350141 0.11348153 0.11346934 0.11346859 0.1134535
 0.11343831 0.1134468 ]
[0.39473684 0.44736842 0.        ]
-----------end of analyzing the loss ratio:75.53731870651245
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc93830a170>
---------------------------------
SparseEpoch: [141][1/398]	Time 0.584	Data 0.000	Loss 0.8631	
SparseEpoch: [141][101/398]	Time 0.581	Data 0.000	Loss 2.1805	
SparseEpoch: [141][201/398]	Time 0.580	Data 0.000	Loss 0.7969	
SparseEpoch: [141][301/398]	Time 0.581	Data 0.000	Loss 2.4097	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.9424	
Epoch(adapt):{0} Loss 0.8705	
Epoch(adapt):{0} Loss 0.7128	
Epoch(adapt):{0} Loss 0.6785	
------------------the total time cost:1167.209771156311
>>>>>meta updating
Epoch: 0141 | TRAIN: 0.3997 0.7110 0.8690 | 0.3095 0.3095 0.1435 | 0.1189 22.5647 17.3830 0.3266 0.6251 0.7474 ||TEST: 1.2678 0.3974 0.6557 | 0.5239 0.5239 0.2077 | 0.1415 25.1822 20.1954 0.2835 0.5561 0.6838 | 116.7038
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.42919807 0.42921857 0.42924182 0.42925657 0.42923919 0.42921177
 0.42926555 0.42925997 0.42932447 0.42928903 0.42927613 0.42926936
 0.42922342 0.42926859 0.42922511 0.42916067 0.42920218 0.42921166
 0.42938054 0.42932543]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.42925681 0.42924642 0.42924932 0.42923744 0.42925445 0.42925991
 0.42925672 0.42926031 0.42925745 0.42923506 0.42925183 0.42925312
 0.42925055 0.42931097 0.4293295  0.42929916 0.4293073  0.4293115
 0.42930242 0.42927177]
[0.         0.28947368 0.        ]
-----------end of analyzing the loss ratio:75.44221591949463
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cca5e2f0be0>
---------------------------------
SparseEpoch: [142][1/398]	Time 0.578	Data 0.000	Loss 0.5076	
SparseEpoch: [142][101/398]	Time 0.580	Data 0.000	Loss 0.5113	
SparseEpoch: [142][201/398]	Time 0.580	Data 0.000	Loss 0.4484	
SparseEpoch: [142][301/398]	Time 0.580	Data 0.000	Loss 0.4762	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.27994909 0.27990589 0.27993062 0.28011278 0.27999014 0.28007305
 0.28005675 0.2800947  0.28007442 0.28007227 0.28011201 0.28008685
 0.28011123 0.2800852  0.28010573 0.28009432 0.28012148 0.28017901
 0.28026052 0.28028514]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.28008514 0.28007467 0.28008738 0.28009933 0.2800905  0.28008862
 0.2800955  0.28010444 0.2800854  0.28007576 0.28011091 0.28009745
 0.28010043 0.28009494 0.28009606 0.28009145 0.28007653 0.28007629
 0.28009524 0.28008298]
[0. 0. 0.]
-----------end of analyzing the loss ratio:75.77810597419739
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9380d8520>
---------------------------------
SparseEpoch: [142][1/398]	Time 0.579	Data 0.000	Loss 0.3180	
SparseEpoch: [142][101/398]	Time 0.580	Data 0.000	Loss 0.3827	
SparseEpoch: [142][201/398]	Time 0.580	Data 0.000	Loss 0.2776	
SparseEpoch: [142][301/398]	Time 0.580	Data 0.000	Loss 0.3094	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.13367679 0.13365523 0.13364737 0.1336503  0.13362551 0.13358806
 0.13357796 0.13355728 0.13352339 0.13348956 0.13345786 0.13344957
 0.13338166 0.13336577 0.13335276 0.13334545 0.13334362 0.13334304
 0.13332302 0.1332895 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.13351752 0.1335174  0.13350657 0.13350501 0.1335021  0.13349394
 0.13349075 0.13349058 0.13347923 0.13348055 0.13348148 0.13347864
 0.13347418 0.13346267 0.13345789 0.13346062 0.13345395 0.13345886
 0.13344824 0.13344468]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:75.64329791069031
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938236830>
---------------------------------
SparseEpoch: [142][1/398]	Time 0.579	Data 0.000	Loss 1.3430	
SparseEpoch: [142][101/398]	Time 0.580	Data 0.000	Loss 1.5556	
SparseEpoch: [142][201/398]	Time 0.580	Data 0.000	Loss 2.1000	
SparseEpoch: [142][301/398]	Time 0.580	Data 0.000	Loss 1.8034	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.9244	
Epoch(adapt):{0} Loss 0.7134	
Epoch(adapt):{0} Loss 0.4197	
Epoch(adapt):{0} Loss 0.5400	
------------------the total time cost:1165.5176484584808
>>>>>meta updating
Epoch: 0142 | TRAIN: 0.3842 0.7246 0.8743 | 0.3158 0.3158 0.1529 | 0.1195 22.7303 17.7144 0.3184 0.6178 0.7436 ||TEST: 1.2319 0.4031 0.6565 | 0.5210 0.5210 0.2033 | 0.1431 25.4524 20.6604 0.2750 0.5461 0.6763 | 117.0919
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.41905635 0.41905213 0.41908449 0.41902891 0.41910505 0.41905849
 0.41905994 0.41902019 0.41891809 0.41884234 0.41876607 0.41876248
 0.41880908 0.41889213 0.41899373 0.41902534 0.41897635 0.4189172
 0.41892387 0.41890403]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.4187576  0.41875977 0.4187664  0.41875688 0.41875856 0.41872152
 0.41872154 0.41875326 0.41877424 0.41877019 0.41881023 0.41880137
 0.41883526 0.41885467 0.41888032 0.41890327 0.41891384 0.4189162
 0.41894894 0.41896711]
[0.         0.07894737 0.        ]
-----------end of analyzing the loss ratio:75.66975569725037
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938148400>
---------------------------------
SparseEpoch: [143][1/398]	Time 0.579	Data 0.000	Loss 0.3053	
SparseEpoch: [143][101/398]	Time 0.581	Data 0.000	Loss 0.4015	
SparseEpoch: [143][201/398]	Time 0.580	Data 0.000	Loss 0.3219	
SparseEpoch: [143][301/398]	Time 0.580	Data 0.000	Loss 0.3906	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.30846253 0.30840241 0.30836127 0.30825077 0.30811185 0.30806555
 0.30801153 0.30804044 0.30798271 0.30791274 0.30782971 0.30782783
 0.30772912 0.30759658 0.30760979 0.30742764 0.30731184 0.30725618
 0.30717099 0.3071395 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.30794347 0.30791271 0.30792951 0.30794592 0.30790649 0.30789082
 0.30789646 0.30789121 0.30785446 0.30784394 0.30785225 0.30783633
 0.30783857 0.30784384 0.30787329 0.30787611 0.30787936 0.30787915
 0.30787332 0.30786471]
[0.5        0.         0.07894737]
-----------end of analyzing the loss ratio:75.59189510345459
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938149d80>
---------------------------------
SparseEpoch: [143][1/398]	Time 0.578	Data 0.000	Loss 0.5136	
SparseEpoch: [143][101/398]	Time 0.580	Data 0.000	Loss 0.5638	
SparseEpoch: [143][201/398]	Time 0.580	Data 0.000	Loss 0.6465	
SparseEpoch: [143][301/398]	Time 0.581	Data 0.000	Loss 0.5818	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.12889819 0.12888907 0.12889105 0.12890938 0.12887908 0.12887473
 0.12885341 0.12885246 0.12884934 0.12884429 0.12883638 0.1288288
 0.12883    0.12883216 0.1288201  0.12881176 0.12879875 0.12878674
 0.12878274 0.12875254]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.12890126 0.12888168 0.1288812  0.12886649 0.12886892 0.12885646
 0.12885864 0.12884178 0.12884755 0.12883217 0.12882578 0.12882886
 0.12882996 0.12882602 0.12884161 0.12883976 0.12880971 0.12879803
 0.1287928  0.12878966]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:75.37318587303162
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc89df1e1d0>
---------------------------------
SparseEpoch: [143][1/398]	Time 0.578	Data 0.000	Loss 1.0717	
SparseEpoch: [143][101/398]	Time 0.580	Data 0.000	Loss 1.1425	
SparseEpoch: [143][201/398]	Time 0.580	Data 0.000	Loss 1.1015	
SparseEpoch: [143][301/398]	Time 0.581	Data 0.000	Loss 1.9487	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.6043	
Epoch(adapt):{0} Loss 0.6386	
Epoch(adapt):{0} Loss 0.8221	
Epoch(adapt):{0} Loss 0.8575	
------------------the total time cost:1167.6664340496063
>>>>>meta updating
Epoch: 0143 | TRAIN: 0.3715 0.7286 0.8807 | 0.3127 0.3127 0.1496 | 0.1194 22.6612 17.5357 0.3227 0.6205 0.7455 ||TEST: 1.2623 0.4083 0.6646 | 0.5229 0.5229 0.2073 | 0.1442 25.4586 20.5434 0.2804 0.5480 0.6772 | 116.9228
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.35023397 0.35022704 0.35025885 0.35026119 0.35027862 0.35024328
 0.35025922 0.35025999 0.35033461 0.35031615 0.3503076  0.35030653
 0.35027651 0.35030173 0.35029089 0.35030818 0.35031415 0.35033773
 0.35034817 0.35036341]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.35027231 0.35027224 0.35027681 0.35028706 0.35030954 0.35031871
 0.35032613 0.35033086 0.3503211  0.35031741 0.35032172 0.35031902
 0.35031639 0.35031574 0.350309   0.35031359 0.35030994 0.35034525
 0.35035273 0.35035998]
[0. 0. 0.]
-----------end of analyzing the loss ratio:75.37649536132812
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938f9f0a0>
---------------------------------
SparseEpoch: [144][1/398]	Time 0.577	Data 0.000	Loss 0.3041	
SparseEpoch: [144][101/398]	Time 0.580	Data 0.000	Loss 0.3066	
SparseEpoch: [144][201/398]	Time 0.580	Data 0.000	Loss 0.4080	
SparseEpoch: [144][301/398]	Time 0.579	Data 0.000	Loss 0.6281	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.39594658 0.39586699 0.39581719 0.39568271 0.39559021 0.39553461
 0.3954415  0.39543374 0.39532778 0.39525628 0.39517124 0.39509873
 0.39498556 0.39494505 0.39497845 0.39492739 0.39487872 0.39476766
 0.39469129 0.39469517]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.3953176  0.3953078  0.3952748  0.3952594  0.39524338 0.3952772
 0.39528369 0.39526674 0.39526739 0.39521175 0.39518414 0.39520002
 0.39518504 0.3951621  0.39516786 0.39514456 0.39511742 0.39510991
 0.39509557 0.39508031]
[0.44736842 0.         0.5       ]
-----------end of analyzing the loss ratio:75.62966680526733
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938b451b0>
---------------------------------
SparseEpoch: [144][1/398]	Time 0.579	Data 0.000	Loss 0.9805	
SparseEpoch: [144][101/398]	Time 0.580	Data 0.000	Loss 1.0513	
SparseEpoch: [144][201/398]	Time 0.581	Data 0.000	Loss 0.8343	
SparseEpoch: [144][301/398]	Time 0.581	Data 0.000	Loss 1.1688	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.12375142 0.12374689 0.12374232 0.12375903 0.12376709 0.12375076
 0.12373683 0.12372895 0.12372    0.12374728 0.12376937 0.123772
 0.12379568 0.12381094 0.12382554 0.12382339 0.12382511 0.12380343
 0.12380445 0.12380975]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.12376063 0.12374533 0.1237455  0.12372998 0.12372556 0.12371539
 0.12371916 0.12372323 0.12372932 0.12374362 0.12376029 0.12375225
 0.12378123 0.12378108 0.12379689 0.12380956 0.12380424 0.12381641
 0.12381503 0.1238226 ]
[0. 0. 0.]
-----------end of analyzing the loss ratio:75.63181567192078
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9385e77c0>
---------------------------------
SparseEpoch: [144][1/398]	Time 0.585	Data 0.000	Loss 0.8188	
SparseEpoch: [144][101/398]	Time 0.580	Data 0.000	Loss 0.9594	
SparseEpoch: [144][201/398]	Time 0.579	Data 0.000	Loss 2.1078	
SparseEpoch: [144][301/398]	Time 0.579	Data 0.000	Loss 1.6323	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.5691	
Epoch(adapt):{0} Loss 0.6250	
Epoch(adapt):{0} Loss 0.8252	
Epoch(adapt):{0} Loss 0.5459	
------------------the total time cost:1166.380603313446
>>>>>meta updating
Epoch: 0144 | TRAIN: 0.3852 0.7172 0.8735 | 0.3023 0.3023 0.1464 | 0.1191 22.6250 17.5623 0.3231 0.6211 0.7457 ||TEST: 1.2648 0.4070 0.6589 | 0.5146 0.5146 0.2058 | 0.1426 25.3598 20.5566 0.2791 0.5483 0.6785 | 116.7494
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.30969452 0.30972295 0.30969772 0.3096416  0.30962299 0.30954442
 0.30955906 0.30953987 0.30949043 0.30952563 0.30949752 0.30944532
 0.30941935 0.30946871 0.3095063  0.30947954 0.30946357 0.30944552
 0.3094427  0.30945902]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.30952612 0.30952007 0.30950832 0.30948929 0.30952541 0.3094808
 0.30946259 0.30949469 0.3094877  0.30944944 0.30944786 0.30953046
 0.3095358  0.30955793 0.30956543 0.30956322 0.30958911 0.30957624
 0.30953481 0.30953839]
[0.         0.13157895 0.02631579]
-----------end of analyzing the loss ratio:75.60268521308899
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9382d29b0>
---------------------------------
SparseEpoch: [145][1/398]	Time 0.579	Data 0.000	Loss 0.1979	
SparseEpoch: [145][101/398]	Time 0.581	Data 0.000	Loss 0.4493	
SparseEpoch: [145][201/398]	Time 0.581	Data 0.000	Loss 0.4422	
SparseEpoch: [145][301/398]	Time 0.581	Data 0.000	Loss 0.8285	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.35283003 0.35232007 0.35226792 0.3520388  0.35182775 0.35148749
 0.35121319 0.35100343 0.35084945 0.35072378 0.35051595 0.35025977
 0.35017408 0.35003688 0.34990747 0.3498085  0.34985771 0.34995717
 0.34974685 0.34948172]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.35075653 0.35074632 0.35073688 0.35079493 0.35077842 0.35077966
 0.35075624 0.35075561 0.35076039 0.35072897 0.35070638 0.35068158
 0.35061485 0.35058451 0.3506238  0.35055891 0.35054012 0.35049476
 0.35050958 0.35048826]
[0.5 0.  0.5]
-----------end of analyzing the loss ratio:75.57377409934998
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc89de11bd0>
---------------------------------
SparseEpoch: [145][1/398]	Time 0.582	Data 0.000	Loss 0.7471	
SparseEpoch: [145][101/398]	Time 0.580	Data 0.000	Loss 1.1775	
SparseEpoch: [145][201/398]	Time 0.580	Data 0.000	Loss 0.8922	
SparseEpoch: [145][301/398]	Time 0.580	Data 0.000	Loss 1.0500	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11458888 0.11460484 0.1146084  0.11460282 0.11460996 0.11456808
 0.11458098 0.11456962 0.11459776 0.11459267 0.11459476 0.11457748
 0.11456578 0.11455116 0.11455059 0.11454295 0.11455514 0.11454847
 0.11454278 0.1145358 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11458192 0.11458618 0.11459063 0.11458607 0.11458405 0.11460065
 0.11459345 0.11460868 0.11460286 0.11460023 0.11459749 0.11459285
 0.11458441 0.11457701 0.11457723 0.11457716 0.11456203 0.11455019
 0.11454729 0.11455358]
[0.5        0.44736842 0.        ]
-----------end of analyzing the loss ratio:75.49231743812561
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938791db0>
---------------------------------
SparseEpoch: [145][1/398]	Time 0.579	Data 0.000	Loss 1.1148	
SparseEpoch: [145][101/398]	Time 0.580	Data 0.000	Loss 1.3301	
SparseEpoch: [145][201/398]	Time 0.580	Data 0.000	Loss 1.5651	
SparseEpoch: [145][301/398]	Time 0.580	Data 0.000	Loss 1.5246	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.6398	
Epoch(adapt):{0} Loss 0.8974	
Epoch(adapt):{0} Loss 0.4253	
Epoch(adapt):{0} Loss 0.6976	
------------------the total time cost:1167.2639770507812
>>>>>meta updating
Epoch: 0145 | TRAIN: 0.3763 0.7255 0.8760 | 0.3272 0.3272 0.1528 | 0.1198 22.7634 17.6989 0.3162 0.6194 0.7444 ||TEST: 1.2324 0.4082 0.6606 | 0.5378 0.5378 0.2085 | 0.1411 25.2463 20.4142 0.2774 0.5513 0.6815 | 116.7368
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.43549097 0.43548639 0.43544251 0.43553971 0.43545204 0.43542246
 0.43544849 0.43540107 0.43544072 0.43547526 0.43551779 0.43557909
 0.4356691  0.43572293 0.43565237 0.43561419 0.43565441 0.43555893
 0.43551255 0.43552296]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.4355892  0.43559451 0.43559548 0.43557862 0.43558558 0.43555511
 0.43555717 0.43551116 0.43548526 0.43549517 0.43548304 0.43549086
 0.43548706 0.43546318 0.43542787 0.43545109 0.43545478 0.43545654
 0.43546918 0.43546813]
[0.         0.         0.23684211]
-----------end of analyzing the loss ratio:75.69256520271301
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938fc6140>
---------------------------------
SparseEpoch: [146][1/398]	Time 0.578	Data 0.000	Loss 0.5220	
SparseEpoch: [146][101/398]	Time 0.579	Data 0.000	Loss 1.3670	
SparseEpoch: [146][201/398]	Time 0.580	Data 0.000	Loss 0.5450	
SparseEpoch: [146][301/398]	Time 0.580	Data 0.000	Loss 0.7280	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.33484318 0.33489551 0.33491959 0.33501916 0.3349428  0.33485584
 0.33476615 0.33474687 0.33468364 0.33469942 0.33475558 0.33475922
 0.33473936 0.3347379  0.33471391 0.33475943 0.33475427 0.33473932
 0.33481927 0.33482661]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.33479937 0.33480702 0.33479089 0.33475769 0.33474117 0.33470368
 0.33470514 0.33470513 0.33471935 0.33470956 0.33476683 0.33477061
 0.33474576 0.33477975 0.334767   0.33475626 0.33475023 0.33477286
 0.3347738  0.33476187]
[0. 0. 0.]
-----------end of analyzing the loss ratio:75.49932098388672
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938b47310>
---------------------------------
SparseEpoch: [146][1/398]	Time 0.577	Data 0.000	Loss 0.1988	
SparseEpoch: [146][101/398]	Time 0.579	Data 0.000	Loss 0.3384	
SparseEpoch: [146][201/398]	Time 0.579	Data 0.000	Loss 0.1902	
SparseEpoch: [146][301/398]	Time 0.579	Data 0.000	Loss 0.2443	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.14093881 0.14083606 0.1407368  0.14061588 0.14060635 0.14056926
 0.14045181 0.1403851  0.14029765 0.14026948 0.14014568 0.14003073
 0.13993053 0.13984661 0.13973517 0.13972813 0.13968517 0.1396951
 0.13965887 0.13960652]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.14038802 0.14035062 0.14033098 0.14032531 0.14033098 0.14032916
 0.14031033 0.1402965  0.14025401 0.14023349 0.14020147 0.14014676
 0.14012109 0.140091   0.14008402 0.14006738 0.14003039 0.14001853
 0.13998953 0.13997196]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:75.51148724555969
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc939ee6050>
---------------------------------
SparseEpoch: [146][1/398]	Time 0.581	Data 0.000	Loss 1.3759	
SparseEpoch: [146][101/398]	Time 0.581	Data 0.000	Loss 1.4193	
SparseEpoch: [146][201/398]	Time 0.581	Data 0.000	Loss 1.8748	
SparseEpoch: [146][301/398]	Time 0.581	Data 0.000	Loss 1.5638	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.7880	
Epoch(adapt):{0} Loss 0.6918	
Epoch(adapt):{0} Loss 0.8636	
Epoch(adapt):{0} Loss 1.2520	
------------------the total time cost:1166.5781359672546
>>>>>meta updating
Epoch: 0146 | TRAIN: 0.3902 0.7083 0.8694 | 0.3159 0.3159 0.1571 | 0.1183 22.5875 17.5705 0.3216 0.6215 0.7469 ||TEST: 1.2534 0.3975 0.6540 | 0.5212 0.5212 0.2075 | 0.1408 25.1916 20.3479 0.2798 0.5525 0.6825 | 116.5547
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.35198512 0.35197202 0.35193418 0.35196657 0.35192159 0.35188309
 0.35185978 0.35184473 0.35183976 0.35182179 0.35187779 0.35184989
 0.3518536  0.35183277 0.35191859 0.35188293 0.35188635 0.35188456
 0.35190096 0.35186281]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.35187272 0.35187601 0.35187748 0.35187441 0.3518773  0.35187494
 0.35187879 0.3518787  0.35188096 0.35188    0.3518797  0.35187762
 0.35187632 0.35187626 0.3518793  0.35187756 0.35187538 0.35187596
 0.35187217 0.35187542]
[0.         0.         0.44736842]
-----------end of analyzing the loss ratio:75.69309544563293
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938b45960>
---------------------------------
SparseEpoch: [147][1/398]	Time 0.579	Data 0.000	Loss 0.8451	
SparseEpoch: [147][101/398]	Time 0.581	Data 0.000	Loss 0.7888	
SparseEpoch: [147][201/398]	Time 0.580	Data 0.000	Loss 1.2512	
SparseEpoch: [147][301/398]	Time 0.581	Data 0.000	Loss 1.2660	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.57972685 0.5798332  0.57972047 0.57974064 0.57974688 0.57975692
 0.57983836 0.5797144  0.57972181 0.57962737 0.57967859 0.57965899
 0.57983014 0.57966473 0.579695   0.57957059 0.57958148 0.57966228
 0.5796237  0.5796982 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.57960772 0.5796075  0.57961477 0.57959664 0.57960842 0.57960797
 0.57960699 0.5796075  0.57961027 0.57961578 0.57962031 0.57962074
 0.57961635 0.57961456 0.57959774 0.57959341 0.57959353 0.57957532
 0.5795915  0.57960451]
[0.28947368 0.         0.39473684]
-----------end of analyzing the loss ratio:75.43044066429138
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cca5e211ed0>
---------------------------------
SparseEpoch: [147][1/398]	Time 0.580	Data 0.000	Loss 0.6288	
SparseEpoch: [147][101/398]	Time 0.582	Data 0.000	Loss 0.8653	
SparseEpoch: [147][201/398]	Time 0.581	Data 0.000	Loss 0.9037	
SparseEpoch: [147][301/398]	Time 0.582	Data 0.000	Loss 0.8550	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11053236 0.11054954 0.11055684 0.1105752  0.11057349 0.11058173
 0.11058323 0.1105946  0.11060429 0.11061918 0.11060967 0.11058871
 0.11058966 0.11058691 0.11059095 0.11055184 0.11054696 0.1105551
 0.11054265 0.11053827]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11058798 0.11059209 0.11058979 0.11059176 0.11059731 0.11060295
 0.11061598 0.11061916 0.11061296 0.11061653 0.11061662 0.1106213
 0.11062286 0.11063488 0.11062499 0.11062568 0.11062437 0.11061051
 0.11060242 0.11059613]
[0. 0. 0.]
-----------end of analyzing the loss ratio:75.43643736839294
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc89de6f5b0>
---------------------------------
SparseEpoch: [147][1/398]	Time 0.588	Data 0.000	Loss 1.2041	
SparseEpoch: [147][101/398]	Time 0.579	Data 0.000	Loss 1.4427	
SparseEpoch: [147][201/398]	Time 0.579	Data 0.000	Loss 0.8758	
SparseEpoch: [147][301/398]	Time 0.579	Data 0.000	Loss 1.1809	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.0799	
Epoch(adapt):{0} Loss 1.0040	
Epoch(adapt):{0} Loss 0.9546	
Epoch(adapt):{0} Loss 0.7231	
------------------the total time cost:1166.7508370876312
>>>>>meta updating
Epoch: 0147 | TRAIN: 0.4022 0.7087 0.8686 | 0.3279 0.3279 0.1568 | 0.1182 22.4137 17.2217 0.3312 0.6300 0.7513 ||TEST: 1.2183 0.3951 0.6542 | 0.5406 0.5406 0.2103 | 0.1411 25.0883 20.0747 0.2865 0.5590 0.6870 | 117.0990
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.40938689 0.4094615  0.40956667 0.4097248  0.40973043 0.40978348
 0.40982772 0.40976626 0.40974161 0.40964043 0.40967252 0.40970131
 0.40967897 0.40975143 0.40985792 0.40979402 0.40970726 0.40972898
 0.40978493 0.40972923]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.40964955 0.40965719 0.40965561 0.40965837 0.40964637 0.40964407
 0.40964529 0.4096393  0.40963003 0.40963408 0.40963213 0.40963033
 0.40963857 0.40963448 0.40964419 0.4096463  0.40966078 0.40965783
 0.40966164 0.40966395]
[0. 0. 0.]
-----------end of analyzing the loss ratio:75.65493154525757
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938947190>
---------------------------------
SparseEpoch: [148][1/398]	Time 0.577	Data 0.000	Loss 0.2729	
SparseEpoch: [148][101/398]	Time 0.579	Data 0.000	Loss 0.2264	
SparseEpoch: [148][201/398]	Time 0.579	Data 0.000	Loss 1.0598	
SparseEpoch: [148][301/398]	Time 0.579	Data 0.000	Loss 0.3314	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.39603783 0.39578275 0.39547745 0.39489734 0.39440365 0.39396399
 0.39366863 0.393255   0.39279248 0.39262403 0.39231969 0.39223994
 0.39216995 0.39202808 0.39193801 0.39206026 0.39191702 0.39162083
 0.39155889 0.39176721]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.39250001 0.39250347 0.39251537 0.3925227  0.39250899 0.39250539
 0.392508   0.392512   0.39250775 0.39248738 0.39246738 0.39245922
 0.3924525  0.39245611 0.39245609 0.39239994 0.39236945 0.39234987
 0.3923492  0.3923444 ]
[0.44736842 0.         0.5       ]
-----------end of analyzing the loss ratio:75.64353227615356
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc89de6cfa0>
---------------------------------
SparseEpoch: [148][1/398]	Time 0.586	Data 0.000	Loss 1.2843	
SparseEpoch: [148][101/398]	Time 0.581	Data 0.000	Loss 1.0656	
SparseEpoch: [148][201/398]	Time 0.581	Data 0.000	Loss 0.9346	
SparseEpoch: [148][301/398]	Time 0.581	Data 0.000	Loss 0.7535	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.10647587 0.10647931 0.10647424 0.10646892 0.10646783 0.10646139
 0.10645878 0.10645254 0.1064418  0.10643587 0.10643392 0.10644418
 0.1064486  0.10642176 0.10642192 0.10641806 0.10642743 0.1064132
 0.10642303 0.10642415]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.10645185 0.10644974 0.10644884 0.10645076 0.10644177 0.10644776
 0.10646082 0.10644947 0.10644228 0.10643762 0.10643467 0.10644403
 0.10642474 0.10642103 0.106422   0.1064313  0.10642499 0.10643666
 0.10643981 0.10646008]
[0.39473684 0.18421053 0.        ]
-----------end of analyzing the loss ratio:75.67998766899109
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9383706d0>
---------------------------------
SparseEpoch: [148][1/398]	Time 0.578	Data 0.000	Loss 0.6882	
SparseEpoch: [148][101/398]	Time 0.582	Data 0.000	Loss 1.6032	
SparseEpoch: [148][201/398]	Time 0.581	Data 0.000	Loss 1.2877	
SparseEpoch: [148][301/398]	Time 0.581	Data 0.000	Loss 1.3026	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.6762	
Epoch(adapt):{0} Loss 0.8450	
Epoch(adapt):{0} Loss 0.7535	
Epoch(adapt):{0} Loss 0.9786	
------------------the total time cost:1167.6942284107208
>>>>>meta updating
Epoch: 0148 | TRAIN: 0.3474 0.7458 0.8869 | 0.3112 0.3112 0.1565 | 0.1164 22.2257 17.0972 0.3356 0.6323 0.7538 ||TEST: 1.2570 0.4175 0.6678 | 0.5148 0.5148 0.2119 | 0.1410 25.0931 20.1175 0.2865 0.5575 0.6857 | 117.3110
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.35073005 0.35078218 0.3507191  0.35064295 0.35042396 0.35030296
 0.35039708 0.35053076 0.35052419 0.35036002 0.35012995 0.35025699
 0.35017088 0.35010818 0.35013676 0.35014493 0.35030655 0.35015698
 0.35017783 0.3502834 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.35033909 0.35033836 0.35031888 0.35028332 0.35025185 0.35025518
 0.35024875 0.35023298 0.35020203 0.35020451 0.35017197 0.35015591
 0.35016719 0.35016299 0.3501489  0.35013056 0.35012069 0.35014882
 0.35016663 0.35015769]
[0.         0.18421053 0.34210526]
-----------end of analyzing the loss ratio:75.661052942276
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938a19960>
---------------------------------
SparseEpoch: [149][1/398]	Time 0.578	Data 0.000	Loss 0.5713	
SparseEpoch: [149][101/398]	Time 0.580	Data 0.000	Loss 1.1632	
SparseEpoch: [149][201/398]	Time 0.581	Data 0.000	Loss 0.5613	
SparseEpoch: [149][301/398]	Time 0.581	Data 0.000	Loss 0.6540	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.38148822 0.38143997 0.3814356  0.38126578 0.38126462 0.38125551
 0.38132125 0.38138985 0.38138135 0.38135529 0.38140824 0.38133074
 0.38129501 0.3812867  0.38121075 0.3811411  0.38107345 0.38103697
 0.38102872 0.38101939]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.3813807  0.38137393 0.38135616 0.38135588 0.38134523 0.3813538
 0.38135688 0.38136283 0.38137771 0.38136129 0.38136863 0.38138983
 0.38141094 0.38139911 0.38138068 0.38137493 0.3813823  0.38139774
 0.38136815 0.38135163]
[0.5 0.  0. ]
-----------end of analyzing the loss ratio:75.60049629211426
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9382f1c00>
---------------------------------
SparseEpoch: [149][1/398]	Time 0.578	Data 0.000	Loss 0.3527	
SparseEpoch: [149][101/398]	Time 0.580	Data 0.000	Loss 0.4772	
SparseEpoch: [149][201/398]	Time 0.580	Data 0.000	Loss 0.5350	
SparseEpoch: [149][301/398]	Time 0.580	Data 0.000	Loss 0.9426	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.13706025 0.13705138 0.13703399 0.13702717 0.13702258 0.13702973
 0.13703855 0.13704084 0.13703867 0.1370451  0.13704214 0.13702158
 0.13701974 0.13701583 0.1369995  0.13699157 0.13697792 0.13698029
 0.13696847 0.13694952]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.13700246 0.13698542 0.13699194 0.13699986 0.1370077  0.13699843
 0.13700585 0.13703102 0.13706037 0.13703494 0.13704604 0.13703025
 0.13703111 0.13702804 0.13704626 0.13706393 0.13705048 0.13703985
 0.1370159  0.13699885]
[0.5 0.  0. ]
-----------end of analyzing the loss ratio:75.96819543838501
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938c6c520>
---------------------------------
SparseEpoch: [149][1/398]	Time 0.578	Data 0.000	Loss 1.8118	
SparseEpoch: [149][101/398]	Time 0.580	Data 0.000	Loss 1.9960	
SparseEpoch: [149][201/398]	Time 0.581	Data 0.000	Loss 1.4734	
SparseEpoch: [149][301/398]	Time 0.580	Data 0.000	Loss 1.4064	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.3593	
Epoch(adapt):{0} Loss 0.7823	
Epoch(adapt):{0} Loss 1.0046	
Epoch(adapt):{0} Loss 0.6547	
------------------the total time cost:1167.3660826683044
>>>>>meta updating
Epoch: 0149 | TRAIN: 0.3508 0.7395 0.8872 | 0.3061 0.3061 0.1517 | 0.1163 22.2925 17.2483 0.3292 0.6312 0.7546 ||TEST: 1.2592 0.4070 0.6666 | 0.5071 0.5071 0.2098 | 0.1405 25.1133 20.1753 0.2821 0.5562 0.6860 | 116.5746
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.34836863 0.34839802 0.34827309 0.3482531  0.34822943 0.3481702
 0.34818325 0.34816831 0.34813178 0.34808652 0.34802646 0.34805783
 0.34812325 0.34822236 0.34824902 0.34822956 0.34817823 0.34816766
 0.34810299 0.34798954]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.3481041  0.34809697 0.34809897 0.34809443 0.34810016 0.3480856
 0.34808031 0.34807709 0.34807801 0.34804033 0.34801739 0.34801781
 0.34802548 0.34802407 0.3480144  0.34799396 0.34799139 0.34799683
 0.34799403 0.34799705]
[0.         0.5        0.34210526]
-----------end of analyzing the loss ratio:75.47881984710693
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938f6c910>
---------------------------------
SparseEpoch: [150][1/398]	Time 0.586	Data 0.000	Loss 1.0598	
SparseEpoch: [150][101/398]	Time 0.581	Data 0.000	Loss 0.5991	
SparseEpoch: [150][201/398]	Time 0.580	Data 0.000	Loss 0.7056	
SparseEpoch: [150][301/398]	Time 0.581	Data 0.000	Loss 0.8381	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.30110597 0.30104514 0.30104434 0.30099143 0.30094022 0.30086014
 0.3008225  0.30071925 0.30061422 0.30052121 0.30048369 0.30038771
 0.3003396  0.30041795 0.30036994 0.30034138 0.30021963 0.30007938
 0.30013562 0.30005369]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.30052872 0.30050934 0.30050827 0.30049708 0.30049471 0.30047871
 0.30047345 0.30047745 0.30046483 0.30047692 0.30047961 0.30047271
 0.30049089 0.30048324 0.30049554 0.3004774  0.300465   0.30045999
 0.30046874 0.30047134]
[0.5        0.         0.39473684]
-----------end of analyzing the loss ratio:75.76942229270935
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938b47f10>
---------------------------------
SparseEpoch: [150][1/398]	Time 0.587	Data 0.000	Loss 1.0960	
SparseEpoch: [150][101/398]	Time 0.580	Data 0.000	Loss 0.8032	
SparseEpoch: [150][201/398]	Time 0.581	Data 0.000	Loss 1.1353	
SparseEpoch: [150][301/398]	Time 0.581	Data 0.000	Loss 0.7959	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.12224501 0.12224939 0.12228022 0.12228661 0.12226942 0.12226878
 0.12226117 0.12225058 0.12224107 0.12223751 0.12226365 0.12223246
 0.12220339 0.12220184 0.12218813 0.12218549 0.12216946 0.12217189
 0.12215803 0.12216992]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.12219924 0.12219847 0.12222167 0.12223161 0.12220206 0.12221088
 0.12222205 0.12223398 0.12224047 0.12225706 0.12224362 0.12220781
 0.12220846 0.12216634 0.12216905 0.12218894 0.12217836 0.12216685
 0.12217442 0.12216644]
[0.44736842 0.18421053 0.        ]
-----------end of analyzing the loss ratio:75.44362759590149
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9383d3880>
---------------------------------
SparseEpoch: [150][1/398]	Time 0.579	Data 0.000	Loss 1.5621	
SparseEpoch: [150][101/398]	Time 0.580	Data 0.000	Loss 1.6000	
SparseEpoch: [150][201/398]	Time 0.581	Data 0.000	Loss 1.2034	
SparseEpoch: [150][301/398]	Time 0.581	Data 0.000	Loss 1.4737	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.5986	
Epoch(adapt):{0} Loss 0.9552	
Epoch(adapt):{0} Loss 0.6089	
Epoch(adapt):{0} Loss 0.6372	
------------------the total time cost:1166.8602764606476
>>>>>meta updating
Epoch: 0150 | TRAIN: 0.3361 0.7501 0.8904 | 0.2975 0.2975 0.1503 | 0.1170 22.4063 17.3223 0.3258 0.6276 0.7515 ||TEST: 1.2700 0.4052 0.6688 | 0.5057 0.5057 0.2065 | 0.1414 25.1678 20.1944 0.2850 0.5555 0.6836 | 116.8973
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.39445486 0.39452259 0.39457362 0.39458791 0.3946003  0.39463475
 0.39465383 0.39459607 0.39465747 0.39461801 0.39466707 0.39474149
 0.39478843 0.39477459 0.39480949 0.39477796 0.39468467 0.39471134
 0.39472887 0.39475428]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.39473419 0.39472249 0.39470959 0.39469821 0.39466377 0.39468209
 0.39467529 0.39467222 0.39468412 0.39465647 0.39466396 0.39466372
 0.39464341 0.39462275 0.39460249 0.39463034 0.39461486 0.39463581
 0.39460211 0.39461725]
[0.         0.         0.44736842]
-----------end of analyzing the loss ratio:75.8007128238678
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc93822fb80>
---------------------------------
SparseEpoch: [151][1/398]	Time 0.578	Data 0.000	Loss 0.7077	
SparseEpoch: [151][101/398]	Time 0.580	Data 0.000	Loss 0.6610	
SparseEpoch: [151][201/398]	Time 0.580	Data 0.000	Loss 0.6983	
SparseEpoch: [151][301/398]	Time 0.580	Data 0.000	Loss 2.0032	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.49031439 0.49029112 0.49023024 0.49024498 0.49023817 0.49026588
 0.49031153 0.49029698 0.49027858 0.49022033 0.49025163 0.49018687
 0.49009407 0.4900988  0.49009274 0.49007428 0.49003641 0.49013495
 0.49016434 0.49009835]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.49030217 0.49030771 0.4903229  0.49031175 0.49033335 0.49030329
 0.49025631 0.49024817 0.49024751 0.49025334 0.49024601 0.49023612
 0.49023889 0.49020699 0.49019129 0.49020522 0.49017051 0.49015797
 0.49017711 0.49017928]
[0.34210526 0.         0.39473684]
-----------end of analyzing the loss ratio:75.89515852928162
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc89dff9ae0>
---------------------------------
SparseEpoch: [151][1/398]	Time 0.578	Data 0.000	Loss 0.7126	
SparseEpoch: [151][101/398]	Time 0.580	Data 0.000	Loss 0.9326	
SparseEpoch: [151][201/398]	Time 0.580	Data 0.000	Loss 0.7366	
SparseEpoch: [151][301/398]	Time 0.580	Data 0.000	Loss 0.9627	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11473116 0.11472816 0.11471525 0.11471148 0.11471357 0.11468949
 0.11469052 0.11467499 0.11468846 0.11468535 0.11468989 0.11470269
 0.11469592 0.11468356 0.11468363 0.11469021 0.11468561 0.11468866
 0.11466181 0.11465572]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11473358 0.11473616 0.11473299 0.11473829 0.11473771 0.11472883
 0.11472113 0.11471809 0.1147076  0.11468986 0.11468488 0.11468558
 0.11468759 0.11469833 0.11469561 0.11468112 0.11467252 0.11465797
 0.11465759 0.11465824]
[0.5        0.44736842 0.        ]
-----------end of analyzing the loss ratio:76.02107262611389
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938dd8ca0>
---------------------------------
SparseEpoch: [151][1/398]	Time 0.587	Data 0.000	Loss 1.4718	
SparseEpoch: [151][101/398]	Time 0.580	Data 0.000	Loss 1.5068	
SparseEpoch: [151][201/398]	Time 0.580	Data 0.000	Loss 1.5741	
SparseEpoch: [151][301/398]	Time 0.580	Data 0.000	Loss 1.7293	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.8840	
Epoch(adapt):{0} Loss 1.8062	
Epoch(adapt):{0} Loss 1.1202	
Epoch(adapt):{0} Loss 0.6378	
------------------the total time cost:1167.4510383605957
>>>>>meta updating
Epoch: 0151 | TRAIN: 0.3327 0.7603 0.8928 | 0.3134 0.3134 0.1471 | 0.1135 21.8545 16.5848 0.3434 0.6446 0.7632 ||TEST: 1.2689 0.4055 0.6634 | 0.5257 0.5257 0.2061 | 0.1405 24.9198 19.6603 0.2937 0.5666 0.6917 | 116.6289
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.29502336 0.29506796 0.29510136 0.2951337  0.29509681 0.29505096
 0.2950131  0.29500623 0.29500188 0.29495889 0.29498692 0.29501698
 0.29500335 0.29504037 0.29503254 0.29503272 0.2950043  0.29499166
 0.29500587 0.29506346]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.29496464 0.29496547 0.29496794 0.29497544 0.29499363 0.29497706
 0.29498152 0.29497269 0.29493978 0.29494254 0.29496584 0.29498303
 0.29498915 0.29499775 0.29500085 0.29501709 0.29503151 0.29504403
 0.29504123 0.29503744]
[0. 0. 0.]
-----------end of analyzing the loss ratio:75.88263416290283
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9382f2d40>
---------------------------------
SparseEpoch: [152][1/398]	Time 0.579	Data 0.000	Loss 0.1994	
SparseEpoch: [152][101/398]	Time 0.580	Data 0.000	Loss 0.3115	
SparseEpoch: [152][201/398]	Time 0.580	Data 0.000	Loss 0.2024	
SparseEpoch: [152][301/398]	Time 0.579	Data 0.000	Loss 0.4528	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.30782268 0.30791084 0.30791283 0.30790094 0.30782663 0.30785815
 0.30780749 0.30779707 0.30785394 0.30784881 0.30782032 0.30784602
 0.30788419 0.30784121 0.30784709 0.30788074 0.30786898 0.30786387
 0.30786793 0.30785948]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.30792742 0.30793751 0.30795167 0.30793414 0.30794313 0.30791149
 0.30791082 0.30787826 0.30786466 0.30785998 0.30785202 0.30786937
 0.30787679 0.30787705 0.30786747 0.30786387 0.30784623 0.30782847
 0.30784974 0.3078079 ]
[0.  0.  0.5]
-----------end of analyzing the loss ratio:75.62008905410767
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938a48fd0>
---------------------------------
SparseEpoch: [152][1/398]	Time 0.577	Data 0.000	Loss 1.2018	
SparseEpoch: [152][101/398]	Time 0.579	Data 0.000	Loss 1.0458	
SparseEpoch: [152][201/398]	Time 0.579	Data 0.000	Loss 0.7610	
SparseEpoch: [152][301/398]	Time 0.579	Data 0.000	Loss 0.9360	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.12526114 0.12527456 0.12525287 0.12522669 0.12522861 0.12522389
 0.1252274  0.12521482 0.12519654 0.12518315 0.12518064 0.1252042
 0.1251973  0.12520556 0.12520242 0.12521552 0.12523819 0.12524477
 0.12522342 0.12520387]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.12529    0.1252878  0.12525136 0.12522753 0.12522463 0.12522265
 0.12520506 0.12522089 0.12522098 0.12518651 0.12518449 0.12518523
 0.12517807 0.12522238 0.12523115 0.1252111  0.12521332 0.12518764
 0.12516636 0.12512884]
[0.02631579 0.5        0.        ]
-----------end of analyzing the loss ratio:75.61579418182373
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9399477c0>
---------------------------------
SparseEpoch: [152][1/398]	Time 0.580	Data 0.000	Loss 1.0820	
SparseEpoch: [152][101/398]	Time 0.580	Data 0.000	Loss 1.9112	
SparseEpoch: [152][201/398]	Time 0.580	Data 0.000	Loss 1.3550	
SparseEpoch: [152][301/398]	Time 0.580	Data 0.000	Loss 1.3507	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.6572	
Epoch(adapt):{0} Loss 0.4409	
Epoch(adapt):{0} Loss 1.3149	
Epoch(adapt):{0} Loss 0.7051	
------------------the total time cost:1166.5034770965576
>>>>>meta updating
Epoch: 0152 | TRAIN: 0.3938 0.7065 0.8690 | 0.3072 0.3072 0.1480 | 0.1173 22.4983 17.5054 0.3208 0.6240 0.7495 ||TEST: 1.2541 0.3901 0.6528 | 0.5253 0.5253 0.2071 | 0.1408 25.2370 20.4578 0.2773 0.5502 0.6808 | 117.3767
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.38145146 0.38144284 0.38147102 0.38147475 0.38145434 0.38144519
 0.38142892 0.38144149 0.38141697 0.3814486  0.38147439 0.38144487
 0.38140496 0.38137445 0.38131051 0.38135864 0.38138538 0.38142643
 0.38137321 0.3813712 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.38137277 0.38138353 0.3813863  0.38140118 0.38141791 0.38140675
 0.38144402 0.38143806 0.38144083 0.38147942 0.38145815 0.38145036
 0.38146286 0.38147818 0.38147224 0.38149812 0.38149869 0.38148408
 0.38148469 0.38146382]
[0.         0.23684211 0.        ]
-----------end of analyzing the loss ratio:75.57021641731262
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc93850b0a0>
---------------------------------
SparseEpoch: [153][1/398]	Time 0.578	Data 0.000	Loss 0.3431	
SparseEpoch: [153][101/398]	Time 0.580	Data 0.000	Loss 0.5327	
SparseEpoch: [153][201/398]	Time 0.580	Data 0.000	Loss 0.4493	
SparseEpoch: [153][301/398]	Time 0.580	Data 0.000	Loss 0.3893	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.28171913 0.28170131 0.28174565 0.28174593 0.28180885 0.28187809
 0.28184308 0.28188837 0.2818837  0.28190071 0.28196005 0.28203678
 0.28208605 0.28213675 0.2821964  0.282171   0.28215059 0.2821723
 0.28229041 0.28234826]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.28200581 0.28198867 0.28200018 0.28199455 0.2819969  0.28199222
 0.28198436 0.28195286 0.28194197 0.2819363  0.28193793 0.28193751
 0.28194242 0.28193041 0.28192071 0.28192415 0.28192426 0.28191535
 0.28191284 0.28187854]
[0.  0.  0.5]
-----------end of analyzing the loss ratio:75.80100321769714
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc89df1ebc0>
---------------------------------
SparseEpoch: [153][1/398]	Time 0.578	Data 0.000	Loss 0.6259	
SparseEpoch: [153][101/398]	Time 0.580	Data 0.000	Loss 0.8970	
SparseEpoch: [153][201/398]	Time 0.580	Data 0.000	Loss 0.7112	
SparseEpoch: [153][301/398]	Time 0.580	Data 0.000	Loss 0.7427	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.12406657 0.12405837 0.12405764 0.12405362 0.12406244 0.12406564
 0.12406089 0.12407701 0.12406384 0.12405164 0.12404751 0.12405697
 0.12406225 0.12404678 0.12403285 0.12403314 0.12403136 0.12404733
 0.12404374 0.12403238]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.12404695 0.12404906 0.12405341 0.1240562  0.12406535 0.12405936
 0.12405495 0.12404628 0.1240449  0.12404236 0.12404417 0.1240508
 0.12404448 0.12405131 0.12405222 0.1240472  0.12405736 0.12405781
 0.12404646 0.12404854]
[0.34210526 0.         0.        ]
-----------end of analyzing the loss ratio:75.47544479370117
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938a8ebc0>
---------------------------------
SparseEpoch: [153][1/398]	Time 0.579	Data 0.000	Loss 0.9908	
SparseEpoch: [153][101/398]	Time 0.581	Data 0.000	Loss 1.3938	
SparseEpoch: [153][201/398]	Time 0.580	Data 0.000	Loss 1.2468	
SparseEpoch: [153][301/398]	Time 0.580	Data 0.000	Loss 1.4210	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.4693	
Epoch(adapt):{0} Loss 0.7621	
Epoch(adapt):{0} Loss 0.7384	
Epoch(adapt):{0} Loss 0.5876	
------------------the total time cost:1166.7622117996216
>>>>>meta updating
Epoch: 0153 | TRAIN: 0.3320 0.7467 0.8901 | 0.3045 0.3045 0.1494 | 0.1147 22.0871 16.9640 0.3331 0.6379 0.7594 ||TEST: 1.2670 0.4055 0.6646 | 0.5123 0.5123 0.2078 | 0.1410 25.1115 20.1477 0.2848 0.5570 0.6863 | 116.8125
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.26721817 0.26715142 0.26714657 0.26712454 0.26715857 0.26719721
 0.26716144 0.26709767 0.2671085  0.26714545 0.26720205 0.26721267
 0.26717976 0.26720019 0.26719404 0.26720952 0.26713374 0.26712469
 0.26711908 0.26713653]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.26715958 0.26717107 0.26716742 0.26715858 0.26715014 0.26714525
 0.26714704 0.26713117 0.26712719 0.26712284 0.26712711 0.26712686
 0.26713007 0.26713051 0.26712763 0.2671344  0.26714328 0.26715028
 0.26714262 0.26713841]
[0. 0. 0.]
-----------end of analyzing the loss ratio:75.71890902519226
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938b68550>
---------------------------------
SparseEpoch: [154][1/398]	Time 0.577	Data 0.000	Loss 0.1265	
SparseEpoch: [154][101/398]	Time 0.579	Data 0.000	Loss 0.4821	
SparseEpoch: [154][201/398]	Time 0.579	Data 0.000	Loss 0.3630	
SparseEpoch: [154][301/398]	Time 0.579	Data 0.000	Loss 0.4307	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.32949049 0.32944385 0.32941915 0.32945203 0.32940528 0.32939718
 0.32939417 0.32931361 0.32923642 0.32915434 0.32917051 0.32905955
 0.32885311 0.32877681 0.32868641 0.32863782 0.32871754 0.32868991
 0.32867614 0.32862323]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.32911814 0.32913412 0.32911293 0.32912161 0.32911233 0.32908705
 0.32910768 0.32911524 0.32911588 0.32913087 0.32913556 0.32912757
 0.32914207 0.32918963 0.32918462 0.32917119 0.3291447  0.32915127
 0.32916491 0.32914664]
[0.5 0.  0. ]
-----------end of analyzing the loss ratio:75.55324721336365
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938d594e0>
---------------------------------
SparseEpoch: [154][1/398]	Time 0.579	Data 0.000	Loss 0.2889	
SparseEpoch: [154][101/398]	Time 0.580	Data 0.000	Loss 0.3846	
SparseEpoch: [154][201/398]	Time 0.580	Data 0.000	Loss 0.3818	
SparseEpoch: [154][301/398]	Time 0.580	Data 0.000	Loss 0.5522	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.12844642 0.12842148 0.12839088 0.12836816 0.12837085 0.12831705
 0.12835102 0.12833742 0.12831133 0.12828074 0.12826285 0.12824482
 0.12821934 0.12816978 0.12816461 0.12813817 0.12814013 0.12811286
 0.12807052 0.12807573]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.12842444 0.12839496 0.12837244 0.12834587 0.12831821 0.12834972
 0.12831439 0.1283516  0.12830588 0.12829171 0.1282626  0.12824525
 0.12819818 0.12818643 0.12814085 0.12812296 0.12810089 0.12811713
 0.12812283 0.12812634]
[0.44736842 0.34210526 0.        ]
-----------end of analyzing the loss ratio:75.63890814781189
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc93820b7c0>
---------------------------------
SparseEpoch: [154][1/398]	Time 0.578	Data 0.000	Loss 1.5490	
SparseEpoch: [154][101/398]	Time 0.580	Data 0.000	Loss 1.3668	
SparseEpoch: [154][201/398]	Time 0.581	Data 0.000	Loss 1.8361	
SparseEpoch: [154][301/398]	Time 0.581	Data 0.000	Loss 1.7663	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.5022	
Epoch(adapt):{0} Loss 0.9957	
Epoch(adapt):{0} Loss 0.6254	
Epoch(adapt):{0} Loss 0.9341	
------------------the total time cost:1165.7827804088593
>>>>>meta updating
Epoch: 0154 | TRAIN: 0.3653 0.7269 0.8771 | 0.2975 0.2975 0.1477 | 0.1172 22.3467 17.2626 0.3308 0.6280 0.7518 ||TEST: 1.2459 0.4036 0.6624 | 0.5159 0.5159 0.2065 | 0.1419 25.2045 20.3118 0.2857 0.5525 0.6812 | 116.7344
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.37769928 0.37772146 0.37769269 0.37762545 0.37766375 0.3777471
 0.37776566 0.37788496 0.37784815 0.37776287 0.37780452 0.3779213
 0.37793301 0.37794034 0.37790918 0.37779838 0.37785837 0.37795084
 0.37796692 0.37798111]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.37793819 0.37794974 0.37793216 0.37794634 0.37792816 0.37790373
 0.37784927 0.37786623 0.37781061 0.37779879 0.37776103 0.37778641
 0.37776482 0.37780591 0.37782639 0.37781269 0.37780066 0.37781784
 0.37780873 0.37779374]
[0.         0.         0.02631579]
-----------end of analyzing the loss ratio:75.63442134857178
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9382d1450>
---------------------------------
SparseEpoch: [155][1/398]	Time 0.578	Data 0.000	Loss 0.5193	
SparseEpoch: [155][101/398]	Time 0.580	Data 0.000	Loss 0.4520	
SparseEpoch: [155][201/398]	Time 0.580	Data 0.000	Loss 0.5875	
SparseEpoch: [155][301/398]	Time 0.580	Data 0.000	Loss 0.1913	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.44374801 0.44370865 0.44372044 0.44373788 0.4437087  0.44382162
 0.44387208 0.44392598 0.44396418 0.44393083 0.44393394 0.44396055
 0.44398817 0.44393829 0.4439925  0.44407159 0.44397143 0.44398923
 0.44396875 0.44405231]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.44395081 0.44394434 0.4439402  0.44394211 0.44394792 0.4439324
 0.44393775 0.44394303 0.44396949 0.44396358 0.44395455 0.44395019
 0.44393856 0.44394445 0.44394611 0.44394549 0.44393426 0.4439047
 0.44389819 0.44388857]
[0.  0.  0.5]
-----------end of analyzing the loss ratio:75.62575149536133
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938b7e4d0>
---------------------------------
SparseEpoch: [155][1/398]	Time 0.578	Data 0.000	Loss 0.7741	
SparseEpoch: [155][101/398]	Time 0.580	Data 0.000	Loss 0.7912	
SparseEpoch: [155][201/398]	Time 0.579	Data 0.000	Loss 0.7793	
SparseEpoch: [155][301/398]	Time 0.579	Data 0.000	Loss 0.5928	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.1147318  0.11472329 0.11474341 0.11472008 0.1147018  0.1147024
 0.11466776 0.1146429  0.11461388 0.11462194 0.11461335 0.114594
 0.11460819 0.11455351 0.11453899 0.11452635 0.11448652 0.11447031
 0.11445131 0.11443608]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.1147431  0.11472316 0.11474044 0.11469944 0.11469525 0.11468527
 0.11466737 0.11464329 0.11462034 0.11462302 0.11461155 0.11458779
 0.11460862 0.11457062 0.11455177 0.1145461  0.11449968 0.11446968
 0.11445268 0.11444532]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:75.74290490150452
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc89de12710>
---------------------------------
SparseEpoch: [155][1/398]	Time 0.578	Data 0.000	Loss 1.0928	
SparseEpoch: [155][101/398]	Time 0.581	Data 0.000	Loss 1.0817	
SparseEpoch: [155][201/398]	Time 0.581	Data 0.000	Loss 1.2695	
SparseEpoch: [155][301/398]	Time 0.581	Data 0.000	Loss 1.6022	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.6939	
Epoch(adapt):{0} Loss 0.6082	
Epoch(adapt):{0} Loss 0.5201	
Epoch(adapt):{0} Loss 0.7356	
------------------the total time cost:1167.8284466266632
>>>>>meta updating
Epoch: 0155 | TRAIN: 0.3276 0.7527 0.8937 | 0.2968 0.2968 0.1450 | 0.1129 21.8228 16.6293 0.3449 0.6426 0.7617 ||TEST: 1.2744 0.4078 0.6678 | 0.5210 0.5210 0.2115 | 0.1406 25.0033 19.9192 0.2900 0.5617 0.6883 | 116.9578
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.30253211 0.30254272 0.30258244 0.30258298 0.30256692 0.30257899
 0.30256886 0.30262574 0.30257911 0.30259013 0.30256642 0.3025556
 0.30261292 0.30266759 0.30263201 0.30262727 0.30264531 0.30267276
 0.30264834 0.30270899]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.30259427 0.30256314 0.30256759 0.30258005 0.30254819 0.30254328
 0.30258671 0.30259556 0.30259755 0.30256959 0.30256659 0.30258494
 0.30256879 0.30256663 0.30258486 0.30259652 0.30260192 0.30257896
 0.30260522 0.30261213]
[0. 0. 0.]
-----------end of analyzing the loss ratio:75.64194393157959
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938931300>
---------------------------------
SparseEpoch: [156][1/398]	Time 0.585	Data 0.000	Loss 0.1871	
SparseEpoch: [156][101/398]	Time 0.580	Data 0.000	Loss 0.5940	
SparseEpoch: [156][201/398]	Time 0.579	Data 0.000	Loss 0.3564	
SparseEpoch: [156][301/398]	Time 0.579	Data 0.000	Loss 0.2855	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.31208268 0.31201961 0.31202374 0.31193707 0.3118533  0.31178004
 0.31182546 0.31165089 0.31151446 0.31139863 0.31133346 0.31135126
 0.31124565 0.31117385 0.31107399 0.31090741 0.31087335 0.3108446
 0.31085977 0.31080187]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.31159437 0.31155474 0.31156103 0.31151457 0.31144294 0.31141081
 0.31140802 0.31138015 0.3113545  0.3113581  0.31133326 0.31133042
 0.31134947 0.31136982 0.31133428 0.3113587  0.3113852  0.31134023
 0.31127114 0.31126755]
[0.5 0.  0.5]
-----------end of analyzing the loss ratio:75.75172448158264
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc93856e1d0>
---------------------------------
SparseEpoch: [156][1/398]	Time 0.579	Data 0.000	Loss 0.9336	
SparseEpoch: [156][101/398]	Time 0.580	Data 0.000	Loss 0.9482	
SparseEpoch: [156][201/398]	Time 0.580	Data 0.000	Loss 0.9012	
SparseEpoch: [156][301/398]	Time 0.580	Data 0.000	Loss 0.9563	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.1125945  0.1125938  0.1125843  0.11255546 0.11254872 0.11253006
 0.11252289 0.11251844 0.11251969 0.11251307 0.11250008 0.11248232
 0.11247488 0.11246771 0.11245144 0.11242934 0.11241714 0.11241332
 0.11241804 0.11242788]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11248485 0.11249447 0.11249328 0.11249679 0.1124959  0.11249393
 0.11248572 0.11248435 0.11248606 0.11247982 0.11247642 0.11248759
 0.11248801 0.11248897 0.11248817 0.11248791 0.11249681 0.11249167
 0.11248974 0.11249429]
[0.39473684 0.02631579 0.        ]
-----------end of analyzing the loss ratio:75.47971892356873
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938c408b0>
---------------------------------
SparseEpoch: [156][1/398]	Time 0.580	Data 0.000	Loss 1.0465	
SparseEpoch: [156][101/398]	Time 0.581	Data 0.000	Loss 1.2677	
SparseEpoch: [156][201/398]	Time 0.581	Data 0.000	Loss 0.5717	
SparseEpoch: [156][301/398]	Time 0.581	Data 0.000	Loss 1.3208	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.3666	
Epoch(adapt):{0} Loss 0.6192	
Epoch(adapt):{0} Loss 0.4670	
Epoch(adapt):{0} Loss 0.5737	
------------------the total time cost:1166.8731191158295
>>>>>meta updating
Epoch: 0156 | TRAIN: 0.3341 0.7517 0.8894 | 0.2935 0.2935 0.1464 | 0.1138 21.9342 16.8043 0.3416 0.6398 0.7599 ||TEST: 1.2867 0.4103 0.6635 | 0.5173 0.5173 0.2106 | 0.1403 25.0304 20.0282 0.2874 0.5591 0.6866 | 117.3586
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.39208768 0.39218626 0.3922075  0.39233426 0.39229338 0.39218768
 0.39228722 0.39221185 0.3923104  0.39232358 0.39231659 0.39225485
 0.39222629 0.39230675 0.39218666 0.39228213 0.39242122 0.39237952
 0.39240867 0.39236187]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.3923311  0.39233097 0.39230307 0.39231537 0.39232128 0.39231071
 0.39232253 0.39231102 0.39232609 0.39233865 0.39237364 0.3923512
 0.39237083 0.39236007 0.39237931 0.39237634 0.39236456 0.3923331
 0.39235239 0.39237404]
[0. 0. 0.]
-----------end of analyzing the loss ratio:75.42940068244934
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938d3ec20>
---------------------------------
SparseEpoch: [157][1/398]	Time 0.577	Data 0.000	Loss 0.2235	
SparseEpoch: [157][101/398]	Time 0.580	Data 0.000	Loss 0.5419	
SparseEpoch: [157][201/398]	Time 0.579	Data 0.000	Loss 0.7246	
SparseEpoch: [157][301/398]	Time 0.579	Data 0.000	Loss 0.1953	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.36328731 0.36318624 0.36308336 0.36300288 0.36305248 0.3629511
 0.3629316  0.36287935 0.36286887 0.36289459 0.36290369 0.36293081
 0.36289829 0.36291666 0.36290771 0.36277898 0.36286146 0.36290891
 0.36283358 0.36277028]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.3628496  0.3628573  0.36284688 0.36285238 0.36285685 0.36284449
 0.36284423 0.36282897 0.36282939 0.36282732 0.36285465 0.36288742
 0.36289408 0.3628969  0.36289166 0.36289629 0.36290309 0.36290644
 0.36294163 0.36292678]
[0.5 0.  0. ]
-----------end of analyzing the loss ratio:75.82497215270996
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938b7d300>
---------------------------------
SparseEpoch: [157][1/398]	Time 0.578	Data 0.000	Loss 0.6200	
SparseEpoch: [157][101/398]	Time 0.579	Data 0.000	Loss 0.3977	
SparseEpoch: [157][201/398]	Time 0.579	Data 0.000	Loss 0.5593	
SparseEpoch: [157][301/398]	Time 0.579	Data 0.000	Loss 0.5283	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.12296883 0.12296298 0.1229516  0.12297218 0.12296837 0.12297813
 0.122984   0.12297758 0.12298654 0.12298967 0.1230031  0.12301505
 0.12302172 0.12303743 0.12304831 0.12306731 0.12303922 0.12305068
 0.12304742 0.12304935]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.12295931 0.12296541 0.12296326 0.12295865 0.12296321 0.12296395
 0.12297537 0.12296607 0.12297272 0.12299581 0.12301842 0.12301018
 0.12301584 0.12303914 0.1230205  0.1230332  0.12304874 0.12306525
 0.12305307 0.12305072]
[0. 0. 0.]
-----------end of analyzing the loss ratio:75.67619490623474
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9382f09d0>
---------------------------------
SparseEpoch: [157][1/398]	Time 0.576	Data 0.000	Loss 2.0547	
SparseEpoch: [157][101/398]	Time 0.579	Data 0.000	Loss 1.1252	
SparseEpoch: [157][201/398]	Time 0.579	Data 0.000	Loss 1.0551	
SparseEpoch: [157][301/398]	Time 0.579	Data 0.000	Loss 1.2905	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.7182	
Epoch(adapt):{0} Loss 0.6367	
Epoch(adapt):{0} Loss 0.3686	
Epoch(adapt):{0} Loss 1.0082	
------------------the total time cost:1165.9301421642303
>>>>>meta updating
Epoch: 0157 | TRAIN: 0.3177 0.7666 0.8970 | 0.2999 0.2999 0.1427 | 0.1151 22.1460 17.1045 0.3324 0.6337 0.7572 ||TEST: 1.2697 0.4132 0.6689 | 0.5190 0.5190 0.2074 | 0.1421 25.2452 20.3467 0.2841 0.5516 0.6807 | 116.6059
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.33709352 0.33705672 0.33703176 0.33705407 0.33704579 0.33707621
 0.33710114 0.33711535 0.33710571 0.33706264 0.33705561 0.33695206
 0.33696895 0.33698432 0.33695093 0.3369374  0.33691791 0.33685755
 0.33681456 0.33679746]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.33709235 0.33709684 0.33708894 0.33708809 0.33708951 0.33708109
 0.33708672 0.33706941 0.33707119 0.3370969  0.33708096 0.3371109
 0.33708665 0.33706609 0.33704449 0.33696773 0.33698081 0.33697893
 0.33700202 0.33698632]
[0.         0.5        0.28947368]
-----------end of analyzing the loss ratio:75.67379426956177
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938d58940>
---------------------------------
SparseEpoch: [158][1/398]	Time 0.580	Data 0.000	Loss 1.0623	
SparseEpoch: [158][101/398]	Time 0.581	Data 0.000	Loss 1.0142	
SparseEpoch: [158][201/398]	Time 0.581	Data 0.000	Loss 0.6962	
SparseEpoch: [158][301/398]	Time 0.581	Data 0.000	Loss 0.6672	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.33303397 0.33306537 0.33304406 0.33305555 0.33302697 0.33285799
 0.33299372 0.3331901  0.33326889 0.33355122 0.333785   0.33393324
 0.33403274 0.3344053  0.33463043 0.33489849 0.33522394 0.33558551
 0.33595843 0.3364405 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.33364909 0.33367207 0.33368495 0.33369869 0.33370087 0.33370263
 0.33371609 0.33371871 0.33373746 0.33369869 0.33370672 0.33371949
 0.33371724 0.3337182  0.3337203  0.3337081  0.33371515 0.33372657
 0.33373168 0.33372022]
[0. 0. 0.]
-----------end of analyzing the loss ratio:75.69392156600952
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9382c6d10>
---------------------------------
SparseEpoch: [158][1/398]	Time 0.578	Data 0.000	Loss 0.3132	
SparseEpoch: [158][101/398]	Time 0.578	Data 0.000	Loss 0.3512	
SparseEpoch: [158][201/398]	Time 0.579	Data 0.000	Loss 0.3924	
SparseEpoch: [158][301/398]	Time 0.579	Data 0.000	Loss 0.3419	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.13002294 0.13001449 0.1299192  0.12988114 0.12984997 0.12984113
 0.12982097 0.12979866 0.12977916 0.12976055 0.12977701 0.12975821
 0.12970601 0.12965028 0.12961636 0.12959313 0.12957181 0.12957984
 0.12957504 0.12953178]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.12977962 0.12976564 0.12978119 0.12977467 0.12978069 0.12978731
 0.1297624  0.12976066 0.12976264 0.12978393 0.12977033 0.12976767
 0.12978017 0.12978438 0.12977006 0.12975894 0.12975228 0.12975516
 0.12974741 0.12973006]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:75.68348550796509
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9386a6080>
---------------------------------
SparseEpoch: [158][1/398]	Time 0.578	Data 0.000	Loss 1.6295	
SparseEpoch: [158][101/398]	Time 0.580	Data 0.000	Loss 1.6593	
SparseEpoch: [158][201/398]	Time 0.580	Data 0.000	Loss 1.3570	
SparseEpoch: [158][301/398]	Time 0.580	Data 0.000	Loss 1.4078	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.5782	
Epoch(adapt):{0} Loss 0.8614	
Epoch(adapt):{0} Loss 0.4937	
Epoch(adapt):{0} Loss 0.5832	
------------------the total time cost:1166.7430777549744
>>>>>meta updating
Epoch: 0158 | TRAIN: 0.3195 0.7655 0.8976 | 0.2946 0.2946 0.1488 | 0.1121 21.7240 16.5609 0.3459 0.6449 0.7643 ||TEST: 1.2546 0.4155 0.6704 | 0.5090 0.5090 0.2066 | 0.1411 25.0493 19.9951 0.2903 0.5595 0.6862 | 116.6793
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.36175853 0.36192775 0.36199843 0.36211081 0.36211588 0.36211347
 0.36208881 0.36211211 0.36232889 0.36210881 0.36216377 0.3621933
 0.36220909 0.36219083 0.36224563 0.36230816 0.36224247 0.36221763
 0.36219559 0.36217443]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.36204152 0.36205978 0.36208791 0.36210432 0.36212679 0.36212603
 0.36213222 0.36211133 0.36213834 0.36212871 0.36213102 0.36215638
 0.36215439 0.36218609 0.36218529 0.36218538 0.36220153 0.36219964
 0.36221744 0.36223629]
[0. 0. 0.]
-----------end of analyzing the loss ratio:75.56553316116333
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9384fe380>
---------------------------------
SparseEpoch: [159][1/398]	Time 0.577	Data 0.000	Loss 0.2890	
SparseEpoch: [159][101/398]	Time 0.580	Data 0.000	Loss 0.3224	
SparseEpoch: [159][201/398]	Time 0.580	Data 0.000	Loss 0.4123	
SparseEpoch: [159][301/398]	Time 0.579	Data 0.000	Loss 0.3575	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.48013915 0.48015838 0.48022495 0.4802781  0.48036294 0.48036812
 0.48035216 0.48040792 0.48047953 0.48057992 0.4805422  0.480556
 0.480583   0.48059562 0.48067913 0.48084712 0.48084976 0.48073978
 0.48087362 0.48091228]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.48055807 0.48056239 0.48053301 0.48053749 0.48057269 0.48056591
 0.48054385 0.48054523 0.4805512  0.48054821 0.48057941 0.48059402
 0.48059382 0.4805858  0.48056384 0.48055252 0.48052228 0.48053614
 0.48052782 0.48052042]
[0.  0.  0.5]
-----------end of analyzing the loss ratio:75.66566944122314
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938b7d2a0>
---------------------------------
SparseEpoch: [159][1/398]	Time 0.577	Data 0.000	Loss 1.1996	
SparseEpoch: [159][101/398]	Time 0.580	Data 0.000	Loss 0.9951	
SparseEpoch: [159][201/398]	Time 0.579	Data 0.000	Loss 1.3904	
SparseEpoch: [159][301/398]	Time 0.580	Data 0.000	Loss 0.5848	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.12220988 0.12221925 0.1222308  0.12223076 0.1222159  0.12221834
 0.12225547 0.12224295 0.12226627 0.12224788 0.1222678  0.12228901
 0.12230937 0.12235614 0.12235518 0.12236164 0.12239212 0.12237105
 0.12237436 0.12237998]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.12223874 0.12224269 0.12224846 0.12226368 0.12227119 0.12226537
 0.12225868 0.12224914 0.1222581  0.12224467 0.12224762 0.1222519
 0.12224761 0.12225575 0.12225707 0.12225864 0.12226726 0.12226828
 0.12228389 0.12229453]
[0. 0. 0.]
-----------end of analyzing the loss ratio:76.19375848770142
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938fa9660>
---------------------------------
SparseEpoch: [159][1/398]	Time 0.579	Data 0.000	Loss 0.9179	
SparseEpoch: [159][101/398]	Time 0.578	Data 0.000	Loss 1.2296	
SparseEpoch: [159][201/398]	Time 0.579	Data 0.000	Loss 1.5528	
SparseEpoch: [159][301/398]	Time 0.579	Data 0.000	Loss 1.6026	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.8230	
Epoch(adapt):{0} Loss 0.7024	
Epoch(adapt):{0} Loss 0.5721	
Epoch(adapt):{0} Loss 0.4799	
------------------the total time cost:1166.980842590332
>>>>>meta updating
Epoch: 0159 | TRAIN: 0.3137 0.7719 0.8993 | 0.3027 0.3027 0.1574 | 0.1143 22.0181 16.9252 0.3361 0.6384 0.7603 ||TEST: 1.2634 0.4169 0.6704 | 0.5114 0.5114 0.2138 | 0.1413 25.0990 20.0577 0.2881 0.5585 0.6852 | 116.7961
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.3149258  0.31496246 0.31499592 0.31500036 0.31497505 0.31500344
 0.31500144 0.31500144 0.31500216 0.31501539 0.31495997 0.31500759
 0.31505715 0.31504508 0.31501768 0.31501119 0.3149883  0.31499245
 0.31497132 0.31495945]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.31504651 0.31506744 0.31507006 0.31506356 0.31509761 0.31509067
 0.31508825 0.31502236 0.31501556 0.31501593 0.31501416 0.3149723
 0.3149555  0.31498353 0.31500009 0.31497614 0.31496963 0.31495894
 0.31490692 0.31489609]
[0.  0.  0.5]
-----------end of analyzing the loss ratio:75.77064251899719
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9386a49d0>
---------------------------------
SparseEpoch: [160][1/398]	Time 0.581	Data 0.000	Loss 1.0571	
SparseEpoch: [160][101/398]	Time 0.580	Data 0.000	Loss 0.7919	
SparseEpoch: [160][201/398]	Time 0.580	Data 0.000	Loss 1.0974	
SparseEpoch: [160][301/398]	Time 0.580	Data 0.000	Loss 0.5450	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.41021522 0.40983906 0.40968791 0.40968497 0.40958125 0.40929642
 0.40903944 0.40904653 0.40889865 0.40864011 0.40855412 0.40857286
 0.40839983 0.40833836 0.40819822 0.40812621 0.40810511 0.40805517
 0.40803528 0.40784885]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.40869429 0.40868446 0.40868289 0.4086894  0.40865932 0.40865296
 0.40862222 0.40865346 0.40862808 0.40857403 0.4085679  0.4085639
 0.4085566  0.40853861 0.40851431 0.4085258  0.40851789 0.40853746
 0.40854782 0.40855122]
[0.5        0.         0.23684211]
-----------end of analyzing the loss ratio:75.90339303016663
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc93890b070>
---------------------------------
SparseEpoch: [160][1/398]	Time 0.578	Data 0.000	Loss 0.7679	
SparseEpoch: [160][101/398]	Time 0.580	Data 0.000	Loss 0.7896	
SparseEpoch: [160][201/398]	Time 0.580	Data 0.000	Loss 0.7974	
SparseEpoch: [160][301/398]	Time 0.581	Data 0.000	Loss 1.0265	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11230904 0.11231378 0.11232778 0.11234475 0.1123522  0.11233442
 0.11232188 0.11233232 0.11235069 0.11232643 0.11231989 0.11233521
 0.11233873 0.11234362 0.11236836 0.1123619  0.11238039 0.11237372
 0.11236389 0.11237098]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.112383   0.11235288 0.11235689 0.11234406 0.11235828 0.11235867
 0.11240178 0.11235782 0.11234361 0.11232157 0.11231887 0.11235141
 0.11232364 0.11231266 0.11230151 0.11229203 0.11229941 0.11225718
 0.11226892 0.11226764]
[0.         0.39473684 0.        ]
-----------end of analyzing the loss ratio:75.96171832084656
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938750f40>
---------------------------------
SparseEpoch: [160][1/398]	Time 0.578	Data 0.000	Loss 0.6607	
SparseEpoch: [160][101/398]	Time 0.579	Data 0.000	Loss 0.9489	
SparseEpoch: [160][201/398]	Time 0.579	Data 0.000	Loss 1.1152	
SparseEpoch: [160][301/398]	Time 0.579	Data 0.000	Loss 1.1880	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.5616	
Epoch(adapt):{0} Loss 0.9424	
Epoch(adapt):{0} Loss 0.8673	
Epoch(adapt):{0} Loss 0.5957	
------------------the total time cost:1167.5761716365814
>>>>>meta updating
Epoch: 0160 | TRAIN: 0.3058 0.7725 0.9021 | 0.2893 0.2893 0.1379 | 0.1090 21.3624 16.2022 0.3524 0.6557 0.7730 ||TEST: 1.2613 0.4165 0.6719 | 0.5122 0.5122 0.2071 | 0.1388 24.8010 19.6991 0.2932 0.5660 0.6924 | 116.9690
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.25492864 0.25490541 0.25485984 0.25483925 0.25483548 0.2548343
 0.254848   0.25485284 0.25488306 0.25487234 0.25486813 0.25490058
 0.25487662 0.25489651 0.25490742 0.25487127 0.25487165 0.25494682
 0.25494961 0.25491208]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.25491502 0.25490557 0.25490879 0.25493685 0.25494144 0.25493365
 0.25491079 0.25490955 0.25490712 0.254878   0.25486528 0.25487221
 0.25490174 0.25490842 0.25491098 0.25491169 0.25488665 0.25490478
 0.25490208 0.25489477]
[0.         0.         0.02631579]
-----------end of analyzing the loss ratio:75.67324042320251
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc89df1d0f0>
---------------------------------
SparseEpoch: [161][1/398]	Time 0.579	Data 0.000	Loss 0.2646	
SparseEpoch: [161][101/398]	Time 0.580	Data 0.000	Loss 0.7466	
SparseEpoch: [161][201/398]	Time 0.580	Data 0.000	Loss 0.4684	
SparseEpoch: [161][301/398]	Time 0.580	Data 0.000	Loss 0.3835	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.36337156 0.36315424 0.36309122 0.36300294 0.362851   0.36284386
 0.3628709  0.3629547  0.36286149 0.36278033 0.36283286 0.36273535
 0.36289758 0.36290797 0.36301768 0.36306956 0.36312041 0.36329447
 0.36322877 0.36324441]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.36277156 0.36278297 0.3627986  0.36280447 0.36281575 0.36280555
 0.36283066 0.36283688 0.36282916 0.36284391 0.36286429 0.36283444
 0.36283457 0.36284818 0.36285106 0.36283494 0.36282476 0.36283964
 0.36285325 0.36284394]
[0.07894737 0.         0.        ]
-----------end of analyzing the loss ratio:75.64935255050659
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938d640d0>
---------------------------------
SparseEpoch: [161][1/398]	Time 0.578	Data 0.000	Loss 0.3123	
SparseEpoch: [161][101/398]	Time 0.580	Data 0.000	Loss 0.4298	
SparseEpoch: [161][201/398]	Time 0.579	Data 0.000	Loss 0.3490	
SparseEpoch: [161][301/398]	Time 0.580	Data 0.000	Loss 0.3821	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.12333139 0.12330362 0.12319323 0.12316296 0.12315007 0.12317594
 0.12306809 0.12299879 0.12289525 0.12283363 0.1227998  0.12272579
 0.12265791 0.1225777  0.12252972 0.12247674 0.12241929 0.12241532
 0.12242973 0.12237127]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.12292496 0.12290347 0.12292776 0.12292215 0.12288691 0.12284627
 0.12285309 0.12283959 0.12281351 0.12281315 0.12279854 0.12279394
 0.12278435 0.12282022 0.12280484 0.12277765 0.1227772  0.12275831
 0.12274568 0.12274338]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:75.85760974884033
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938d59810>
---------------------------------
SparseEpoch: [161][1/398]	Time 0.578	Data 0.000	Loss 2.6246	
SparseEpoch: [161][101/398]	Time 0.579	Data 0.000	Loss 1.5743	
SparseEpoch: [161][201/398]	Time 0.580	Data 0.000	Loss 1.9368	
SparseEpoch: [161][301/398]	Time 0.580	Data 0.000	Loss 1.0812	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.5937	
Epoch(adapt):{0} Loss 0.5632	
Epoch(adapt):{0} Loss 0.5338	
Epoch(adapt):{0} Loss 1.1142	
------------------the total time cost:1166.7262909412384
>>>>>meta updating
Epoch: 0161 | TRAIN: 0.3402 0.7452 0.8877 | 0.2986 0.2986 0.1471 | 0.1123 21.8478 16.7240 0.3368 0.6425 0.7639 ||TEST: 1.3104 0.3998 0.6601 | 0.5200 0.5200 0.2085 | 0.1410 25.1528 20.1434 0.2817 0.5570 0.6857 | 116.8091
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.3295845  0.32959455 0.32951589 0.32948922 0.3294925  0.32949242
 0.32952218 0.32950313 0.32945945 0.32954002 0.32963652 0.32958694
 0.32982491 0.32986755 0.32989696 0.32999616 0.33001566 0.3300367
 0.3298986  0.33002871]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.32955233 0.32952727 0.32953438 0.32955684 0.32955934 0.32956292
 0.32957207 0.32957558 0.32958241 0.32958189 0.32958432 0.32958448
 0.32960847 0.32958728 0.32959005 0.32962229 0.32963249 0.32963203
 0.32962975 0.32961914]
[0. 0. 0.]
-----------end of analyzing the loss ratio:75.67729902267456
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938c422c0>
---------------------------------
SparseEpoch: [162][1/398]	Time 0.578	Data 0.000	Loss 0.3112	
SparseEpoch: [162][101/398]	Time 0.579	Data 0.000	Loss 0.5230	
SparseEpoch: [162][201/398]	Time 0.580	Data 0.000	Loss 0.3614	
SparseEpoch: [162][301/398]	Time 0.579	Data 0.000	Loss 0.4427	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.36519009 0.36517409 0.36514656 0.36509482 0.36501608 0.36493896
 0.36491319 0.36493045 0.36495478 0.3649379  0.36493219 0.36490783
 0.36494959 0.36492938 0.36489255 0.36484873 0.36478439 0.364715
 0.36462032 0.36456879]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.36496116 0.36496502 0.36498742 0.36496102 0.36496743 0.3649771
 0.36496711 0.3649702  0.36496032 0.36496258 0.3649346  0.36493502
 0.36492845 0.36492668 0.36491381 0.36492216 0.36493762 0.36494175
 0.36494708 0.36493917]
[0.5        0.         0.23684211]
-----------end of analyzing the loss ratio:75.60537481307983
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938379f00>
---------------------------------
SparseEpoch: [162][1/398]	Time 0.578	Data 0.000	Loss 0.6782	
SparseEpoch: [162][101/398]	Time 0.580	Data 0.000	Loss 0.6011	
SparseEpoch: [162][201/398]	Time 0.580	Data 0.000	Loss 0.9579	
SparseEpoch: [162][301/398]	Time 0.580	Data 0.000	Loss 0.5527	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.10425769 0.10423602 0.10424742 0.10424632 0.10423572 0.1042372
 0.10424026 0.10423508 0.10422889 0.10421774 0.10422328 0.10423084
 0.10423307 0.10423159 0.10423221 0.10424148 0.10426258 0.1042329
 0.10422413 0.10421556]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.10423493 0.10424642 0.10423903 0.10426254 0.10424466 0.10425818
 0.10425318 0.10424883 0.10422767 0.10423113 0.10421838 0.10421339
 0.10422541 0.10423442 0.10423506 0.10425074 0.10424381 0.10424473
 0.10425536 0.10426369]
[0.5        0.07894737 0.        ]
-----------end of analyzing the loss ratio:75.79309034347534
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938d65930>
---------------------------------
SparseEpoch: [162][1/398]	Time 0.579	Data 0.000	Loss 0.9176	
SparseEpoch: [162][101/398]	Time 0.580	Data 0.000	Loss 0.8000	
SparseEpoch: [162][201/398]	Time 0.580	Data 0.000	Loss 1.2809	
SparseEpoch: [162][301/398]	Time 0.581	Data 0.000	Loss 2.1600	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.7612	
Epoch(adapt):{0} Loss 0.5232	
Epoch(adapt):{0} Loss 0.8126	
Epoch(adapt):{0} Loss 0.5040	
------------------the total time cost:1167.6640317440033
>>>>>meta updating
Epoch: 0162 | TRAIN: 0.3272 0.7542 0.8938 | 0.2837 0.2837 0.1424 | 0.1137 21.9447 16.8333 0.3390 0.6383 0.7599 ||TEST: 1.3391 0.4055 0.6611 | 0.5106 0.5106 0.2089 | 0.1416 25.1156 20.0583 0.2881 0.5585 0.6853 | 116.9466
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.33206721 0.33239018 0.33250542 0.33272927 0.3327253  0.33281279
 0.33295436 0.3328656  0.33275002 0.33294133 0.3330872  0.33317272
 0.33349931 0.33343711 0.33368177 0.33387105 0.33403344 0.33416435
 0.33442597 0.33447709]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.3330027  0.33298308 0.3329851  0.33297534 0.33298383 0.33297
 0.33296721 0.33298259 0.33295047 0.33298712 0.33297247 0.33298887
 0.33300052 0.3329814  0.33298026 0.33296715 0.33300375 0.33301125
 0.33300779 0.33300407]
[0. 0. 0.]
-----------end of analyzing the loss ratio:75.96488928794861
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9382c6ce0>
---------------------------------
SparseEpoch: [163][1/398]	Time 0.587	Data 0.000	Loss 0.3133	
SparseEpoch: [163][101/398]	Time 0.580	Data 0.000	Loss 0.3226	
SparseEpoch: [163][201/398]	Time 0.580	Data 0.000	Loss 0.2287	
SparseEpoch: [163][301/398]	Time 0.580	Data 0.000	Loss 0.3355	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.40814452 0.40817576 0.40812493 0.40809821 0.40813211 0.40823607
 0.40825866 0.40826185 0.40825332 0.40824063 0.40814472 0.40820141
 0.40813962 0.4081255  0.40813513 0.40816977 0.40816646 0.40822844
 0.40822456 0.40817052]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.40826499 0.40826058 0.40826424 0.40826439 0.40825996 0.40825596
 0.40824229 0.4082434  0.40823525 0.40823079 0.4082221  0.40822233
 0.40819874 0.40819167 0.4081972  0.40819812 0.40817961 0.40817967
 0.40818821 0.40818377]
[0.         0.         0.34210526]
-----------end of analyzing the loss ratio:75.72376847267151
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9382d2fe0>
---------------------------------
SparseEpoch: [163][1/398]	Time 0.578	Data 0.000	Loss 0.8586	
SparseEpoch: [163][101/398]	Time 0.580	Data 0.000	Loss 0.5290	
SparseEpoch: [163][201/398]	Time 0.580	Data 0.000	Loss 0.7772	
SparseEpoch: [163][301/398]	Time 0.580	Data 0.000	Loss 0.5712	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.10847077 0.1084704  0.10845903 0.10846906 0.10846013 0.10844615
 0.10843951 0.10842648 0.10838313 0.10837027 0.10835541 0.10834492
 0.10833376 0.1083136  0.10830885 0.10828654 0.10828635 0.10826448
 0.10826393 0.10826027]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.10846702 0.10845128 0.10842679 0.10841299 0.10839325 0.10840167
 0.10839914 0.10838282 0.10838192 0.10837125 0.1083622  0.10833774
 0.1083576  0.10835161 0.10834187 0.10834842 0.10833186 0.10833731
 0.10832176 0.10831028]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:75.50445652008057
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938931300>
---------------------------------
SparseEpoch: [163][1/398]	Time 0.578	Data 0.000	Loss 1.0319	
SparseEpoch: [163][101/398]	Time 0.580	Data 0.000	Loss 1.1518	
SparseEpoch: [163][201/398]	Time 0.581	Data 0.000	Loss 2.0396	
SparseEpoch: [163][301/398]	Time 0.580	Data 0.000	Loss 1.3925	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.6653	
Epoch(adapt):{0} Loss 0.5312	
Epoch(adapt):{0} Loss 0.4209	
Epoch(adapt):{0} Loss 0.7392	
------------------the total time cost:1166.8746364116669
>>>>>meta updating
Epoch: 0163 | TRAIN: 0.3666 0.7248 0.8764 | 0.3217 0.3217 0.1522 | 0.1145 22.1478 17.1408 0.3289 0.6340 0.7570 ||TEST: 1.2662 0.3949 0.6525 | 0.5380 0.5380 0.2088 | 0.1419 25.2748 20.3955 0.2798 0.5517 0.6811 | 116.9169
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.35070585 0.35062992 0.35061413 0.35069251 0.35072227 0.35074643
 0.35068706 0.35068665 0.35077718 0.35074815 0.35069391 0.35072444
 0.35071511 0.35065696 0.35068654 0.35069311 0.35074144 0.35071888
 0.35066058 0.3506392 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.35072349 0.35068762 0.35063096 0.35063772 0.35065249 0.3506632
 0.35069604 0.35070112 0.35067217 0.35068854 0.35076856 0.35072255
 0.35077814 0.35073805 0.35074009 0.350721   0.35073748 0.35074755
 0.35076002 0.35073608]
[0. 0. 0.]
-----------end of analyzing the loss ratio:75.71450304985046
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938b6b430>
---------------------------------
SparseEpoch: [164][1/398]	Time 0.577	Data 0.000	Loss 0.4610	
SparseEpoch: [164][101/398]	Time 0.580	Data 0.000	Loss 0.3321	
SparseEpoch: [164][201/398]	Time 0.580	Data 0.000	Loss 0.2849	
SparseEpoch: [164][301/398]	Time 0.580	Data 0.000	Loss 0.3857	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.34119755 0.34121182 0.34121689 0.34121299 0.34116831 0.3411586
 0.34114208 0.34111068 0.34109497 0.34106428 0.34098746 0.34091475
 0.34086404 0.34082152 0.34076642 0.34077783 0.34077878 0.34078917
 0.34081264 0.34082796]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.34105259 0.34106514 0.34106893 0.34105268 0.34105188 0.34105313
 0.34104854 0.34103483 0.34104282 0.34103788 0.34103081 0.34102342
 0.34100235 0.34099377 0.34099004 0.34097871 0.34096946 0.34096716
 0.34096706 0.34095957]
[0.23684211 0.         0.5       ]
-----------end of analyzing the loss ratio:75.67343235015869
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9382c7bb0>
---------------------------------
SparseEpoch: [164][1/398]	Time 0.578	Data 0.000	Loss 0.7123	
SparseEpoch: [164][101/398]	Time 0.580	Data 0.000	Loss 1.0393	
SparseEpoch: [164][201/398]	Time 0.580	Data 0.000	Loss 1.5421	
SparseEpoch: [164][301/398]	Time 0.580	Data 0.000	Loss 1.2616	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11934885 0.11935277 0.11935365 0.11935317 0.11935945 0.11936095
 0.11934314 0.11934993 0.11934819 0.11936444 0.11936496 0.11935802
 0.11934045 0.11934548 0.11934122 0.11934018 0.11934715 0.11934996
 0.11935167 0.11935214]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11935751 0.11936018 0.11936205 0.11936709 0.11938277 0.1193794
 0.11937577 0.11937039 0.11936297 0.11937006 0.11936132 0.11935549
 0.11934486 0.11934156 0.11933933 0.1193414  0.11933983 0.11934265
 0.1193466  0.11934474]
[0.28947368 0.23684211 0.        ]
-----------end of analyzing the loss ratio:75.83806490898132
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938944a30>
---------------------------------
SparseEpoch: [164][1/398]	Time 0.578	Data 0.000	Loss 1.4357	
SparseEpoch: [164][101/398]	Time 0.582	Data 0.000	Loss 1.5156	
SparseEpoch: [164][201/398]	Time 0.581	Data 0.000	Loss 1.1789	
SparseEpoch: [164][301/398]	Time 0.581	Data 0.000	Loss 1.1384	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.6642	
Epoch(adapt):{0} Loss 0.8551	
Epoch(adapt):{0} Loss 0.8311	
Epoch(adapt):{0} Loss 0.8517	
------------------the total time cost:1167.6363019943237
>>>>>meta updating
Epoch: 0164 | TRAIN: 0.3000 0.7810 0.9039 | 0.2955 0.2955 0.1437 | 0.1113 21.6823 16.5744 0.3430 0.6459 0.7666 ||TEST: 1.2838 0.4131 0.6681 | 0.5200 0.5200 0.2080 | 0.1411 25.1019 20.0350 0.2868 0.5585 0.6854 | 116.8901
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.25559278 0.25560729 0.25555786 0.25556493 0.25555088 0.25555695
 0.25556671 0.25556021 0.25555392 0.25554647 0.25560398 0.25563749
 0.25562252 0.25561038 0.25562352 0.25562689 0.25562077 0.25561748
 0.25559011 0.25560025]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.25558997 0.25559751 0.25559952 0.25559289 0.25557983 0.25558382
 0.25559398 0.25559876 0.25559309 0.25558381 0.25556829 0.25556349
 0.25556446 0.25556805 0.25558418 0.25559688 0.25558777 0.25559908
 0.25561067 0.25561246]
[0.         0.         0.07894737]
-----------end of analyzing the loss ratio:75.67414283752441
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9380d8f10>
---------------------------------
SparseEpoch: [165][1/398]	Time 0.578	Data 0.000	Loss 0.3367	
SparseEpoch: [165][101/398]	Time 0.580	Data 0.000	Loss 0.3845	
SparseEpoch: [165][201/398]	Time 0.580	Data 0.000	Loss 0.3249	
SparseEpoch: [165][301/398]	Time 0.580	Data 0.000	Loss 0.3607	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.34082073 0.34082089 0.34073023 0.34071731 0.34066338 0.34062019
 0.34057091 0.34060132 0.34061779 0.34056751 0.34063212 0.34066012
 0.3405868  0.34056632 0.34060721 0.34064093 0.34065851 0.3405664
 0.34050101 0.34046425]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.34061985 0.34059738 0.34061315 0.34063208 0.34061781 0.3406295
 0.34062207 0.34060332 0.340591   0.34064148 0.34060559 0.34062065
 0.34062763 0.34063237 0.34065149 0.34063776 0.34062628 0.34060264
 0.34060243 0.3406255 ]
[0.5 0.  0. ]
-----------end of analyzing the loss ratio:75.75591349601746
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938a1bee0>
---------------------------------
SparseEpoch: [165][1/398]	Time 0.578	Data 0.000	Loss 0.3438	
SparseEpoch: [165][101/398]	Time 0.580	Data 0.000	Loss 0.4345	
SparseEpoch: [165][201/398]	Time 0.580	Data 0.000	Loss 0.4414	
SparseEpoch: [165][301/398]	Time 0.580	Data 0.000	Loss 0.6643	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.13577919 0.13572227 0.13570568 0.13562232 0.13557338 0.13552185
 0.13553873 0.13549745 0.13547708 0.13540638 0.13534852 0.13529375
 0.13527276 0.13523183 0.13515943 0.13508925 0.1350583  0.135022
 0.13495594 0.13491807]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.13553694 0.13554198 0.13551767 0.13547211 0.13542572 0.1354547
 0.13545326 0.13540351 0.13540602 0.13537787 0.13536059 0.13534311
 0.13529261 0.13530333 0.13530356 0.13534935 0.1353161  0.13528572
 0.13525841 0.13524176]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:75.90677452087402
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938f15ba0>
---------------------------------
SparseEpoch: [165][1/398]	Time 0.580	Data 0.000	Loss 1.3182	
SparseEpoch: [165][101/398]	Time 0.580	Data 0.000	Loss 1.3856	
SparseEpoch: [165][201/398]	Time 0.580	Data 0.000	Loss 1.3698	
SparseEpoch: [165][301/398]	Time 0.580	Data 0.000	Loss 1.9095	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.4820	
Epoch(adapt):{0} Loss 0.6579	
Epoch(adapt):{0} Loss 1.1858	
Epoch(adapt):{0} Loss 0.5718	
------------------the total time cost:1166.6115350723267
>>>>>meta updating
Epoch: 0165 | TRAIN: 0.3156 0.7652 0.8972 | 0.2900 0.2900 0.1414 | 0.1134 21.9536 16.9572 0.3364 0.6383 0.7607 ||TEST: 1.2842 0.4063 0.6676 | 0.5142 0.5142 0.2128 | 0.1428 25.3212 20.3827 0.2816 0.5514 0.6805 | 116.9161
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.29022259 0.29017233 0.29023958 0.29027846 0.29022295 0.29026703
 0.29034059 0.29033466 0.29026348 0.29020591 0.29020296 0.29018674
 0.29016865 0.2901963  0.2901787  0.29016765 0.29008549 0.29003632
 0.2900931  0.29010912]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.29030213 0.29028535 0.29024643 0.29022044 0.29020918 0.29018176
 0.29018304 0.29019549 0.29018261 0.29017628 0.29019497 0.29023672
 0.29021308 0.29021016 0.29019724 0.29020733 0.29021149 0.29020909
 0.29018686 0.29020472]
[0.         0.39473684 0.        ]
-----------end of analyzing the loss ratio:75.84889125823975
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938a4a200>
---------------------------------
SparseEpoch: [166][1/398]	Time 0.578	Data 0.000	Loss 0.5530	
SparseEpoch: [166][101/398]	Time 0.580	Data 0.000	Loss 0.4030	
SparseEpoch: [166][201/398]	Time 0.580	Data 0.000	Loss 0.5018	
SparseEpoch: [166][301/398]	Time 0.580	Data 0.000	Loss 0.3895	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.38155864 0.38146762 0.38150486 0.38143752 0.38143521 0.38146455
 0.38140227 0.38113044 0.3811086  0.38101001 0.38098858 0.38094196
 0.38087672 0.38077584 0.38076973 0.38065734 0.3807096  0.38068615
 0.38058999 0.38051268]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.38095805 0.38095001 0.38094113 0.38094782 0.3809565  0.38094328
 0.38094905 0.38097237 0.38095818 0.38094746 0.3809654  0.38097205
 0.38096761 0.38097644 0.38098147 0.38097622 0.38098996 0.38098718
 0.38098469 0.38098127]
[0.5 0.  0. ]
-----------end of analyzing the loss ratio:75.78728008270264
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cca5e2138e0>
---------------------------------
SparseEpoch: [166][1/398]	Time 0.577	Data 0.000	Loss 0.2579	
SparseEpoch: [166][101/398]	Time 0.580	Data 0.000	Loss 0.4055	
SparseEpoch: [166][201/398]	Time 0.579	Data 0.000	Loss 0.4901	
SparseEpoch: [166][301/398]	Time 0.580	Data 0.000	Loss 0.5308	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11633143 0.11631659 0.11628711 0.11626111 0.11625468 0.11624609
 0.11621244 0.11617369 0.11615594 0.11614292 0.11613491 0.11612479
 0.11608445 0.11605335 0.11602054 0.11601634 0.11599131 0.11600572
 0.11596785 0.11594735]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11619257 0.11619647 0.11618559 0.11617345 0.11616949 0.11616639
 0.1161718  0.11615115 0.11614906 0.11614526 0.11613719 0.11614008
 0.116142   0.11614102 0.11614217 0.11612831 0.11612945 0.11612585
 0.11612114 0.11610423]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:75.64281177520752
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938d4eda0>
---------------------------------
SparseEpoch: [166][1/398]	Time 0.580	Data 0.000	Loss 1.2660	
SparseEpoch: [166][101/398]	Time 0.581	Data 0.000	Loss 1.2213	
SparseEpoch: [166][201/398]	Time 0.580	Data 0.000	Loss 1.8691	
SparseEpoch: [166][301/398]	Time 0.580	Data 0.000	Loss 1.1405	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.6713	
Epoch(adapt):{0} Loss 0.4490	
Epoch(adapt):{0} Loss 0.7157	
Epoch(adapt):{0} Loss 0.4355	
------------------the total time cost:1166.4478778839111
>>>>>meta updating
Epoch: 0166 | TRAIN: 0.2978 0.7791 0.9042 | 0.2933 0.2933 0.1479 | 0.1136 21.9199 16.8547 0.3399 0.6400 0.7616 ||TEST: 1.3128 0.4170 0.6698 | 0.5155 0.5155 0.2101 | 0.1420 25.1360 20.0499 0.2886 0.5585 0.6855 | 117.2171
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.28627363 0.28617684 0.28612927 0.2861161  0.28611884 0.28609646
 0.28613223 0.28614564 0.28612531 0.28610685 0.2861374  0.28608388
 0.2860691  0.28605573 0.2861451  0.2861889  0.28621718 0.28622604
 0.2862148  0.28625844]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.28610197 0.28611095 0.2860923  0.28610447 0.28611701 0.28609548
 0.28609487 0.2860938  0.28611607 0.28611519 0.28612073 0.28611305
 0.28610606 0.28610574 0.286106   0.28610594 0.28609388 0.28607671
 0.28606469 0.28608247]
[0.         0.18421053 0.44736842]
-----------end of analyzing the loss ratio:75.77454900741577
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc89defc700>
---------------------------------
SparseEpoch: [167][1/398]	Time 0.578	Data 0.000	Loss 0.6549	
SparseEpoch: [167][101/398]	Time 0.580	Data 0.000	Loss 0.8025	
SparseEpoch: [167][201/398]	Time 0.581	Data 0.000	Loss 1.4266	
SparseEpoch: [167][301/398]	Time 0.580	Data 0.000	Loss 0.8938	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.35163203 0.35149442 0.35123588 0.35105419 0.35094809 0.35079894
 0.35051988 0.35057019 0.35054711 0.35045598 0.35042728 0.35036798
 0.35033468 0.35028596 0.3503601  0.35017315 0.35010861 0.35000563
 0.35008289 0.34995543]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.35052231 0.35052199 0.35052895 0.35050946 0.35050826 0.35051207
 0.35048049 0.35048069 0.35046066 0.35046639 0.3504489  0.35046441
 0.3504511  0.35044413 0.3504442  0.35042791 0.35042117 0.3504041
 0.35040872 0.35042715]
[0.5        0.         0.39473684]
-----------end of analyzing the loss ratio:75.65979933738708
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cca5e213640>
---------------------------------
SparseEpoch: [167][1/398]	Time 0.581	Data 0.000	Loss 0.8673	
SparseEpoch: [167][101/398]	Time 0.581	Data 0.000	Loss 0.8897	
SparseEpoch: [167][201/398]	Time 0.580	Data 0.000	Loss 0.7605	
SparseEpoch: [167][301/398]	Time 0.580	Data 0.000	Loss 0.9071	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.12011272 0.12009848 0.1200915  0.12009069 0.120096   0.12009519
 0.12009826 0.12009794 0.12010163 0.12010862 0.12010568 0.12010144
 0.12008682 0.12007601 0.12008029 0.12008153 0.12008246 0.12007566
 0.1200667  0.12006599]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.12006701 0.12007223 0.12007558 0.12007952 0.12008703 0.12009713
 0.12009472 0.1201076  0.12010899 0.12010466 0.12010244 0.12010424
 0.12010812 0.12010355 0.1201076  0.12011059 0.12010805 0.12010714
 0.1201111  0.12009512]
[0.5 0.  0. ]
-----------end of analyzing the loss ratio:75.65550780296326
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938de97b0>
---------------------------------
SparseEpoch: [167][1/398]	Time 0.577	Data 0.000	Loss 1.9673	
SparseEpoch: [167][101/398]	Time 0.580	Data 0.000	Loss 1.7797	
SparseEpoch: [167][201/398]	Time 0.580	Data 0.000	Loss 1.5032	
SparseEpoch: [167][301/398]	Time 0.580	Data 0.000	Loss 0.9799	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.5197	
Epoch(adapt):{0} Loss 0.7420	
Epoch(adapt):{0} Loss 0.7076	
Epoch(adapt):{0} Loss 0.6578	
------------------the total time cost:1166.3335540294647
>>>>>meta updating
Epoch: 0167 | TRAIN: 0.2871 0.7829 0.9082 | 0.2814 0.2814 0.1404 | 0.1087 21.3268 16.2364 0.3553 0.6537 0.7714 ||TEST: 1.3394 0.4170 0.6725 | 0.5070 0.5070 0.2071 | 0.1406 24.9708 19.8471 0.2931 0.5622 0.6878 | 117.0992
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.27288832 0.27292864 0.27296724 0.27292081 0.27299886 0.27294574
 0.27293319 0.27291232 0.2728594  0.2727853  0.27267909 0.27265392
 0.27275613 0.27278071 0.27287977 0.27296465 0.27299949 0.27305387
 0.27299497 0.27303597]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.27279206 0.27280389 0.27278447 0.2727853  0.27277471 0.27277004
 0.27276955 0.27275617 0.27274932 0.2727365  0.27269131 0.27268827
 0.27269313 0.27271693 0.27271035 0.27270706 0.27267657 0.27267023
 0.27266208 0.2726595 ]
[0.         0.07894737 0.5       ]
-----------end of analyzing the loss ratio:76.0160903930664
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9385e7310>
---------------------------------
SparseEpoch: [168][1/398]	Time 0.588	Data 0.000	Loss 0.7383	
SparseEpoch: [168][101/398]	Time 0.580	Data 0.000	Loss 1.1962	
SparseEpoch: [168][201/398]	Time 0.581	Data 0.000	Loss 0.7692	
SparseEpoch: [168][301/398]	Time 0.580	Data 0.000	Loss 1.1201	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.3334368  0.33337945 0.33327887 0.33329473 0.33323461 0.33316879
 0.33317901 0.33304765 0.33300884 0.33303352 0.33297902 0.33290392
 0.33288438 0.33280786 0.33278996 0.33278524 0.33279411 0.33275253
 0.33258819 0.33256275]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.33298909 0.33299904 0.33298166 0.33299328 0.33300074 0.33301899
 0.33302957 0.33304181 0.33304373 0.33305028 0.33304027 0.33303279
 0.33302625 0.33298997 0.33295705 0.33295112 0.33298021 0.33296091
 0.33295209 0.33297204]
[0.5        0.         0.28947368]
-----------end of analyzing the loss ratio:75.78197169303894
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938dea0b0>
---------------------------------
SparseEpoch: [168][1/398]	Time 0.579	Data 0.000	Loss 0.5656	
SparseEpoch: [168][101/398]	Time 0.580	Data 0.000	Loss 0.7502	
SparseEpoch: [168][201/398]	Time 0.580	Data 0.000	Loss 0.7301	
SparseEpoch: [168][301/398]	Time 0.580	Data 0.000	Loss 0.6081	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11844129 0.11844433 0.11844433 0.11844797 0.11845604 0.11846594
 0.11843812 0.11843826 0.11843095 0.11842896 0.11843123 0.11841738
 0.11842093 0.11841933 0.1184258  0.11841629 0.11839501 0.11838467
 0.1183864  0.118389  ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11845998 0.11845296 0.1184531  0.11844184 0.11843588 0.11841852
 0.11841769 0.11842801 0.11843401 0.11843224 0.1184238  0.11842216
 0.11842414 0.11841542 0.11841106 0.11842666 0.11841467 0.11841186
 0.11841418 0.1184238 ]
[0.39473684 0.23684211 0.        ]
-----------end of analyzing the loss ratio:75.69087529182434
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9383d1b10>
---------------------------------
SparseEpoch: [168][1/398]	Time 0.579	Data 0.000	Loss 0.6656	
SparseEpoch: [168][101/398]	Time 0.579	Data 0.000	Loss 1.6957	
SparseEpoch: [168][201/398]	Time 0.580	Data 0.000	Loss 1.1826	
SparseEpoch: [168][301/398]	Time 0.580	Data 0.000	Loss 1.2885	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.4278	
Epoch(adapt):{0} Loss 1.0697	
Epoch(adapt):{0} Loss 0.5328	
Epoch(adapt):{0} Loss 0.8383	
------------------the total time cost:1168.0089700222015
>>>>>meta updating
Epoch: 0168 | TRAIN: 0.2852 0.7844 0.9078 | 0.2841 0.2841 0.1382 | 0.1084 21.3206 16.1714 0.3501 0.6584 0.7759 ||TEST: 1.2837 0.4190 0.6721 | 0.5134 0.5134 0.2048 | 0.1403 25.0127 19.8998 0.2865 0.5620 0.6896 | 116.7842
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.35192683 0.35191483 0.35194862 0.35202239 0.35200931 0.35200417
 0.35200422 0.3520188  0.35200702 0.35206527 0.35206291 0.3519912
 0.3520449  0.35201149 0.35199858 0.35204462 0.35197318 0.35196259
 0.35195752 0.35192857]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.35196106 0.35193387 0.35193121 0.35195469 0.35201432 0.35199127
 0.35200243 0.35205039 0.35201975 0.35207133 0.3520863  0.35207597
 0.35205646 0.35203784 0.35203896 0.35204392 0.35203476 0.35209193
 0.35204314 0.35202415]
[0. 0. 0.]
-----------end of analyzing the loss ratio:75.9987735748291
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc89dd9b970>
---------------------------------
SparseEpoch: [169][1/398]	Time 0.577	Data 0.000	Loss 0.2900	
SparseEpoch: [169][101/398]	Time 0.579	Data 0.000	Loss 0.3488	
SparseEpoch: [169][201/398]	Time 0.579	Data 0.000	Loss 0.2611	
SparseEpoch: [169][301/398]	Time 0.579	Data 0.000	Loss 0.5594	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.37768014 0.37752881 0.37731158 0.37723654 0.37730282 0.37727029
 0.3771864  0.37718446 0.3768313  0.37674372 0.37674706 0.37661081
 0.37663449 0.37674223 0.37659712 0.3766236  0.37650126 0.37637583
 0.37619811 0.37630564]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.37675369 0.3767627  0.37678444 0.37679942 0.37678639 0.37678263
 0.37678364 0.37673134 0.37674352 0.37673367 0.37672909 0.37676063
 0.37675547 0.37674692 0.3767228  0.37671956 0.37667835 0.37663867
 0.37665536 0.37662667]
[0.44736842 0.         0.5       ]
-----------end of analyzing the loss ratio:75.80984950065613
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc89df1e860>
---------------------------------
SparseEpoch: [169][1/398]	Time 0.578	Data 0.000	Loss 1.1485	
SparseEpoch: [169][101/398]	Time 0.580	Data 0.000	Loss 0.9465	
SparseEpoch: [169][201/398]	Time 0.580	Data 0.000	Loss 0.8774	
SparseEpoch: [169][301/398]	Time 0.580	Data 0.000	Loss 1.2560	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.10912933 0.10912697 0.10911732 0.10909927 0.10911128 0.10910919
 0.10911968 0.10911521 0.10912402 0.10913085 0.10912132 0.10911844
 0.10910864 0.10910112 0.1090967  0.10908931 0.10908293 0.10908508
 0.10907119 0.10907565]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.10910999 0.10910996 0.10911327 0.10912004 0.10912524 0.10912547
 0.10912594 0.10912753 0.10912779 0.10912773 0.10912737 0.10912319
 0.10911472 0.10911009 0.10910635 0.10911194 0.10910916 0.1091093
 0.10910392 0.10909884]
[0.44736842 0.5        0.        ]
-----------end of analyzing the loss ratio:75.60076594352722
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938d5a4a0>
---------------------------------
SparseEpoch: [169][1/398]	Time 0.578	Data 0.000	Loss 1.0746	
SparseEpoch: [169][101/398]	Time 0.580	Data 0.000	Loss 1.3513	
SparseEpoch: [169][201/398]	Time 0.580	Data 0.000	Loss 1.5283	
SparseEpoch: [169][301/398]	Time 0.580	Data 0.000	Loss 1.0972	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.0126	
Epoch(adapt):{0} Loss 0.6664	
Epoch(adapt):{0} Loss 0.9182	
Epoch(adapt):{0} Loss 0.6246	
------------------the total time cost:1166.417367219925
>>>>>meta updating
Epoch: 0169 | TRAIN: 0.2952 0.7803 0.9048 | 0.2994 0.2994 0.1392 | 0.1089 21.4869 16.4842 0.3426 0.6501 0.7711 ||TEST: 1.2739 0.4111 0.6685 | 0.5283 0.5283 0.2083 | 0.1410 25.1352 20.1785 0.2851 0.5553 0.6839 | 117.2168
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.27883241 0.27878869 0.27880473 0.27879843 0.27878532 0.27872214
 0.27871093 0.27878491 0.27876297 0.27877185 0.27881373 0.27883934
 0.27886899 0.27887711 0.2788933  0.27887279 0.27886693 0.27884425
 0.27881851 0.27883452]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.27882698 0.27881769 0.2788247  0.27881938 0.27881458 0.27882292
 0.27881203 0.27879598 0.27880581 0.2788049  0.27881161 0.27881183
 0.27880524 0.27881016 0.27877789 0.27877982 0.27877321 0.27876427
 0.27876804 0.27876993]
[0.         0.         0.39473684]
-----------end of analyzing the loss ratio:75.92540860176086
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938b17be0>
---------------------------------
SparseEpoch: [170][1/398]	Time 0.578	Data 0.000	Loss 0.7270	
SparseEpoch: [170][101/398]	Time 0.580	Data 0.000	Loss 0.5777	
SparseEpoch: [170][201/398]	Time 0.580	Data 0.000	Loss 1.0096	
SparseEpoch: [170][301/398]	Time 0.580	Data 0.000	Loss 1.2667	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.35504465 0.35505176 0.35499497 0.35500716 0.35497663 0.35500221
 0.35500239 0.35498614 0.35497818 0.35500517 0.35498834 0.35498222
 0.35495709 0.3549555  0.35489887 0.35484939 0.35482075 0.35482324
 0.35483124 0.35477462]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.35498558 0.3549782  0.3549938  0.35502315 0.35502517 0.35503092
 0.35503347 0.35501543 0.35500298 0.35497539 0.35499044 0.35499048
 0.35497523 0.35497651 0.35498346 0.35497371 0.35495565 0.35494011
 0.35491397 0.35493158]
[0.5        0.         0.44736842]
-----------end of analyzing the loss ratio:75.8739984035492
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938e14c10>
---------------------------------
SparseEpoch: [170][1/398]	Time 0.580	Data 0.000	Loss 0.5457	
SparseEpoch: [170][101/398]	Time 0.581	Data 0.000	Loss 0.6818	
SparseEpoch: [170][201/398]	Time 0.581	Data 0.000	Loss 0.9717	
SparseEpoch: [170][301/398]	Time 0.581	Data 0.000	Loss 0.7872	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.10014961 0.10009279 0.09999328 0.09974095 0.09968905 0.09963539
 0.09944349 0.09923909 0.09912528 0.09900852 0.09890305 0.09878563
 0.0987281  0.09865768 0.09854912 0.09846067 0.0983924  0.09826526
 0.09806334 0.09796826]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.09921679 0.09919233 0.09916364 0.09911329 0.09908383 0.09904695
 0.09902273 0.09900497 0.09898139 0.09899234 0.09894354 0.09891676
 0.09889653 0.09888248 0.09883819 0.09880254 0.09874857 0.09874568
 0.09873509 0.0987585 ]
[0.5        0.44736842 0.        ]
-----------end of analyzing the loss ratio:75.6188108921051
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938237b80>
---------------------------------
SparseEpoch: [170][1/398]	Time 0.579	Data 0.000	Loss 1.3394	
SparseEpoch: [170][101/398]	Time 0.581	Data 0.000	Loss 1.5530	
SparseEpoch: [170][201/398]	Time 0.581	Data 0.000	Loss 0.9116	
SparseEpoch: [170][301/398]	Time 0.581	Data 0.000	Loss 1.5961	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.4642	
Epoch(adapt):{0} Loss 0.6751	
Epoch(adapt):{0} Loss 0.9057	
Epoch(adapt):{0} Loss 0.6571	
------------------the total time cost:1167.3971371650696
>>>>>meta updating
Epoch: 0170 | TRAIN: 0.3276 0.7482 0.8938 | 0.2938 0.2938 0.1394 | 0.1079 21.2729 16.2018 0.3519 0.6569 0.7754 ||TEST: 1.3121 0.3910 0.6600 | 0.5237 0.5237 0.2105 | 0.1406 25.0341 19.9827 0.2876 0.5601 0.6875 | 117.2210
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.27046352 0.27045998 0.27051781 0.27054707 0.27058076 0.27052721
 0.27056499 0.27060424 0.27059519 0.27059708 0.27063511 0.27066031
 0.2707141  0.27066307 0.27063178 0.27064547 0.27064626 0.27066239
 0.2706565  0.27065503]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.27062556 0.2706184  0.27063198 0.27059872 0.27058782 0.27061793
 0.27059412 0.27058282 0.27061331 0.2706006  0.27060249 0.27059923
 0.27062941 0.27064273 0.27064451 0.27065101 0.2706386  0.27066142
 0.2706864  0.27067878]
[0. 0. 0.]
-----------end of analyzing the loss ratio:76.2347800731659
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938377c40>
---------------------------------
SparseEpoch: [171][1/398]	Time 0.578	Data 0.000	Loss 0.1875	
SparseEpoch: [171][101/398]	Time 0.581	Data 0.000	Loss 0.2321	
SparseEpoch: [171][201/398]	Time 0.580	Data 0.000	Loss 0.3726	
SparseEpoch: [171][301/398]	Time 0.580	Data 0.000	Loss 0.4667	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.4117615  0.41164767 0.41160454 0.41142972 0.41130062 0.41105926
 0.41103119 0.4110431  0.41088972 0.41094897 0.41086174 0.41074516
 0.41066154 0.41044336 0.41030394 0.41009961 0.41010701 0.40995879
 0.40984772 0.40964659]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.41088595 0.41088457 0.41086421 0.41086642 0.4108911  0.41089124
 0.41089551 0.4108975  0.41090956 0.41090979 0.4108814  0.41090227
 0.41093262 0.41094029 0.41094501 0.41093414 0.41089792 0.4108814
 0.41090209 0.41091374]
[0.5 0.  0. ]
-----------end of analyzing the loss ratio:75.81602311134338
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc939945f00>
---------------------------------
SparseEpoch: [171][1/398]	Time 0.578	Data 0.000	Loss 0.3934	
SparseEpoch: [171][101/398]	Time 0.580	Data 0.000	Loss 0.3404	
SparseEpoch: [171][201/398]	Time 0.580	Data 0.000	Loss 0.3561	
SparseEpoch: [171][301/398]	Time 0.580	Data 0.000	Loss 0.4935	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.09643395 0.09643792 0.09642975 0.09643049 0.09641829 0.09642807
 0.09643115 0.09643661 0.09642606 0.09642302 0.09641837 0.09642497
 0.09641487 0.09640345 0.09640276 0.09639685 0.09639164 0.09638954
 0.09637648 0.09637856]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.09654658 0.09654213 0.09653988 0.09653797 0.09651286 0.09648289
 0.09647617 0.09644893 0.09642519 0.09642615 0.09641607 0.09641117
 0.09641473 0.0964194  0.09640616 0.09639568 0.09636371 0.09632754
 0.09632792 0.09631543]
[0.44736842 0.5        0.        ]
-----------end of analyzing the loss ratio:75.73162198066711
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938fc6560>
---------------------------------
SparseEpoch: [171][1/398]	Time 0.584	Data 0.000	Loss 0.8691	
SparseEpoch: [171][101/398]	Time 0.581	Data 0.000	Loss 1.3892	
SparseEpoch: [171][201/398]	Time 0.581	Data 0.000	Loss 0.8130	
SparseEpoch: [171][301/398]	Time 0.581	Data 0.000	Loss 1.5016	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.5752	
Epoch(adapt):{0} Loss 0.6560	
Epoch(adapt):{0} Loss 0.5320	
Epoch(adapt):{0} Loss 1.1312	
------------------the total time cost:1167.2028512954712
>>>>>meta updating
Epoch: 0171 | TRAIN: 0.2921 0.7759 0.9031 | 0.2819 0.2819 0.1445 | 0.1098 21.5253 16.4387 0.3469 0.6493 0.7689 ||TEST: 1.3676 0.4051 0.6619 | 0.5073 0.5073 0.2048 | 0.1412 25.1037 20.0848 0.2875 0.5571 0.6851 | 117.0690
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.23429974 0.23426334 0.23423634 0.23421661 0.2341946  0.23420305
 0.23420856 0.23422222 0.23425609 0.23423944 0.23424949 0.23421467
 0.23420613 0.23422305 0.23426815 0.23425692 0.23423966 0.23417276
 0.23417927 0.23422937]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.23421848 0.23421303 0.23423704 0.23422966 0.23423421 0.23424085
 0.23423568 0.23423737 0.23424193 0.23425126 0.23425026 0.234241
 0.234246   0.23424197 0.23424517 0.23423847 0.23423783 0.23422838
 0.23424384 0.23424239]
[0.         0.39473684 0.        ]
-----------end of analyzing the loss ratio:76.00668168067932
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938a4ab60>
---------------------------------
SparseEpoch: [172][1/398]	Time 0.578	Data 0.000	Loss 0.3335	
SparseEpoch: [172][101/398]	Time 0.580	Data 0.000	Loss 0.2315	
SparseEpoch: [172][201/398]	Time 0.580	Data 0.000	Loss 0.5798	
SparseEpoch: [172][301/398]	Time 0.580	Data 0.000	Loss 0.5927	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.31590208 0.31585338 0.31587188 0.31589071 0.31585821 0.31584678
 0.3158315  0.31586891 0.31576268 0.3157306  0.3157219  0.31577579
 0.31575773 0.31574033 0.3158527  0.31580228 0.31578133 0.31580946
 0.31572652 0.3158016 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.31574135 0.31574124 0.31573587 0.3157327  0.31573992 0.31574034
 0.31571985 0.31572977 0.31572596 0.31570408 0.31570123 0.31569787
 0.31569756 0.31570438 0.31571701 0.31571172 0.31572553 0.31573089
 0.31573683 0.31573496]
[0.02631579 0.         0.13157895]
-----------end of analyzing the loss ratio:76.06164693832397
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc93822c5b0>
---------------------------------
SparseEpoch: [172][1/398]	Time 0.579	Data 0.000	Loss 0.3845	
SparseEpoch: [172][101/398]	Time 0.581	Data 0.000	Loss 0.4013	
SparseEpoch: [172][201/398]	Time 0.581	Data 0.000	Loss 0.4957	
SparseEpoch: [172][301/398]	Time 0.581	Data 0.000	Loss 0.4835	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.10185145 0.10184236 0.10183663 0.1018408  0.10185192 0.10184687
 0.10184637 0.10185389 0.1018388  0.10184256 0.10185026 0.10184304
 0.10183924 0.10184016 0.10183677 0.10184228 0.10184611 0.10185357
 0.10186327 0.10185813]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.10186132 0.1018577  0.1018505  0.10184122 0.10184779 0.10186072
 0.10185702 0.10185024 0.10185372 0.10184697 0.10184929 0.10184731
 0.10184401 0.10186852 0.10185782 0.10184584 0.10183955 0.10185518
 0.10185578 0.10185876]
[0.         0.34210526 0.        ]
-----------end of analyzing the loss ratio:75.98065948486328
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc89df76440>
---------------------------------
SparseEpoch: [172][1/398]	Time 0.578	Data 0.000	Loss 1.3071	
SparseEpoch: [172][101/398]	Time 0.580	Data 0.000	Loss 0.7345	
SparseEpoch: [172][201/398]	Time 0.580	Data 0.000	Loss 1.7743	
SparseEpoch: [172][301/398]	Time 0.579	Data 0.000	Loss 1.2266	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.1392	
Epoch(adapt):{0} Loss 0.3574	
Epoch(adapt):{0} Loss 1.0243	
Epoch(adapt):{0} Loss 0.5562	
------------------the total time cost:1167.9629778862
>>>>>meta updating
Epoch: 0172 | TRAIN: 0.3006 0.7677 0.9025 | 0.2862 0.2862 0.1398 | 0.1098 21.4612 16.3430 0.3508 0.6528 0.7704 ||TEST: 1.3148 0.4055 0.6668 | 0.5152 0.5152 0.2026 | 0.1406 24.9850 19.8486 0.2910 0.5627 0.6887 | 117.2049
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.31554892 0.31555412 0.31548607 0.31547231 0.31528851 0.31540353
 0.31538937 0.31533326 0.31523929 0.31523397 0.31541234 0.3153476
 0.31541197 0.3153963  0.31525527 0.31509717 0.31506272 0.31512157
 0.31514331 0.31514944]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.31529438 0.31530957 0.31529553 0.31530006 0.31529572 0.31529816
 0.31531322 0.31532581 0.31533054 0.31532839 0.31532436 0.31534187
 0.31533794 0.31534237 0.31526722 0.31525935 0.31525097 0.31524459
 0.31524257 0.31524558]
[0.         0.34210526 0.44736842]
-----------end of analyzing the loss ratio:75.91583681106567
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9389333a0>
---------------------------------
SparseEpoch: [173][1/398]	Time 0.578	Data 0.000	Loss 0.6665	
SparseEpoch: [173][101/398]	Time 0.580	Data 0.000	Loss 0.7780	
SparseEpoch: [173][201/398]	Time 0.580	Data 0.000	Loss 0.7461	
SparseEpoch: [173][301/398]	Time 0.581	Data 0.000	Loss 0.9426	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.34530334 0.34518591 0.34501044 0.34501325 0.34490148 0.34488508
 0.34490294 0.34485126 0.34479679 0.34475862 0.34476641 0.34474009
 0.34476094 0.34480193 0.344807   0.34470904 0.34477981 0.34463762
 0.34461188 0.34457837]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.34486585 0.34488837 0.34489506 0.34489816 0.34485503 0.34484953
 0.34483531 0.3447975  0.34477695 0.34477353 0.34475263 0.34469306
 0.34466044 0.34466023 0.34467704 0.34466276 0.34469284 0.34474246
 0.34477952 0.34472667]
[0.5        0.         0.18421053]
-----------end of analyzing the loss ratio:75.80852603912354
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc93822ee00>
---------------------------------
SparseEpoch: [173][1/398]	Time 0.587	Data 0.000	Loss 0.5836	
SparseEpoch: [173][101/398]	Time 0.580	Data 0.000	Loss 0.5915	
SparseEpoch: [173][201/398]	Time 0.580	Data 0.000	Loss 0.6494	
SparseEpoch: [173][301/398]	Time 0.580	Data 0.000	Loss 0.3866	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11584643 0.11582146 0.11580535 0.11576926 0.11574694 0.11572772
 0.11569545 0.11568918 0.11567818 0.11566307 0.11566077 0.11565282
 0.11563739 0.11563114 0.11562241 0.11558566 0.11557829 0.11558158
 0.11557075 0.11554839]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11590787 0.11587572 0.11585574 0.11585049 0.11582996 0.11578317
 0.11574166 0.11570875 0.11568231 0.11565937 0.11567161 0.1156409
 0.11562558 0.11561076 0.11557844 0.11556263 0.1155571  0.11550974
 0.11548514 0.1154703 ]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:75.8188910484314
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938234490>
---------------------------------
SparseEpoch: [173][1/398]	Time 0.578	Data 0.000	Loss 2.1018	
SparseEpoch: [173][101/398]	Time 0.579	Data 0.000	Loss 2.2908	
SparseEpoch: [173][201/398]	Time 0.580	Data 0.000	Loss 1.3776	
SparseEpoch: [173][301/398]	Time 0.580	Data 0.000	Loss 1.1995	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.4336	
Epoch(adapt):{0} Loss 0.3291	
Epoch(adapt):{0} Loss 0.6189	
Epoch(adapt):{0} Loss 0.6655	
------------------the total time cost:1168.8612849712372
>>>>>meta updating
Epoch: 0173 | TRAIN: 0.3320 0.7468 0.8879 | 0.2974 0.2974 0.1504 | 0.1114 21.8422 16.9111 0.3311 0.6418 0.7658 ||TEST: 1.2972 0.3904 0.6547 | 0.5192 0.5192 0.2145 | 0.1403 25.1919 20.4009 0.2753 0.5525 0.6841 | 117.2206
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.48228469 0.48228533 0.48229973 0.48228384 0.48231994 0.48234162
 0.48230275 0.48239259 0.48237434 0.48240905 0.48231995 0.48234344
 0.48234005 0.4823459  0.48237053 0.48236238 0.48235303 0.48232255
 0.48228558 0.48226505]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.48237463 0.48236556 0.48235065 0.4823478  0.48235472 0.48234981
 0.48234813 0.48237941 0.48237894 0.48237373 0.48238025 0.48238211
 0.48238887 0.48237211 0.48236792 0.48236037 0.48235822 0.48237173
 0.48237077 0.48235715]
[0.  0.5 0. ]
-----------end of analyzing the loss ratio:75.87709474563599
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9398d27a0>
---------------------------------
SparseEpoch: [174][1/398]	Time 0.595	Data 0.000	Loss 0.2992	
SparseEpoch: [174][101/398]	Time 0.580	Data 0.000	Loss 0.7622	
SparseEpoch: [174][201/398]	Time 0.580	Data 0.000	Loss 0.3551	
SparseEpoch: [174][301/398]	Time 0.580	Data 0.000	Loss 0.5988	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.33527136 0.33523653 0.33517589 0.33508595 0.33505205 0.33495613
 0.33490578 0.33479022 0.33472966 0.33462601 0.33466257 0.33462568
 0.33453117 0.33453264 0.33458468 0.33462235 0.3345798  0.33459012
 0.33452728 0.33448204]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.33463452 0.3346548  0.33465125 0.33463272 0.33462086 0.33462868
 0.33464244 0.33465425 0.33464492 0.3346427  0.334647   0.33464829
 0.33463643 0.33466002 0.33466976 0.33467471 0.33467554 0.33466384
 0.33463379 0.33460703]
[0.5 0.  0.5]
-----------end of analyzing the loss ratio:75.89385509490967
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938944430>
---------------------------------
SparseEpoch: [174][1/398]	Time 0.579	Data 0.000	Loss 0.9894	
SparseEpoch: [174][101/398]	Time 0.581	Data 0.000	Loss 0.9091	
SparseEpoch: [174][201/398]	Time 0.581	Data 0.000	Loss 1.3072	
SparseEpoch: [174][301/398]	Time 0.581	Data 0.000	Loss 1.4180	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.12328001 0.12328166 0.12327946 0.1232806  0.12327967 0.12327932
 0.12328059 0.12328054 0.12328283 0.12328255 0.12328292 0.12328375
 0.12328029 0.12328193 0.12328319 0.12328051 0.12327107 0.12327069
 0.1232704  0.12327173]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.12326148 0.12326499 0.12326832 0.12327417 0.12327691 0.12327597
 0.12327751 0.12328546 0.12329069 0.12328293 0.12328389 0.12329395
 0.12328597 0.12328396 0.12328629 0.12327905 0.12327119 0.12326694
 0.12325886 0.12325857]
[0.44736842 0.5        0.        ]
-----------end of analyzing the loss ratio:76.08114385604858
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938208970>
---------------------------------
SparseEpoch: [174][1/398]	Time 0.578	Data 0.000	Loss 1.1885	
SparseEpoch: [174][101/398]	Time 0.580	Data 0.000	Loss 2.4758	
SparseEpoch: [174][201/398]	Time 0.580	Data 0.000	Loss 1.5469	
SparseEpoch: [174][301/398]	Time 0.580	Data 0.000	Loss 1.3678	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.5529	
Epoch(adapt):{0} Loss 0.5948	
Epoch(adapt):{0} Loss 0.5720	
Epoch(adapt):{0} Loss 0.5277	
------------------the total time cost:1167.171215057373
>>>>>meta updating
Epoch: 0174 | TRAIN: 0.2682 0.7999 0.9136 | 0.2771 0.2771 0.1379 | 0.1113 21.5839 16.4213 0.3498 0.6492 0.7680 ||TEST: 1.3023 0.4145 0.6723 | 0.5071 0.5071 0.2069 | 0.1432 25.1868 20.0350 0.2907 0.5589 0.6850 | 117.2297
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.27625746 0.27627469 0.27628587 0.27634884 0.27638634 0.27638485
 0.27644223 0.27644695 0.27645372 0.27648781 0.27651113 0.27656961
 0.27651857 0.27661339 0.27667927 0.27665127 0.27660931 0.27660795
 0.27663535 0.27669733]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.27651005 0.27650313 0.27650324 0.27650315 0.27651335 0.27651122
 0.27648756 0.27648676 0.27649396 0.27650004 0.27650608 0.27650621
 0.27651092 0.2764946  0.27649313 0.27649633 0.27649499 0.27650432
 0.27649067 0.2764874 ]
[0. 0. 0.]
-----------end of analyzing the loss ratio:75.86960649490356
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938e16cb0>
---------------------------------
SparseEpoch: [175][1/398]	Time 0.577	Data 0.000	Loss 0.3057	
SparseEpoch: [175][101/398]	Time 0.580	Data 0.000	Loss 0.2998	
SparseEpoch: [175][201/398]	Time 0.579	Data 0.000	Loss 0.2243	
SparseEpoch: [175][301/398]	Time 0.579	Data 0.000	Loss 0.1994	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.39712739 0.39714415 0.39710214 0.39704354 0.39701794 0.39691732
 0.39689573 0.3968851  0.39696806 0.39696749 0.39686459 0.3968021
 0.39684017 0.39686067 0.39691082 0.39685379 0.39683628 0.39677335
 0.39678489 0.3967441 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.39695802 0.39696624 0.39697783 0.3969717  0.39697292 0.39696508
 0.39695717 0.3969258  0.39691254 0.39691363 0.39693394 0.39694301
 0.39695096 0.39695437 0.3969521  0.39692747 0.39691029 0.39690388
 0.39690582 0.39690391]
[0.5        0.         0.39473684]
-----------end of analyzing the loss ratio:75.6736228466034
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc93822fb20>
---------------------------------
SparseEpoch: [175][1/398]	Time 0.578	Data 0.000	Loss 0.5766	
SparseEpoch: [175][101/398]	Time 0.580	Data 0.000	Loss 0.7929	
SparseEpoch: [175][201/398]	Time 0.580	Data 0.000	Loss 1.0273	
SparseEpoch: [175][301/398]	Time 0.580	Data 0.000	Loss 0.4915	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11305844 0.11307878 0.11307594 0.11304767 0.11304498 0.11303535
 0.1130302  0.11304062 0.11303796 0.11301752 0.11300461 0.11298847
 0.11299762 0.11298276 0.112971   0.11298583 0.11299897 0.11298013
 0.1129892  0.11299287]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11297966 0.11299415 0.11300147 0.11300319 0.11299361 0.11300256
 0.11302152 0.11300428 0.1130188  0.11301779 0.11300033 0.1130026
 0.11304135 0.11301783 0.11303138 0.11302165 0.1130421  0.11305166
 0.11303873 0.11303771]
[0.23684211 0.         0.        ]
-----------end of analyzing the loss ratio:75.67369890213013
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc89defe920>
---------------------------------
SparseEpoch: [175][1/398]	Time 0.577	Data 0.000	Loss 1.2598	
SparseEpoch: [175][101/398]	Time 0.580	Data 0.000	Loss 1.3118	
SparseEpoch: [175][201/398]	Time 0.580	Data 0.000	Loss 0.8267	
SparseEpoch: [175][301/398]	Time 0.580	Data 0.000	Loss 1.0326	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.6396	
Epoch(adapt):{0} Loss 0.5103	
Epoch(adapt):{0} Loss 0.7421	
Epoch(adapt):{0} Loss 0.4577	
------------------the total time cost:1166.1550023555756
>>>>>meta updating
Epoch: 0175 | TRAIN: 0.2809 0.7936 0.9094 | 0.2811 0.2811 0.1368 | 0.1082 21.2818 16.1567 0.3530 0.6573 0.7752 ||TEST: 1.3297 0.4111 0.6664 | 0.5173 0.5173 0.2069 | 0.1403 25.0311 20.0910 0.2868 0.5584 0.6867 | 116.8517
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.30349191 0.30350462 0.30354617 0.30355266 0.30361652 0.30368743
 0.30370028 0.30365348 0.30366714 0.3036807  0.30367491 0.30370026
 0.30374875 0.30375812 0.30376586 0.30375599 0.30375759 0.30376039
 0.30373914 0.3037382 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.30371906 0.30371143 0.30368974 0.30369929 0.30369812 0.30370599
 0.30369514 0.30369703 0.30368786 0.30369528 0.30369015 0.30368869
 0.30367306 0.30367653 0.30367329 0.3036678  0.30367291 0.3036874
 0.30369041 0.30368507]
[0.         0.         0.28947368]
-----------end of analyzing the loss ratio:75.88206481933594
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc93882f850>
---------------------------------
SparseEpoch: [176][1/398]	Time 0.577	Data 0.000	Loss 0.5846	
SparseEpoch: [176][101/398]	Time 0.580	Data 0.000	Loss 0.6016	
SparseEpoch: [176][201/398]	Time 0.580	Data 0.000	Loss 0.5619	
SparseEpoch: [176][301/398]	Time 0.580	Data 0.000	Loss 1.0216	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.30789877 0.30772514 0.30754217 0.30743541 0.30741245 0.30736241
 0.30722035 0.30702465 0.30705363 0.30695814 0.30694983 0.30694159
 0.30684145 0.30668948 0.30656932 0.30645702 0.30643189 0.3062432
 0.30600409 0.30608664]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.30694741 0.30697884 0.30699644 0.30699776 0.30699583 0.30702053
 0.30699564 0.30701355 0.30698082 0.30698486 0.30692794 0.30695752
 0.3069436  0.30693767 0.30692765 0.30694512 0.30693489 0.30691769
 0.30697076 0.3069833 ]
[0.44736842 0.         0.39473684]
-----------end of analyzing the loss ratio:76.0257625579834
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938d3e440>
---------------------------------
SparseEpoch: [176][1/398]	Time 0.578	Data 0.000	Loss 0.7651	
SparseEpoch: [176][101/398]	Time 0.581	Data 0.000	Loss 1.2462	
SparseEpoch: [176][201/398]	Time 0.580	Data 0.000	Loss 0.9885	
SparseEpoch: [176][301/398]	Time 0.581	Data 0.000	Loss 0.8071	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11648977 0.11644568 0.11642221 0.11636271 0.11635673 0.11636374
 0.11637447 0.11635568 0.11633247 0.11626135 0.11622659 0.11622322
 0.11619524 0.11616286 0.11619848 0.11621113 0.11618457 0.11619726
 0.11615922 0.11618969]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11636749 0.11636126 0.11634529 0.11635393 0.11633134 0.11632175
 0.11628018 0.11629195 0.1162621  0.11626344 0.11624199 0.1162405
 0.11622702 0.11623354 0.11621912 0.11624869 0.11622667 0.11622873
 0.11623523 0.11620856]
[0.44736842 0.5        0.        ]
-----------end of analyzing the loss ratio:75.88456559181213
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9383092d0>
---------------------------------
SparseEpoch: [176][1/398]	Time 0.578	Data 0.000	Loss 1.0040	
SparseEpoch: [176][101/398]	Time 0.580	Data 0.000	Loss 1.5588	
SparseEpoch: [176][201/398]	Time 0.580	Data 0.000	Loss 1.5928	
SparseEpoch: [176][301/398]	Time 0.580	Data 0.000	Loss 1.2855	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.5350	
Epoch(adapt):{0} Loss 0.5430	
Epoch(adapt):{0} Loss 0.5040	
Epoch(adapt):{0} Loss 0.5507	
------------------the total time cost:1168.8955931663513
>>>>>meta updating
Epoch: 0176 | TRAIN: 0.2963 0.7794 0.9031 | 0.2927 0.2927 0.1533 | 0.1093 21.4493 16.3801 0.3462 0.6539 0.7734 ||TEST: 1.3402 0.4045 0.6601 | 0.5154 0.5154 0.2098 | 0.1404 25.0839 20.1526 0.2837 0.5571 0.6861 | 117.1710
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.24336141 0.24337553 0.24339331 0.24342518 0.24340015 0.24339931
 0.24340521 0.24342058 0.24339888 0.2433601  0.24328811 0.24325639
 0.24324201 0.2432647  0.24326959 0.24323038 0.24323356 0.2432437
 0.24325726 0.2432707 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.24324538 0.2432447  0.2432575  0.2432519  0.24322593 0.24323679
 0.2432384  0.24325355 0.24330251 0.24330067 0.24333718 0.24336799
 0.24338966 0.24340548 0.24342139 0.24340586 0.24341152 0.24341717
 0.24341949 0.24340107]
[0.         0.28947368 0.        ]
-----------end of analyzing the loss ratio:75.82137989997864
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc939945c30>
---------------------------------
SparseEpoch: [177][1/398]	Time 0.577	Data 0.000	Loss 0.2741	
SparseEpoch: [177][101/398]	Time 0.579	Data 0.000	Loss 0.5156	
SparseEpoch: [177][201/398]	Time 0.580	Data 0.000	Loss 0.4124	
SparseEpoch: [177][301/398]	Time 0.580	Data 0.000	Loss 0.4632	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.28420775 0.28420539 0.28419019 0.28416549 0.28417337 0.28415965
 0.28413857 0.28410846 0.28409495 0.28412043 0.28407186 0.2840525
 0.28408307 0.28412605 0.28405768 0.28407664 0.28401576 0.28396166
 0.28394044 0.28395819]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.28414299 0.28412416 0.28411745 0.28410984 0.28410546 0.2840935
 0.28409702 0.28410036 0.28411935 0.28412254 0.28411509 0.28411105
 0.28411358 0.28409692 0.28410096 0.2840962  0.28406588 0.28407349
 0.2840817  0.28409184]
[0.44736842 0.         0.34210526]
-----------end of analyzing the loss ratio:75.71547317504883
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc93822c2e0>
---------------------------------
SparseEpoch: [177][1/398]	Time 0.578	Data 0.000	Loss 0.8547	
SparseEpoch: [177][101/398]	Time 0.581	Data 0.000	Loss 0.7173	
SparseEpoch: [177][201/398]	Time 0.581	Data 0.000	Loss 1.0757	
SparseEpoch: [177][301/398]	Time 0.580	Data 0.000	Loss 1.0183	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11608609 0.11608818 0.11608915 0.11608492 0.11608015 0.11608095
 0.11608379 0.11609148 0.11608258 0.1160708  0.11606556 0.11607041
 0.11606519 0.116075   0.11606863 0.11606154 0.11606038 0.11606569
 0.11607016 0.11607475]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11608786 0.11608489 0.11607241 0.11606944 0.11607721 0.11605307
 0.1160545  0.11604585 0.11604736 0.11607098 0.11607902 0.11606644
 0.11606283 0.11606577 0.11606486 0.1160602  0.11607038 0.11607017
 0.11607754 0.11607639]
[0.34210526 0.         0.        ]
-----------end of analyzing the loss ratio:75.90184235572815
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc89dd69180>
---------------------------------
SparseEpoch: [177][1/398]	Time 0.578	Data 0.000	Loss 0.9299	
SparseEpoch: [177][101/398]	Time 0.580	Data 0.000	Loss 1.0038	
SparseEpoch: [177][201/398]	Time 0.580	Data 0.000	Loss 1.1880	
SparseEpoch: [177][301/398]	Time 0.579	Data 0.000	Loss 0.8614	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.8389	
Epoch(adapt):{0} Loss 0.6026	
Epoch(adapt):{0} Loss 0.7678	
Epoch(adapt):{0} Loss 0.6298	
------------------the total time cost:1169.0075969696045
>>>>>meta updating
Epoch: 0177 | TRAIN: 0.2711 0.7990 0.9127 | 0.2922 0.2922 0.1394 | 0.1087 21.3967 16.3895 0.3463 0.6538 0.7741 ||TEST: 1.2732 0.4138 0.6707 | 0.5211 0.5211 0.2085 | 0.1410 25.1127 20.1017 0.2856 0.5571 0.6849 | 117.9557
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.29367447 0.29363471 0.29356439 0.29349983 0.29356197 0.29358327
 0.29353499 0.29362912 0.29357785 0.29346638 0.2934573  0.2932993
 0.29321893 0.29322619 0.29320593 0.29317351 0.2932059  0.29312987
 0.29314484 0.29314439]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.29332515 0.29332591 0.29333413 0.2933208  0.29335045 0.29337981
 0.29335932 0.2933832  0.2934081  0.2934269  0.29345196 0.29345807
 0.29345843 0.29347547 0.2934818  0.29348578 0.29346407 0.29348578
 0.29349173 0.29350285]
[0.         0.39473684 0.        ]
-----------end of analyzing the loss ratio:75.93447542190552
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9387521d0>
---------------------------------
SparseEpoch: [178][1/398]	Time 0.577	Data 0.000	Loss 0.4770	
SparseEpoch: [178][101/398]	Time 0.580	Data 0.000	Loss 0.2661	
SparseEpoch: [178][201/398]	Time 0.580	Data 0.000	Loss 0.3809	
SparseEpoch: [178][301/398]	Time 0.580	Data 0.000	Loss 0.3876	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.34289623 0.34295155 0.3428575  0.34284814 0.34274458 0.34281252
 0.34284634 0.34280661 0.34268767 0.3427367  0.34284118 0.3427524
 0.34280325 0.3427065  0.34279955 0.34274968 0.34261335 0.34263794
 0.3425649  0.34243481]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.34280853 0.3428038  0.34280148 0.34281342 0.34280074 0.34281289
 0.34280205 0.3427986  0.34278861 0.34278694 0.34278363 0.34279383
 0.34278269 0.34278052 0.34280124 0.34281491 0.34281151 0.34280942
 0.34282811 0.34281312]
[0.5        0.         0.18421053]
-----------end of analyzing the loss ratio:76.18066382408142
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc89dc58670>
---------------------------------
SparseEpoch: [178][1/398]	Time 0.578	Data 0.000	Loss 0.6301	
SparseEpoch: [178][101/398]	Time 0.581	Data 0.000	Loss 0.4868	
SparseEpoch: [178][201/398]	Time 0.581	Data 0.000	Loss 0.4105	
SparseEpoch: [178][301/398]	Time 0.580	Data 0.000	Loss 0.7077	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.12625993 0.12625436 0.12626562 0.12626088 0.12627049 0.12625912
 0.1262615  0.12626806 0.12627931 0.12627832 0.12628843 0.12629274
 0.12630657 0.12631181 0.12631543 0.12632154 0.1263327  0.12633592
 0.12634482 0.12632131]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.12641884 0.12640747 0.12640635 0.12639707 0.12638624 0.12637419
 0.12634775 0.12633708 0.12631368 0.12628919 0.126282   0.12626553
 0.12627074 0.12626793 0.12629243 0.12627384 0.12625888 0.12624928
 0.12625206 0.12622288]
[0.  0.5 0. ]
-----------end of analyzing the loss ratio:76.13385725021362
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc89dd9be80>
---------------------------------
SparseEpoch: [178][1/398]	Time 0.578	Data 0.000	Loss 1.6023	
SparseEpoch: [178][101/398]	Time 0.580	Data 0.000	Loss 0.8647	
SparseEpoch: [178][201/398]	Time 0.580	Data 0.000	Loss 1.4037	
SparseEpoch: [178][301/398]	Time 0.580	Data 0.000	Loss 1.5051	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.6456	
Epoch(adapt):{0} Loss 0.4339	
Epoch(adapt):{0} Loss 0.9211	
Epoch(adapt):{0} Loss 0.7338	
------------------the total time cost:1168.2592997550964
>>>>>meta updating
Epoch: 0178 | TRAIN: 0.2864 0.7812 0.9058 | 0.2752 0.2752 0.1342 | 0.1078 21.3512 16.4369 0.3469 0.6511 0.7721 ||TEST: 1.3123 0.4106 0.6685 | 0.5098 0.5098 0.2078 | 0.1415 25.1897 20.3012 0.2839 0.5535 0.6820 | 117.2447
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.27533609 0.27514736 0.27501069 0.27503277 0.27505523 0.27489482
 0.27479214 0.27469621 0.27452151 0.27445299 0.27443113 0.27459988
 0.27461411 0.27446802 0.27435584 0.27427447 0.27416696 0.27406741
 0.27391778 0.27397854]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.27440376 0.27439434 0.27439435 0.27440491 0.27439377 0.27438582
 0.27437695 0.27434466 0.27435904 0.27439385 0.27441015 0.27441151
 0.27440314 0.27441029 0.27441679 0.2744232  0.27445691 0.27446443
 0.27446799 0.27444146]
[0.         0.44736842 0.        ]
-----------end of analyzing the loss ratio:75.96577572822571
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cca5deca800>
---------------------------------
SparseEpoch: [179][1/398]	Time 0.578	Data 0.000	Loss 0.3705	
SparseEpoch: [179][101/398]	Time 0.581	Data 0.000	Loss 0.3518	
SparseEpoch: [179][201/398]	Time 0.580	Data 0.000	Loss 0.3886	
SparseEpoch: [179][301/398]	Time 0.580	Data 0.000	Loss 0.2561	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.31020691 0.31021143 0.31031879 0.31037013 0.31033946 0.31028262
 0.31029299 0.31032133 0.31035407 0.31039032 0.31043314 0.31042267
 0.31050107 0.31056171 0.31059858 0.31063564 0.31071825 0.31068709
 0.31069825 0.31073099]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.31048896 0.31048714 0.31046463 0.31044617 0.31046255 0.31046718
 0.31047032 0.31043398 0.3104321  0.3104099  0.31038792 0.310388
 0.31038048 0.31035995 0.31035416 0.3103458  0.31037069 0.31037239
 0.31035669 0.31032134]
[0.  0.  0.5]
-----------end of analyzing the loss ratio:76.02907729148865
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938768eb0>
---------------------------------
SparseEpoch: [179][1/398]	Time 0.581	Data 0.000	Loss 0.6803	
SparseEpoch: [179][101/398]	Time 0.579	Data 0.000	Loss 0.8595	
SparseEpoch: [179][201/398]	Time 0.580	Data 0.000	Loss 1.2891	
SparseEpoch: [179][301/398]	Time 0.580	Data 0.000	Loss 0.8018	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.10084996 0.10085185 0.10086386 0.10086882 0.10083979 0.10081766
 0.10080987 0.10080171 0.10080818 0.10083033 0.10081933 0.10079411
 0.10081507 0.10081627 0.10079337 0.10079916 0.10079061 0.10077691
 0.10079435 0.10083016]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.10083432 0.10082082 0.100823   0.10081539 0.1008042  0.10080799
 0.100823   0.10080564 0.10081454 0.10081425 0.10083209 0.1008287
 0.10080669 0.1008187  0.10083047 0.10082012 0.10082611 0.10081781
 0.10082962 0.10083277]
[0.39473684 0.         0.        ]
-----------end of analyzing the loss ratio:76.05926609039307
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9386a7880>
---------------------------------
SparseEpoch: [179][1/398]	Time 0.585	Data 0.000	Loss 0.6507	
SparseEpoch: [179][101/398]	Time 0.579	Data 0.000	Loss 1.1504	
SparseEpoch: [179][201/398]	Time 0.579	Data 0.000	Loss 1.0055	
SparseEpoch: [179][301/398]	Time 0.579	Data 0.000	Loss 1.4194	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.3977	
Epoch(adapt):{0} Loss 0.5607	
Epoch(adapt):{0} Loss 0.6250	
Epoch(adapt):{0} Loss 0.6291	
------------------the total time cost:1169.2083702087402
>>>>>meta updating
Epoch: 0179 | TRAIN: 0.3400 0.7474 0.8876 | 0.3017 0.3017 0.1397 | 0.1067 21.2231 16.2624 0.3477 0.6577 0.7778 ||TEST: 1.3381 0.3913 0.6558 | 0.5323 0.5323 0.2104 | 0.1405 25.0672 20.0903 0.2856 0.5578 0.6863 | 117.1013
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.37910807 0.37908862 0.37909248 0.37905136 0.37908629 0.3791006
 0.37911264 0.37910724 0.37910375 0.37914452 0.37918629 0.37919315
 0.37915615 0.3791461  0.37913731 0.37907525 0.37908218 0.37907947
 0.37909123 0.37907132]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.37922699 0.37921044 0.37916518 0.37913413 0.37910824 0.37909979
 0.37910744 0.37913317 0.37908695 0.37917868 0.37916327 0.37919216
 0.37921101 0.37923307 0.37920362 0.37914288 0.3791168  0.37909998
 0.37908848 0.37902014]
[0.  0.  0.5]
-----------end of analyzing the loss ratio:76.00905895233154
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938836e60>
---------------------------------
SparseEpoch: [180][1/398]	Time 0.583	Data 0.000	Loss 0.6259	
SparseEpoch: [180][101/398]	Time 0.580	Data 0.000	Loss 1.1748	
SparseEpoch: [180][201/398]	Time 0.580	Data 0.000	Loss 0.7610	
SparseEpoch: [180][301/398]	Time 0.580	Data 0.000	Loss 0.8792	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.29711047 0.29724099 0.29720407 0.29723677 0.29727684 0.29717413
 0.29710272 0.29707516 0.29703576 0.29716832 0.29717271 0.29708666
 0.29712111 0.29710086 0.29711037 0.29706162 0.29703622 0.29706547
 0.29702614 0.29703167]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.29724669 0.29722535 0.29719175 0.2971909  0.29719048 0.2971884
 0.29719605 0.29721043 0.29719999 0.29719791 0.29716962 0.29715353
 0.29710972 0.29711952 0.2971098  0.29711278 0.29708801 0.29708078
 0.29706545 0.29704213]
[0.44736842 0.         0.5       ]
-----------end of analyzing the loss ratio:75.94731092453003
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc89dc5bd00>
---------------------------------
SparseEpoch: [180][1/398]	Time 0.578	Data 0.000	Loss 0.9428	
SparseEpoch: [180][101/398]	Time 0.581	Data 0.000	Loss 0.8359	
SparseEpoch: [180][201/398]	Time 0.581	Data 0.000	Loss 0.7466	
SparseEpoch: [180][301/398]	Time 0.580	Data 0.000	Loss 1.4606	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.10259456 0.10259306 0.10259885 0.10260161 0.10260119 0.10260063
 0.10261242 0.10261524 0.1026092  0.10258383 0.10258314 0.10258836
 0.10256287 0.10256013 0.102565   0.10255643 0.10255053 0.1025589
 0.10256903 0.1025747 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.10260826 0.10261969 0.10260441 0.10261177 0.1026475  0.1026961
 0.1026574  0.10265668 0.10261034 0.10258453 0.10257171 0.10257898
 0.10254503 0.10256076 0.10255063 0.10254411 0.10253699 0.10253856
 0.10253912 0.10254338]
[0.34210526 0.34210526 0.        ]
-----------end of analyzing the loss ratio:75.90089797973633
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9382f1d20>
---------------------------------
SparseEpoch: [180][1/398]	Time 0.578	Data 0.000	Loss 1.1510	
SparseEpoch: [180][101/398]	Time 0.581	Data 0.000	Loss 1.9272	
SparseEpoch: [180][201/398]	Time 0.581	Data 0.000	Loss 1.0283	
SparseEpoch: [180][301/398]	Time 0.581	Data 0.000	Loss 1.8659	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.7690	
Epoch(adapt):{0} Loss 0.7309	
Epoch(adapt):{0} Loss 0.4548	
Epoch(adapt):{0} Loss 0.7992	
------------------the total time cost:1167.1822068691254
>>>>>meta updating
Epoch: 0180 | TRAIN: 0.2657 0.8011 0.9137 | 0.2841 0.2841 0.1405 | 0.1088 21.3283 16.2309 0.3530 0.6570 0.7749 ||TEST: 1.3153 0.4147 0.6723 | 0.5131 0.5131 0.2097 | 0.1405 24.9781 19.8836 0.2904 0.5627 0.6891 | 117.3876
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.25383013 0.25383276 0.25386344 0.25388291 0.25385081 0.25385102
 0.25385921 0.25391759 0.25391518 0.2539166  0.25391208 0.25393966
 0.25392588 0.25391208 0.2539509  0.25403198 0.25402157 0.25404622
 0.25401363 0.25403916]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.25386954 0.25386891 0.25389731 0.25391776 0.25391417 0.25390777
 0.25392492 0.25392599 0.25393885 0.25393394 0.25393254 0.25390332
 0.25389752 0.25390312 0.25392703 0.25391785 0.25394009 0.25392126
 0.25390316 0.2539012 ]
[0. 0. 0.]
-----------end of analyzing the loss ratio:76.14767217636108
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc89de12fe0>
---------------------------------
SparseEpoch: [181][1/398]	Time 0.577	Data 0.000	Loss 0.1977	
SparseEpoch: [181][101/398]	Time 0.579	Data 0.000	Loss 0.2813	
SparseEpoch: [181][201/398]	Time 0.580	Data 0.000	Loss 0.1659	
SparseEpoch: [181][301/398]	Time 0.579	Data 0.000	Loss 0.2641	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.43093274 0.43083992 0.43082766 0.43074325 0.43066196 0.43057401
 0.43046266 0.4304438  0.43042052 0.43037666 0.43032125 0.43026276
 0.43017538 0.43021227 0.4302164  0.43016976 0.43012716 0.4301291
 0.43003678 0.42995416]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.43042049 0.43043467 0.43041216 0.43040753 0.43039461 0.43038857
 0.43040836 0.43038604 0.43037117 0.43035448 0.43033438 0.43030988
 0.43030992 0.43027096 0.43024783 0.43020625 0.43019329 0.43018352
 0.43022165 0.43023162]
[0.5        0.         0.39473684]
-----------end of analyzing the loss ratio:76.01241183280945
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc89dc5b8e0>
---------------------------------
SparseEpoch: [181][1/398]	Time 0.587	Data 0.000	Loss 1.0104	
SparseEpoch: [181][101/398]	Time 0.580	Data 0.000	Loss 0.6519	
SparseEpoch: [181][201/398]	Time 0.580	Data 0.000	Loss 0.8331	
SparseEpoch: [181][301/398]	Time 0.580	Data 0.000	Loss 0.6239	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11331807 0.11332442 0.11330733 0.11328022 0.1132876  0.11332054
 0.11331971 0.11331667 0.11333188 0.11335435 0.1133315  0.1133324
 0.11334168 0.11333883 0.11334376 0.11335062 0.11335227 0.11334155
 0.11334997 0.11335353]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11334135 0.11334591 0.11334515 0.11333928 0.11333773 0.11334001
 0.11333867 0.11334255 0.11334258 0.11335027 0.11335253 0.11334587
 0.11334161 0.11333726 0.11334005 0.11333774 0.11333521 0.11333572
 0.11333756 0.11333803]
[0.         0.34210526 0.        ]
-----------end of analyzing the loss ratio:75.8380823135376
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9387c6e30>
---------------------------------
SparseEpoch: [181][1/398]	Time 0.577	Data 0.000	Loss 1.2708	
SparseEpoch: [181][101/398]	Time 0.580	Data 0.000	Loss 1.0886	
SparseEpoch: [181][201/398]	Time 0.580	Data 0.000	Loss 0.9484	
SparseEpoch: [181][301/398]	Time 0.580	Data 0.000	Loss 1.4228	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.6827	
Epoch(adapt):{0} Loss 0.4876	
Epoch(adapt):{0} Loss 0.4250	
Epoch(adapt):{0} Loss 0.5428	
------------------the total time cost:1168.110407590866
>>>>>meta updating
Epoch: 0181 | TRAIN: 0.2723 0.7923 0.9121 | 0.2961 0.2961 0.1328 | 0.1048 20.8560 15.7688 0.3631 0.6676 0.7833 ||TEST: 1.3746 0.4117 0.6654 | 0.5380 0.5380 0.2072 | 0.1403 24.9322 19.8196 0.2925 0.5636 0.6902 | 117.1358
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.24207345 0.24210706 0.24209465 0.24204831 0.24213181 0.2421708
 0.24216428 0.24217046 0.24209212 0.24203002 0.24179337 0.24175916
 0.24162803 0.24166877 0.24167827 0.24177198 0.24178813 0.24184848
 0.24185228 0.24174615]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.24186704 0.24186287 0.24186504 0.24187525 0.2418838  0.24190199
 0.24191292 0.24191029 0.24192526 0.24193069 0.24192733 0.24192931
 0.2419186  0.24190515 0.2418946  0.24189454 0.24191419 0.24192858
 0.24192381 0.24193628]
[0.         0.13157895 0.        ]
-----------end of analyzing the loss ratio:75.75169229507446
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc89ddc6b90>
---------------------------------
SparseEpoch: [182][1/398]	Time 0.577	Data 0.000	Loss 0.1957	
SparseEpoch: [182][101/398]	Time 0.580	Data 0.000	Loss 0.2255	
SparseEpoch: [182][201/398]	Time 0.580	Data 0.000	Loss 0.2418	
SparseEpoch: [182][301/398]	Time 0.581	Data 0.000	Loss 0.4110	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.35990334 0.35998588 0.3600255  0.36008281 0.36016814 0.36021231
 0.36016578 0.36027412 0.36041094 0.36044357 0.36062219 0.36079457
 0.36091107 0.36086332 0.36088896 0.36095659 0.36101244 0.36118151
 0.3611823  0.36126259]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.36058159 0.36059944 0.36059185 0.36058538 0.36056959 0.36055928
 0.3605616  0.36056153 0.3605499  0.36054551 0.36053139 0.36056329
 0.36054632 0.36054617 0.36054278 0.36052192 0.36053198 0.36051413
 0.3605206  0.36041438]
[0.  0.  0.5]
-----------end of analyzing the loss ratio:75.87787532806396
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc89dccfb20>
---------------------------------
SparseEpoch: [182][1/398]	Time 0.577	Data 0.000	Loss 0.6395	
SparseEpoch: [182][101/398]	Time 0.580	Data 0.000	Loss 0.6122	
SparseEpoch: [182][201/398]	Time 0.579	Data 0.000	Loss 0.5418	
SparseEpoch: [182][301/398]	Time 0.580	Data 0.000	Loss 0.5545	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.10834649 0.10832835 0.10829537 0.10827549 0.10828089 0.108245
 0.10824189 0.10823141 0.10821245 0.10821954 0.1081718  0.10815773
 0.10819013 0.10818626 0.10819695 0.10820823 0.10818899 0.10815284
 0.10813407 0.1081275 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.10820706 0.10820045 0.10820098 0.10819623 0.10819763 0.10819989
 0.10819644 0.10820118 0.10819489 0.10819948 0.10819472 0.10819784
 0.1081966  0.10818216 0.10817746 0.10817466 0.10816541 0.10816945
 0.10817108 0.1081636 ]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:76.35476326942444
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938c6e1a0>
---------------------------------
SparseEpoch: [182][1/398]	Time 0.578	Data 0.000	Loss 1.3155	
SparseEpoch: [182][101/398]	Time 0.581	Data 0.000	Loss 1.8093	
SparseEpoch: [182][201/398]	Time 0.580	Data 0.000	Loss 1.3964	
SparseEpoch: [182][301/398]	Time 0.580	Data 0.000	Loss 1.0502	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.4862	
Epoch(adapt):{0} Loss 0.7311	
Epoch(adapt):{0} Loss 0.4256	
Epoch(adapt):{0} Loss 0.6083	
------------------the total time cost:1168.4066398143768
>>>>>meta updating
Epoch: 0182 | TRAIN: 0.3000 0.7725 0.9014 | 0.2902 0.2902 0.1443 | 0.1075 21.1864 16.0911 0.3555 0.6606 0.7775 ||TEST: 1.2990 0.3975 0.6576 | 0.5166 0.5166 0.2130 | 0.1402 24.9875 19.9395 0.2885 0.5611 0.6888 | 117.0913
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.32462527 0.32464532 0.3247111  0.32479787 0.32469413 0.32467608
 0.32462071 0.32471059 0.32469821 0.32469772 0.32467373 0.32461939
 0.32457546 0.32451051 0.32455973 0.32465039 0.32459078 0.32464385
 0.32451297 0.32456593]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.32474038 0.32474262 0.32471824 0.32473345 0.32472141 0.32471472
 0.32465091 0.3246643  0.32468135 0.32470766 0.32474023 0.32472841
 0.3247153  0.32470298 0.32470905 0.32467062 0.32468436 0.32466295
 0.32467383 0.32469911]
[0.         0.18421053 0.        ]
-----------end of analyzing the loss ratio:76.00879073143005
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9385e4880>
---------------------------------
SparseEpoch: [183][1/398]	Time 0.577	Data 0.000	Loss 0.2959	
SparseEpoch: [183][101/398]	Time 0.580	Data 0.000	Loss 0.2398	
SparseEpoch: [183][201/398]	Time 0.580	Data 0.000	Loss 0.3157	
SparseEpoch: [183][301/398]	Time 0.580	Data 0.000	Loss 0.5022	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.39415751 0.3941426  0.39418711 0.39423769 0.39428799 0.3943189
 0.39435368 0.39437776 0.3943421  0.39436482 0.39444625 0.39441612
 0.39446075 0.39448697 0.39452334 0.3945384  0.39455671 0.39448864
 0.39451062 0.39456092]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.39438537 0.39437156 0.3943855  0.39437689 0.394382   0.3943772
 0.39438607 0.39439974 0.39439027 0.39437358 0.39440808 0.39443017
 0.39442489 0.39438189 0.39438863 0.39439291 0.39442112 0.39442408
 0.39441822 0.39442262]
[0. 0. 0.]
-----------end of analyzing the loss ratio:75.93875026702881
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9385b31c0>
---------------------------------
SparseEpoch: [183][1/398]	Time 0.577	Data 0.000	Loss 0.1661	
SparseEpoch: [183][101/398]	Time 0.580	Data 0.000	Loss 0.4827	
SparseEpoch: [183][201/398]	Time 0.579	Data 0.000	Loss 0.3108	
SparseEpoch: [183][301/398]	Time 0.579	Data 0.000	Loss 0.2660	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11648079 0.11647862 0.11645305 0.1164306  0.11640322 0.11638169
 0.11636803 0.11632456 0.11630747 0.11626697 0.11622885 0.11620109
 0.11616381 0.11612448 0.11611387 0.11611315 0.11612759 0.1161097
 0.11608038 0.11605831]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11644879 0.11642964 0.11640573 0.11640045 0.11637613 0.11636812
 0.1163325  0.11632926 0.11630628 0.11626421 0.11622105 0.11622083
 0.11619095 0.11615757 0.11613823 0.11613919 0.11614907 0.11612408
 0.11611093 0.11610837]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:76.18069815635681
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc89ddc7d00>
---------------------------------
SparseEpoch: [183][1/398]	Time 0.589	Data 0.000	Loss 1.8174	
SparseEpoch: [183][101/398]	Time 0.580	Data 0.000	Loss 0.9184	
SparseEpoch: [183][201/398]	Time 0.580	Data 0.000	Loss 1.3508	
SparseEpoch: [183][301/398]	Time 0.580	Data 0.000	Loss 1.4684	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.7803	
Epoch(adapt):{0} Loss 0.7426	
Epoch(adapt):{0} Loss 0.6153	
Epoch(adapt):{0} Loss 0.6151	
------------------the total time cost:1168.0626890659332
>>>>>meta updating
Epoch: 0183 | TRAIN: 0.3050 0.7666 0.8988 | 0.2857 0.2857 0.1362 | 0.1093 21.5495 16.6281 0.3414 0.6478 0.7693 ||TEST: 1.2868 0.3964 0.6620 | 0.5201 0.5201 0.2072 | 0.1417 25.2580 20.3297 0.2805 0.5524 0.6812 | 117.2421
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.39341381 0.39337704 0.39331079 0.39332978 0.39331558 0.39332321
 0.39321255 0.3931862  0.39308139 0.39307274 0.39300206 0.39296652
 0.39293839 0.39288355 0.39283885 0.39273172 0.39266234 0.39271028
 0.3926011  0.39250744]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.39308721 0.39307494 0.39308915 0.39307465 0.39306603 0.3930506
 0.39304695 0.3930445  0.39304282 0.39300084 0.39298623 0.39299612
 0.39300412 0.3930028  0.39299362 0.39300522 0.39299654 0.39300301
 0.39300852 0.39300913]
[0.         0.5        0.02631579]
-----------end of analyzing the loss ratio:76.31286716461182
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc89dd0dcc0>
---------------------------------
SparseEpoch: [184][1/398]	Time 0.579	Data 0.000	Loss 0.2912	
SparseEpoch: [184][101/398]	Time 0.581	Data 0.000	Loss 0.4150	
SparseEpoch: [184][201/398]	Time 0.580	Data 0.000	Loss 1.3016	
SparseEpoch: [184][301/398]	Time 0.580	Data 0.000	Loss 0.5371	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.35403137 0.35398217 0.35396082 0.35390807 0.3538178  0.35385805
 0.35376101 0.35378981 0.35385391 0.35383473 0.35374662 0.35372585
 0.35369239 0.35366486 0.35367474 0.35358679 0.35359496 0.35345683
 0.35335264 0.35329983]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.35383562 0.3538194  0.35379097 0.35377571 0.35375152 0.3537559
 0.35376324 0.35374766 0.35373684 0.35380664 0.35377572 0.35374056
 0.35376406 0.3537539  0.35374154 0.35377195 0.35375756 0.35376242
 0.35373583 0.35372541]
[0.5 0.  0.5]
-----------end of analyzing the loss ratio:75.93453407287598
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc89dc5b970>
---------------------------------
SparseEpoch: [184][1/398]	Time 0.580	Data 0.000	Loss 0.7609	
SparseEpoch: [184][101/398]	Time 0.580	Data 0.000	Loss 0.6722	
SparseEpoch: [184][201/398]	Time 0.580	Data 0.000	Loss 1.0968	
SparseEpoch: [184][301/398]	Time 0.581	Data 0.000	Loss 0.8364	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.09823506 0.09823825 0.09821627 0.09821545 0.09821067 0.09818988
 0.09818956 0.09820985 0.09819345 0.09819639 0.09821178 0.09818935
 0.09816611 0.09815643 0.09813911 0.09813624 0.09813989 0.09811901
 0.0981181  0.09812441]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.09815641 0.09815398 0.09815794 0.0981523  0.09816048 0.0981912
 0.09820878 0.09820232 0.09818826 0.09820465 0.09821972 0.09819605
 0.0981769  0.0981822  0.09815649 0.09815902 0.0981615  0.09817611
 0.09816242 0.09815554]
[0.44736842 0.         0.        ]
-----------end of analyzing the loss ratio:75.96148490905762
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9382c4b50>
---------------------------------
SparseEpoch: [184][1/398]	Time 0.593	Data 0.000	Loss 1.6144	
SparseEpoch: [184][101/398]	Time 0.581	Data 0.000	Loss 1.1804	
SparseEpoch: [184][201/398]	Time 0.580	Data 0.000	Loss 0.8214	
SparseEpoch: [184][301/398]	Time 0.580	Data 0.000	Loss 1.3722	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.5488	
Epoch(adapt):{0} Loss 0.5459	
Epoch(adapt):{0} Loss 0.6187	
Epoch(adapt):{0} Loss 0.8138	
------------------the total time cost:1168.9767384529114
>>>>>meta updating
Epoch: 0184 | TRAIN: 0.2664 0.8061 0.9135 | 0.2816 0.2816 0.1366 | 0.1076 21.2482 16.2073 0.3517 0.6579 0.7762 ||TEST: 1.2915 0.4121 0.6678 | 0.5184 0.5184 0.2108 | 0.1412 25.0616 20.0006 0.2903 0.5593 0.6860 | 117.5719
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.28851077 0.28851093 0.28847922 0.28847564 0.28846107 0.28844175
 0.28845093 0.28852581 0.28847845 0.28837083 0.28828879 0.28832306
 0.288314   0.28835971 0.28839468 0.2884417  0.28835856 0.28843586
 0.28841163 0.28854747]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.28832411 0.28826549 0.28830413 0.28829866 0.28833082 0.28832004
 0.28831461 0.28832737 0.2883053  0.2883072  0.28834027 0.2883296
 0.28834327 0.28838576 0.28838392 0.28840816 0.28842295 0.28843891
 0.28844664 0.28844422]
[0.         0.02631579 0.        ]
-----------end of analyzing the loss ratio:76.22790145874023
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938d66260>
---------------------------------
SparseEpoch: [185][1/398]	Time 0.577	Data 0.000	Loss 0.2220	
SparseEpoch: [185][101/398]	Time 0.580	Data 0.000	Loss 0.2647	
SparseEpoch: [185][201/398]	Time 0.580	Data 0.000	Loss 0.2424	
SparseEpoch: [185][301/398]	Time 0.580	Data 0.000	Loss 0.2899	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.33325254 0.33313862 0.33320618 0.33322024 0.33328316 0.33327687
 0.33323819 0.33313268 0.33314761 0.3331008  0.33300601 0.33304705
 0.33299781 0.3330388  0.33301983 0.33301321 0.33295283 0.33291776
 0.33297043 0.33291468]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.33311075 0.33313496 0.33312628 0.33308435 0.3330695  0.33306194
 0.33307276 0.33307783 0.33308338 0.33305021 0.33306896 0.33306809
 0.33303389 0.33303463 0.33302254 0.33304544 0.33302216 0.33303798
 0.33303447 0.33302177]
[0.5 0.  0.5]
-----------end of analyzing the loss ratio:76.13419651985168
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938b7d030>
---------------------------------
SparseEpoch: [185][1/398]	Time 0.578	Data 0.000	Loss 0.7589	
SparseEpoch: [185][101/398]	Time 0.581	Data 0.000	Loss 1.0335	
SparseEpoch: [185][201/398]	Time 0.581	Data 0.000	Loss 0.8449	
SparseEpoch: [185][301/398]	Time 0.580	Data 0.000	Loss 0.6703	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.08869106 0.08869359 0.08870004 0.08870605 0.08870365 0.08869821
 0.08870101 0.08869807 0.08870269 0.08869918 0.08869852 0.08870609
 0.08870216 0.08870685 0.08869817 0.0886933  0.08869394 0.08869665
 0.08868871 0.08869584]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.08872676 0.0887277  0.08871157 0.08871198 0.08870851 0.0887083
 0.08870508 0.08870714 0.08871171 0.08869978 0.08870232 0.08869468
 0.0886823  0.08868051 0.08867864 0.0886806  0.08867719 0.08867646
 0.08866971 0.08866393]
[0.44736842 0.5        0.        ]
-----------end of analyzing the loss ratio:76.13199281692505
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc89dd0e860>
---------------------------------
SparseEpoch: [185][1/398]	Time 0.580	Data 0.000	Loss 1.5028	
SparseEpoch: [185][101/398]	Time 0.580	Data 0.000	Loss 1.0609	
SparseEpoch: [185][201/398]	Time 0.580	Data 0.000	Loss 1.4006	
SparseEpoch: [185][301/398]	Time 0.580	Data 0.000	Loss 2.5939	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.5496	
Epoch(adapt):{0} Loss 0.4545	
Epoch(adapt):{0} Loss 0.6885	
Epoch(adapt):{0} Loss 0.6495	
------------------the total time cost:1167.7664897441864
>>>>>meta updating
Epoch: 0185 | TRAIN: 0.2833 0.7862 0.9060 | 0.2728 0.2728 0.1357 | 0.1062 21.0485 16.0003 0.3592 0.6610 0.7787 ||TEST: 1.3851 0.4047 0.6599 | 0.5110 0.5110 0.2098 | 0.1419 25.0958 19.9703 0.2914 0.5598 0.6861 | 117.4434
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.22442158 0.22451175 0.22454093 0.22453438 0.22460265 0.22470749
 0.22486995 0.22474206 0.22458174 0.22469417 0.2244721  0.22438431
 0.22440516 0.2244663  0.22453879 0.22453838 0.22448198 0.22443654
 0.22435836 0.22447844]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.22466458 0.22462434 0.22460443 0.22459463 0.22459144 0.22458057
 0.22457489 0.22458665 0.22456235 0.22454986 0.22452342 0.22451047
 0.22451019 0.22448155 0.22447742 0.22444898 0.22443508 0.22444841
 0.22441638 0.2244346 ]
[0.         0.44736842 0.44736842]
-----------end of analyzing the loss ratio:76.03192639350891
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc89de12aa0>
---------------------------------
SparseEpoch: [186][1/398]	Time 0.579	Data 0.000	Loss 0.6530	
SparseEpoch: [186][101/398]	Time 0.581	Data 0.000	Loss 0.6494	
SparseEpoch: [186][201/398]	Time 0.581	Data 0.000	Loss 0.9858	
SparseEpoch: [186][301/398]	Time 0.581	Data 0.000	Loss 0.7374	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.25755681 0.25755424 0.25756883 0.25758047 0.25755243 0.25759266
 0.25758464 0.25756591 0.25753977 0.25754933 0.25759027 0.25757287
 0.25758644 0.25756748 0.2575671  0.25761554 0.25763147 0.25763714
 0.2576859  0.25765391]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.2575204  0.25751339 0.25752889 0.25754193 0.25754869 0.25755428
 0.25756409 0.25756531 0.25755411 0.25754582 0.2575605  0.25754907
 0.25755367 0.25754513 0.25754722 0.25753596 0.25755357 0.25756139
 0.25755746 0.25756644]
[0. 0. 0.]
-----------end of analyzing the loss ratio:75.95469117164612
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9398f9ea0>
---------------------------------
SparseEpoch: [186][1/398]	Time 0.577	Data 0.000	Loss 0.2489	
SparseEpoch: [186][101/398]	Time 0.579	Data 0.000	Loss 0.1903	
SparseEpoch: [186][201/398]	Time 0.579	Data 0.000	Loss 0.1941	
SparseEpoch: [186][301/398]	Time 0.579	Data 0.000	Loss 0.2054	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.12254631 0.12252538 0.12250506 0.12250343 0.12247349 0.12243115
 0.12241285 0.12236494 0.12230737 0.12229074 0.12225472 0.12223951
 0.12218195 0.12220511 0.12219111 0.12220309 0.12218166 0.12209169
 0.12207404 0.12204533]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.12239718 0.12240267 0.1223842  0.12237525 0.12235996 0.12238654
 0.12235254 0.12232768 0.1222984  0.12227393 0.1222608  0.12224049
 0.12223609 0.12222491 0.12224717 0.12227113 0.12228101 0.12225325
 0.12220466 0.12213311]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:75.8773365020752
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938f17d90>
---------------------------------
SparseEpoch: [186][1/398]	Time 0.582	Data 0.000	Loss 1.7048	
SparseEpoch: [186][101/398]	Time 0.581	Data 0.000	Loss 1.2420	
SparseEpoch: [186][201/398]	Time 0.581	Data 0.000	Loss 1.0743	
SparseEpoch: [186][301/398]	Time 0.581	Data 0.000	Loss 1.7682	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.8241	
Epoch(adapt):{0} Loss 0.7572	
Epoch(adapt):{0} Loss 0.5310	
Epoch(adapt):{0} Loss 0.5457	
------------------the total time cost:1167.872899055481
>>>>>meta updating
Epoch: 0186 | TRAIN: 0.2699 0.8001 0.9135 | 0.2710 0.2710 0.1321 | 0.1044 20.7407 15.5493 0.3682 0.6744 0.7871 ||TEST: 1.3667 0.4120 0.6658 | 0.5145 0.5145 0.2065 | 0.1404 24.8856 19.6597 0.2942 0.5673 0.6933 | 117.2125
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.27472949 0.27476983 0.27477083 0.27470545 0.27473137 0.27477133
 0.27476343 0.27469108 0.27470187 0.27471916 0.27471519 0.27469803
 0.27470782 0.27474665 0.27476758 0.27474973 0.27474482 0.27479143
 0.2747899  0.27471714]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.27468244 0.27468551 0.27470305 0.27469761 0.27469867 0.27472809
 0.27471939 0.27472377 0.27474406 0.27474712 0.27474734 0.27473798
 0.27474932 0.27472863 0.27473664 0.27473194 0.27473204 0.27473312
 0.27474145 0.2747481 ]
[0. 0. 0.]
-----------end of analyzing the loss ratio:76.28047108650208
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9382f1990>
---------------------------------
SparseEpoch: [187][1/398]	Time 0.577	Data 0.000	Loss 0.2178	
SparseEpoch: [187][101/398]	Time 0.579	Data 0.000	Loss 0.3657	
SparseEpoch: [187][201/398]	Time 0.579	Data 0.000	Loss 0.1428	
SparseEpoch: [187][301/398]	Time 0.579	Data 0.000	Loss 0.3169	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.48496881 0.48485892 0.48478831 0.48477281 0.48474563 0.48468855
 0.48472201 0.4846839  0.4846988  0.48476105 0.48480372 0.48477342
 0.48471521 0.48464805 0.48464956 0.48465341 0.48458759 0.48462392
 0.48456596 0.48450585]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.48476647 0.48473508 0.48472454 0.48474194 0.48476048 0.48476255
 0.48477415 0.48479579 0.48479526 0.48477715 0.48478925 0.48478122
 0.48475109 0.4847589  0.4847586  0.48474813 0.48474807 0.48474657
 0.48474686 0.48474301]
[0.5 0.  0. ]
-----------end of analyzing the loss ratio:76.06648683547974
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938509e70>
---------------------------------
SparseEpoch: [187][1/398]	Time 0.577	Data 0.000	Loss 0.3781	
SparseEpoch: [187][101/398]	Time 0.579	Data 0.000	Loss 0.4746	
SparseEpoch: [187][201/398]	Time 0.579	Data 0.000	Loss 0.5915	
SparseEpoch: [187][301/398]	Time 0.580	Data 0.000	Loss 0.4828	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.10858892 0.10858895 0.10857225 0.10856498 0.10856609 0.10856401
 0.10858685 0.10860078 0.10859766 0.10858174 0.10858443 0.10859776
 0.10858554 0.10857216 0.1085802  0.10856159 0.10855369 0.1085527
 0.10856162 0.10856514]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.10855865 0.1085681  0.10858269 0.10859863 0.10861549 0.10859279
 0.10859344 0.10858199 0.10859095 0.10858924 0.10858972 0.10858697
 0.10857975 0.10856945 0.10857691 0.10857198 0.10857685 0.10856903
 0.10857707 0.10857032]
[0.39473684 0.         0.        ]
-----------end of analyzing the loss ratio:75.91630864143372
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938946590>
---------------------------------
SparseEpoch: [187][1/398]	Time 0.577	Data 0.000	Loss 1.0816	
SparseEpoch: [187][101/398]	Time 0.579	Data 0.000	Loss 1.0866	
SparseEpoch: [187][201/398]	Time 0.580	Data 0.000	Loss 1.9844	
SparseEpoch: [187][301/398]	Time 0.580	Data 0.000	Loss 1.5968	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.6095	
Epoch(adapt):{0} Loss 0.6304	
Epoch(adapt):{0} Loss 0.4805	
Epoch(adapt):{0} Loss 0.7852	
------------------the total time cost:1166.3609013557434
>>>>>meta updating
Epoch: 0187 | TRAIN: 0.2789 0.7822 0.9069 | 0.2828 0.2828 0.1270 | 0.1067 21.1863 16.2339 0.3498 0.6569 0.7777 ||TEST: 1.3687 0.4064 0.6606 | 0.5227 0.5227 0.2040 | 0.1416 25.1465 20.1815 0.2870 0.5558 0.6836 | 117.0295
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.29605196 0.29588468 0.29575716 0.29576927 0.29575053 0.29574809
 0.29577184 0.29573436 0.29575112 0.29566508 0.29554322 0.29545972
 0.29550846 0.29544403 0.29553231 0.29553874 0.29553926 0.29559778
 0.29553711 0.29565622]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.29554618 0.29555964 0.29550202 0.29557979 0.29557998 0.29558323
 0.29557424 0.295591   0.29559021 0.29558338 0.29555191 0.29555177
 0.29554989 0.29556377 0.2955437  0.29553369 0.29555122 0.29556875
 0.29558166 0.29562789]
[0.         0.18421053 0.        ]
-----------end of analyzing the loss ratio:76.13231253623962
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cca5e306860>
---------------------------------
SparseEpoch: [188][1/398]	Time 0.578	Data 0.000	Loss 0.4086	
SparseEpoch: [188][101/398]	Time 0.580	Data 0.000	Loss 0.3359	
SparseEpoch: [188][201/398]	Time 0.580	Data 0.000	Loss 0.2973	
SparseEpoch: [188][301/398]	Time 0.580	Data 0.000	Loss 0.2630	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.27683579 0.27680551 0.27681843 0.27684087 0.27689656 0.27700624
 0.27703971 0.27702317 0.27708799 0.27718141 0.27731882 0.27738423
 0.27730549 0.27731265 0.27732799 0.2773327  0.2772818  0.27719546
 0.27702317 0.27710577]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.27733142 0.27732468 0.277324   0.27731691 0.27732311 0.27732857
 0.277309   0.27730327 0.27731256 0.2773041  0.27727662 0.2772702
 0.27725543 0.27723505 0.27724866 0.27724654 0.27722206 0.27717212
 0.27714581 0.27715546]
[0.         0.         0.44736842]
-----------end of analyzing the loss ratio:76.1598527431488
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc89de6d120>
---------------------------------
SparseEpoch: [188][1/398]	Time 0.578	Data 0.000	Loss 0.5720	
SparseEpoch: [188][101/398]	Time 0.581	Data 0.000	Loss 0.5980	
SparseEpoch: [188][201/398]	Time 0.580	Data 0.000	Loss 0.6127	
SparseEpoch: [188][301/398]	Time 0.580	Data 0.000	Loss 1.0054	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11575534 0.11575887 0.11576008 0.11575087 0.11575313 0.11575477
 0.11576005 0.11576831 0.11576392 0.11576797 0.11576042 0.11575462
 0.11576276 0.1157629  0.11576194 0.11576763 0.1157618  0.11575474
 0.11574705 0.11574877]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11576533 0.11575555 0.11575749 0.11575306 0.11576346 0.11576156
 0.11575704 0.11576111 0.11576166 0.11576641 0.11576185 0.11576617
 0.11576923 0.1157699  0.11576285 0.11574771 0.11573957 0.11572977
 0.11572472 0.11572198]
[0.44736842 0.5        0.        ]
-----------end of analyzing the loss ratio:76.21991300582886
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938506500>
---------------------------------
SparseEpoch: [188][1/398]	Time 0.578	Data 0.000	Loss 1.2162	
SparseEpoch: [188][101/398]	Time 0.581	Data 0.000	Loss 0.9347	
SparseEpoch: [188][201/398]	Time 0.580	Data 0.000	Loss 1.3579	
SparseEpoch: [188][301/398]	Time 0.580	Data 0.000	Loss 1.7741	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.4371	
Epoch(adapt):{0} Loss 0.5292	
Epoch(adapt):{0} Loss 0.5102	
Epoch(adapt):{0} Loss 0.6397	
------------------the total time cost:1167.9919321537018
>>>>>meta updating
Epoch: 0188 | TRAIN: 0.2488 0.8074 0.9192 | 0.2767 0.2767 0.1445 | 0.1061 21.1038 16.1149 0.3528 0.6607 0.7796 ||TEST: 1.3571 0.4140 0.6699 | 0.5009 0.5009 0.2087 | 0.1409 25.1241 20.1607 0.2845 0.5560 0.6846 | 117.7896
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.19774318 0.19774147 0.19769067 0.1976817  0.19769285 0.19771408
 0.19775332 0.1977783  0.1977106  0.19774223 0.19772611 0.19774547
 0.19774275 0.19774453 0.19770411 0.19774176 0.19775594 0.19777471
 0.19776764 0.19776703]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.19773983 0.19772968 0.19774048 0.1977419  0.19774418 0.19773375
 0.19773131 0.19772919 0.19774254 0.19774908 0.1977509  0.19775271
 0.19775533 0.19774818 0.1977481  0.1977414  0.19773729 0.19773608
 0.19773645 0.19773603]
[0. 0. 0.]
-----------end of analyzing the loss ratio:76.05156660079956
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938902f20>
---------------------------------
SparseEpoch: [189][1/398]	Time 0.577	Data 0.000	Loss 0.3848	
SparseEpoch: [189][101/398]	Time 0.580	Data 0.000	Loss 0.3232	
SparseEpoch: [189][201/398]	Time 0.579	Data 0.000	Loss 0.2253	
SparseEpoch: [189][301/398]	Time 0.579	Data 0.000	Loss 0.4699	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.37320596 0.37241336 0.37157189 0.37064192 0.36964145 0.36873466
 0.36772044 0.36696088 0.36597636 0.36491863 0.36424052 0.36360152
 0.36260836 0.36164301 0.36098998 0.3601171  0.35916272 0.35845746
 0.35776208 0.35684358]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.36532297 0.36516197 0.36510884 0.36501298 0.36490982 0.36486471
 0.36472063 0.36469005 0.36462444 0.36466368 0.36463606 0.36450026
 0.36443452 0.36433585 0.36433093 0.36425262 0.36420643 0.36414169
 0.36416581 0.36407154]
[0.5 0.  0.5]
-----------end of analyzing the loss ratio:76.22454953193665
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938b6af50>
---------------------------------
SparseEpoch: [189][1/398]	Time 0.578	Data 0.000	Loss 0.6974	
SparseEpoch: [189][101/398]	Time 0.581	Data 0.000	Loss 1.0566	
SparseEpoch: [189][201/398]	Time 0.581	Data 0.000	Loss 1.4422	
SparseEpoch: [189][301/398]	Time 0.581	Data 0.000	Loss 0.8792	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.10064806 0.10065805 0.10066438 0.10065808 0.10067757 0.10067937
 0.10068101 0.10067818 0.10067095 0.10068102 0.10067904 0.10067094
 0.100676   0.10069016 0.10070424 0.10071127 0.10071155 0.10070051
 0.10070384 0.10070696]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.10070179 0.10070864 0.10069723 0.10069324 0.10068812 0.10069659
 0.10069824 0.10068837 0.1006843  0.10068017 0.10067574 0.10067382
 0.10066887 0.10066477 0.10067486 0.10066889 0.10067799 0.10067546
 0.10067639 0.10066941]
[0.         0.18421053 0.        ]
-----------end of analyzing the loss ratio:76.09374713897705
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9384a5270>
---------------------------------
SparseEpoch: [189][1/398]	Time 0.577	Data 0.000	Loss 0.9123	
SparseEpoch: [189][101/398]	Time 0.580	Data 0.000	Loss 0.7710	
SparseEpoch: [189][201/398]	Time 0.580	Data 0.000	Loss 1.0853	
SparseEpoch: [189][301/398]	Time 0.580	Data 0.000	Loss 1.1397	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.4901	
Epoch(adapt):{0} Loss 0.8227	
Epoch(adapt):{0} Loss 0.5047	
Epoch(adapt):{0} Loss 0.6141	
------------------the total time cost:1167.3542246818542
>>>>>meta updating
Epoch: 0189 | TRAIN: 0.2801 0.7831 0.9076 | 0.2849 0.2849 0.1344 | 0.1080 21.4482 16.5644 0.3390 0.6515 0.7742 ||TEST: 1.3057 0.4063 0.6622 | 0.5203 0.5203 0.2077 | 0.1413 25.2567 20.4443 0.2781 0.5508 0.6809 | 116.9218
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.24884255 0.24879223 0.24880011 0.24878549 0.24880429 0.24881232
 0.24880951 0.24883816 0.24881242 0.24887786 0.24889786 0.24885602
 0.24884776 0.24882217 0.24879741 0.24877155 0.24886627 0.24887543
 0.24880302 0.24878397]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.2488663  0.24890088 0.24891502 0.24890179 0.24890164 0.24889789
 0.24887349 0.24888716 0.24888687 0.24888973 0.24887872 0.248897
 0.24890046 0.24889412 0.24889131 0.24890161 0.24890248 0.24890403
 0.24891026 0.24891027]
[0.         0.28947368 0.        ]
-----------end of analyzing the loss ratio:76.05362915992737
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc89ddb2f50>
---------------------------------
SparseEpoch: [190][1/398]	Time 0.579	Data 0.000	Loss 0.3636	
SparseEpoch: [190][101/398]	Time 0.580	Data 0.000	Loss 0.4044	
SparseEpoch: [190][201/398]	Time 0.580	Data 0.000	Loss 0.3332	
SparseEpoch: [190][301/398]	Time 0.580	Data 0.000	Loss 0.3456	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.32759447 0.32758077 0.32754968 0.32761805 0.32766024 0.32766134
 0.32764246 0.32764359 0.32762165 0.32762115 0.32762141 0.32762662
 0.32764779 0.32761584 0.32755431 0.32753061 0.32755634 0.32753523
 0.3275269  0.32756288]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.32768098 0.32768917 0.3276891  0.3276879  0.32768031 0.32766714
 0.32766289 0.3276165  0.32761162 0.32760628 0.32759491 0.32759722
 0.32761497 0.32761577 0.32758746 0.32758974 0.32758455 0.32757223
 0.32757479 0.32759742]
[0.44736842 0.         0.39473684]
-----------end of analyzing the loss ratio:76.13849353790283
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9383707f0>
---------------------------------
SparseEpoch: [190][1/398]	Time 0.579	Data 0.000	Loss 0.7425	
SparseEpoch: [190][101/398]	Time 0.580	Data 0.000	Loss 1.0305	
SparseEpoch: [190][201/398]	Time 0.581	Data 0.000	Loss 0.6911	
SparseEpoch: [190][301/398]	Time 0.581	Data 0.000	Loss 0.8641	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.10174398 0.10174299 0.10174438 0.10174523 0.10175008 0.10174562
 0.10174134 0.101738   0.10173711 0.10174834 0.10174874 0.10175207
 0.10175297 0.10176145 0.10176325 0.10176421 0.10176416 0.10177057
 0.10176432 0.10175958]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.10179188 0.10179448 0.10178806 0.10177637 0.10177232 0.10177407
 0.10176864 0.10176461 0.10176421 0.10174962 0.10175377 0.1017491
 0.10174423 0.10174272 0.10174853 0.10174479 0.10174623 0.10172929
 0.10172901 0.10171289]
[0.  0.5 0. ]
-----------end of analyzing the loss ratio:76.09122586250305
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc89de6d1b0>
---------------------------------
SparseEpoch: [190][1/398]	Time 0.578	Data 0.000	Loss 1.0718	
SparseEpoch: [190][101/398]	Time 0.580	Data 0.000	Loss 0.6834	
SparseEpoch: [190][201/398]	Time 0.580	Data 0.000	Loss 1.4563	
SparseEpoch: [190][301/398]	Time 0.579	Data 0.000	Loss 1.0640	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.6219	
Epoch(adapt):{0} Loss 0.8045	
Epoch(adapt):{0} Loss 0.5702	
Epoch(adapt):{0} Loss 0.6226	
------------------the total time cost:1167.3359997272491
>>>>>meta updating
Epoch: 0190 | TRAIN: 0.2479 0.8153 0.9203 | 0.2698 0.2698 0.1383 | 0.1068 21.1762 16.1775 0.3511 0.6590 0.7786 ||TEST: 1.3332 0.4145 0.6756 | 0.5090 0.5090 0.2063 | 0.1412 25.1139 20.1187 0.2860 0.5576 0.6855 | 117.3199
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.22340234 0.22336853 0.22342774 0.22345955 0.22344964 0.22341494
 0.22352685 0.22352234 0.2235281  0.22361569 0.22363716 0.22357871
 0.22358804 0.22365618 0.22369928 0.22380545 0.2236679  0.22376747
 0.22377121 0.2236962 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.22356401 0.22361579 0.22360432 0.22363466 0.22358464 0.22358513
 0.22361088 0.22361856 0.22363898 0.22363559 0.22361682 0.22360162
 0.22362021 0.22361941 0.22361353 0.22360678 0.22359991 0.22361253
 0.22361656 0.22361769]
[0. 0. 0.]
-----------end of analyzing the loss ratio:76.25936436653137
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938d3df60>
---------------------------------
SparseEpoch: [191][1/398]	Time 0.577	Data 0.000	Loss 0.2611	
SparseEpoch: [191][101/398]	Time 0.579	Data 0.000	Loss 0.2863	
SparseEpoch: [191][201/398]	Time 0.579	Data 0.000	Loss 0.3340	
SparseEpoch: [191][301/398]	Time 0.579	Data 0.000	Loss 0.2665	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.32284903 0.32286548 0.32282674 0.32279483 0.32279261 0.3226542
 0.32251839 0.32247486 0.32247841 0.32244422 0.32250382 0.32251688
 0.32244614 0.32248596 0.32249517 0.32244102 0.32240543 0.32236786
 0.32237293 0.32243407]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.32254344 0.32254291 0.3225262  0.3225285  0.32252638 0.32250206
 0.32248389 0.32248053 0.32247145 0.32245436 0.32244565 0.32245146
 0.32247959 0.32247856 0.32246932 0.3224726  0.32245748 0.32246704
 0.3224411  0.32245191]
[0.39473684 0.         0.44736842]
-----------end of analyzing the loss ratio:76.02079510688782
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc89de43700>
---------------------------------
SparseEpoch: [191][1/398]	Time 0.583	Data 0.000	Loss 0.7152	
SparseEpoch: [191][101/398]	Time 0.580	Data 0.000	Loss 0.8884	
SparseEpoch: [191][201/398]	Time 0.580	Data 0.000	Loss 0.8986	
SparseEpoch: [191][301/398]	Time 0.580	Data 0.000	Loss 1.2794	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11119451 0.11120378 0.11118799 0.11119186 0.11118507 0.11117917
 0.11117187 0.11118054 0.11118965 0.11117551 0.11118528 0.11118224
 0.11118342 0.11118311 0.11119521 0.11120269 0.1112033  0.11120285
 0.11120357 0.11120652]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11120215 0.11118913 0.11118057 0.1111887  0.11120266 0.11120017
 0.11119109 0.11119206 0.1111938  0.11118977 0.11117259 0.11118489
 0.11117648 0.11117316 0.11115781 0.11116902 0.11118326 0.11117266
 0.11117404 0.11116573]
[0.         0.23684211 0.        ]
-----------end of analyzing the loss ratio:76.00951528549194
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938753310>
---------------------------------
SparseEpoch: [191][1/398]	Time 0.578	Data 0.000	Loss 0.9749	
SparseEpoch: [191][101/398]	Time 0.580	Data 0.000	Loss 1.4808	
SparseEpoch: [191][201/398]	Time 0.579	Data 0.000	Loss 1.1321	
SparseEpoch: [191][301/398]	Time 0.579	Data 0.000	Loss 1.4129	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.5551	
Epoch(adapt):{0} Loss 0.5548	
Epoch(adapt):{0} Loss 0.7626	
Epoch(adapt):{0} Loss 0.4417	
------------------the total time cost:1167.487069606781
>>>>>meta updating
Epoch: 0191 | TRAIN: 0.2750 0.7942 0.9108 | 0.2756 0.2756 0.1373 | 0.1081 21.3387 16.4278 0.3478 0.6535 0.7740 ||TEST: 1.3565 0.4076 0.6652 | 0.5118 0.5118 0.2065 | 0.1424 25.2505 20.3095 0.2835 0.5540 0.6826 | 117.4649
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.29192017 0.29191085 0.29189705 0.29189352 0.2920151  0.29203648
 0.29212079 0.29199663 0.29197624 0.2918156  0.29186658 0.29192272
 0.29190074 0.29197977 0.291977   0.29197819 0.29192327 0.29200708
 0.29197441 0.29182244]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.29186008 0.29185578 0.29186949 0.29186011 0.29185091 0.29184493
 0.29183826 0.29183624 0.29184614 0.2918503  0.29185345 0.29182742
 0.29182675 0.2918288  0.29182781 0.29183097 0.29183056 0.29181875
 0.29184241 0.29183104]
[0.         0.         0.39473684]
-----------end of analyzing the loss ratio:76.12899971008301
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc939077670>
---------------------------------
SparseEpoch: [192][1/398]	Time 0.577	Data 0.000	Loss 0.3776	
SparseEpoch: [192][101/398]	Time 0.580	Data 0.000	Loss 0.8566	
SparseEpoch: [192][201/398]	Time 0.579	Data 0.000	Loss 1.1529	
SparseEpoch: [192][301/398]	Time 0.579	Data 0.000	Loss 0.5065	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.33153278 0.33147895 0.33144152 0.33133537 0.33130414 0.33122807
 0.33109397 0.33106234 0.33098089 0.33094176 0.33095844 0.33103082
 0.33107169 0.33095076 0.33097493 0.33091239 0.33094824 0.33095586
 0.33099148 0.33086744]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.33100094 0.33099557 0.33099613 0.33098054 0.330967   0.33093102
 0.33094929 0.33093391 0.33093472 0.33095912 0.33096256 0.33096832
 0.33098212 0.33095825 0.33097725 0.33101737 0.33101901 0.33099952
 0.33101045 0.33098398]
[0.5 0.  0. ]
-----------end of analyzing the loss ratio:75.99753928184509
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cca5e306b00>
---------------------------------
SparseEpoch: [192][1/398]	Time 0.577	Data 0.000	Loss 0.4855	
SparseEpoch: [192][101/398]	Time 0.580	Data 0.000	Loss 0.4077	
SparseEpoch: [192][201/398]	Time 0.580	Data 0.000	Loss 0.2676	
SparseEpoch: [192][301/398]	Time 0.580	Data 0.000	Loss 0.3940	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.10916796 0.10914748 0.10914091 0.10913569 0.10911853 0.10908928
 0.1090809  0.10908112 0.10907053 0.10906537 0.10904784 0.10905046
 0.10904924 0.1090162  0.10900987 0.10900948 0.10899835 0.10896558
 0.10895882 0.10894415]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.10905071 0.10904814 0.10904427 0.10904758 0.10904906 0.10906259
 0.10905886 0.10906457 0.10907071 0.10906326 0.10905728 0.10904731
 0.10905651 0.10905246 0.10906252 0.10905775 0.10905244 0.10905988
 0.10906997 0.1090694 ]
[0.5 0.  0. ]
-----------end of analyzing the loss ratio:75.97960066795349
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938140f70>
---------------------------------
SparseEpoch: [192][1/398]	Time 0.578	Data 0.000	Loss 0.8697	
SparseEpoch: [192][101/398]	Time 0.580	Data 0.000	Loss 0.8553	
SparseEpoch: [192][201/398]	Time 0.579	Data 0.000	Loss 0.8505	
SparseEpoch: [192][301/398]	Time 0.579	Data 0.000	Loss 1.2124	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.5700	
Epoch(adapt):{0} Loss 0.4948	
Epoch(adapt):{0} Loss 0.5585	
Epoch(adapt):{0} Loss 0.4396	
------------------the total time cost:1166.2559628486633
>>>>>meta updating
Epoch: 0192 | TRAIN: 0.2514 0.8079 0.9180 | 0.2616 0.2616 0.1293 | 0.1061 21.0113 15.9189 0.3582 0.6650 0.7822 ||TEST: 1.3793 0.4165 0.6681 | 0.5062 0.5062 0.2039 | 0.1409 24.9902 19.8850 0.2917 0.5622 0.6890 | 117.1202
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.26070802 0.26071895 0.26061707 0.26057359 0.26066541 0.26069308
 0.26070182 0.26080261 0.26080973 0.26090766 0.26092751 0.26092161
 0.26094125 0.26091988 0.26094731 0.26099047 0.26108131 0.26110516
 0.26110293 0.26095227]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.26092952 0.26090672 0.2608952  0.26089243 0.26089199 0.26090652
 0.26091613 0.26093813 0.26096728 0.26097022 0.26094162 0.26093631
 0.26094572 0.26095367 0.26096575 0.26096338 0.26095056 0.26093393
 0.26090683 0.26090679]
[0. 0. 0.]
-----------end of analyzing the loss ratio:76.1457839012146
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc89ddcec50>
---------------------------------
SparseEpoch: [193][1/398]	Time 0.579	Data 0.000	Loss 0.5879	
SparseEpoch: [193][101/398]	Time 0.580	Data 0.000	Loss 0.3741	
SparseEpoch: [193][201/398]	Time 0.579	Data 0.000	Loss 0.2540	
SparseEpoch: [193][301/398]	Time 0.579	Data 0.000	Loss 0.3999	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.32268198 0.32249028 0.32231035 0.32212217 0.32182783 0.3216791
 0.32162078 0.32136316 0.32108925 0.32095315 0.32088771 0.32055431
 0.32041989 0.32026656 0.32015504 0.31995566 0.31983202 0.31954625
 0.3194493  0.31937476]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.32100909 0.32100357 0.3209891  0.32099338 0.3209834  0.32099944
 0.32100124 0.32099414 0.32099507 0.32099144 0.32099555 0.3209882
 0.3210024  0.32099735 0.32100487 0.32098384 0.32098209 0.32096653
 0.3209651  0.32097271]
[0.5        0.         0.44736842]
-----------end of analyzing the loss ratio:76.17130970954895
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc89db8a920>
---------------------------------
SparseEpoch: [193][1/398]	Time 0.578	Data 0.000	Loss 0.8849	
SparseEpoch: [193][101/398]	Time 0.580	Data 0.000	Loss 1.0442	
SparseEpoch: [193][201/398]	Time 0.580	Data 0.000	Loss 0.6866	
SparseEpoch: [193][301/398]	Time 0.580	Data 0.000	Loss 0.9457	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11958831 0.11961645 0.11962419 0.11963962 0.11962838 0.11962253
 0.11961811 0.11961268 0.11962596 0.11961893 0.1196493  0.11966162
 0.11967184 0.11967194 0.11969836 0.11969537 0.1196908  0.11970267
 0.11972319 0.11972298]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11961756 0.11961819 0.11961457 0.11962144 0.11962755 0.11962228
 0.11963203 0.11963193 0.11961775 0.11962021 0.11964563 0.11965479
 0.11965637 0.11967105 0.11967015 0.11969419 0.11970182 0.11969449
 0.11968971 0.11967565]
[0. 0. 0.]
-----------end of analyzing the loss ratio:76.5135908126831
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cca5e212320>
---------------------------------
SparseEpoch: [193][1/398]	Time 0.595	Data 0.000	Loss 0.8382	
SparseEpoch: [193][101/398]	Time 0.578	Data 0.000	Loss 1.4008	
SparseEpoch: [193][201/398]	Time 0.578	Data 0.000	Loss 1.7753	
SparseEpoch: [193][301/398]	Time 0.578	Data 0.000	Loss 0.7811	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.5114	
Epoch(adapt):{0} Loss 0.6212	
Epoch(adapt):{0} Loss 0.5358	
Epoch(adapt):{0} Loss 0.6643	
------------------the total time cost:1167.3882265090942
>>>>>meta updating
Epoch: 0193 | TRAIN: 0.2492 0.8123 0.9193 | 0.2723 0.2723 0.1374 | 0.1045 20.8404 15.7931 0.3623 0.6686 0.7850 ||TEST: 1.3793 0.4174 0.6708 | 0.5121 0.5121 0.2135 | 0.1403 24.9321 19.7431 0.2926 0.5647 0.6905 | 117.6495
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.26535656 0.26516441 0.26510203 0.26500743 0.26500514 0.26483783
 0.26475002 0.26469345 0.26461206 0.26453462 0.2643541  0.26433823
 0.26433118 0.26433545 0.26445385 0.26452645 0.26445639 0.26433635
 0.26430576 0.26422056]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.26447402 0.26448005 0.26445463 0.26444724 0.26445183 0.26445158
 0.26445574 0.26443775 0.26443775 0.26442296 0.2644211  0.26443218
 0.26444189 0.26444695 0.26444377 0.26444772 0.26441469 0.26441555
 0.26444302 0.26444011]
[0.         0.5        0.34210526]
-----------end of analyzing the loss ratio:76.2181293964386
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9387682e0>
---------------------------------
SparseEpoch: [194][1/398]	Time 0.579	Data 0.000	Loss 0.4077	
SparseEpoch: [194][101/398]	Time 0.581	Data 0.000	Loss 0.9756	
SparseEpoch: [194][201/398]	Time 0.581	Data 0.000	Loss 0.8148	
SparseEpoch: [194][301/398]	Time 0.581	Data 0.000	Loss 0.5768	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.31045204 0.31026095 0.31009372 0.30998617 0.30977018 0.3095995
 0.30940501 0.30909106 0.30890601 0.30880894 0.30878269 0.30854209
 0.30843207 0.30836786 0.30810975 0.30784798 0.30772817 0.30758381
 0.307397   0.30722063]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.30882963 0.30880388 0.30880573 0.30880455 0.30884498 0.30883642
 0.30884269 0.3088364  0.30882824 0.30880989 0.30876457 0.30874981
 0.30874584 0.30876978 0.30873594 0.30877828 0.30875707 0.30876489
 0.30878703 0.30876561]
[0.5        0.         0.23684211]
-----------end of analyzing the loss ratio:76.25072646141052
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938faac20>
---------------------------------
SparseEpoch: [194][1/398]	Time 0.578	Data 0.000	Loss 0.4337	
SparseEpoch: [194][101/398]	Time 0.580	Data 0.000	Loss 0.8831	
SparseEpoch: [194][201/398]	Time 0.581	Data 0.000	Loss 0.9168	
SparseEpoch: [194][301/398]	Time 0.581	Data 0.000	Loss 0.5910	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11205966 0.11206181 0.11205781 0.11205214 0.11202152 0.11201376
 0.11201661 0.11201265 0.11199899 0.11199465 0.11200014 0.11198756
 0.11197909 0.11196808 0.11198977 0.11197976 0.11196416 0.1119403
 0.11193038 0.11194169]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11206456 0.11204956 0.11202961 0.11200697 0.11200759 0.11198905
 0.11198884 0.11199604 0.1119855  0.11199107 0.11199486 0.11199861
 0.11198364 0.11198047 0.11198267 0.11198428 0.11198719 0.11198984
 0.11197567 0.11196648]
[0.44736842 0.5        0.        ]
-----------end of analyzing the loss ratio:76.26920294761658
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938397df0>
---------------------------------
SparseEpoch: [194][1/398]	Time 0.578	Data 0.000	Loss 0.8836	
SparseEpoch: [194][101/398]	Time 0.580	Data 0.000	Loss 1.6494	
SparseEpoch: [194][201/398]	Time 0.580	Data 0.000	Loss 1.6990	
SparseEpoch: [194][301/398]	Time 0.580	Data 0.000	Loss 0.7069	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.4193	
Epoch(adapt):{0} Loss 0.9178	
Epoch(adapt):{0} Loss 0.3808	
Epoch(adapt):{0} Loss 0.4312	
------------------the total time cost:1168.5531780719757
>>>>>meta updating
Epoch: 0194 | TRAIN: 0.2507 0.8111 0.9190 | 0.2750 0.2750 0.1344 | 0.1052 20.9355 15.9462 0.3580 0.6668 0.7841 ||TEST: 1.3443 0.4106 0.6676 | 0.5233 0.5233 0.2034 | 0.1401 24.9946 19.9621 0.2860 0.5615 0.6895 | 117.6571
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.31599465 0.31585857 0.3159023  0.3159842  0.31601542 0.31612722
 0.3160927  0.31598529 0.31612493 0.31612768 0.31609035 0.3160273
 0.31605356 0.31608029 0.31614409 0.31613016 0.31608602 0.31608414
 0.31606829 0.31610503]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.31611512 0.31612459 0.31612319 0.3161173  0.31610862 0.31610999
 0.3161117  0.31611415 0.31612626 0.31612827 0.31610385 0.31610717
 0.31610517 0.3161035  0.3160975  0.31609772 0.31610121 0.31609436
 0.31610096 0.31610113]
[0.         0.         0.39473684]
-----------end of analyzing the loss ratio:76.35497331619263
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc89defd360>
---------------------------------
SparseEpoch: [195][1/398]	Time 0.579	Data 0.000	Loss 0.6325	
SparseEpoch: [195][101/398]	Time 0.579	Data 0.000	Loss 0.8078	
SparseEpoch: [195][201/398]	Time 0.580	Data 0.000	Loss 1.3978	
SparseEpoch: [195][301/398]	Time 0.580	Data 0.000	Loss 0.8600	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.2982203  0.29817389 0.29818971 0.29807097 0.29806283 0.2980221
 0.29794791 0.29788775 0.29792423 0.29789807 0.29794077 0.29799561
 0.29798954 0.2980619  0.29792802 0.29803356 0.2980346  0.29801533
 0.29810616 0.29801961]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.29796294 0.29793616 0.29794168 0.29792617 0.29791582 0.29791483
 0.29788303 0.2979091  0.29789068 0.29790017 0.2978993  0.29790821
 0.29791373 0.29789877 0.29793031 0.29791206 0.29793643 0.29794723
 0.29796203 0.29796402]
[0. 0. 0.]
-----------end of analyzing the loss ratio:76.24955296516418
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9389322f0>
---------------------------------
SparseEpoch: [195][1/398]	Time 0.579	Data 0.000	Loss 0.2381	
SparseEpoch: [195][101/398]	Time 0.579	Data 0.000	Loss 0.3909	
SparseEpoch: [195][201/398]	Time 0.579	Data 0.000	Loss 0.2596	
SparseEpoch: [195][301/398]	Time 0.579	Data 0.000	Loss 0.2643	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.10130114 0.1012971  0.10129489 0.1012861  0.1012925  0.10129492
 0.10130076 0.10130067 0.10130541 0.10131578 0.10131933 0.10131641
 0.10130413 0.10130069 0.1012922  0.10128728 0.10128802 0.10128539
 0.10128193 0.10127704]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.10131158 0.10130735 0.10130934 0.10131075 0.10130817 0.1013126
 0.10130775 0.10130386 0.10131426 0.10131406 0.10131744 0.10130706
 0.10130494 0.10130078 0.10130711 0.10131106 0.10131089 0.10130783
 0.1013055  0.10130207]
[0.5        0.18421053 0.        ]
-----------end of analyzing the loss ratio:76.35269594192505
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938a18820>
---------------------------------
SparseEpoch: [195][1/398]	Time 0.579	Data 0.000	Loss 1.4963	
SparseEpoch: [195][101/398]	Time 0.580	Data 0.000	Loss 0.7950	
SparseEpoch: [195][201/398]	Time 0.580	Data 0.000	Loss 1.5945	
SparseEpoch: [195][301/398]	Time 0.580	Data 0.000	Loss 1.0700	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.3704	
Epoch(adapt):{0} Loss 0.5226	
Epoch(adapt):{0} Loss 0.5170	
Epoch(adapt):{0} Loss 0.5627	
------------------the total time cost:1167.3489751815796
>>>>>meta updating
Epoch: 0195 | TRAIN: 0.2569 0.7948 0.9152 | 0.2608 0.2608 0.1312 | 0.1023 20.4838 15.3388 0.3742 0.6791 0.7919 ||TEST: 1.3940 0.4038 0.6655 | 0.5048 0.5048 0.2073 | 0.1403 24.8522 19.6173 0.2961 0.5683 0.6932 | 117.3733
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.23191415 0.23193449 0.23196761 0.23191727 0.23189172 0.23192149
 0.23194943 0.23195882 0.23199457 0.2319559  0.2319939  0.2319987
 0.23206486 0.23208146 0.23207674 0.23203927 0.23212788 0.23219379
 0.23216494 0.23220936]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.23196054 0.23195636 0.23195916 0.2319539  0.23194944 0.23195807
 0.23196672 0.23196237 0.23195754 0.23196293 0.23195876 0.23197589
 0.23197671 0.23198667 0.23197741 0.23198217 0.23197035 0.23197511
 0.23198067 0.23198695]
[0. 0. 0.]
-----------end of analyzing the loss ratio:76.26364922523499
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938a4eef0>
---------------------------------
SparseEpoch: [196][1/398]	Time 0.577	Data 0.000	Loss 0.1356	
SparseEpoch: [196][101/398]	Time 0.580	Data 0.000	Loss 0.1592	
SparseEpoch: [196][201/398]	Time 0.579	Data 0.000	Loss 0.4247	
SparseEpoch: [196][301/398]	Time 0.579	Data 0.000	Loss 0.2674	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.30159934 0.30152373 0.30158095 0.30166051 0.30167261 0.3017507
 0.30163585 0.30152232 0.30151857 0.30143695 0.3014548  0.30149421
 0.30145927 0.30154671 0.30147583 0.30147689 0.30150365 0.30147961
 0.30150758 0.30152888]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.30151336 0.30148999 0.30149159 0.30149398 0.30146179 0.30144705
 0.30143214 0.30141469 0.30139734 0.30140369 0.30144932 0.30142671
 0.30146776 0.30148396 0.30147417 0.30148448 0.30148301 0.30151127
 0.30147136 0.30146893]
[0. 0. 0.]
-----------end of analyzing the loss ratio:76.24798560142517
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938e588b0>
---------------------------------
SparseEpoch: [196][1/398]	Time 0.577	Data 0.000	Loss 0.1582	
SparseEpoch: [196][101/398]	Time 0.579	Data 0.000	Loss 0.2398	
SparseEpoch: [196][201/398]	Time 0.579	Data 0.000	Loss 0.2442	
SparseEpoch: [196][301/398]	Time 0.579	Data 0.000	Loss 0.1906	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11294079 0.11290475 0.11292182 0.11291261 0.11292172 0.11292417
 0.11292993 0.11292393 0.11290843 0.11289773 0.11290935 0.11291108
 0.11289891 0.11288086 0.11287828 0.11283983 0.11282691 0.11281511
 0.11278156 0.1127807 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11294788 0.11292941 0.11294636 0.11292701 0.11291884 0.11293126
 0.11291355 0.11290163 0.11289855 0.11289512 0.11290646 0.11289806
 0.11287086 0.1128491  0.11283299 0.1127993  0.11280559 0.11277787
 0.11276861 0.11278489]
[0.5        0.44736842 0.        ]
-----------end of analyzing the loss ratio:75.94871139526367
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc89df76770>
---------------------------------
SparseEpoch: [196][1/398]	Time 0.578	Data 0.000	Loss 0.9315	
SparseEpoch: [196][101/398]	Time 0.580	Data 0.000	Loss 1.4655	
SparseEpoch: [196][201/398]	Time 0.580	Data 0.000	Loss 1.5416	
SparseEpoch: [196][301/398]	Time 0.580	Data 0.000	Loss 0.9780	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.8361	
Epoch(adapt):{0} Loss 0.3842	
Epoch(adapt):{0} Loss 0.7373	
Epoch(adapt):{0} Loss 0.6925	
------------------the total time cost:1166.4312748908997
>>>>>meta updating
Epoch: 0196 | TRAIN: 0.2523 0.8047 0.9181 | 0.2652 0.2652 0.1331 | 0.1059 21.0709 16.1637 0.3515 0.6614 0.7814 ||TEST: 1.3875 0.4107 0.6662 | 0.5055 0.5055 0.2092 | 0.1431 25.2556 20.2539 0.2867 0.5551 0.6829 | 117.1792
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.23263813 0.23271151 0.23267851 0.23268288 0.232663   0.2327274
 0.2327419  0.23274381 0.2327586  0.23274608 0.23278667 0.2327943
 0.23280305 0.23275971 0.23268119 0.23282034 0.23283336 0.23289986
 0.23288449 0.2329797 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.23286693 0.23284855 0.23285387 0.23281078 0.23278385 0.23278326
 0.23281042 0.23279976 0.2327761  0.23277503 0.23275273 0.23276837
 0.2327651  0.23277029 0.23276915 0.23276496 0.2327796  0.23273397
 0.23274442 0.23274941]
[0.         0.         0.39473684]
-----------end of analyzing the loss ratio:76.20428729057312
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc93997f670>
---------------------------------
SparseEpoch: [197][1/398]	Time 0.578	Data 0.000	Loss 0.4594	
SparseEpoch: [197][101/398]	Time 0.581	Data 0.000	Loss 0.6483	
SparseEpoch: [197][201/398]	Time 0.580	Data 0.000	Loss 0.5075	
SparseEpoch: [197][301/398]	Time 0.580	Data 0.000	Loss 0.8271	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.35625331 0.35608255 0.35603868 0.35584584 0.35573574 0.35548892
 0.35532591 0.35516434 0.35501168 0.35477735 0.35461175 0.35427804
 0.35398332 0.35382509 0.3535837  0.35346445 0.35317394 0.35308986
 0.35288178 0.35262938]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.35481973 0.3548011  0.35474087 0.35474115 0.35471522 0.35470385
 0.35470907 0.3546918  0.35468034 0.3546713  0.35463764 0.35459354
 0.35459512 0.35455808 0.35450579 0.35449019 0.35450778 0.35447427
 0.35443145 0.35443489]
[0.5        0.         0.44736842]
-----------end of analyzing the loss ratio:76.23595714569092
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9388ed8d0>
---------------------------------
SparseEpoch: [197][1/398]	Time 0.578	Data 0.000	Loss 0.9249	
SparseEpoch: [197][101/398]	Time 0.580	Data 0.000	Loss 1.2491	
SparseEpoch: [197][201/398]	Time 0.580	Data 0.000	Loss 0.7112	
SparseEpoch: [197][301/398]	Time 0.580	Data 0.000	Loss 0.9519	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.10905179 0.10903452 0.10901845 0.10899682 0.10893993 0.10894849
 0.10892565 0.10893522 0.10892592 0.10891068 0.10886908 0.10885669
 0.10884551 0.10883337 0.10881461 0.10883139 0.1088049  0.10879619
 0.10877401 0.10875661]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.10912188 0.10908343 0.10904355 0.1090397  0.109014   0.10898267
 0.10893863 0.10892891 0.10892673 0.10891224 0.10886515 0.10883911
 0.10884148 0.10883142 0.10881274 0.1087809  0.10874314 0.10872507
 0.10870785 0.10867953]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:76.38457179069519
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9398f94b0>
---------------------------------
SparseEpoch: [197][1/398]	Time 0.579	Data 0.000	Loss 1.1845	
SparseEpoch: [197][101/398]	Time 0.580	Data 0.000	Loss 2.2546	
SparseEpoch: [197][201/398]	Time 0.580	Data 0.000	Loss 0.8622	
SparseEpoch: [197][301/398]	Time 0.580	Data 0.000	Loss 1.6103	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.8933	
Epoch(adapt):{0} Loss 0.5750	
Epoch(adapt):{0} Loss 0.6291	
Epoch(adapt):{0} Loss 0.6315	
------------------the total time cost:1169.484493970871
>>>>>meta updating
Epoch: 0197 | TRAIN: 0.2455 0.8167 0.9199 | 0.2783 0.2783 0.1383 | 0.1044 20.7840 15.7068 0.3644 0.6713 0.7870 ||TEST: 1.3455 0.4196 0.6688 | 0.5135 0.5135 0.2075 | 0.1406 24.9474 19.7923 0.2924 0.5644 0.6906 | 117.2381
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.23669408 0.23678176 0.23674737 0.23665915 0.23663207 0.23678286
 0.2369211  0.23672074 0.23669202 0.23665217 0.23677969 0.23684269
 0.23675025 0.23669243 0.23664251 0.23656697 0.23644385 0.23639662
 0.23634915 0.23631988]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.23675215 0.23674008 0.23675189 0.23674187 0.23670112 0.23667921
 0.23665778 0.23664819 0.23664662 0.23664876 0.23665443 0.23666243
 0.23675571 0.23676283 0.23674917 0.23672137 0.23672948 0.23674271
 0.23674859 0.23674435]
[0.  0.5 0. ]
-----------end of analyzing the loss ratio:76.21098780632019
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc9390775b0>
---------------------------------
SparseEpoch: [198][1/398]	Time 0.579	Data 0.000	Loss 0.2882	
SparseEpoch: [198][101/398]	Time 0.580	Data 0.000	Loss 0.6186	
SparseEpoch: [198][201/398]	Time 0.580	Data 0.000	Loss 0.5155	
SparseEpoch: [198][301/398]	Time 0.580	Data 0.000	Loss 0.4600	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.31335054 0.31328291 0.31321268 0.31312678 0.31305832 0.31300323
 0.31286722 0.31277362 0.31261057 0.31254155 0.31251018 0.31243531
 0.31232994 0.31229549 0.31218709 0.31214588 0.3121184  0.3120672
 0.31199543 0.3119474 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.31253609 0.31254463 0.31252536 0.31251722 0.31249808 0.3125047
 0.31251237 0.31249471 0.31251589 0.31250667 0.31249992 0.31252933
 0.31252357 0.31251356 0.31253013 0.3125561  0.3125566  0.31252665
 0.31254335 0.31253527]
[0.5 0.  0. ]
-----------end of analyzing the loss ratio:76.57445812225342
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc89dccd7b0>
---------------------------------
SparseEpoch: [198][1/398]	Time 0.578	Data 0.000	Loss 0.2733	
SparseEpoch: [198][101/398]	Time 0.580	Data 0.000	Loss 0.5005	
SparseEpoch: [198][201/398]	Time 0.580	Data 0.000	Loss 0.3003	
SparseEpoch: [198][301/398]	Time 0.580	Data 0.000	Loss 0.5495	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.10871249 0.1087045  0.10871782 0.1087249  0.10868704 0.1086714
 0.10867241 0.10865972 0.10865386 0.1086429  0.10864351 0.10865046
 0.10865166 0.10863196 0.10863483 0.10864437 0.10864269 0.10863053
 0.10864041 0.10863639]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.10832274 0.10829128 0.10837666 0.10845647 0.10848274 0.10855358
 0.10857944 0.10859784 0.10861077 0.10864771 0.10867055 0.10864115
 0.10871264 0.10871646 0.10879338 0.10885597 0.10893777 0.10893189
 0.10896035 0.10898693]
[0.39473684 0.         0.        ]
-----------end of analyzing the loss ratio:76.14396333694458
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc938c40f40>
---------------------------------
SparseEpoch: [198][1/398]	Time 0.577	Data 0.000	Loss 1.1327	
SparseEpoch: [198][101/398]	Time 0.579	Data 0.000	Loss 0.6679	
SparseEpoch: [198][201/398]	Time 0.579	Data 0.000	Loss 0.5796	
SparseEpoch: [198][301/398]	Time 0.579	Data 0.000	Loss 1.1357	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.3844	
Epoch(adapt):{0} Loss 0.6345	
Epoch(adapt):{0} Loss 0.4162	
Epoch(adapt):{0} Loss 0.5611	
------------------the total time cost:1167.6783266067505
>>>>>meta updating
Epoch: 0198 | TRAIN: 0.2455 0.8086 0.9185 | 0.2652 0.2652 0.1318 | 0.1053 20.9878 16.0649 0.3544 0.6647 0.7833 ||TEST: 1.3671 0.4118 0.6697 | 0.5081 0.5081 0.2071 | 0.1413 25.1009 20.1013 0.2867 0.5580 0.6862 | 117.1814
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.29715008 0.29715058 0.29710521 0.29716534 0.29712797 0.29714028
 0.29717237 0.29715286 0.29713297 0.29710473 0.29701945 0.29707382
 0.29710537 0.29705137 0.29695471 0.29694852 0.29695268 0.2969815
 0.29694513 0.29680138]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.29712887 0.29713155 0.29711549 0.29710684 0.29708869 0.29710059
 0.29711149 0.29707714 0.2970606  0.29704249 0.29701808 0.29703086
 0.29702053 0.2970102  0.29703095 0.29703342 0.29704216 0.29704129
 0.29703723 0.29703253]
[0.         0.5        0.18421053]
-----------end of analyzing the loss ratio:76.08688998222351
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc89dc725f0>
---------------------------------
SparseEpoch: [199][1/398]	Time 0.578	Data 0.000	Loss 0.4733	
SparseEpoch: [199][101/398]	Time 0.580	Data 0.000	Loss 0.4401	
SparseEpoch: [199][201/398]	Time 0.580	Data 0.000	Loss 0.3939	
SparseEpoch: [199][301/398]	Time 0.580	Data 0.000	Loss 0.4740	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.28369175 0.28167439 0.27968355 0.27757063 0.27576241 0.27402244
 0.27260312 0.27146954 0.26972983 0.26828906 0.26718398 0.2660226
 0.26493003 0.26389572 0.26270569 0.26205864 0.26126809 0.26065475
 0.26016056 0.26017916]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.26797673 0.26793721 0.26784976 0.26776983 0.26774674 0.26777756
 0.26779908 0.26772536 0.26776858 0.26775918 0.26767652 0.2676121
 0.26756665 0.26754169 0.26749346 0.26750131 0.26744265 0.26737973
 0.2673569  0.26731374]
[0.44736842 0.         0.5       ]
-----------end of analyzing the loss ratio:76.28720188140869
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc93877a950>
---------------------------------
SparseEpoch: [199][1/398]	Time 0.578	Data 0.000	Loss 0.9669	
SparseEpoch: [199][101/398]	Time 0.581	Data 0.000	Loss 0.6491	
SparseEpoch: [199][201/398]	Time 0.581	Data 0.000	Loss 1.0031	
SparseEpoch: [199][301/398]	Time 0.581	Data 0.000	Loss 0.8380	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.10363434 0.103629   0.10361808 0.10361214 0.10360611 0.1036024
 0.1035927  0.10358359 0.1035755  0.10356075 0.10354674 0.10352117
 0.10351378 0.10354093 0.10351399 0.10348696 0.10348735 0.10348757
 0.10346356 0.10345197]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.1036253  0.10361846 0.10359914 0.10359136 0.10360497 0.10359823
 0.10358888 0.10358065 0.10357903 0.10356429 0.10354877 0.10353943
 0.10351755 0.10351126 0.10351788 0.10350897 0.10349927 0.10349425
 0.10347698 0.10346974]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:76.17073583602905
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7cc93814ae00>
---------------------------------
SparseEpoch: [199][1/398]	Time 0.578	Data 0.000	Loss 1.1680	
SparseEpoch: [199][101/398]	Time 0.580	Data 0.000	Loss 1.1012	
SparseEpoch: [199][201/398]	Time 0.580	Data 0.000	Loss 1.0719	
SparseEpoch: [199][301/398]	Time 0.580	Data 0.000	Loss 0.7255	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.4450	
Epoch(adapt):{0} Loss 0.7261	
Epoch(adapt):{0} Loss 0.7539	
Epoch(adapt):{0} Loss 0.5542	
------------------the total time cost:1168.519372701645
>>>>>meta updating
Epoch: 0199 | TRAIN: 0.2444 0.8184 0.9208 | 0.2649 0.2649 0.1293 | 0.1048 20.7107 15.4537 0.3726 0.6748 0.7869 ||TEST: 1.3862 0.4163 0.6697 | 0.5118 0.5118 0.2029 | 0.1403 24.8298 19.5650 0.2988 0.5686 0.6931 | 117.3096
