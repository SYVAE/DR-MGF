--------0117  loss landscape--------
Parameter Space: ABS: 44229076.0, REL: 1.7705
LOSS FORMAT: SEMANTIC_LOSS MEAN_IOU PIX_ACC | DEPTH_LOSS ABS_ERR REL_ERR | NORMAL_LOSS MEAN MED <11.25 <22.5 <30
Applying data augmentation on NYUv2.
metalr:0.1
metaGF: modified by sy...(global view)
metaGF: modified by sy...
['encoder_block.0.forwardlist.0.bias', 'encoder_block.1.forwardlist.0.bias', 'encoder_block.2.forwardlist.0.bias', 'encoder_block.3.forwardlist.0.bias', 'encoder_block.4.forwardlist.0.bias', 'decoder_block.0.forwardlist.0.bias', 'decoder_block.1.forwardlist.0.bias', 'decoder_block.2.forwardlist.0.bias', 'decoder_block.3.forwardlist.0.bias', 'decoder_block.4.forwardlist.0.bias', 'conv_block_enc.0.forwardlist.0.bias', 'conv_block_enc.1.forwardlist.0.bias', 'conv_block_enc.2.forwardlist.0.forwardlist.0.bias', 'conv_block_enc.2.forwardlist.1.forwardlist.0.bias', 'conv_block_enc.3.forwardlist.0.forwardlist.0.bias', 'conv_block_enc.3.forwardlist.1.forwardlist.0.bias', 'conv_block_enc.4.forwardlist.0.forwardlist.0.bias', 'conv_block_enc.4.forwardlist.1.forwardlist.0.bias', 'conv_block_dec.0.forwardlist.0.bias', 'conv_block_dec.1.forwardlist.0.bias', 'conv_block_dec.2.forwardlist.0.forwardlist.0.bias', 'conv_block_dec.2.forwardlist.1.forwardlist.0.bias', 'conv_block_dec.3.forwardlist.0.forwardlist.0.bias', 'conv_block_dec.3.forwardlist.1.forwardlist.0.bias', 'conv_block_dec.4.forwardlist.0.forwardlist.0.bias', 'conv_block_dec.4.forwardlist.1.forwardlist.0.bias', 'encoder_att.0.0.0.bias', 'encoder_att.0.0.3.bias', 'encoder_att.0.1.0.bias', 'encoder_att.0.1.3.bias', 'encoder_att.0.2.0.bias', 'encoder_att.0.2.3.bias', 'encoder_att.0.3.0.bias', 'encoder_att.0.3.3.bias', 'encoder_att.0.4.0.bias', 'encoder_att.0.4.3.bias', 'encoder_att.1.0.0.bias', 'encoder_att.1.0.3.bias', 'encoder_att.1.1.0.bias', 'encoder_att.1.1.3.bias', 'encoder_att.1.2.0.bias', 'encoder_att.1.2.3.bias', 'encoder_att.1.3.0.bias', 'encoder_att.1.3.3.bias', 'encoder_att.1.4.0.bias', 'encoder_att.1.4.3.bias', 'encoder_att.2.0.0.bias', 'encoder_att.2.0.3.bias', 'encoder_att.2.1.0.bias', 'encoder_att.2.1.3.bias', 'encoder_att.2.2.0.bias', 'encoder_att.2.2.3.bias', 'encoder_att.2.3.0.bias', 'encoder_att.2.3.3.bias', 'encoder_att.2.4.0.bias', 'encoder_att.2.4.3.bias', 'decoder_att.0.0.0.bias', 'decoder_att.0.0.3.bias', 'decoder_att.0.1.0.bias', 'decoder_att.0.1.3.bias', 'decoder_att.0.2.0.bias', 'decoder_att.0.2.3.bias', 'decoder_att.0.3.0.bias', 'decoder_att.0.3.3.bias', 'decoder_att.0.4.0.bias', 'decoder_att.0.4.3.bias', 'decoder_att.1.0.0.bias', 'decoder_att.1.0.3.bias', 'decoder_att.1.1.0.bias', 'decoder_att.1.1.3.bias', 'decoder_att.1.2.0.bias', 'decoder_att.1.2.3.bias', 'decoder_att.1.3.0.bias', 'decoder_att.1.3.3.bias', 'decoder_att.1.4.0.bias', 'decoder_att.1.4.3.bias', 'decoder_att.2.0.0.bias', 'decoder_att.2.0.3.bias', 'decoder_att.2.1.0.bias', 'decoder_att.2.1.3.bias', 'decoder_att.2.2.0.bias', 'decoder_att.2.2.3.bias', 'decoder_att.2.3.0.bias', 'decoder_att.2.3.3.bias', 'decoder_att.2.4.0.bias', 'decoder_att.2.4.3.bias', 'encoder_block_att.0.forwardlist.0.bias', 'encoder_block_att.1.forwardlist.0.bias', 'encoder_block_att.2.forwardlist.0.bias', 'encoder_block_att.3.forwardlist.0.bias', 'encoder_block_att.4.forwardlist.0.bias', 'decoder_block_att.0.forwardlist.0.bias', 'decoder_block_att.1.forwardlist.0.bias', 'decoder_block_att.2.forwardlist.0.bias', 'decoder_block_att.3.forwardlist.0.bias', 'decoder_block_att.4.forwardlist.0.bias', 'pred_task1.forwardlist.0.bias', 'pred_task1.forwardlist.1.bias', 'pred_task2.forwardlist.0.bias', 'pred_task2.forwardlist.1.bias', 'pred_task3.forwardlist.0.bias', 'pred_task3.forwardlist.1.bias']
lr:0.0001
[0.  0.5 0.5]
-----------end of analyzing the loss ratio:0.0005407333374023438
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7446090e7eb0>
---------------------------------
SparseEpoch: [0][1/398]	Time 0.878	Data 0.000	Loss 6.7505	
SparseEpoch: [0][101/398]	Time 0.634	Data 0.000	Loss 4.6535	
SparseEpoch: [0][201/398]	Time 0.632	Data 0.000	Loss 3.7440	
SparseEpoch: [0][301/398]	Time 0.629	Data 0.000	Loss 3.6600	
lr:0.0001
[0.5 0.  0.5]
-----------end of analyzing the loss ratio:0.00014734268188476562
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7446098d41f0>
---------------------------------
SparseEpoch: [0][1/398]	Time 0.658	Data 0.000	Loss 6.5783	
SparseEpoch: [0][101/398]	Time 0.663	Data 0.000	Loss 3.1382	
SparseEpoch: [0][201/398]	Time 0.678	Data 0.000	Loss 2.9533	
SparseEpoch: [0][301/398]	Time 0.683	Data 0.000	Loss 2.8190	
lr:0.0001
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:0.00014328956604003906
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x744609830160>
---------------------------------
SparseEpoch: [0][1/398]	Time 0.611	Data 0.000	Loss 7.9390	
SparseEpoch: [0][101/398]	Time 0.656	Data 0.000	Loss 4.6696	
SparseEpoch: [0][201/398]	Time 0.661	Data 0.000	Loss 4.8331	
SparseEpoch: [0][301/398]	Time 0.666	Data 0.000	Loss 4.2031	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 2.7859	
Epoch(adapt):{0} Loss 3.5905	
Epoch(adapt):{0} Loss 3.2902	
Epoch(adapt):{0} Loss 2.7083	
------------------the total time cost:1054.5433406829834
>>>>>meta updating
Epoch: 0000 | TRAIN: 1.8273 0.0894 0.3817 | 0.8102 0.8102 0.3924 | 0.2913 40.9392 39.1590 0.0582 0.2272 0.3530 ||TEST: 1.8300 0.0929 0.3850 | 0.8565 0.8565 0.3296 | 0.2851 40.5760 39.2948 0.0592 0.2243 0.3500 | 126.7258
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.95058167 1.95056096 1.95059156 1.9505785  1.95057173 1.95058001
 1.95059699 1.95057766 1.95055951 1.95053697 1.95055035 1.9505165
 1.9505265  1.95047843 1.95050659 1.95051453 1.95050611 1.95052636
 1.95050579 1.95054295]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.95056591 1.95056881 1.95055794 1.95056123 1.95055246 1.95052398
 1.95052021 1.95052861 1.95053039 1.95053595 1.9505339  1.95053409
 1.95055366 1.9505561  1.95055141 1.9505571  1.95056415 1.95054152
 1.95054671 1.95054775]
[0.         0.18421053 0.        ]
-----------end of analyzing the loss ratio:78.82424759864807
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc5fec80>
---------------------------------
SparseEpoch: [1][1/398]	Time 0.645	Data 0.000	Loss 1.9727	
SparseEpoch: [1][101/398]	Time 0.677	Data 0.000	Loss 3.4976	
SparseEpoch: [1][201/398]	Time 0.676	Data 0.000	Loss 1.5193	
SparseEpoch: [1][301/398]	Time 0.688	Data 0.000	Loss 1.8156	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.15228783 1.15209939 1.15194194 1.15167418 1.15136014 1.15115435
 1.15092262 1.15058884 1.15040732 1.15024667 1.15002695 1.14976647
 1.14958568 1.14927573 1.14908381 1.14899157 1.14878755 1.14849916
 1.1482892  1.14804621]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.15024521 1.15026138 1.15025078 1.15024735 1.15023599 1.15025594
 1.15022085 1.15019372 1.1501752  1.15016403 1.15013291 1.15013227
 1.15009676 1.15007032 1.15006106 1.15002967 1.14998347 1.14995813
 1.14996187 1.14990797]
[0.5 0.  0.5]
-----------end of analyzing the loss ratio:86.2664647102356
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x74460813bd60>
---------------------------------
SparseEpoch: [1][1/398]	Time 0.687	Data 0.000	Loss 3.4043	
SparseEpoch: [1][101/398]	Time 0.716	Data 0.000	Loss 3.6075	
SparseEpoch: [1][201/398]	Time 0.711	Data 0.000	Loss 3.3083	
SparseEpoch: [1][301/398]	Time 0.710	Data 0.000	Loss 3.2405	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.33647327 0.33647352 0.33647125 0.33646981 0.33646975 0.33646737
 0.33646567 0.33646063 0.33645965 0.33645762 0.33645647 0.33645638
 0.33645647 0.33645307 0.3364497  0.33644425 0.33644511 0.3364449
 0.33644576 0.33644132]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.33646027 0.33645879 0.3364584  0.33645802 0.33645852 0.33645847
 0.33645885 0.33645781 0.33645756 0.33645686 0.33645757 0.3364568
 0.33645604 0.33645753 0.33645856 0.33645895 0.33645687 0.33645778
 0.33645568 0.33645546]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:75.5719141960144
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x74460816ba90>
---------------------------------
SparseEpoch: [1][1/398]	Time 0.613	Data 0.000	Loss 4.2269	
SparseEpoch: [1][101/398]	Time 0.628	Data 0.000	Loss 4.5943	
SparseEpoch: [1][201/398]	Time 0.666	Data 0.000	Loss 4.8136	
SparseEpoch: [1][301/398]	Time 0.700	Data 0.000	Loss 4.0508	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 3.6962	
Epoch(adapt):{0} Loss 3.0667	
Epoch(adapt):{0} Loss 2.8010	
Epoch(adapt):{0} Loss 3.0719	
------------------the total time cost:1393.6154296398163
>>>>>meta updating
Epoch: 0001 | TRAIN: 1.7184 0.0949 0.4090 | 0.7908 0.7908 0.3489 | 0.2785 39.8994 37.9261 0.0636 0.2360 0.3681 ||TEST: 1.7166 0.1002 0.4206 | 0.9082 0.9082 0.3182 | 0.2711 39.4057 37.8665 0.0642 0.2372 0.3696 | 142.3216
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.60635064 1.60633624 1.60631684 1.60630554 1.60629067 1.60629271
 1.60627755 1.60632488 1.60628703 1.60629396 1.60627578 1.6062482
 1.60625072 1.60624031 1.60626584 1.60627121 1.60626214 1.60624
 1.60624974 1.60626315]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.60623176 1.60622517 1.60625513 1.60626771 1.60627778 1.6062677
 1.60628052 1.60628073 1.6062829  1.60627134 1.60629225 1.60627625
 1.60626336 1.6062739  1.60627931 1.60628998 1.60627936 1.60627558
 1.60625235 1.60625128]
[0.         0.39473684 0.        ]
-----------end of analyzing the loss ratio:77.11168217658997
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc5518a0>
---------------------------------
SparseEpoch: [2][1/398]	Time 0.645	Data 0.000	Loss 1.9845	
SparseEpoch: [2][101/398]	Time 0.684	Data 0.000	Loss 2.1720	
SparseEpoch: [2][201/398]	Time 0.680	Data 0.000	Loss 2.2691	
SparseEpoch: [2][301/398]	Time 0.680	Data 0.000	Loss 2.2458	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.75189762 0.75190669 0.75187816 0.75186642 0.75186701 0.75187343
 0.75186436 0.75185772 0.75183778 0.7518298  0.75182505 0.75180702
 0.75180419 0.75181482 0.75180126 0.75180852 0.75180403 0.75180236
 0.75180278 0.75181223]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.75183138 0.75183406 0.75183384 0.75183038 0.75182871 0.75182539
 0.75181464 0.75182195 0.75182684 0.75182649 0.7518281  0.75183651
 0.7518415  0.75184517 0.75185368 0.75185624 0.75185833 0.75185813
 0.75185713 0.75185417]
[0.23684211 0.         0.        ]
-----------end of analyzing the loss ratio:76.6797776222229
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7446096eb370>
---------------------------------
SparseEpoch: [2][1/398]	Time 0.648	Data 0.000	Loss 1.4616	
SparseEpoch: [2][101/398]	Time 0.646	Data 0.000	Loss 1.0833	
SparseEpoch: [2][201/398]	Time 0.690	Data 0.000	Loss 1.0896	
SparseEpoch: [2][301/398]	Time 0.746	Data 0.000	Loss 1.8583	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.34667999 0.3466824  0.34667589 0.34667538 0.34666357 0.34664023
 0.34661394 0.34660332 0.34658365 0.34656739 0.34656248 0.34654202
 0.34654092 0.34655294 0.34653564 0.34651976 0.34649554 0.34646894
 0.34646449 0.34644762]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.34661809 0.34660537 0.34660991 0.34661044 0.34660059 0.34659368
 0.34657742 0.34656734 0.34656121 0.34656531 0.34656767 0.34656364
 0.34656551 0.34655167 0.34653955 0.34654018 0.34654075 0.34654362
 0.34653754 0.34654105]
[0.5        0.44736842 0.        ]
-----------end of analyzing the loss ratio:78.50745892524719
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7446091a16c0>
---------------------------------
SparseEpoch: [2][1/398]	Time 0.642	Data 0.000	Loss 4.2126	
SparseEpoch: [2][101/398]	Time 0.672	Data 0.000	Loss 3.3135	
SparseEpoch: [2][201/398]	Time 0.678	Data 0.000	Loss 4.0888	
SparseEpoch: [2][301/398]	Time 0.690	Data 0.000	Loss 3.2279	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 3.3987	
Epoch(adapt):{0} Loss 2.6008	
Epoch(adapt):{0} Loss 2.4479	
Epoch(adapt):{0} Loss 2.7109	
------------------the total time cost:1337.8821563720703
>>>>>meta updating
Epoch: 0002 | TRAIN: 1.6509 0.1211 0.4369 | 0.7437 0.7437 0.3338 | 0.2725 39.3546 37.1281 0.0646 0.2450 0.3799 ||TEST: 1.6530 0.1257 0.4370 | 0.8380 0.8380 0.3034 | 0.2656 38.8632 37.0401 0.0672 0.2471 0.3835 | 127.8564
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.7020099  1.70207473 1.70212641 1.70214937 1.70216231 1.70217937
 1.7022166  1.70222015 1.70222722 1.70229927 1.70233989 1.7023356
 1.70231341 1.70234604 1.70238554 1.70251567 1.70263561 1.70269111
 1.70278336 1.70278667]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.70234213 1.70236069 1.70237597 1.70236635 1.70236237 1.70235537
 1.70236115 1.70234319 1.70234418 1.70234656 1.70233597 1.70234268
 1.7023369  1.70234995 1.7023461  1.70235378 1.70233941 1.70232646
 1.70231549 1.70231303]
[0.  0.  0.5]
-----------end of analyzing the loss ratio:74.91311550140381
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc5fdf60>
---------------------------------
SparseEpoch: [3][1/398]	Time 0.617	Data 0.000	Loss 3.9405	
SparseEpoch: [3][101/398]	Time 0.649	Data 0.000	Loss 3.7180	
SparseEpoch: [3][201/398]	Time 0.645	Data 0.000	Loss 2.8671	
SparseEpoch: [3][301/398]	Time 0.649	Data 0.000	Loss 2.8205	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.89066566 0.89061368 0.89055891 0.89049382 0.89044396 0.89035094
 0.89028342 0.89024529 0.89018919 0.89012946 0.89010341 0.89007002
 0.88997427 0.88995172 0.88989106 0.88982137 0.88976493 0.88972182
 0.88966256 0.88958486]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.89010189 0.89010386 0.89012679 0.89012137 0.890108   0.89011963
 0.89011427 0.89012766 0.89010952 0.89012437 0.89010978 0.89011903
 0.89013088 0.89012108 0.89011918 0.89012127 0.89013712 0.89013942
 0.89013189 0.8901196 ]
[0.5 0.  0. ]
-----------end of analyzing the loss ratio:79.05946087837219
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc327520>
---------------------------------
SparseEpoch: [3][1/398]	Time 0.645	Data 0.000	Loss 2.5164	
SparseEpoch: [3][101/398]	Time 0.669	Data 0.000	Loss 1.6174	
SparseEpoch: [3][201/398]	Time 0.657	Data 0.000	Loss 1.7700	
SparseEpoch: [3][301/398]	Time 0.654	Data 0.000	Loss 1.5814	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.28731895 0.2873063  0.28730838 0.28729804 0.28729169 0.287288
 0.28728312 0.28728502 0.28727938 0.2872639  0.28725721 0.28724681
 0.28723726 0.28725054 0.28724172 0.28723107 0.28721172 0.28720242
 0.28720002 0.28721398]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.28727313 0.28727345 0.28727553 0.28727176 0.28727632 0.28727555
 0.28727113 0.28727018 0.28726454 0.28726722 0.28726105 0.28725828
 0.28725989 0.28725398 0.28724345 0.2872405  0.28724375 0.28723857
 0.28724589 0.2872436 ]
[0.44736842 0.39473684 0.        ]
-----------end of analyzing the loss ratio:76.24012684822083
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7446099c21d0>
---------------------------------
SparseEpoch: [3][1/398]	Time 0.618	Data 0.000	Loss 3.3857	
SparseEpoch: [3][101/398]	Time 0.657	Data 0.000	Loss 4.8620	
SparseEpoch: [3][201/398]	Time 0.649	Data 0.000	Loss 4.5277	
SparseEpoch: [3][301/398]	Time 0.647	Data 0.000	Loss 4.0174	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 2.5862	
Epoch(adapt):{0} Loss 3.3416	
Epoch(adapt):{0} Loss 1.9175	
Epoch(adapt):{0} Loss 2.8436	
------------------the total time cost:1272.2249445915222
>>>>>meta updating
Epoch: 0003 | TRAIN: 1.6136 0.1267 0.4477 | 0.7344 0.7344 0.3659 | 0.2582 37.8882 35.5293 0.0832 0.2758 0.4104 ||TEST: 1.6107 0.1326 0.4512 | 0.7907 0.7907 0.3066 | 0.2515 37.3939 35.4985 0.0888 0.2811 0.4129 | 122.0653
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.72525301 1.72524843 1.72518001 1.72511988 1.72512153 1.72512338
 1.72513109 1.72509056 1.72508484 1.72506342 1.72502637 1.72500833
 1.72499101 1.72498268 1.72497017 1.72496667 1.72497197 1.72498517
 1.72495562 1.72494479]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.72516985 1.72516505 1.72513384 1.72512002 1.72513981 1.72509601
 1.72509135 1.72508792 1.72509122 1.72505583 1.72504518 1.72503775
 1.72504299 1.72504121 1.72503736 1.72502007 1.72500017 1.72500383
 1.72498726 1.72495643]
[0.  0.5 0.5]
-----------end of analyzing the loss ratio:81.4921805858612
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc0020e0>
---------------------------------
SparseEpoch: [4][1/398]	Time 0.764	Data 0.000	Loss 3.6662	
SparseEpoch: [4][101/398]	Time 0.755	Data 0.000	Loss 3.9339	
SparseEpoch: [4][201/398]	Time 0.747	Data 0.000	Loss 3.0574	
SparseEpoch: [4][301/398]	Time 0.718	Data 0.000	Loss 3.7319	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.80449884 0.80450947 0.80452091 0.80454353 0.80454258 0.80455292
 0.80456932 0.80456686 0.80455822 0.80456294 0.80456647 0.80457831
 0.80458022 0.80459026 0.80458388 0.80459799 0.80459951 0.80460262
 0.80462455 0.80462828]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.8045755  0.80457495 0.80456386 0.80456277 0.80456566 0.80455989
 0.80456015 0.80456015 0.80456061 0.8045727  0.80456905 0.80456045
 0.80455257 0.80455302 0.80455949 0.80456302 0.80457301 0.80457248
 0.80455384 0.80456286]
[0.         0.         0.13157895]
-----------end of analyzing the loss ratio:77.49081683158875
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x744609944160>
---------------------------------
SparseEpoch: [4][1/398]	Time 0.621	Data 0.000	Loss 1.3263	
SparseEpoch: [4][101/398]	Time 0.658	Data 0.000	Loss 1.3526	
SparseEpoch: [4][201/398]	Time 0.660	Data 0.000	Loss 1.0414	
SparseEpoch: [4][301/398]	Time 0.655	Data 0.000	Loss 1.1668	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.30500016 0.30499246 0.304981   0.30497572 0.30495973 0.30495712
 0.30494707 0.30494047 0.30492892 0.3049298  0.30491678 0.3049127
 0.30490687 0.30490498 0.30489907 0.30487827 0.30486918 0.30486694
 0.30485698 0.30484649]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.30494849 0.30494033 0.3049439  0.3049374  0.30493003 0.30492693
 0.30492738 0.30492629 0.3049275  0.30492432 0.30492077 0.30491744
 0.30491906 0.30491397 0.3049118  0.30491229 0.30492    0.30491594
 0.30491719 0.30490866]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:79.20631504058838
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444dc319b40>
---------------------------------
SparseEpoch: [4][1/398]	Time 0.611	Data 0.000	Loss 4.3586	
SparseEpoch: [4][101/398]	Time 0.709	Data 0.000	Loss 4.2201	
SparseEpoch: [4][201/398]	Time 0.681	Data 0.000	Loss 4.1382	
SparseEpoch: [4][301/398]	Time 0.679	Data 0.000	Loss 3.2943	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 2.9904	
Epoch(adapt):{0} Loss 2.3811	
Epoch(adapt):{0} Loss 2.5760	
Epoch(adapt):{0} Loss 2.2770	
------------------the total time cost:1306.5239946842194
>>>>>meta updating
Epoch: 0004 | TRAIN: 1.5961 0.1334 0.4538 | 0.7313 0.7313 0.3766 | 0.2487 36.9156 34.6250 0.1005 0.2934 0.4256 ||TEST: 1.6025 0.1369 0.4526 | 0.7633 0.7633 0.3159 | 0.2397 36.1651 34.2774 0.1104 0.3041 0.4328 | 120.1593
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.58286532 1.58287128 1.58292359 1.58294022 1.58290565 1.58293276
 1.58292644 1.58286214 1.58294404 1.58294114 1.58297013 1.58296747
 1.58291675 1.58304871 1.58302836 1.58309138 1.58307697 1.58312712
 1.58314024 1.58316315]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.5830042  1.5829888  1.58299551 1.58300523 1.58298994 1.58298737
 1.58298194 1.58296994 1.58297055 1.58296901 1.5829538  1.582945
 1.5829554  1.58296018 1.58295351 1.5829561  1.58295337 1.58292001
 1.58293248 1.58292494]
[0.         0.         0.39473684]
-----------end of analyzing the loss ratio:76.59832739830017
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x744608683f70>
---------------------------------
SparseEpoch: [5][1/398]	Time 0.616	Data 0.000	Loss 2.1734	
SparseEpoch: [5][101/398]	Time 0.654	Data 0.000	Loss 3.4020	
SparseEpoch: [5][201/398]	Time 0.655	Data 0.000	Loss 3.0899	
SparseEpoch: [5][301/398]	Time 0.655	Data 0.000	Loss 2.8433	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.02523386 1.02525638 1.02521338 1.02519417 1.0252162  1.02522768
 1.02520325 1.02515805 1.02513111 1.02509699 1.02509736 1.02508937
 1.02509711 1.02506262 1.02509833 1.02515031 1.02515936 1.02509677
 1.0250616  1.02507235]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.02511973 1.02512989 1.02513631 1.02512645 1.02513564 1.02512983
 1.02512318 1.0250901  1.02509932 1.02508953 1.02507846 1.02510586
 1.02512832 1.02513197 1.02515958 1.02512261 1.02511855 1.02512169
 1.02513416 1.02511905]
[0.44736842 0.         0.02631579]
-----------end of analyzing the loss ratio:78.15204358100891
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc509180>
---------------------------------
SparseEpoch: [5][1/398]	Time 0.624	Data 0.000	Loss 0.9276	
SparseEpoch: [5][101/398]	Time 0.681	Data 0.000	Loss 1.3749	
SparseEpoch: [5][201/398]	Time 0.678	Data 0.000	Loss 1.6312	
SparseEpoch: [5][301/398]	Time 0.662	Data 0.000	Loss 2.0859	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.28424335 0.28424657 0.2842339  0.28421748 0.28420984 0.28420283
 0.28420708 0.28420721 0.28418443 0.28418477 0.28419329 0.28419179
 0.28419029 0.2841915  0.28419374 0.28421118 0.28421205 0.28418312
 0.28418442 0.2841935 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.28431878 0.28432423 0.28429868 0.28429788 0.28429418 0.28426784
 0.2842554  0.28424378 0.2842193  0.28419774 0.2841967  0.2841738
 0.2841837  0.284197   0.28420227 0.28419758 0.28419002 0.2841806
 0.28416983 0.28414783]
[0.39473684 0.5        0.        ]
-----------end of analyzing the loss ratio:85.32943105697632
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc56c5e0>
---------------------------------
SparseEpoch: [5][1/398]	Time 0.685	Data 0.000	Loss 3.1840	
SparseEpoch: [5][101/398]	Time 0.648	Data 0.000	Loss 3.9232	
SparseEpoch: [5][201/398]	Time 0.648	Data 0.000	Loss 4.3963	
SparseEpoch: [5][301/398]	Time 0.663	Data 0.000	Loss 3.9420	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 2.8825	
Epoch(adapt):{0} Loss 2.7981	
Epoch(adapt):{0} Loss 2.3982	
Epoch(adapt):{0} Loss 3.8724	
------------------the total time cost:1280.2122056484222
>>>>>meta updating
Epoch: 0005 | TRAIN: 1.5513 0.1331 0.4653 | 0.7035 0.7035 0.3277 | 0.2453 36.7267 34.1515 0.0908 0.2935 0.4328 ||TEST: 1.5603 0.1393 0.4652 | 0.7908 0.7908 0.2920 | 0.2332 35.7892 33.7653 0.0988 0.3022 0.4385 | 116.6035
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.61765143 1.61770737 1.61773505 1.61773369 1.61775103 1.61778508
 1.61782944 1.61780226 1.61781272 1.61778635 1.61781409 1.61780844
 1.61782396 1.61782899 1.61784759 1.6178897  1.6178721  1.6179006
 1.61789931 1.61791359]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.61782269 1.61780989 1.61782352 1.61782566 1.61780761 1.61780013
 1.61780945 1.61779947 1.61782279 1.61781586 1.61780761 1.61779654
 1.61778387 1.61781566 1.61783061 1.61778942 1.61777229 1.61779387
 1.61777631 1.617772  ]
[0.  0.  0.5]
-----------end of analyzing the loss ratio:73.6191771030426
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc5ff520>
---------------------------------
SparseEpoch: [6][1/398]	Time 0.605	Data 0.000	Loss 2.9609	
SparseEpoch: [6][101/398]	Time 0.620	Data 0.000	Loss 2.6248	
SparseEpoch: [6][201/398]	Time 0.623	Data 0.000	Loss 4.3552	
SparseEpoch: [6][301/398]	Time 0.624	Data 0.000	Loss 2.6602	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.7007016  0.70071825 0.7006877  0.70066466 0.70064896 0.70063715
 0.70063497 0.70062186 0.70060772 0.70058383 0.70060122 0.70058631
 0.70058228 0.70054908 0.70055591 0.70053554 0.70051291 0.70047839
 0.7004679  0.7004527 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.70060034 0.70060024 0.70059267 0.70059773 0.70059088 0.70058658
 0.70058551 0.70058245 0.70058133 0.70059632 0.70059558 0.70059766
 0.70060095 0.70059936 0.70060694 0.70060162 0.70060391 0.70060079
 0.70060913 0.7006053 ]
[0.5 0.  0. ]
-----------end of analyzing the loss ratio:73.84844303131104
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc25a410>
---------------------------------
SparseEpoch: [6][1/398]	Time 0.609	Data 0.000	Loss 1.2135	
SparseEpoch: [6][101/398]	Time 0.623	Data 0.000	Loss 1.5267	
SparseEpoch: [6][201/398]	Time 0.624	Data 0.000	Loss 1.3084	
SparseEpoch: [6][301/398]	Time 0.624	Data 0.000	Loss 1.2779	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.2663066  0.26630077 0.26630355 0.26630461 0.26629554 0.26630049
 0.26629571 0.26628731 0.26628256 0.26630265 0.26629525 0.26629258
 0.2662957  0.26628319 0.26628117 0.26628624 0.2662866  0.26628195
 0.2662799  0.26627902]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.2662921  0.26629166 0.26629546 0.26629485 0.26629496 0.26630454
 0.26630053 0.26628975 0.26629004 0.26629494 0.26629775 0.26629882
 0.26630003 0.26629683 0.26628612 0.26628997 0.26630161 0.266306
 0.26630511 0.26629916]
[0.5        0.23684211 0.        ]
-----------end of analyzing the loss ratio:73.9559018611908
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc002410>
---------------------------------
SparseEpoch: [6][1/398]	Time 0.606	Data 0.000	Loss 3.0079	
SparseEpoch: [6][101/398]	Time 0.627	Data 0.000	Loss 3.7532	
SparseEpoch: [6][201/398]	Time 0.624	Data 0.000	Loss 5.5589	
SparseEpoch: [6][301/398]	Time 0.625	Data 0.000	Loss 3.4971	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 2.5358	
Epoch(adapt):{0} Loss 2.9662	
Epoch(adapt):{0} Loss 2.2944	
Epoch(adapt):{0} Loss 2.6447	
------------------the total time cost:1214.1017897129059
>>>>>meta updating
Epoch: 0006 | TRAIN: 1.5145 0.1489 0.4774 | 0.6816 0.6816 0.3126 | 0.2368 35.8256 33.1917 0.1062 0.3121 0.4495 ||TEST: 1.5326 0.1512 0.4743 | 0.7622 0.7622 0.2854 | 0.2271 35.0294 32.8605 0.1163 0.3212 0.4552 | 114.7068
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.5263977  1.52631184 1.52621862 1.52614306 1.52603285 1.52597321
 1.52603412 1.5260027  1.52595215 1.52582248 1.52577314 1.52570845
 1.52579962 1.52576723 1.52579677 1.52580923 1.52579482 1.52570488
 1.52576141 1.52566544]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.52581393 1.52581355 1.52580605 1.52579673 1.52578046 1.52578403
 1.52577698 1.52576423 1.52576049 1.52578093 1.52577317 1.52577689
 1.52576936 1.52576576 1.52577437 1.52579299 1.52579834 1.52581345
 1.52581117 1.5258139 ]
[0.  0.5 0. ]
-----------end of analyzing the loss ratio:73.6710729598999
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7446091a16c0>
---------------------------------
SparseEpoch: [7][1/398]	Time 0.605	Data 0.000	Loss 1.8879	
SparseEpoch: [7][101/398]	Time 0.627	Data 0.000	Loss 1.7385	
SparseEpoch: [7][201/398]	Time 0.627	Data 0.000	Loss 1.6140	
SparseEpoch: [7][301/398]	Time 0.626	Data 0.000	Loss 1.4135	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.66108028 0.66106916 0.6610666  0.66103462 0.66102237 0.66101448
 0.6610059  0.66098723 0.66098754 0.66095694 0.66092321 0.66089318
 0.66088265 0.66088399 0.6608784  0.66086271 0.66083924 0.66084151
 0.6608263  0.66081734]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.66100485 0.66099191 0.6609779  0.66096145 0.66095722 0.66095251
 0.66094991 0.66095436 0.66094202 0.66093438 0.66093811 0.66092496
 0.66092593 0.6609248  0.6609132  0.66090657 0.66088966 0.6608843
 0.66088017 0.66086436]
[0.5 0.  0.5]
-----------end of analyzing the loss ratio:74.0430109500885
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc552ef0>
---------------------------------
SparseEpoch: [7][1/398]	Time 0.605	Data 0.000	Loss 2.9037	
SparseEpoch: [7][101/398]	Time 0.623	Data 0.000	Loss 2.4299	
SparseEpoch: [7][201/398]	Time 0.624	Data 0.000	Loss 2.9440	
SparseEpoch: [7][301/398]	Time 0.623	Data 0.000	Loss 2.6194	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.28753849 0.28752485 0.28751475 0.28751229 0.28751047 0.28748423
 0.28745911 0.28744249 0.28742992 0.28742322 0.28740754 0.28741243
 0.28740546 0.28740665 0.28739924 0.28736449 0.28735322 0.28733311
 0.28733089 0.28732358]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.28747647 0.28745069 0.28744797 0.28744082 0.28742619 0.28742556
 0.28741849 0.28741331 0.2874253  0.2874183  0.2874164  0.28740199
 0.28740667 0.28740885 0.28741075 0.28740895 0.28739819 0.28739613
 0.28739056 0.28738259]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:73.73632764816284
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7446096e89d0>
---------------------------------
SparseEpoch: [7][1/398]	Time 0.614	Data 0.000	Loss 3.1569	
SparseEpoch: [7][101/398]	Time 0.625	Data 0.000	Loss 4.3216	
SparseEpoch: [7][201/398]	Time 0.624	Data 0.000	Loss 3.6878	
SparseEpoch: [7][301/398]	Time 0.624	Data 0.000	Loss 4.2350	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 2.0083	
Epoch(adapt):{0} Loss 2.2112	
Epoch(adapt):{0} Loss 2.2205	
Epoch(adapt):{0} Loss 2.5965	
------------------the total time cost:1213.0067143440247
>>>>>meta updating
Epoch: 0007 | TRAIN: 1.5169 0.1511 0.4824 | 0.6941 0.6941 0.3578 | 0.2347 35.2578 32.3983 0.1315 0.3344 0.4647 ||TEST: 1.5383 0.1528 0.4790 | 0.7322 0.7322 0.3145 | 0.2248 34.4525 32.0624 0.1416 0.3435 0.4713 | 114.8883
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.48112583 1.48101975 1.48100556 1.48098259 1.48098019 1.48096647
 1.48100523 1.48102044 1.48103299 1.4809847  1.48101065 1.48099382
 1.48098534 1.48100669 1.4810167  1.48101462 1.48108152 1.48103256
 1.48106642 1.48109901]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.48101003 1.48100724 1.48100784 1.48099797 1.48099339 1.48100102
 1.48099978 1.48100573 1.48100302 1.48100214 1.48100448 1.4809954
 1.48099295 1.48099793 1.48099573 1.48099372 1.480986   1.4809787
 1.48098048 1.48097076]
[0.  0.  0.5]
-----------end of analyzing the loss ratio:73.69999551773071
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc327640>
---------------------------------
SparseEpoch: [8][1/398]	Time 0.605	Data 0.000	Loss 2.7354	
SparseEpoch: [8][101/398]	Time 0.624	Data 0.000	Loss 2.7362	
SparseEpoch: [8][201/398]	Time 0.624	Data 0.000	Loss 2.0245	
SparseEpoch: [8][301/398]	Time 0.626	Data 0.000	Loss 2.2724	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.79526741 0.79524087 0.79526705 0.79527911 0.79530907 0.79532719
 0.79533136 0.79535306 0.79535832 0.79537234 0.79536072 0.7953477
 0.7953614  0.79535363 0.79539112 0.79542138 0.79540051 0.79539565
 0.79538516 0.79540142]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.79531701 0.79532488 0.7953369  0.79534729 0.79536294 0.79536047
 0.79537179 0.79537005 0.79536752 0.79536356 0.79537559 0.79536929
 0.79537953 0.79537471 0.7953656  0.79536555 0.79538528 0.79539079
 0.79536356 0.79536161]
[0. 0. 0.]
-----------end of analyzing the loss ratio:73.68196320533752
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc388790>
---------------------------------
SparseEpoch: [8][1/398]	Time 0.620	Data 0.000	Loss 0.4132	
SparseEpoch: [8][101/398]	Time 0.621	Data 0.000	Loss 0.5025	
SparseEpoch: [8][201/398]	Time 0.622	Data 0.000	Loss 0.6003	
SparseEpoch: [8][301/398]	Time 0.620	Data 0.000	Loss 1.6458	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.24575957 0.24574694 0.24574253 0.2457285  0.24572901 0.24573258
 0.24572361 0.24569891 0.24569185 0.24568085 0.24568011 0.2456811
 0.24567212 0.24566885 0.24565463 0.24563807 0.24563032 0.24562603
 0.24562201 0.24561942]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.24572958 0.24573222 0.24573766 0.24572546 0.24571719 0.24569867
 0.24570068 0.24569055 0.24569355 0.24568004 0.24567191 0.24566444
 0.24566675 0.24567508 0.24567717 0.24567279 0.24566783 0.2456687
 0.24567758 0.24566782]
[0.5        0.07894737 0.        ]
-----------end of analyzing the loss ratio:73.97791957855225
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc41cdc0>
---------------------------------
SparseEpoch: [8][1/398]	Time 0.605	Data 0.000	Loss 3.0826	
SparseEpoch: [8][101/398]	Time 0.628	Data 0.000	Loss 3.4945	
SparseEpoch: [8][201/398]	Time 0.628	Data 0.000	Loss 3.1931	
SparseEpoch: [8][301/398]	Time 0.627	Data 0.000	Loss 3.0804	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 2.8319	
Epoch(adapt):{0} Loss 2.2009	
Epoch(adapt):{0} Loss 2.9692	
Epoch(adapt):{0} Loss 3.1883	
------------------the total time cost:1213.7713751792908
>>>>>meta updating
Epoch: 0008 | TRAIN: 1.4928 0.1570 0.4873 | 0.6776 0.6776 0.3438 | 0.2275 34.7214 31.9042 0.1300 0.3362 0.4714 ||TEST: 1.4977 0.1605 0.4875 | 0.7199 0.7199 0.2878 | 0.2176 33.8864 31.5101 0.1409 0.3473 0.4791 | 114.8938
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.54303304 1.5430631  1.54305966 1.54306308 1.54305688 1.54304414
 1.54306796 1.54309008 1.54312502 1.54315186 1.54314108 1.54313989
 1.54318069 1.54316764 1.54317048 1.54319369 1.54319479 1.54318398
 1.54317493 1.54316975]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.54314451 1.5431474  1.54316232 1.54316912 1.54316059 1.54314375
 1.54315231 1.54316581 1.54315792 1.54314244 1.54313451 1.54313538
 1.54312371 1.54311404 1.5431233  1.54312843 1.54312729 1.54312809
 1.5431175  1.54312501]
[0.         0.         0.18421053]
-----------end of analyzing the loss ratio:73.63623833656311
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7446099ff910>
---------------------------------
SparseEpoch: [9][1/398]	Time 0.605	Data 0.000	Loss 1.7665	
SparseEpoch: [9][101/398]	Time 0.626	Data 0.000	Loss 2.0087	
SparseEpoch: [9][201/398]	Time 0.624	Data 0.000	Loss 2.2771	
SparseEpoch: [9][301/398]	Time 0.623	Data 0.000	Loss 2.1218	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.88672354 0.88671973 0.88669787 0.88671636 0.88664802 0.88664412
 0.88662916 0.88658829 0.88657921 0.88654575 0.8865334  0.88648542
 0.88642859 0.88639023 0.886353   0.88631723 0.88629357 0.88629881
 0.88625157 0.88622731]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.8865855  0.88657746 0.88656368 0.88656689 0.88656733 0.88657747
 0.88655067 0.88654422 0.88653291 0.88655767 0.88654777 0.88652906
 0.88652299 0.88652894 0.88653214 0.88654656 0.88653455 0.88652783
 0.88650328 0.88649041]
[0.5 0.  0.5]
-----------end of analyzing the loss ratio:73.76668572425842
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc56c0d0>
---------------------------------
SparseEpoch: [9][1/398]	Time 0.605	Data 0.000	Loss 2.7905	
SparseEpoch: [9][101/398]	Time 0.628	Data 0.000	Loss 2.6649	
SparseEpoch: [9][201/398]	Time 0.626	Data 0.000	Loss 2.4274	
SparseEpoch: [9][301/398]	Time 0.625	Data 0.000	Loss 2.9124	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.24667713 0.24668233 0.24669554 0.24668388 0.24667175 0.24666665
 0.24667352 0.24667243 0.24666084 0.24665021 0.24665213 0.24664725
 0.24665588 0.24665837 0.24666382 0.24666178 0.24666271 0.24666399
 0.24666521 0.24666129]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.24663615 0.24664164 0.24663944 0.246643   0.24664392 0.24663953
 0.24664359 0.24664662 0.24664574 0.24665025 0.24664927 0.24666081
 0.24666154 0.24666194 0.24666818 0.24666994 0.24667078 0.24666855
 0.24666699 0.24665849]
[0.07894737 0.         0.        ]
-----------end of analyzing the loss ratio:73.76271557807922
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x744609946440>
---------------------------------
SparseEpoch: [9][1/398]	Time 0.623	Data 0.000	Loss 1.9544	
SparseEpoch: [9][101/398]	Time 0.620	Data 0.000	Loss 3.4024	
SparseEpoch: [9][201/398]	Time 0.623	Data 0.000	Loss 1.7730	
SparseEpoch: [9][301/398]	Time 0.623	Data 0.000	Loss 2.2031	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 2.3725	
Epoch(adapt):{0} Loss 2.5692	
Epoch(adapt):{0} Loss 2.1734	
Epoch(adapt):{0} Loss 2.5776	
------------------the total time cost:1215.505782365799
>>>>>meta updating
Epoch: 0009 | TRAIN: 1.4684 0.1663 0.4983 | 0.6726 0.6726 0.3298 | 0.2243 34.3885 31.3328 0.1319 0.3447 0.4812 ||TEST: 1.4821 0.1700 0.4950 | 0.7214 0.7214 0.2858 | 0.2133 33.5006 30.8419 0.1398 0.3553 0.4902 | 115.3946
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.52964137 1.52966454 1.52962779 1.52954936 1.52950817 1.52949115
 1.52948265 1.52951293 1.52949556 1.52946784 1.52944289 1.5293835
 1.52937198 1.52933338 1.52931485 1.52929124 1.52926761 1.52926571
 1.52924865 1.52916679]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.52952309 1.52950833 1.52950923 1.5294993  1.52949077 1.52947638
 1.52948483 1.52946938 1.52946707 1.52945225 1.52945513 1.52944778
 1.52944994 1.52946359 1.52944829 1.52945353 1.52944394 1.52945004
 1.52942318 1.52941465]
[0.  0.5 0.5]
-----------end of analyzing the loss ratio:73.99468612670898
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d72d1000>
---------------------------------
SparseEpoch: [10][1/398]	Time 0.617	Data 0.000	Loss 2.4736	
SparseEpoch: [10][101/398]	Time 0.627	Data 0.000	Loss 3.5219	
SparseEpoch: [10][201/398]	Time 0.628	Data 0.000	Loss 2.5479	
SparseEpoch: [10][301/398]	Time 0.627	Data 0.000	Loss 2.4997	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.87475903 0.87483006 0.87481985 0.87487217 0.8749091  0.87494468
 0.87494341 0.87496413 0.87498977 0.87503906 0.87508976 0.87505888
 0.87507029 0.87503149 0.87504072 0.87502468 0.87502989 0.87510291
 0.87513667 0.87522634]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.874928   0.87496546 0.8749443  0.87493932 0.87496765 0.87499808
 0.87501265 0.87502121 0.8750344  0.87506952 0.87504662 0.87508213
 0.87509184 0.87507393 0.87504959 0.87506732 0.87506892 0.87507463
 0.87507679 0.87508376]
[0. 0. 0.]
-----------end of analyzing the loss ratio:73.72632265090942
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444dc3b5e70>
---------------------------------
SparseEpoch: [10][1/398]	Time 0.608	Data 0.000	Loss 0.4686	
SparseEpoch: [10][101/398]	Time 0.622	Data 0.000	Loss 0.8521	
SparseEpoch: [10][201/398]	Time 0.622	Data 0.000	Loss 0.6399	
SparseEpoch: [10][301/398]	Time 0.622	Data 0.000	Loss 0.6220	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.22519395 0.22518093 0.22516598 0.22515842 0.22515459 0.22513312
 0.22513436 0.22513101 0.22512121 0.2251229  0.2251222  0.22510493
 0.22509971 0.22509664 0.22510205 0.22510377 0.22510206 0.22508466
 0.22507822 0.22506365]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.2251348  0.22512631 0.22512601 0.22512263 0.22512651 0.22512587
 0.22513316 0.22513302 0.22513037 0.2251204  0.22511688 0.22512131
 0.22512932 0.22512534 0.22511642 0.22511681 0.22511504 0.22510901
 0.22509612 0.22509302]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:73.96836376190186
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc1c5f30>
---------------------------------
SparseEpoch: [10][1/398]	Time 0.605	Data 0.000	Loss 3.3121	
SparseEpoch: [10][101/398]	Time 0.623	Data 0.000	Loss 2.9671	
SparseEpoch: [10][201/398]	Time 0.625	Data 0.000	Loss 3.2865	
SparseEpoch: [10][301/398]	Time 0.625	Data 0.000	Loss 3.8841	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 2.4484	
Epoch(adapt):{0} Loss 2.2124	
Epoch(adapt):{0} Loss 2.4236	
Epoch(adapt):{0} Loss 2.3737	
------------------the total time cost:1214.689868927002
>>>>>meta updating
Epoch: 0010 | TRAIN: 1.4603 0.1643 0.4990 | 0.6559 0.6559 0.3123 | 0.2203 34.0823 30.9130 0.1287 0.3505 0.4886 ||TEST: 1.4826 0.1636 0.4928 | 0.6988 0.6988 0.2747 | 0.2122 33.4160 30.6529 0.1370 0.3589 0.4939 | 114.9439
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.29101148 1.29105167 1.29106125 1.29103442 1.2910739  1.29107314
 1.29108994 1.29108832 1.29116838 1.29120305 1.29122683 1.2911827
 1.29119183 1.29125662 1.29126767 1.2912977  1.29129043 1.29131263
 1.29129366 1.29133104]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.29119083 1.29119482 1.2912048  1.29120205 1.29120306 1.29120318
 1.29119753 1.29119589 1.29119486 1.2912037  1.29121006 1.29119992
 1.29120856 1.29120458 1.29121631 1.29121164 1.29122063 1.2912217
 1.29120522 1.29119446]
[0. 0. 0.]
-----------end of analyzing the loss ratio:73.6742491722107
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x744609645c30>
---------------------------------
SparseEpoch: [11][1/398]	Time 0.607	Data 0.000	Loss 2.0400	
SparseEpoch: [11][101/398]	Time 0.621	Data 0.000	Loss 1.1813	
SparseEpoch: [11][201/398]	Time 0.620	Data 0.000	Loss 1.6165	
SparseEpoch: [11][301/398]	Time 0.621	Data 0.000	Loss 1.4859	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.2755725  1.27546675 1.27533877 1.2752908  1.27528805 1.2751824
 1.27510095 1.27501969 1.27490265 1.27488076 1.27480435 1.27467342
 1.27458471 1.27445992 1.27438651 1.27428986 1.2741874  1.27408947
 1.27403946 1.27397369]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.27484437 1.27483564 1.2748378  1.27482986 1.27483565 1.27484723
 1.27483313 1.27482168 1.27483888 1.27483636 1.27484826 1.27483505
 1.27482985 1.27481636 1.27481027 1.27479079 1.27477791 1.27478351
 1.27477877 1.27478085]
[0.5        0.         0.34210526]
-----------end of analyzing the loss ratio:73.81100940704346
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7446099fc4c0>
---------------------------------
SparseEpoch: [11][1/398]	Time 0.606	Data 0.000	Loss 2.1539	
SparseEpoch: [11][101/398]	Time 0.631	Data 0.000	Loss 1.9598	
SparseEpoch: [11][201/398]	Time 0.628	Data 0.000	Loss 2.8228	
SparseEpoch: [11][301/398]	Time 0.627	Data 0.000	Loss 2.2967	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.2478159  0.24781266 0.24782148 0.24781194 0.24780887 0.24780216
 0.24780093 0.24780128 0.24779162 0.24778785 0.2477855  0.24777552
 0.24777215 0.24777497 0.24777774 0.24777402 0.24777786 0.2477707
 0.2477757  0.24776526]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.24785634 0.2478426  0.24783305 0.2478204  0.24780783 0.24781315
 0.24780485 0.24780511 0.24780797 0.24779447 0.24778824 0.24778243
 0.24776853 0.24775912 0.24775357 0.24774745 0.24773698 0.24772668
 0.24771873 0.24770602]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:73.72402548789978
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc58f6a0>
---------------------------------
SparseEpoch: [11][1/398]	Time 0.606	Data 0.000	Loss 2.5915	
SparseEpoch: [11][101/398]	Time 0.625	Data 0.000	Loss 3.1106	
SparseEpoch: [11][201/398]	Time 0.624	Data 0.000	Loss 4.4711	
SparseEpoch: [11][301/398]	Time 0.623	Data 0.000	Loss 3.2762	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 2.0793	
Epoch(adapt):{0} Loss 2.2088	
Epoch(adapt):{0} Loss 1.8729	
Epoch(adapt):{0} Loss 2.4569	
------------------the total time cost:1213.3196313381195
>>>>>meta updating
Epoch: 0011 | TRAIN: 1.4430 0.1805 0.5048 | 0.6460 0.6460 0.3272 | 0.2198 33.8477 30.6761 0.1420 0.3588 0.4943 ||TEST: 1.4749 0.1768 0.4942 | 0.6955 0.6955 0.2861 | 0.2091 32.9198 29.9997 0.1535 0.3728 0.5047 | 115.3195
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.39598777 1.39601714 1.39602695 1.39608952 1.39610417 1.39602996
 1.39602049 1.39599389 1.39590697 1.39586038 1.3958437  1.39581151
 1.39583223 1.39585682 1.39583067 1.39578173 1.39578369 1.39573622
 1.3957301  1.39569751]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.39596193 1.39593661 1.39593794 1.39593015 1.39592518 1.39591855
 1.39592233 1.39592737 1.39589232 1.39587498 1.39585969 1.39583253
 1.39582115 1.39581469 1.39579939 1.39579006 1.3957772  1.39579418
 1.3957922  1.39577193]
[0.  0.5 0.5]
-----------end of analyzing the loss ratio:73.7845709323883
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444dc2513c0>
---------------------------------
SparseEpoch: [12][1/398]	Time 0.652	Data 0.000	Loss 2.5862	
SparseEpoch: [12][101/398]	Time 0.617	Data 0.000	Loss 2.4178	
SparseEpoch: [12][201/398]	Time 0.619	Data 0.000	Loss 3.8990	
SparseEpoch: [12][301/398]	Time 0.620	Data 0.000	Loss 3.2901	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.71270726 0.71257145 0.71246347 0.71230502 0.71224625 0.71214349
 0.71217553 0.71207057 0.71201013 0.71191581 0.71187985 0.71184019
 0.71177951 0.71175253 0.71160378 0.71155943 0.71150019 0.71149806
 0.71142101 0.71129823]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.71202874 0.71199731 0.71198729 0.71198015 0.71198109 0.71197205
 0.71194377 0.71193468 0.71191899 0.71193328 0.71192615 0.71192583
 0.71188546 0.71186246 0.71185759 0.71186137 0.71185066 0.71182187
 0.71180966 0.71180781]
[0.5 0.  0.5]
-----------end of analyzing the loss ratio:73.79726576805115
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc045a20>
---------------------------------
SparseEpoch: [12][1/398]	Time 0.607	Data 0.000	Loss 2.6616	
SparseEpoch: [12][101/398]	Time 0.626	Data 0.000	Loss 2.3486	
SparseEpoch: [12][201/398]	Time 0.625	Data 0.000	Loss 2.4645	
SparseEpoch: [12][301/398]	Time 0.623	Data 0.000	Loss 2.4257	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.2449288  0.24490516 0.24485043 0.24481723 0.24476466 0.24471266
 0.24467515 0.24460911 0.24455133 0.24448238 0.24444034 0.24438171
 0.24431659 0.2443099  0.24425746 0.2442104  0.24420696 0.24415902
 0.24410686 0.24404857]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.24466586 0.24463452 0.24463706 0.24460376 0.24459155 0.24456164
 0.24453999 0.24451979 0.24448695 0.24444302 0.24444494 0.24443699
 0.24442152 0.24439315 0.24435313 0.24434136 0.24432701 0.2443108
 0.24430534 0.24429029]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:73.84010529518127
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc153c40>
---------------------------------
SparseEpoch: [12][1/398]	Time 0.613	Data 0.000	Loss 3.4555	
SparseEpoch: [12][101/398]	Time 0.628	Data 0.000	Loss 4.0714	
SparseEpoch: [12][201/398]	Time 0.624	Data 0.000	Loss 3.0916	
SparseEpoch: [12][301/398]	Time 0.625	Data 0.000	Loss 3.0949	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 2.2798	
Epoch(adapt):{0} Loss 2.4061	
Epoch(adapt):{0} Loss 2.0973	
Epoch(adapt):{0} Loss 2.0044	
------------------the total time cost:1212.038411140442
>>>>>meta updating
Epoch: 0012 | TRAIN: 1.3926 0.1942 0.5236 | 0.6225 0.6225 0.2991 | 0.2121 32.9235 29.4772 0.1610 0.3813 0.5142 ||TEST: 1.4382 0.1894 0.5122 | 0.6925 0.6925 0.2755 | 0.2009 31.9894 28.8774 0.1717 0.3936 0.5239 | 114.8658
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.35488121 1.35499135 1.35504243 1.35504162 1.35505944 1.35510135
 1.35513297 1.35513586 1.35520686 1.35519138 1.35517861 1.35525454
 1.35524994 1.35537474 1.35535941 1.35532603 1.35532869 1.35532236
 1.35535328 1.35545086]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.35525638 1.35524061 1.35524186 1.35524089 1.35523155 1.35522046
 1.35519772 1.35521579 1.35522478 1.35522307 1.35522717 1.35522439
 1.35522022 1.3552142  1.35521327 1.35521951 1.35522059 1.35522505
 1.35522047 1.35521265]
[0. 0. 0.]
-----------end of analyzing the loss ratio:73.89802956581116
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444dc318970>
---------------------------------
SparseEpoch: [13][1/398]	Time 0.606	Data 0.000	Loss 1.6394	
SparseEpoch: [13][101/398]	Time 0.625	Data 0.000	Loss 1.3206	
SparseEpoch: [13][201/398]	Time 0.622	Data 0.000	Loss 2.7528	
SparseEpoch: [13][301/398]	Time 0.621	Data 0.000	Loss 1.4329	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.76138707 0.76137561 0.7613077  0.76128562 0.76121241 0.76123508
 0.76108635 0.76106507 0.76109576 0.76101118 0.76102006 0.76091734
 0.76084474 0.76078861 0.76076824 0.76073415 0.76067179 0.76066961
 0.76063367 0.76058717]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.76101251 0.76102279 0.76103614 0.76103539 0.76101654 0.76099936
 0.76100499 0.76100544 0.7610184  0.76100228 0.76100593 0.76100731
 0.76101521 0.76100218 0.76102249 0.76102384 0.76104957 0.76104273
 0.76103922 0.7610267 ]
[0.5 0.  0. ]
-----------end of analyzing the loss ratio:73.9022626876831
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d72d1990>
---------------------------------
SparseEpoch: [13][1/398]	Time 0.606	Data 0.000	Loss 1.3034	
SparseEpoch: [13][101/398]	Time 0.625	Data 0.000	Loss 1.4002	
SparseEpoch: [13][201/398]	Time 0.624	Data 0.000	Loss 1.1013	
SparseEpoch: [13][301/398]	Time 0.622	Data 0.000	Loss 1.3437	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.23446653 0.23443953 0.23444994 0.2344345  0.23442654 0.23442297
 0.23440501 0.23439918 0.23438566 0.23438315 0.23438219 0.23436723
 0.23435894 0.23436383 0.23434613 0.23435005 0.23434046 0.23432882
 0.23431798 0.23431609]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.23445041 0.23444687 0.23443505 0.23443162 0.23442364 0.23441796
 0.23439552 0.23438535 0.23439649 0.23439256 0.23438184 0.23436903
 0.23436526 0.23438656 0.23441494 0.23440495 0.23439397 0.23439851
 0.23439054 0.23439224]
[0.5        0.13157895 0.        ]
-----------end of analyzing the loss ratio:73.88333559036255
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444dc318fd0>
---------------------------------
SparseEpoch: [13][1/398]	Time 0.606	Data 0.000	Loss 2.9712	
SparseEpoch: [13][101/398]	Time 0.622	Data 0.000	Loss 2.6658	
SparseEpoch: [13][201/398]	Time 0.623	Data 0.000	Loss 3.8772	
SparseEpoch: [13][301/398]	Time 0.622	Data 0.000	Loss 4.3377	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.6463	
Epoch(adapt):{0} Loss 2.7074	
Epoch(adapt):{0} Loss 1.9651	
Epoch(adapt):{0} Loss 2.4578	
------------------the total time cost:1212.0217969417572
>>>>>meta updating
Epoch: 0013 | TRAIN: 1.3765 0.2004 0.5267 | 0.6253 0.6253 0.2942 | 0.2136 33.0733 29.8085 0.1601 0.3772 0.5088 ||TEST: 1.4283 0.1949 0.5125 | 0.6874 0.6874 0.2693 | 0.2053 32.3474 29.3106 0.1720 0.3885 0.5168 | 114.9671
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.39283649 1.39292479 1.39303991 1.393067   1.39320281 1.39316016
 1.39332504 1.39334645 1.39344518 1.39348331 1.39360954 1.39355825
 1.39354443 1.39362241 1.39367305 1.3937795  1.39386733 1.39394951
 1.39402358 1.39416276]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.39353311 1.3935559  1.39353684 1.39354239 1.39352406 1.39352657
 1.39351278 1.39351296 1.39352604 1.3935083  1.39349424 1.39349769
 1.39348505 1.39348677 1.39348644 1.39349844 1.39350432 1.39348258
 1.39348036 1.39347733]
[0.  0.  0.5]
-----------end of analyzing the loss ratio:73.80924987792969
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d7324b80>
---------------------------------
SparseEpoch: [14][1/398]	Time 0.605	Data 0.000	Loss 2.3056	
SparseEpoch: [14][101/398]	Time 0.621	Data 0.000	Loss 2.8888	
SparseEpoch: [14][201/398]	Time 0.622	Data 0.000	Loss 3.9585	
SparseEpoch: [14][301/398]	Time 0.623	Data 0.000	Loss 2.0243	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.77134996 0.77125915 0.771223   0.77116744 0.77108893 0.77102688
 0.77099566 0.77089871 0.77082367 0.77069364 0.77065552 0.77061578
 0.7706174  0.77058124 0.77057281 0.77053874 0.7704636  0.77034442
 0.77022597 0.77022652]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.77090368 0.77089213 0.77089382 0.77088434 0.77083742 0.77079953
 0.77075621 0.77071023 0.77071389 0.77066413 0.77066638 0.77066256
 0.77065673 0.77063377 0.77060817 0.77061118 0.77059056 0.77060367
 0.77062451 0.77059593]
[0.44736842 0.         0.34210526]
-----------end of analyzing the loss ratio:73.87344622612
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc1535e0>
---------------------------------
SparseEpoch: [14][1/398]	Time 0.606	Data 0.000	Loss 2.6463	
SparseEpoch: [14][101/398]	Time 0.621	Data 0.000	Loss 2.1356	
SparseEpoch: [14][201/398]	Time 0.623	Data 0.000	Loss 2.1867	
SparseEpoch: [14][301/398]	Time 0.625	Data 0.000	Loss 1.6893	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.22979496 0.22978956 0.22978078 0.22977952 0.22978196 0.22978941
 0.2297892  0.22980099 0.22979633 0.22978278 0.22979324 0.22979798
 0.22978047 0.22978198 0.22978728 0.22978619 0.2298085  0.22979987
 0.22980491 0.22979191]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.22977306 0.22977459 0.22977217 0.22977331 0.22976317 0.22976528
 0.22976565 0.22977365 0.22978982 0.22978377 0.22978841 0.22979661
 0.22977858 0.22976512 0.22977811 0.22977474 0.22977304 0.22978536
 0.229787   0.2297878 ]
[0. 0. 0.]
-----------end of analyzing the loss ratio:73.94407677650452
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc266b90>
---------------------------------
SparseEpoch: [14][1/398]	Time 0.611	Data 0.000	Loss 2.3818	
SparseEpoch: [14][101/398]	Time 0.627	Data 0.000	Loss 2.2437	
SparseEpoch: [14][201/398]	Time 0.625	Data 0.000	Loss 2.2059	
SparseEpoch: [14][301/398]	Time 0.624	Data 0.000	Loss 2.7855	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 2.0620	
Epoch(adapt):{0} Loss 1.9102	
Epoch(adapt):{0} Loss 1.9316	
Epoch(adapt):{0} Loss 2.2616	
------------------the total time cost:1213.7100987434387
>>>>>meta updating
Epoch: 0014 | TRAIN: 1.3631 0.1909 0.5321 | 0.6330 0.6330 0.3105 | 0.2066 32.3462 28.8344 0.1697 0.3919 0.5249 ||TEST: 1.4081 0.1857 0.5197 | 0.6727 0.6727 0.2747 | 0.1980 31.6250 28.4573 0.1798 0.4007 0.5314 | 115.0338
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.37056682 1.37041345 1.37036631 1.37038934 1.37034873 1.37038147
 1.37038114 1.3704434  1.37037112 1.37036691 1.37032167 1.37019507
 1.37008909 1.37006605 1.36999551 1.36994962 1.36984715 1.36974202
 1.3696903  1.36958039]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.37030917 1.37029318 1.37027452 1.37030059 1.37031958 1.37031552
 1.37034287 1.37036011 1.37033203 1.37033291 1.37033335 1.37031437
 1.37031127 1.3702739  1.37027295 1.37027639 1.37029275 1.37027445
 1.37031596 1.37030625]
[0.         0.5        0.23684211]
-----------end of analyzing the loss ratio:73.73121571540833
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444dc250d60>
---------------------------------
SparseEpoch: [15][1/398]	Time 0.609	Data 0.000	Loss 1.9355	
SparseEpoch: [15][101/398]	Time 0.629	Data 0.000	Loss 2.0566	
SparseEpoch: [15][201/398]	Time 0.626	Data 0.000	Loss 2.5281	
SparseEpoch: [15][301/398]	Time 0.626	Data 0.000	Loss 1.7855	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.8621211  0.86212623 0.86213415 0.86213719 0.86211951 0.86221211
 0.86219314 0.8621443  0.86210099 0.86206842 0.86203668 0.86211328
 0.86215295 0.86215466 0.86218492 0.86221061 0.86221377 0.86219267
 0.86220351 0.86220388]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.86207627 0.86206046 0.8620636  0.86208215 0.86207008 0.86206635
 0.8620529  0.86206796 0.8620639  0.86208168 0.86207914 0.86205328
 0.86204713 0.86205648 0.86209099 0.86207569 0.86207407 0.86210355
 0.86210907 0.86211926]
[0.02631579 0.         0.13157895]
-----------end of analyzing the loss ratio:73.78605937957764
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc3cfcd0>
---------------------------------
SparseEpoch: [15][1/398]	Time 0.609	Data 0.000	Loss 1.1979	
SparseEpoch: [15][101/398]	Time 0.623	Data 0.000	Loss 1.3974	
SparseEpoch: [15][201/398]	Time 0.623	Data 0.000	Loss 0.9461	
SparseEpoch: [15][301/398]	Time 0.624	Data 0.000	Loss 0.8048	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.22296218 0.22294331 0.22291834 0.22289598 0.22287167 0.22285924
 0.22280557 0.22280535 0.22278354 0.22278103 0.22273616 0.22270759
 0.22269556 0.22267658 0.22266429 0.22263389 0.22261227 0.22259399
 0.22256096 0.22253062]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.22289035 0.2228577  0.22283545 0.22280982 0.22281668 0.22279205
 0.22279    0.22279318 0.22277588 0.2227747  0.22274867 0.22273128
 0.22271519 0.22272317 0.22271618 0.2226898  0.22267898 0.22266806
 0.22265612 0.22263658]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:73.88437390327454
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d7325e10>
---------------------------------
SparseEpoch: [15][1/398]	Time 0.628	Data 0.000	Loss 2.5223	
SparseEpoch: [15][101/398]	Time 0.625	Data 0.000	Loss 3.5186	
SparseEpoch: [15][201/398]	Time 0.624	Data 0.000	Loss 3.5073	
SparseEpoch: [15][301/398]	Time 0.626	Data 0.000	Loss 2.3417	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 2.9356	
Epoch(adapt):{0} Loss 2.3839	
Epoch(adapt):{0} Loss 2.4590	
Epoch(adapt):{0} Loss 1.9406	
------------------the total time cost:1214.9455287456512
>>>>>meta updating
Epoch: 0015 | TRAIN: 1.3538 0.2037 0.5365 | 0.6037 0.6037 0.2941 | 0.2071 32.4537 28.9211 0.1651 0.3882 0.5230 ||TEST: 1.3982 0.1986 0.5251 | 0.6609 0.6609 0.2659 | 0.1981 31.6776 28.5383 0.1767 0.3989 0.5303 | 115.1741
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.37817947 1.37820756 1.37824867 1.37825599 1.3783094  1.3783242
 1.37837524 1.37839249 1.37837199 1.37840645 1.37841668 1.37844852
 1.37845438 1.37847611 1.37853475 1.3785871  1.37859979 1.37857943
 1.37856847 1.37863474]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.37844511 1.37839346 1.3783867  1.37838867 1.37838911 1.37839594
 1.3783909  1.37837009 1.3783951  1.37840031 1.3784143  1.3784184
 1.37840356 1.37839766 1.37836465 1.37834396 1.37836695 1.37833945
 1.37834347 1.37835004]
[0.         0.         0.39473684]
-----------end of analyzing the loss ratio:73.8483898639679
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x744608138940>
---------------------------------
SparseEpoch: [16][1/398]	Time 0.606	Data 0.000	Loss 2.7953	
SparseEpoch: [16][101/398]	Time 0.627	Data 0.000	Loss 2.3521	
SparseEpoch: [16][201/398]	Time 0.624	Data 0.000	Loss 2.1064	
SparseEpoch: [16][301/398]	Time 0.625	Data 0.000	Loss 2.5202	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.03307608 1.03303896 1.03299868 1.03289141 1.03278602 1.03269426
 1.0326709  1.03261448 1.03258636 1.03251973 1.03242805 1.03230245
 1.03224227 1.03221431 1.03222129 1.03217525 1.03211553 1.03199196
 1.03189537 1.03184834]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.0325421  1.0325355  1.03252292 1.03252079 1.03251373 1.03250093
 1.03250718 1.03245344 1.03246587 1.0324821  1.03248788 1.03247854
 1.03243823 1.03245008 1.03243172 1.03243635 1.03240909 1.03239704
 1.03240688 1.03236712]
[0.5 0.  0.5]
-----------end of analyzing the loss ratio:73.92996168136597
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc324f70>
---------------------------------
SparseEpoch: [16][1/398]	Time 0.606	Data 0.000	Loss 2.4005	
SparseEpoch: [16][101/398]	Time 0.624	Data 0.000	Loss 3.6937	
SparseEpoch: [16][201/398]	Time 0.626	Data 0.000	Loss 3.2348	
SparseEpoch: [16][301/398]	Time 0.627	Data 0.000	Loss 2.2291	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.23736249 0.23735105 0.2373454  0.23732927 0.23728467 0.23728059
 0.23725281 0.23721914 0.23722394 0.23719461 0.23718191 0.23713879
 0.23713644 0.23712842 0.23709214 0.237081   0.23705662 0.23701447
 0.23701442 0.23702127]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.23723394 0.23722775 0.23721823 0.237216   0.2372021  0.23720658
 0.23719509 0.23718549 0.23719009 0.23718198 0.23718461 0.23717544
 0.23717805 0.23718203 0.23716644 0.23715141 0.23714252 0.23714462
 0.23714058 0.23712811]
[0.44736842 0.5        0.        ]
-----------end of analyzing the loss ratio:73.67247223854065
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc3cd4b0>
---------------------------------
SparseEpoch: [16][1/398]	Time 0.608	Data 0.000	Loss 3.4846	
SparseEpoch: [16][101/398]	Time 0.621	Data 0.000	Loss 3.6671	
SparseEpoch: [16][201/398]	Time 0.623	Data 0.000	Loss 3.1127	
SparseEpoch: [16][301/398]	Time 0.621	Data 0.000	Loss 3.9415	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 2.2753	
Epoch(adapt):{0} Loss 2.1068	
Epoch(adapt):{0} Loss 1.9487	
Epoch(adapt):{0} Loss 3.2049	
------------------the total time cost:1215.3492548465729
>>>>>meta updating
Epoch: 0016 | TRAIN: 1.3299 0.2214 0.5469 | 0.6197 0.6197 0.2762 | 0.2019 31.9533 28.3471 0.1699 0.3984 0.5337 ||TEST: 1.3758 0.2097 0.5340 | 0.6861 0.6861 0.2580 | 0.1922 31.0767 27.6655 0.1826 0.4133 0.5449 | 114.8276
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.27497506 1.27494849 1.27495399 1.27493142 1.27494791 1.27495394
 1.27483898 1.27480242 1.27470812 1.27474446 1.27472396 1.27464087
 1.27463009 1.27458671 1.27456985 1.27457442 1.2745638  1.27459804
 1.27456749 1.27456846]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.27474396 1.27475156 1.27474814 1.27475222 1.27474589 1.27477149
 1.27476835 1.27475876 1.27475352 1.27472179 1.27470897 1.27472001
 1.27471031 1.27469    1.27465537 1.27463894 1.27461889 1.27462093
 1.27462261 1.27465338]
[0.         0.34210526 0.34210526]
-----------end of analyzing the loss ratio:73.72659015655518
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc047af0>
---------------------------------
SparseEpoch: [17][1/398]	Time 0.605	Data 0.000	Loss 2.4604	
SparseEpoch: [17][101/398]	Time 0.626	Data 0.000	Loss 2.2315	
SparseEpoch: [17][201/398]	Time 0.625	Data 0.000	Loss 2.0335	
SparseEpoch: [17][301/398]	Time 0.625	Data 0.000	Loss 1.8882	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.95199268 0.95199885 0.95197806 0.95196632 0.95190097 0.95188692
 0.95189845 0.95187508 0.95179954 0.95183794 0.95180604 0.95184622
 0.95182717 0.95174778 0.95177538 0.95180295 0.95179424 0.95180319
 0.95180316 0.95186404]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.95184997 0.95186618 0.95186405 0.95186442 0.95186158 0.95184905
 0.95185969 0.95187232 0.95186911 0.95186427 0.95184679 0.95182286
 0.95182062 0.95181215 0.95180985 0.95180886 0.95181145 0.95183674
 0.95182934 0.95180956]
[0.18421053 0.         0.28947368]
-----------end of analyzing the loss ratio:73.84737777709961
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444dc343b80>
---------------------------------
SparseEpoch: [17][1/398]	Time 0.614	Data 0.000	Loss 1.5987	
SparseEpoch: [17][101/398]	Time 0.623	Data 0.000	Loss 1.8302	
SparseEpoch: [17][201/398]	Time 0.627	Data 0.000	Loss 1.5821	
SparseEpoch: [17][301/398]	Time 0.626	Data 0.000	Loss 1.5076	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.20155194 0.20155994 0.20157775 0.20151814 0.20152836 0.20153132
 0.20148753 0.20148365 0.201504   0.20152758 0.20153419 0.20150885
 0.20148341 0.20145181 0.2014312  0.20141461 0.20144836 0.20145934
 0.20146742 0.20147462]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.20153853 0.20150161 0.20149878 0.20152521 0.20150107 0.20149155
 0.20152485 0.20155216 0.20151763 0.20153143 0.20151626 0.20150597
 0.20149938 0.20151225 0.20146737 0.20146326 0.20147259 0.20147677
 0.20146444 0.20144179]
[0.28947368 0.5        0.        ]
-----------end of analyzing the loss ratio:73.74556636810303
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc536ec0>
---------------------------------
SparseEpoch: [17][1/398]	Time 0.606	Data 0.000	Loss 3.0516	
SparseEpoch: [17][101/398]	Time 0.620	Data 0.000	Loss 3.1687	
SparseEpoch: [17][201/398]	Time 0.619	Data 0.000	Loss 2.9650	
SparseEpoch: [17][301/398]	Time 0.619	Data 0.000	Loss 3.2205	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 2.0746	
Epoch(adapt):{0} Loss 2.0351	
Epoch(adapt):{0} Loss 2.3007	
Epoch(adapt):{0} Loss 1.6088	
------------------the total time cost:1214.2023384571075
>>>>>meta updating
Epoch: 0017 | TRAIN: 1.3104 0.2284 0.5539 | 0.5905 0.5905 0.2712 | 0.2005 31.7007 28.0925 0.1790 0.4062 0.5387 ||TEST: 1.3496 0.2218 0.5424 | 0.6612 0.6612 0.2562 | 0.1919 30.9488 27.6001 0.1915 0.4159 0.5451 | 114.9043
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.28049166 1.28049103 1.28050302 1.2805123  1.2805475  1.28055118
 1.28050361 1.28051872 1.28055032 1.2805276  1.28055751 1.28056171
 1.28057041 1.28051285 1.28054429 1.28051481 1.28057348 1.28054619
 1.28053734 1.28056306]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.2805744  1.2805666  1.2805499  1.28052874 1.2805591  1.28054216
 1.28053875 1.28050284 1.28051586 1.28052746 1.28053455 1.28054951
 1.28054691 1.28053516 1.28049627 1.2805194  1.28050978 1.28053056
 1.28052513 1.28050804]
[0.         0.         0.23684211]
-----------end of analyzing the loss ratio:73.9807345867157
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7446099fd000>
---------------------------------
SparseEpoch: [18][1/398]	Time 0.606	Data 0.000	Loss 1.9959	
SparseEpoch: [18][101/398]	Time 0.622	Data 0.000	Loss 1.4487	
SparseEpoch: [18][201/398]	Time 0.620	Data 0.000	Loss 2.2588	
SparseEpoch: [18][301/398]	Time 0.620	Data 0.000	Loss 1.8443	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.68283057 0.68286105 0.68288127 0.68283334 0.6828897  0.682873
 0.68293858 0.68295878 0.68299107 0.68298451 0.68304855 0.68308528
 0.68306279 0.68315817 0.68322653 0.68327987 0.68332683 0.683363
 0.68332944 0.68332525]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.68301092 0.6829877  0.68300578 0.68300357 0.68300022 0.68298991
 0.68298962 0.68300231 0.68301995 0.68302069 0.68302596 0.68303308
 0.6830449  0.68304665 0.68304095 0.68304715 0.68307254 0.68306391
 0.68305647 0.68306875]
[0. 0. 0.]
-----------end of analyzing the loss ratio:73.84577417373657
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc41dd50>
---------------------------------
SparseEpoch: [18][1/398]	Time 0.608	Data 0.000	Loss 0.5257	
SparseEpoch: [18][101/398]	Time 0.620	Data 0.000	Loss 1.3673	
SparseEpoch: [18][201/398]	Time 0.620	Data 0.000	Loss 0.7345	
SparseEpoch: [18][301/398]	Time 0.619	Data 0.000	Loss 0.7887	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.21856514 0.21855897 0.218521   0.21848693 0.21848726 0.21845797
 0.21844067 0.21844352 0.21842329 0.21836455 0.21835586 0.21835632
 0.21832943 0.21834236 0.21834558 0.21834947 0.21834111 0.21830682
 0.21828627 0.21825257]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.21846445 0.2184656  0.21844776 0.21845656 0.2184279  0.21842819
 0.21841357 0.21843286 0.21841536 0.21836537 0.21836177 0.21837555
 0.21834225 0.21834891 0.21834371 0.2183511  0.21836397 0.21836602
 0.21837281 0.21835236]
[0.5        0.13157895 0.        ]
-----------end of analyzing the loss ratio:73.79816627502441
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x744609690700>
---------------------------------
SparseEpoch: [18][1/398]	Time 0.605	Data 0.000	Loss 2.2390	
SparseEpoch: [18][101/398]	Time 0.628	Data 0.000	Loss 3.5197	
SparseEpoch: [18][201/398]	Time 0.627	Data 0.000	Loss 2.4551	
SparseEpoch: [18][301/398]	Time 0.627	Data 0.000	Loss 3.2980	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 3.3700	
Epoch(adapt):{0} Loss 1.9697	
Epoch(adapt):{0} Loss 2.0437	
Epoch(adapt):{0} Loss 2.9904	
------------------the total time cost:1212.6031274795532
>>>>>meta updating
Epoch: 0018 | TRAIN: 1.3128 0.2371 0.5565 | 0.5770 0.5770 0.2835 | 0.2038 32.0727 28.5788 0.1748 0.3976 0.5293 ||TEST: 1.3674 0.2248 0.5397 | 0.6384 0.6384 0.2624 | 0.1947 31.2813 28.0206 0.1866 0.4082 0.5372 | 115.2244
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.23790551 1.23790326 1.23782184 1.23785853 1.23791573 1.23793696
 1.23788757 1.23785309 1.23786795 1.23785739 1.23780754 1.23782713
 1.23784119 1.23784412 1.23790796 1.23788474 1.23784351 1.23786871
 1.23787113 1.23789079]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.23786353 1.2378653  1.23787371 1.23786979 1.23788233 1.2378741
 1.23786863 1.23785458 1.23785408 1.23786331 1.23785571 1.23785387
 1.23785456 1.23784451 1.23785706 1.23784935 1.2378495  1.2378527
 1.23783342 1.23784343]
[0.         0.02631579 0.44736842]
-----------end of analyzing the loss ratio:73.9507668018341
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444dc340160>
---------------------------------
SparseEpoch: [19][1/398]	Time 0.605	Data 0.000	Loss 2.4004	
SparseEpoch: [19][101/398]	Time 0.621	Data 0.000	Loss 2.9445	
SparseEpoch: [19][201/398]	Time 0.623	Data 0.000	Loss 2.6042	
SparseEpoch: [19][301/398]	Time 0.622	Data 0.000	Loss 2.4725	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.19298667 1.19277744 1.19267722 1.19255854 1.1924332  1.19231544
 1.19215696 1.19201602 1.19191248 1.19166946 1.1915417  1.19143021
 1.19128973 1.19109943 1.19100069 1.19083846 1.19080665 1.19067212
 1.19048162 1.19038057]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.19166498 1.19169092 1.19166253 1.19164749 1.19165852 1.19164394
 1.19165088 1.19163778 1.19164237 1.19162706 1.19159912 1.19158241
 1.19159034 1.19157177 1.19153556 1.19155875 1.19154417 1.19152173
 1.19151221 1.19150481]
[0.5 0.  0.5]
-----------end of analyzing the loss ratio:73.7413957118988
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x74460813bca0>
---------------------------------
SparseEpoch: [19][1/398]	Time 0.652	Data 0.000	Loss 2.1889	
SparseEpoch: [19][101/398]	Time 0.622	Data 0.000	Loss 2.0200	
SparseEpoch: [19][201/398]	Time 0.622	Data 0.000	Loss 1.9298	
SparseEpoch: [19][301/398]	Time 0.621	Data 0.000	Loss 1.8608	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.2136313  0.21362599 0.21361059 0.21358749 0.2135842  0.21358722
 0.21357728 0.21357685 0.21357764 0.21357663 0.21356018 0.2135435
 0.21354675 0.21354821 0.21355087 0.21355043 0.2135389  0.21351353
 0.21351597 0.21351433]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.21364418 0.21362948 0.21363915 0.21361361 0.21361896 0.21360483
 0.21359364 0.21359268 0.21357846 0.21357813 0.21354331 0.21353896
 0.21352707 0.21353371 0.21353286 0.21352218 0.21350955 0.21349497
 0.21350327 0.21347346]
[0.39473684 0.5        0.        ]
-----------end of analyzing the loss ratio:73.74507212638855
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc534280>
---------------------------------
SparseEpoch: [19][1/398]	Time 0.606	Data 0.000	Loss 3.7664	
SparseEpoch: [19][101/398]	Time 0.618	Data 0.000	Loss 4.1844	
SparseEpoch: [19][201/398]	Time 0.619	Data 0.000	Loss 2.5997	
SparseEpoch: [19][301/398]	Time 0.620	Data 0.000	Loss 3.1558	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.9856	
Epoch(adapt):{0} Loss 1.3973	
Epoch(adapt):{0} Loss 1.7470	
Epoch(adapt):{0} Loss 2.2499	
------------------the total time cost:1211.9107315540314
>>>>>meta updating
Epoch: 0019 | TRAIN: 1.2768 0.2408 0.5636 | 0.5939 0.5939 0.2775 | 0.1966 31.2441 27.3539 0.1868 0.4165 0.5496 ||TEST: 1.3315 0.2302 0.5488 | 0.6470 0.6470 0.2512 | 0.1866 30.4068 26.8446 0.1969 0.4275 0.5586 | 115.1964
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.35742863 1.35744658 1.35745676 1.35753201 1.35752914 1.35757092
 1.35760307 1.35761932 1.35758685 1.35762802 1.35759974 1.3576079
 1.35762978 1.35765785 1.35766876 1.35771506 1.35773826 1.35776054
 1.3577703  1.35779264]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.35762936 1.3576381  1.3576202  1.35762241 1.35759606 1.35759351
 1.35759559 1.35760208 1.35759411 1.35759904 1.35758694 1.35758758
 1.35759761 1.35759679 1.35758531 1.35758487 1.3576028  1.35760361
 1.35760458 1.3576025 ]
[0.         0.         0.28947368]
-----------end of analyzing the loss ratio:73.83878445625305
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc5fd480>
---------------------------------
SparseEpoch: [20][1/398]	Time 0.604	Data 0.000	Loss 1.8486	
SparseEpoch: [20][101/398]	Time 0.623	Data 0.000	Loss 2.2234	
SparseEpoch: [20][201/398]	Time 0.626	Data 0.000	Loss 2.2340	
SparseEpoch: [20][301/398]	Time 0.625	Data 0.000	Loss 1.6866	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.69237092 0.69237015 0.69241876 0.69239964 0.69243169 0.69248285
 0.69253503 0.69258116 0.69254736 0.69252004 0.69252547 0.69255231
 0.69260317 0.6925936  0.69260425 0.69260211 0.69255576 0.69258134
 0.69257965 0.69258581]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.69244424 0.69245538 0.69245447 0.69245933 0.69246038 0.69245152
 0.69246829 0.69247088 0.69247927 0.69249775 0.69249214 0.69251367
 0.69250431 0.69250738 0.69251271 0.69251262 0.69252007 0.69251418
 0.69251167 0.69252229]
[0. 0. 0.]
-----------end of analyzing the loss ratio:73.88517308235168
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc35c370>
---------------------------------
SparseEpoch: [20][1/398]	Time 0.605	Data 0.000	Loss 0.7601	
SparseEpoch: [20][101/398]	Time 0.623	Data 0.000	Loss 0.8763	
SparseEpoch: [20][201/398]	Time 0.622	Data 0.000	Loss 1.1997	
SparseEpoch: [20][301/398]	Time 0.621	Data 0.000	Loss 0.6453	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.21199098 0.21200269 0.21200257 0.21199244 0.21193876 0.2119123
 0.21187665 0.21184214 0.21180298 0.21176442 0.21177477 0.21175852
 0.21174416 0.21171235 0.21171661 0.21171063 0.21169679 0.21168378
 0.21166995 0.21164154]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.21176021 0.21174908 0.21174299 0.21174895 0.21174077 0.21175013
 0.21175999 0.21175854 0.21176157 0.21176078 0.21176501 0.21176627
 0.21178259 0.21178173 0.21177769 0.21176188 0.21176178 0.21177322
 0.21177658 0.21178832]
[0.5 0.  0. ]
-----------end of analyzing the loss ratio:73.90564799308777
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc509270>
---------------------------------
SparseEpoch: [20][1/398]	Time 0.608	Data 0.000	Loss 2.8309	
SparseEpoch: [20][101/398]	Time 0.626	Data 0.000	Loss 3.0075	
SparseEpoch: [20][201/398]	Time 0.625	Data 0.000	Loss 3.0948	
SparseEpoch: [20][301/398]	Time 0.623	Data 0.000	Loss 2.1196	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.9893	
Epoch(adapt):{0} Loss 2.4002	
Epoch(adapt):{0} Loss 1.8399	
Epoch(adapt):{0} Loss 3.3920	
------------------the total time cost:1213.1093137264252
>>>>>meta updating
Epoch: 0020 | TRAIN: 1.2671 0.2559 0.5719 | 0.5835 0.5835 0.2896 | 0.1941 31.0102 27.2102 0.1901 0.4201 0.5533 ||TEST: 1.3196 0.2416 0.5559 | 0.6211 0.6211 0.2587 | 0.1866 30.4151 26.9098 0.1979 0.4264 0.5569 | 115.3790
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.22035689 1.22035789 1.22038814 1.22032096 1.22032489 1.22028756
 1.22034068 1.22032682 1.22032735 1.22028249 1.22026333 1.22031825
 1.22036761 1.22040672 1.22043888 1.22037723 1.220407   1.22036842
 1.22036673 1.22035496]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.22031664 1.22030853 1.22032126 1.22031559 1.22031672 1.22030714
 1.22030472 1.22030013 1.22030243 1.22030063 1.22030303 1.22029955
 1.22030182 1.2203146  1.22030649 1.22032347 1.2203215  1.22032733
 1.22032715 1.22032224]
[0.         0.02631579 0.07894737]
-----------end of analyzing the loss ratio:74.0265724658966
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x744608155060>
---------------------------------
SparseEpoch: [21][1/398]	Time 0.607	Data 0.000	Loss 2.6780	
SparseEpoch: [21][101/398]	Time 0.626	Data 0.000	Loss 1.3461	
SparseEpoch: [21][201/398]	Time 0.626	Data 0.000	Loss 1.5031	
SparseEpoch: [21][301/398]	Time 0.625	Data 0.000	Loss 1.9912	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.78178803 1.78137252 1.78106394 1.78071823 1.7803975  1.78002291
 1.77959245 1.77932162 1.77889363 1.77844356 1.77809767 1.77769649
 1.77731354 1.77692807 1.77659814 1.77624191 1.77584687 1.77542986
 1.77503141 1.77466872]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.77861142 1.7785727  1.77853807 1.77849176 1.77844874 1.7784047
 1.77837968 1.77833406 1.7783308  1.77831362 1.77830943 1.77826859
 1.77823031 1.77819445 1.77814718 1.77812208 1.77809587 1.77807178
 1.77802171 1.77793601]
[0.5 0.  0.5]
-----------end of analyzing the loss ratio:73.9898133277893
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7446095cca60>
---------------------------------
SparseEpoch: [21][1/398]	Time 0.605	Data 0.000	Loss 2.5293	
SparseEpoch: [21][101/398]	Time 0.626	Data 0.000	Loss 3.0945	
SparseEpoch: [21][201/398]	Time 0.626	Data 0.000	Loss 2.7331	
SparseEpoch: [21][301/398]	Time 0.626	Data 0.000	Loss 2.3947	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.23360967 0.23360901 0.23359981 0.23359888 0.23359277 0.23359308
 0.23358414 0.23358685 0.23356434 0.23357445 0.23358427 0.23357328
 0.23355874 0.23354955 0.2335358  0.23354371 0.23352561 0.23352579
 0.23351427 0.23351223]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.23360322 0.23359054 0.23358299 0.2335879  0.23357423 0.2335932
 0.23359637 0.2335817  0.23359022 0.23357638 0.23356449 0.2335752
 0.23356304 0.23354708 0.23353    0.23351399 0.23351095 0.23351343
 0.2334966  0.23349406]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:74.0409836769104
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d73256c0>
---------------------------------
SparseEpoch: [21][1/398]	Time 0.607	Data 0.000	Loss 3.3095	
SparseEpoch: [21][101/398]	Time 0.626	Data 0.000	Loss 2.6326	
SparseEpoch: [21][201/398]	Time 0.626	Data 0.000	Loss 2.4150	
SparseEpoch: [21][301/398]	Time 0.625	Data 0.000	Loss 3.3784	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.8260	
Epoch(adapt):{0} Loss 1.6259	
Epoch(adapt):{0} Loss 1.7129	
Epoch(adapt):{0} Loss 3.4247	
------------------the total time cost:1215.3295023441315
>>>>>meta updating
Epoch: 0021 | TRAIN: 1.2414 0.2705 0.5815 | 0.5926 0.5926 0.2686 | 0.1949 31.3473 27.6987 0.1716 0.4077 0.5469 ||TEST: 1.2991 0.2519 0.5619 | 0.6586 0.6586 0.2506 | 0.1865 30.6189 27.2987 0.1829 0.4169 0.5518 | 115.2676
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.19184758 1.19181886 1.19191004 1.19179378 1.19180031 1.19181288
 1.19188502 1.19179816 1.19190388 1.19209356 1.19222576 1.19218976
 1.1922757  1.19244788 1.19261166 1.19265446 1.19275845 1.19300575
 1.19323516 1.19331265]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.19218914 1.19219698 1.19220998 1.19218476 1.19216747 1.19216492
 1.19216943 1.19216383 1.19215255 1.19214181 1.1921277  1.19211843
 1.19210705 1.19209189 1.19208592 1.19205409 1.19205376 1.19202074
 1.19202951 1.19205015]
[0.         0.         0.39473684]
-----------end of analyzing the loss ratio:73.99280595779419
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc473250>
---------------------------------
SparseEpoch: [22][1/398]	Time 0.609	Data 0.000	Loss 2.8978	
SparseEpoch: [22][101/398]	Time 0.624	Data 0.000	Loss 2.1710	
SparseEpoch: [22][201/398]	Time 0.625	Data 0.000	Loss 2.2882	
SparseEpoch: [22][301/398]	Time 0.625	Data 0.000	Loss 2.3782	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.62222246 0.62214396 0.62225324 0.62234409 0.62240036 0.62241553
 0.62237138 0.62239011 0.62225655 0.62222661 0.62231268 0.62237343
 0.622392   0.62239495 0.62240368 0.62246005 0.62246019 0.62246945
 0.62247361 0.62251534]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.62227461 0.6222721  0.62227679 0.62226432 0.62226804 0.62226663
 0.62226642 0.62226672 0.62227042 0.62226438 0.62224708 0.62223843
 0.6222359  0.62223066 0.62223756 0.62222824 0.6222258  0.62221666
 0.62221963 0.62222476]
[0.         0.         0.39473684]
-----------end of analyzing the loss ratio:74.19156169891357
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d71f2710>
---------------------------------
SparseEpoch: [22][1/398]	Time 0.613	Data 0.000	Loss 1.8179	
SparseEpoch: [22][101/398]	Time 0.628	Data 0.000	Loss 1.2225	
SparseEpoch: [22][201/398]	Time 0.628	Data 0.000	Loss 1.1459	
SparseEpoch: [22][301/398]	Time 0.625	Data 0.000	Loss 1.1223	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.2294377  0.22940927 0.22938861 0.22937378 0.22936417 0.22934781
 0.22931514 0.22929605 0.22930524 0.22925291 0.2292221  0.22919926
 0.22917017 0.22915487 0.22913839 0.2291171  0.2290895  0.22907079
 0.22903912 0.22898863]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.22930881 0.22930666 0.22930601 0.22929278 0.22927339 0.22927284
 0.22927582 0.22927517 0.22925072 0.22921975 0.22922763 0.22922046
 0.22921789 0.22921826 0.22920557 0.22920349 0.22920683 0.2292125
 0.22918341 0.22916033]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:73.82740354537964
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc537940>
---------------------------------
SparseEpoch: [22][1/398]	Time 0.609	Data 0.000	Loss 2.6398	
SparseEpoch: [22][101/398]	Time 0.626	Data 0.000	Loss 3.2326	
SparseEpoch: [22][201/398]	Time 0.627	Data 0.000	Loss 3.0050	
SparseEpoch: [22][301/398]	Time 0.625	Data 0.000	Loss 3.6795	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 2.3903	
Epoch(adapt):{0} Loss 2.1514	
Epoch(adapt):{0} Loss 2.0297	
Epoch(adapt):{0} Loss 1.9117	
------------------the total time cost:1214.8477437496185
>>>>>meta updating
Epoch: 0022 | TRAIN: 1.2465 0.2677 0.5837 | 0.5780 0.5780 0.2771 | 0.1913 30.9280 27.1728 0.1790 0.4183 0.5555 ||TEST: 1.3174 0.2453 0.5571 | 0.6368 0.6368 0.2512 | 0.1871 30.5661 27.1054 0.1892 0.4217 0.5543 | 115.2799
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.33925374 1.33928157 1.33919986 1.33921309 1.3392753  1.33926868
 1.33930092 1.33934244 1.33932686 1.33924429 1.33915594 1.33911375
 1.33913572 1.33914169 1.33910861 1.33910362 1.33911537 1.33913829
 1.33915538 1.3390841 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.33926883 1.33925692 1.33925372 1.33924983 1.33924767 1.33923366
 1.3392064  1.33919493 1.33920105 1.33920289 1.33921809 1.33923094
 1.33920138 1.33920676 1.33919448 1.33920009 1.33920565 1.33920006
 1.33921682 1.33920833]
[0.         0.5        0.23684211]
-----------end of analyzing the loss ratio:73.83325672149658
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc5fd900>
---------------------------------
SparseEpoch: [23][1/398]	Time 0.606	Data 0.000	Loss 1.6993	
SparseEpoch: [23][101/398]	Time 0.625	Data 0.000	Loss 2.3508	
SparseEpoch: [23][201/398]	Time 0.624	Data 0.000	Loss 2.0292	
SparseEpoch: [23][301/398]	Time 0.624	Data 0.000	Loss 2.1530	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.80531288 0.80607615 0.8068468  0.80757212 0.80809105 0.80861236
 0.80941836 0.81034821 0.81115112 0.81187207 0.81264746 0.81349761
 0.81438766 0.81515084 0.81599966 0.81677531 0.81761263 0.81814969
 0.81900756 0.81965619]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.81175735 0.81183208 0.81187012 0.81180025 0.81189398 0.8119745
 0.81199923 0.81206654 0.81210833 0.81217222 0.81227619 0.81228022
 0.81232565 0.81237732 0.81250043 0.81252772 0.81256502 0.81264603
 0.8127126  0.8127108 ]
[0. 0. 0.]
-----------end of analyzing the loss ratio:73.9332218170166
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x74460925cb80>
---------------------------------
SparseEpoch: [23][1/398]	Time 0.605	Data 0.000	Loss 0.6858	
SparseEpoch: [23][101/398]	Time 0.624	Data 0.000	Loss 0.4155	
SparseEpoch: [23][201/398]	Time 0.623	Data 0.000	Loss 0.5970	
SparseEpoch: [23][301/398]	Time 0.622	Data 0.000	Loss 0.3512	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.23657599 0.23659183 0.23659833 0.23658405 0.236568   0.23656048
 0.23654451 0.23649889 0.23650002 0.23648337 0.23647892 0.23649102
 0.23648661 0.23648115 0.23648056 0.23647377 0.23647051 0.23645201
 0.23643736 0.23641279]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.23654639 0.23654881 0.23655472 0.23653612 0.23653505 0.23651738
 0.23651863 0.23652079 0.23653905 0.23649369 0.23645891 0.23645096
 0.23644797 0.23644741 0.23648193 0.23649084 0.23648664 0.23646387
 0.23645427 0.23645194]
[0.5        0.18421053 0.        ]
-----------end of analyzing the loss ratio:74.01721715927124
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc551de0>
---------------------------------
SparseEpoch: [23][1/398]	Time 0.606	Data 0.000	Loss 2.7771	
SparseEpoch: [23][101/398]	Time 0.631	Data 0.000	Loss 1.9786	
SparseEpoch: [23][201/398]	Time 0.629	Data 0.000	Loss 2.9505	
SparseEpoch: [23][301/398]	Time 0.627	Data 0.000	Loss 2.9080	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.9704	
Epoch(adapt):{0} Loss 2.3696	
Epoch(adapt):{0} Loss 2.6776	
Epoch(adapt):{0} Loss 2.2902	
------------------the total time cost:1216.7725338935852
>>>>>meta updating
Epoch: 0023 | TRAIN: 1.2400 0.2568 0.5866 | 0.5585 0.5585 0.2620 | 0.1934 31.0095 27.1971 0.1847 0.4216 0.5551 ||TEST: 1.3053 0.2363 0.5622 | 0.6219 0.6219 0.2468 | 0.1855 30.3289 26.6963 0.1955 0.4304 0.5608 | 115.2705
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.1533533  1.15337661 1.15338968 1.15334329 1.15331765 1.15326934
 1.15331793 1.15334958 1.15335908 1.15330181 1.15325959 1.15329873
 1.15335647 1.15343667 1.15346147 1.15340818 1.15346495 1.15347831
 1.15347474 1.15354725]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.15325626 1.15323498 1.15325409 1.1532657  1.15325341 1.15324126
 1.15323278 1.15324312 1.15328356 1.15329418 1.15330725 1.15330215
 1.15329654 1.15327039 1.15326578 1.15327483 1.15326311 1.15324268
 1.1532485  1.15322189]
[0.         0.02631579 0.5       ]
-----------end of analyzing the loss ratio:73.94588017463684
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc4706d0>
---------------------------------
SparseEpoch: [24][1/398]	Time 0.606	Data 0.000	Loss 2.2768	
SparseEpoch: [24][101/398]	Time 0.623	Data 0.000	Loss 2.3803	
SparseEpoch: [24][201/398]	Time 0.621	Data 0.000	Loss 1.8669	
SparseEpoch: [24][301/398]	Time 0.622	Data 0.000	Loss 2.3904	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.8625955  0.86272091 0.86284036 0.86295421 0.862986   0.86309108
 0.8632616  0.86327758 0.86342012 0.86353672 0.86361371 0.86369695
 0.86369334 0.86379647 0.86382589 0.86391084 0.86395282 0.86404939
 0.86413859 0.86420835]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.86358813 0.86359028 0.86359683 0.8635832  0.86356817 0.86356382
 0.86354756 0.86355899 0.86355168 0.86355987 0.86355017 0.86355369
 0.8635484  0.86356698 0.86357017 0.86358732 0.86358966 0.86357344
 0.86357324 0.86356931]
[0. 0. 0.]
-----------end of analyzing the loss ratio:73.82197785377502
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444dc2a1750>
---------------------------------
SparseEpoch: [24][1/398]	Time 0.605	Data 0.000	Loss 0.4622	
SparseEpoch: [24][101/398]	Time 0.621	Data 0.000	Loss 0.3331	
SparseEpoch: [24][201/398]	Time 0.620	Data 0.000	Loss 0.6142	
SparseEpoch: [24][301/398]	Time 0.621	Data 0.000	Loss 0.4234	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.22753883 0.22752623 0.22752981 0.22752656 0.22749647 0.22749418
 0.22747694 0.22744789 0.22746533 0.22743787 0.22739313 0.22737929
 0.2274008  0.22737954 0.22736463 0.22736791 0.22740067 0.22739403
 0.22735775 0.22734771]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.22741214 0.22741438 0.22743235 0.22744222 0.22746044 0.22745519
 0.22744626 0.22745056 0.22743445 0.2274138  0.22740378 0.22738812
 0.227376   0.22738105 0.22739061 0.22739419 0.22737215 0.22738978
 0.22738485 0.22738736]
[0.5        0.34210526 0.        ]
-----------end of analyzing the loss ratio:73.83035612106323
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d7373700>
---------------------------------
SparseEpoch: [24][1/398]	Time 0.604	Data 0.000	Loss 2.6311	
SparseEpoch: [24][101/398]	Time 0.625	Data 0.000	Loss 4.0866	
SparseEpoch: [24][201/398]	Time 0.626	Data 0.000	Loss 2.0839	
SparseEpoch: [24][301/398]	Time 0.627	Data 0.000	Loss 2.9547	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.8990	
Epoch(adapt):{0} Loss 1.6402	
Epoch(adapt):{0} Loss 2.0250	
Epoch(adapt):{0} Loss 1.6761	
------------------the total time cost:1212.9287390708923
>>>>>meta updating
Epoch: 0024 | TRAIN: 1.2293 0.2624 0.5901 | 0.5492 0.5492 0.2629 | 0.1919 30.9633 27.1811 0.1801 0.4186 0.5549 ||TEST: 1.3038 0.2431 0.5644 | 0.6169 0.6169 0.2477 | 0.1856 30.4183 26.9109 0.1906 0.4248 0.5577 | 115.3063
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.25094039 1.25092967 1.25096781 1.25097349 1.25095725 1.25086508
 1.25089083 1.25090641 1.25090184 1.25084845 1.2508658  1.25086717
 1.25088231 1.25086135 1.25082358 1.25079424 1.25073884 1.25066928
 1.25067734 1.25067527]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.25086817 1.25084128 1.25085181 1.25086502 1.25086403 1.25087632
 1.25090513 1.25089502 1.25083549 1.25084649 1.25088601 1.25089852
 1.25089038 1.25087872 1.25087186 1.25086216 1.25085158 1.25084305
 1.25084988 1.25086601]
[0.         0.39473684 0.        ]
-----------end of analyzing the loss ratio:74.12277626991272
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc50ae30>
---------------------------------
SparseEpoch: [25][1/398]	Time 0.605	Data 0.000	Loss 1.4154	
SparseEpoch: [25][101/398]	Time 0.626	Data 0.000	Loss 2.1758	
SparseEpoch: [25][201/398]	Time 0.628	Data 0.000	Loss 1.2994	
SparseEpoch: [25][301/398]	Time 0.627	Data 0.000	Loss 2.7274	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.41067867 1.41071883 1.41077255 1.41072423 1.41079941 1.41075032
 1.41077389 1.41084042 1.41074306 1.4107955  1.41080426 1.41084739
 1.41076367 1.41075748 1.41078281 1.41074053 1.4107096  1.41065209
 1.41071106 1.41069388]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.41060765 1.41060232 1.41063251 1.41068377 1.41064311 1.41065582
 1.41071961 1.41080612 1.4107673  1.41077688 1.41076312 1.41072479
 1.41074885 1.41079211 1.41081401 1.4108839  1.41088226 1.41086271
 1.41087203 1.41086557]
[0.39473684 0.         0.        ]
-----------end of analyzing the loss ratio:74.04088068008423
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444dc319090>
---------------------------------
SparseEpoch: [25][1/398]	Time 0.608	Data 0.000	Loss 1.1373	
SparseEpoch: [25][101/398]	Time 0.625	Data 0.000	Loss 1.2579	
SparseEpoch: [25][201/398]	Time 0.624	Data 0.000	Loss 1.0738	
SparseEpoch: [25][301/398]	Time 0.624	Data 0.000	Loss 1.0112	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.16556086 0.16556689 0.16555609 0.16555886 0.16556076 0.16555929
 0.16553957 0.16551979 0.16550903 0.16552594 0.16553453 0.16554022
 0.16553075 0.16553348 0.16553141 0.16555713 0.16556295 0.16556006
 0.16555128 0.1655324 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.1655342  0.16552666 0.16552246 0.16552266 0.16552688 0.16553401
 0.16552781 0.16553179 0.16553083 0.16553661 0.16552958 0.16553457
 0.1655468  0.16554773 0.16554925 0.16554648 0.16554435 0.16555128
 0.16555966 0.16555366]
[0. 0. 0.]
-----------end of analyzing the loss ratio:73.85737752914429
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x744609944100>
---------------------------------
SparseEpoch: [25][1/398]	Time 0.607	Data 0.000	Loss 1.9023	
SparseEpoch: [25][101/398]	Time 0.621	Data 0.000	Loss 2.1607	
SparseEpoch: [25][201/398]	Time 0.620	Data 0.000	Loss 1.5397	
SparseEpoch: [25][301/398]	Time 0.621	Data 0.000	Loss 2.0784	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.6901	
Epoch(adapt):{0} Loss 1.8373	
Epoch(adapt):{0} Loss 1.9794	
Epoch(adapt):{0} Loss 2.4149	
------------------the total time cost:1215.9624025821686
>>>>>meta updating
Epoch: 0025 | TRAIN: 1.1632 0.2982 0.6076 | 0.5355 0.5355 0.2513 | 0.1892 30.6005 26.7265 0.1900 0.4263 0.5613 ||TEST: 1.2493 0.2748 0.5792 | 0.6058 0.6058 0.2440 | 0.1832 30.1582 26.6911 0.1963 0.4285 0.5608 | 115.4956
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.25522184 1.255211   1.2551016  1.25505964 1.25509612 1.25499706
 1.25506235 1.25510685 1.255045   1.25500838 1.25502633 1.25502291
 1.25496553 1.25505012 1.25502406 1.25502347 1.25504696 1.25507218
 1.25502491 1.25503436]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.25498108 1.25500703 1.25501482 1.25503237 1.25501384 1.2550136
 1.25499665 1.25499898 1.25497925 1.2550153  1.2550109  1.25500666
 1.25499749 1.25500602 1.2550172  1.2550117  1.25502973 1.25501918
 1.25501252 1.25502399]
[0.         0.13157895 0.        ]
-----------end of analyzing the loss ratio:74.00650978088379
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc56c8b0>
---------------------------------
SparseEpoch: [26][1/398]	Time 0.604	Data 0.000	Loss 1.2434	
SparseEpoch: [26][101/398]	Time 0.624	Data 0.000	Loss 1.4402	
SparseEpoch: [26][201/398]	Time 0.626	Data 0.000	Loss 1.2170	
SparseEpoch: [26][301/398]	Time 0.626	Data 0.000	Loss 1.1647	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.1750513  1.17505937 1.17505105 1.17509047 1.17512137 1.17512926
 1.17521392 1.17523683 1.17522243 1.17529717 1.17531075 1.17534938
 1.17536158 1.17539337 1.17539873 1.17542129 1.17542809 1.175456
 1.17545459 1.17553264]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.17525076 1.17527951 1.17530124 1.17529014 1.17527859 1.17525275
 1.17526938 1.17528674 1.17531335 1.1753151  1.17529961 1.17530122
 1.17528449 1.17528664 1.17529456 1.17529051 1.17531649 1.1753366
 1.17533495 1.17532544]
[0. 0. 0.]
-----------end of analyzing the loss ratio:74.10320544242859
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7446096469b0>
---------------------------------
SparseEpoch: [26][1/398]	Time 0.635	Data 0.000	Loss 0.8723	
SparseEpoch: [26][101/398]	Time 0.625	Data 0.000	Loss 1.1160	
SparseEpoch: [26][201/398]	Time 0.624	Data 0.000	Loss 0.5473	
SparseEpoch: [26][301/398]	Time 0.623	Data 0.000	Loss 1.3871	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.24708752 0.24704935 0.24702801 0.24701208 0.24697171 0.24697008
 0.24697862 0.24696373 0.24693007 0.24691952 0.24690991 0.24686383
 0.24685064 0.24685103 0.24682856 0.24681853 0.24677606 0.24674883
 0.24672678 0.24672289]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.24696844 0.24695572 0.24695205 0.24693443 0.24692008 0.24692027
 0.24690685 0.24690779 0.24690614 0.2469095  0.24691358 0.24691784
 0.24689975 0.2469092  0.24689304 0.24689394 0.24689636 0.24688997
 0.24688892 0.24687653]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:73.82278323173523
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x744609830580>
---------------------------------
SparseEpoch: [26][1/398]	Time 0.608	Data 0.000	Loss 3.2822	
SparseEpoch: [26][101/398]	Time 0.620	Data 0.000	Loss 3.1012	
SparseEpoch: [26][201/398]	Time 0.620	Data 0.000	Loss 3.2266	
SparseEpoch: [26][301/398]	Time 0.621	Data 0.000	Loss 3.0639	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 2.1330	
Epoch(adapt):{0} Loss 1.8322	
Epoch(adapt):{0} Loss 1.7578	
Epoch(adapt):{0} Loss 1.3787	
------------------the total time cost:1214.4058375358582
>>>>>meta updating
Epoch: 0026 | TRAIN: 1.1786 0.2939 0.6091 | 0.5365 0.5365 0.2640 | 0.1899 30.7038 26.8826 0.1879 0.4241 0.5589 ||TEST: 1.2562 0.2654 0.5812 | 0.6028 0.6028 0.2473 | 0.1848 30.3239 26.8414 0.1937 0.4264 0.5582 | 115.3918
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.14373326 1.1437461  1.14367787 1.14362627 1.14361091 1.14360391
 1.14355734 1.14360328 1.14359241 1.14358937 1.14348883 1.14354695
 1.14350336 1.14344066 1.14345996 1.14346131 1.14351297 1.14346079
 1.14354535 1.14352798]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.14367146 1.14363876 1.14362933 1.14360815 1.14359449 1.14355927
 1.14355686 1.143547   1.1435636  1.14358538 1.14357183 1.14356427
 1.14354618 1.14353582 1.14353549 1.14351727 1.14349982 1.14348349
 1.14348208 1.14345706]
[0.         0.18421053 0.5       ]
-----------end of analyzing the loss ratio:73.94769263267517
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444dc2a3790>
---------------------------------
SparseEpoch: [27][1/398]	Time 0.605	Data 0.000	Loss 2.0466	
SparseEpoch: [27][101/398]	Time 0.624	Data 0.000	Loss 2.6146	
SparseEpoch: [27][201/398]	Time 0.625	Data 0.000	Loss 2.3990	
SparseEpoch: [27][301/398]	Time 0.623	Data 0.000	Loss 2.2562	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.11096998 1.11088142 1.11077026 1.11074584 1.11070182 1.11062877
 1.11050115 1.11039903 1.11031211 1.11020332 1.11012753 1.10999345
 1.10988597 1.10975702 1.10973307 1.10969746 1.10955473 1.10948871
 1.10939677 1.10926281]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.11007516 1.11009698 1.11009274 1.11008692 1.11011802 1.11013094
 1.11012379 1.11014341 1.11015236 1.11015745 1.11014864 1.11016037
 1.1101642  1.11018517 1.11021327 1.11022606 1.11022567 1.11022713
 1.11025057 1.11025323]
[0.5 0.  0. ]
-----------end of analyzing the loss ratio:74.09333324432373
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc473430>
---------------------------------
SparseEpoch: [27][1/398]	Time 0.616	Data 0.000	Loss 1.3122	
SparseEpoch: [27][101/398]	Time 0.627	Data 0.000	Loss 1.3326	
SparseEpoch: [27][201/398]	Time 0.624	Data 0.000	Loss 1.1594	
SparseEpoch: [27][301/398]	Time 0.626	Data 0.000	Loss 0.9781	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.18335472 0.18335063 0.18333033 0.18333778 0.1833271  0.18331844
 0.18333263 0.18333328 0.18332989 0.18328992 0.18326612 0.18325592
 0.18324992 0.18323256 0.18322177 0.18321506 0.18321841 0.18318294
 0.1831771  0.18317763]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.18329204 0.1832837  0.18329931 0.18330364 0.18330195 0.18330143
 0.18329499 0.18328995 0.18328915 0.18328141 0.18328934 0.18328404
 0.18329073 0.18329531 0.18328562 0.18328282 0.1832882  0.1832799
 0.18327252 0.18328477]
[0.44736842 0.44736842 0.        ]
-----------end of analyzing the loss ratio:73.86971950531006
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc472290>
---------------------------------
SparseEpoch: [27][1/398]	Time 0.607	Data 0.000	Loss 2.9255	
SparseEpoch: [27][101/398]	Time 0.624	Data 0.000	Loss 2.3856	
SparseEpoch: [27][201/398]	Time 0.625	Data 0.000	Loss 2.8121	
SparseEpoch: [27][301/398]	Time 0.623	Data 0.000	Loss 2.6391	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.4967	
Epoch(adapt):{0} Loss 1.6426	
Epoch(adapt):{0} Loss 1.8649	
Epoch(adapt):{0} Loss 1.6325	
------------------the total time cost:1215.0062782764435
>>>>>meta updating
Epoch: 0027 | TRAIN: 1.1560 0.2922 0.6127 | 0.5704 0.5704 0.2497 | 0.1899 30.7076 26.9920 0.1887 0.4228 0.5567 ||TEST: 1.2468 0.2651 0.5813 | 0.6505 0.6505 0.2409 | 0.1823 30.0667 26.6318 0.1980 0.4302 0.5624 | 115.2443
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.05035864 1.05028703 1.05031355 1.0502226  1.05026898 1.05020205
 1.05021755 1.05019221 1.05018544 1.05018982 1.05015434 1.05009079
 1.05008066 1.05005112 1.04995331 1.05000585 1.0500308  1.05003369
 1.05003697 1.05005371]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.05023205 1.05021478 1.05021247 1.05020869 1.05021417 1.05022309
 1.05023237 1.05025066 1.05024974 1.05023665 1.05022125 1.05022982
 1.05019614 1.05019786 1.05018615 1.05017152 1.05015604 1.0501571
 1.05014712 1.05014268]
[0.         0.23684211 0.5       ]
-----------end of analyzing the loss ratio:74.357595205307
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc2f6080>
---------------------------------
SparseEpoch: [28][1/398]	Time 0.650	Data 0.000	Loss 2.5325	
SparseEpoch: [28][101/398]	Time 0.625	Data 0.000	Loss 2.5768	
SparseEpoch: [28][201/398]	Time 0.626	Data 0.000	Loss 2.6314	
SparseEpoch: [28][301/398]	Time 0.626	Data 0.000	Loss 2.0025	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.68204241 0.68208684 0.68220047 0.68245125 0.68258713 0.68267104
 0.68259046 0.68268357 0.68293409 0.68318767 0.68349018 0.68382554
 0.68409688 0.68417895 0.68430299 0.68450577 0.68471079 0.68496859
 0.68522485 0.68537163]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.68320106 0.68319967 0.68319931 0.68322308 0.68324302 0.68325824
 0.68329564 0.68331724 0.68334265 0.68333088 0.68332371 0.68332209
 0.68333644 0.68336963 0.68338153 0.68342935 0.68342109 0.68348585
 0.68346947 0.68349824]
[0. 0. 0.]
-----------end of analyzing the loss ratio:74.08282232284546
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7446096c4040>
---------------------------------
SparseEpoch: [28][1/398]	Time 0.605	Data 0.000	Loss 0.3272	
SparseEpoch: [28][101/398]	Time 0.620	Data 0.000	Loss 0.5320	
SparseEpoch: [28][201/398]	Time 0.622	Data 0.000	Loss 0.4238	
SparseEpoch: [28][301/398]	Time 0.621	Data 0.000	Loss 0.4679	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.23066377 0.23063686 0.23062192 0.23061892 0.23060228 0.23054994
 0.23054302 0.23046958 0.23040547 0.23036507 0.2303235  0.23028008
 0.23024719 0.23022842 0.23019772 0.23017989 0.23012617 0.23008094
 0.23003632 0.23002692]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.23053943 0.2305092  0.23049207 0.23051617 0.23051014 0.23046339
 0.23044854 0.23041918 0.23037877 0.23035943 0.23031155 0.23028513
 0.23026765 0.23023886 0.23020968 0.23020426 0.2301898  0.23013817
 0.23008314 0.230064  ]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:73.78648567199707
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc12ec50>
---------------------------------
SparseEpoch: [28][1/398]	Time 0.781	Data 0.000	Loss 2.7090	
SparseEpoch: [28][101/398]	Time 0.627	Data 0.000	Loss 3.1401	
SparseEpoch: [28][201/398]	Time 0.626	Data 0.000	Loss 3.3545	
SparseEpoch: [28][301/398]	Time 0.624	Data 0.000	Loss 3.3484	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 2.0849	
Epoch(adapt):{0} Loss 2.7375	
Epoch(adapt):{0} Loss 1.9491	
Epoch(adapt):{0} Loss 1.9069	
------------------the total time cost:1215.5075142383575
>>>>>meta updating
Epoch: 0028 | TRAIN: 1.1413 0.3063 0.6197 | 0.5214 0.5214 0.2423 | 0.1860 30.3398 26.5369 0.1901 0.4298 0.5665 ||TEST: 1.2456 0.2722 0.5834 | 0.6064 0.6064 0.2416 | 0.1798 29.8511 26.3379 0.1975 0.4341 0.5680 | 115.5732
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.08495192 1.084969   1.0848194  1.08478379 1.08483906 1.08481371
 1.08475699 1.08481076 1.08480506 1.08484349 1.08481749 1.08474974
 1.08469324 1.08472911 1.08467898 1.08471142 1.08472472 1.08470923
 1.08469158 1.08466858]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.08487447 1.0848783  1.08486195 1.08487625 1.08487821 1.08487863
 1.08487517 1.08490479 1.08487389 1.08485475 1.08483856 1.08484034
 1.0848166  1.08480823 1.08482283 1.08481336 1.08476455 1.08473846
 1.08470088 1.08471037]
[0.         0.5        0.44736842]
-----------end of analyzing the loss ratio:74.42841243743896
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d72d2ad0>
---------------------------------
SparseEpoch: [29][1/398]	Time 0.613	Data 0.000	Loss 2.8619	
SparseEpoch: [29][101/398]	Time 0.622	Data 0.000	Loss 2.2537	
SparseEpoch: [29][201/398]	Time 0.622	Data 0.000	Loss 4.5617	
SparseEpoch: [29][301/398]	Time 0.624	Data 0.000	Loss 2.3150	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.95931298 0.95939451 0.95947506 0.95950886 0.95952304 0.95955755
 0.9595861  0.95970898 0.9596861  0.95968968 0.95974211 0.95968255
 0.95965633 0.95962827 0.95970008 0.9597142  0.95980792 0.95986375
 0.95989949 0.9599263 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.95983527 0.9598483  0.9598498  0.95983154 0.95979077 0.95978701
 0.9597535  0.95974666 0.95973453 0.95972259 0.95970721 0.95969034
 0.95966104 0.95962855 0.9595897  0.959571   0.95954227 0.95952789
 0.95950708 0.95947396]
[0.  0.  0.5]
-----------end of analyzing the loss ratio:73.89063906669617
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7446096e9840>
---------------------------------
SparseEpoch: [29][1/398]	Time 0.608	Data 0.000	Loss 1.7199	
SparseEpoch: [29][101/398]	Time 0.623	Data 0.000	Loss 1.4070	
SparseEpoch: [29][201/398]	Time 0.624	Data 0.000	Loss 1.9984	
SparseEpoch: [29][301/398]	Time 0.624	Data 0.000	Loss 1.4232	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.23252115 0.23244852 0.23235653 0.23232102 0.23222515 0.23213949
 0.23209623 0.23198935 0.23192885 0.23189822 0.23183104 0.23177285
 0.23168814 0.23164887 0.23160304 0.23153291 0.23140984 0.23133465
 0.23127084 0.23116142]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.23216992 0.23214878 0.23210598 0.23208709 0.23201947 0.23201598
 0.2319661  0.23191332 0.23189923 0.23187918 0.23184775 0.23178709
 0.23175887 0.23174402 0.23170714 0.23166221 0.23162705 0.23158993
 0.23157086 0.23156813]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:74.03246188163757
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x744608154e50>
---------------------------------
SparseEpoch: [29][1/398]	Time 0.614	Data 0.000	Loss 2.9676	
SparseEpoch: [29][101/398]	Time 0.625	Data 0.000	Loss 2.4028	
SparseEpoch: [29][201/398]	Time 0.625	Data 0.000	Loss 2.6385	
SparseEpoch: [29][301/398]	Time 0.623	Data 0.000	Loss 2.3936	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.7187	
Epoch(adapt):{0} Loss 1.9451	
Epoch(adapt):{0} Loss 2.2594	
Epoch(adapt):{0} Loss 2.4454	
------------------the total time cost:1216.0865194797516
>>>>>meta updating
Epoch: 0029 | TRAIN: 1.1241 0.3164 0.6228 | 0.5075 0.5075 0.2524 | 0.1814 29.6723 25.6394 0.2077 0.4479 0.5817 ||TEST: 1.2234 0.2852 0.5904 | 0.5884 0.5884 0.2417 | 0.1741 29.1267 25.4640 0.2141 0.4500 0.5827 | 115.8728
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.07533    1.07533759 1.07523784 1.07525188 1.07524486 1.07523439
 1.0751774  1.07516309 1.07515952 1.07513438 1.07516013 1.07511505
 1.07508041 1.07504675 1.0751061  1.07509479 1.07498604 1.0749956
 1.07494913 1.07490123]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.07516305 1.07515523 1.07516571 1.07516422 1.0751727  1.07516126
 1.07515942 1.07515088 1.07515374 1.07515692 1.07516455 1.07517226
 1.07511435 1.07511153 1.07508693 1.0750801  1.07508129 1.07511349
 1.07508616 1.07507841]
[0.  0.5 0.5]
-----------end of analyzing the loss ratio:73.84032011032104
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d7370940>
---------------------------------
SparseEpoch: [30][1/398]	Time 0.605	Data 0.000	Loss 1.9925	
SparseEpoch: [30][101/398]	Time 0.625	Data 0.000	Loss 2.5082	
SparseEpoch: [30][201/398]	Time 0.627	Data 0.000	Loss 3.3371	
SparseEpoch: [30][301/398]	Time 0.625	Data 0.000	Loss 3.0064	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.76257789 0.76257156 0.76254113 0.76255455 0.76254337 0.76256232
 0.76256213 0.76264624 0.76258247 0.76269548 0.76264184 0.7626861
 0.7626599  0.76272457 0.76269578 0.76270665 0.76273983 0.76274301
 0.76270917 0.7626839 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.76261413 0.7626032  0.76262172 0.76262169 0.76266391 0.7626498
 0.76264936 0.76264059 0.76265561 0.76267642 0.76268719 0.76267731
 0.76266646 0.76268873 0.76267124 0.76268238 0.76268689 0.76269906
 0.76267653 0.76269483]
[0. 0. 0.]
-----------end of analyzing the loss ratio:73.93155765533447
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7446095cd060>
---------------------------------
SparseEpoch: [30][1/398]	Time 0.604	Data 0.000	Loss 0.6778	
SparseEpoch: [30][101/398]	Time 0.625	Data 0.000	Loss 0.9987	
SparseEpoch: [30][201/398]	Time 0.624	Data 0.000	Loss 0.3968	
SparseEpoch: [30][301/398]	Time 0.624	Data 0.000	Loss 0.3648	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.20443377 0.2043281  0.20429153 0.20416746 0.2041061  0.20402293
 0.20389245 0.2038568  0.2037888  0.20379009 0.20373622 0.20370421
 0.20371323 0.20358154 0.20346273 0.20338422 0.20333366 0.20337824
 0.20328962 0.20327188]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.20387649 0.20386653 0.20384035 0.20380542 0.20379224 0.20378786
 0.20378056 0.20378374 0.2037836  0.20374375 0.20371711 0.20374038
 0.20374557 0.20374488 0.20372788 0.20369532 0.2036796  0.20367115
 0.20369599 0.20371573]
[0.5        0.39473684 0.        ]
-----------end of analyzing the loss ratio:73.82918667793274
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc0010c0>
---------------------------------
SparseEpoch: [30][1/398]	Time 0.606	Data 0.000	Loss 2.5194	
SparseEpoch: [30][101/398]	Time 0.623	Data 0.000	Loss 3.6647	
SparseEpoch: [30][201/398]	Time 0.623	Data 0.000	Loss 2.3824	
SparseEpoch: [30][301/398]	Time 0.624	Data 0.000	Loss 4.1822	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 2.2496	
Epoch(adapt):{0} Loss 1.8549	
Epoch(adapt):{0} Loss 2.4147	
Epoch(adapt):{0} Loss 3.0237	
------------------the total time cost:1214.7320318222046
>>>>>meta updating
Epoch: 0030 | TRAIN: 1.1113 0.3211 0.6302 | 0.5083 0.5083 0.2467 | 0.1804 29.6467 25.6388 0.2050 0.4464 0.5811 ||TEST: 1.2280 0.2870 0.5894 | 0.5884 0.5884 0.2434 | 0.1755 29.2956 25.6402 0.2105 0.4469 0.5794 | 115.4477
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.04279521 1.04280692 1.04281948 1.04279974 1.04277793 1.04270945
 1.04277341 1.04284735 1.04285682 1.04286089 1.04283019 1.04282706
 1.04287311 1.04284313 1.04282495 1.04282289 1.0427899  1.0427147
 1.04272793 1.04274408]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.04285688 1.04285043 1.04285852 1.04285455 1.04287831 1.04286216
 1.04286793 1.04286434 1.04286412 1.04286031 1.04285197 1.04285528
 1.04284212 1.0428699  1.04287019 1.04287189 1.04289985 1.04289842
 1.04290422 1.04288712]
[0.         0.         0.13157895]
-----------end of analyzing the loss ratio:74.2702248096466
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444dc340b80>
---------------------------------
SparseEpoch: [31][1/398]	Time 0.603	Data 0.000	Loss 1.1992	
SparseEpoch: [31][101/398]	Time 0.619	Data 0.000	Loss 1.9394	
SparseEpoch: [31][201/398]	Time 0.618	Data 0.000	Loss 1.4881	
SparseEpoch: [31][301/398]	Time 0.621	Data 0.000	Loss 1.2537	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.44113993 1.4410641  1.44106776 1.44114994 1.44117371 1.44106063
 1.44116983 1.44120799 1.44115372 1.44108099 1.44109877 1.44109913
 1.44101202 1.44101434 1.44086422 1.44083282 1.44084395 1.44068593
 1.440545   1.44055604]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.44105467 1.44108223 1.44110418 1.44107194 1.4410516  1.44107521
 1.44105103 1.44104242 1.44108337 1.44110324 1.44110459 1.44109583
 1.4411118  1.44114725 1.44118171 1.44118164 1.44116962 1.44110765
 1.44113852 1.44112441]
[0.44736842 0.         0.        ]
-----------end of analyzing the loss ratio:74.1111364364624
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7446098d4a30>
---------------------------------
SparseEpoch: [31][1/398]	Time 0.608	Data 0.000	Loss 1.4053	
SparseEpoch: [31][101/398]	Time 0.624	Data 0.000	Loss 1.0842	
SparseEpoch: [31][201/398]	Time 0.624	Data 0.000	Loss 0.6096	
SparseEpoch: [31][301/398]	Time 0.622	Data 0.000	Loss 0.8641	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.17680517 0.17676518 0.17671852 0.17669252 0.1766873  0.17660114
 0.17660266 0.17657717 0.17657086 0.17652419 0.17651261 0.17648082
 0.17645343 0.17644502 0.17642879 0.17644926 0.17642992 0.17642357
 0.17641212 0.17640218]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.17662128 0.17661173 0.17661008 0.17661143 0.17658156 0.17657388
 0.1765611  0.17656574 0.17653957 0.1765452  0.17652365 0.17650303
 0.17648516 0.17648336 0.17647434 0.17647576 0.17646431 0.17645542
 0.17647801 0.17646883]
[0.5        0.39473684 0.        ]
-----------end of analyzing the loss ratio:73.91540789604187
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc265360>
---------------------------------
SparseEpoch: [31][1/398]	Time 0.606	Data 0.000	Loss 3.7934	
SparseEpoch: [31][101/398]	Time 0.625	Data 0.000	Loss 3.4136	
SparseEpoch: [31][201/398]	Time 0.626	Data 0.000	Loss 2.7160	
SparseEpoch: [31][301/398]	Time 0.628	Data 0.000	Loss 4.0889	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.5013	
Epoch(adapt):{0} Loss 1.3463	
Epoch(adapt):{0} Loss 1.4747	
Epoch(adapt):{0} Loss 1.4955	
------------------the total time cost:1215.4247698783875
>>>>>meta updating
Epoch: 0031 | TRAIN: 1.0933 0.3209 0.6383 | 0.5341 0.5341 0.2423 | 0.1815 29.7855 25.6935 0.2002 0.4445 0.5808 ||TEST: 1.2088 0.2830 0.5969 | 0.6179 0.6179 0.2361 | 0.1756 29.3183 25.5608 0.2075 0.4482 0.5815 | 115.4257
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.05312954 1.0530033  1.05310178 1.05307963 1.05309168 1.05309162
 1.05306416 1.05306147 1.05306929 1.05310584 1.05309498 1.05313746
 1.05311359 1.05306687 1.05302123 1.05300072 1.05295635 1.05294091
 1.05293203 1.05292759]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.05315112 1.05314362 1.05314367 1.0531248  1.05309787 1.05309982
 1.05307483 1.05307311 1.05306187 1.05306241 1.05308941 1.05310241
 1.05311255 1.05311967 1.05309698 1.05311176 1.05310593 1.05310166
 1.05310296 1.05309541]
[0.  0.5 0. ]
-----------end of analyzing the loss ratio:74.26411414146423
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d71f0a60>
---------------------------------
SparseEpoch: [32][1/398]	Time 0.660	Data 0.000	Loss 1.3439	
SparseEpoch: [32][101/398]	Time 0.623	Data 0.000	Loss 1.2898	
SparseEpoch: [32][201/398]	Time 0.624	Data 0.000	Loss 2.2997	
SparseEpoch: [32][301/398]	Time 0.623	Data 0.000	Loss 1.6469	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.65422111 0.65409891 0.65401356 0.65384769 0.65371935 0.65358159
 0.65336911 0.6532041  0.65315159 0.65299676 0.65295507 0.65292498
 0.65285678 0.65274024 0.65257312 0.65254915 0.65240529 0.65221049
 0.65199074 0.65189362]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.65305535 0.65306386 0.65304819 0.65302306 0.65302726 0.65299865
 0.65296143 0.65298861 0.65296159 0.65300197 0.65298996 0.65301041
 0.6530064  0.6529902  0.65297939 0.65299609 0.65299134 0.65299902
 0.65300498 0.65302033]
[0.5 0.  0. ]
-----------end of analyzing the loss ratio:74.04795384407043
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d71a1a20>
---------------------------------
SparseEpoch: [32][1/398]	Time 0.605	Data 0.000	Loss 1.0717	
SparseEpoch: [32][101/398]	Time 0.626	Data 0.000	Loss 1.2579	
SparseEpoch: [32][201/398]	Time 0.624	Data 0.000	Loss 1.0480	
SparseEpoch: [32][301/398]	Time 0.623	Data 0.000	Loss 1.1821	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.2050303  0.20497766 0.20494571 0.20490168 0.20492859 0.20488687
 0.20479275 0.20474399 0.20476629 0.20470294 0.20469344 0.20470084
 0.20474038 0.20470145 0.20462871 0.20462542 0.20458838 0.20454114
 0.20447705 0.2044443 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.20479774 0.20480841 0.20479721 0.20475392 0.20473865 0.20469987
 0.20468848 0.20469745 0.20468591 0.20467766 0.2046636  0.20468352
 0.2047058  0.20470671 0.20472647 0.20472294 0.20473454 0.20475256
 0.20471668 0.20467469]
[0.5        0.02631579 0.        ]
-----------end of analyzing the loss ratio:73.9676718711853
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d72bb7c0>
---------------------------------
SparseEpoch: [32][1/398]	Time 0.608	Data 0.000	Loss 2.4554	
SparseEpoch: [32][101/398]	Time 0.625	Data 0.000	Loss 2.9962	
SparseEpoch: [32][201/398]	Time 0.625	Data 0.000	Loss 2.2779	
SparseEpoch: [32][301/398]	Time 0.625	Data 0.000	Loss 2.2873	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.9949	
Epoch(adapt):{0} Loss 1.8802	
Epoch(adapt):{0} Loss 1.7017	
Epoch(adapt):{0} Loss 1.6634	
------------------the total time cost:1214.5222430229187
>>>>>meta updating
Epoch: 0032 | TRAIN: 1.0833 0.3301 0.6410 | 0.5245 0.5245 0.2380 | 0.1845 30.2465 26.5175 0.1886 0.4287 0.5671 ||TEST: 1.2025 0.2885 0.5998 | 0.6091 0.6091 0.2335 | 0.1800 29.9082 26.4784 0.1941 0.4312 0.5662 | 115.4299
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.16291834 1.16322265 1.16313886 1.16307209 1.16312919 1.16315847
 1.16323813 1.16340581 1.16325972 1.16337016 1.16319561 1.1631786
 1.16328264 1.1634533  1.16347091 1.1634209  1.16345152 1.16347694
 1.1634989  1.16345174]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.16320817 1.1632135  1.16320675 1.16321585 1.16322663 1.16321748
 1.16320519 1.16320594 1.16320436 1.16320447 1.16321667 1.16322615
 1.16322036 1.16322789 1.16323044 1.16322355 1.16323404 1.1632259
 1.16323432 1.16324429]
[0. 0. 0.]
-----------end of analyzing the loss ratio:73.9411895275116
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x744609941870>
---------------------------------
SparseEpoch: [33][1/398]	Time 0.605	Data 0.000	Loss 1.3867	
SparseEpoch: [33][101/398]	Time 0.622	Data 0.000	Loss 0.9612	
SparseEpoch: [33][201/398]	Time 0.621	Data 0.000	Loss 1.2152	
SparseEpoch: [33][301/398]	Time 0.623	Data 0.000	Loss 1.5339	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.02995819 1.03006266 1.030154   1.03028411 1.03027338 1.03040366
 1.03046077 1.03041402 1.03051564 1.0304885  1.03047684 1.03048568
 1.03045574 1.03059447 1.03074362 1.03084044 1.03081278 1.03093294
 1.03087335 1.03098868]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.03040965 1.03046319 1.03048472 1.03046451 1.03046323 1.03050764
 1.03048771 1.03051798 1.03046031 1.03049871 1.03049213 1.03047754
 1.03045405 1.03043475 1.03050181 1.03050303 1.03048882 1.03051069
 1.03048573 1.03047818]
[0. 0. 0.]
-----------end of analyzing the loss ratio:74.02999877929688
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc1c5ba0>
---------------------------------
SparseEpoch: [33][1/398]	Time 0.604	Data 0.000	Loss 0.5230	
SparseEpoch: [33][101/398]	Time 0.625	Data 0.000	Loss 0.3070	
SparseEpoch: [33][201/398]	Time 0.628	Data 0.000	Loss 0.6150	
SparseEpoch: [33][301/398]	Time 0.627	Data 0.000	Loss 0.3764	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.25763861 0.25761557 0.25757817 0.25749038 0.25744712 0.25737326
 0.25731952 0.2573059  0.25724528 0.25718049 0.25713586 0.25707257
 0.25702888 0.25702702 0.25704614 0.25706387 0.25702125 0.25698934
 0.25696328 0.25691401]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.25731957 0.2573164  0.25728766 0.25729615 0.2572615  0.2572412
 0.25722868 0.25723507 0.25717746 0.25715652 0.25715173 0.2571287
 0.25713431 0.25711163 0.25713144 0.25715407 0.25713706 0.25716227
 0.25717628 0.25717217]
[0.5        0.18421053 0.        ]
-----------end of analyzing the loss ratio:74.07249855995178
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d71a05e0>
---------------------------------
SparseEpoch: [33][1/398]	Time 0.605	Data 0.000	Loss 2.1369	
SparseEpoch: [33][101/398]	Time 0.627	Data 0.000	Loss 2.3266	
SparseEpoch: [33][201/398]	Time 0.625	Data 0.000	Loss 2.5332	
SparseEpoch: [33][301/398]	Time 0.626	Data 0.000	Loss 3.7433	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 2.1721	
Epoch(adapt):{0} Loss 1.7800	
Epoch(adapt):{0} Loss 1.6563	
Epoch(adapt):{0} Loss 1.6941	
------------------the total time cost:1216.6903536319733
>>>>>meta updating
Epoch: 0033 | TRAIN: 1.0733 0.3272 0.6392 | 0.5122 0.5122 0.2630 | 0.1869 30.4636 26.8721 0.1885 0.4235 0.5608 ||TEST: 1.2118 0.2881 0.5940 | 0.5761 0.5761 0.2440 | 0.1814 30.0637 26.7955 0.1942 0.4252 0.5601 | 115.0248
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.14465471 1.14470758 1.14469064 1.14468499 1.14466829 1.14474196
 1.14472438 1.14476564 1.14485622 1.14485024 1.1448666  1.14483225
 1.1448314  1.14487256 1.1448523  1.1447854  1.14469658 1.14470129
 1.14461233 1.14452149]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.14486671 1.14488304 1.14489833 1.14490669 1.14490647 1.14490441
 1.14490201 1.14488878 1.14487782 1.14487593 1.14487622 1.14487174
 1.14484703 1.1448836  1.14486905 1.14487512 1.14488602 1.14488571
 1.14489463 1.14491072]
[0.         0.5        0.13157895]
-----------end of analyzing the loss ratio:74.07567405700684
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x744608138b80>
---------------------------------
SparseEpoch: [34][1/398]	Time 0.605	Data 0.000	Loss 1.6874	
SparseEpoch: [34][101/398]	Time 0.625	Data 0.000	Loss 1.3192	
SparseEpoch: [34][201/398]	Time 0.627	Data 0.000	Loss 2.1334	
SparseEpoch: [34][301/398]	Time 0.626	Data 0.000	Loss 1.9117	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.85243829 0.85225999 0.85222026 0.85212556 0.85195    0.85178621
 0.85164828 0.85142893 0.85126721 0.85108402 0.85087464 0.85069529
 0.85039919 0.85032091 0.85021715 0.85007867 0.85002738 0.84981031
 0.84971691 0.84947146]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.85122694 0.85120695 0.85125153 0.85120946 0.85119217 0.8511475
 0.85107417 0.85103514 0.8510094  0.85099671 0.85097221 0.85090755
 0.85089228 0.85086261 0.85082507 0.85080131 0.85079274 0.85075067
 0.85071962 0.85072581]
[0.5        0.         0.44736842]
-----------end of analyzing the loss ratio:74.06022691726685
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444dc319960>
---------------------------------
SparseEpoch: [34][1/398]	Time 0.605	Data 0.000	Loss 2.0470	
SparseEpoch: [34][101/398]	Time 0.622	Data 0.000	Loss 1.8972	
SparseEpoch: [34][201/398]	Time 0.624	Data 0.000	Loss 1.8349	
SparseEpoch: [34][301/398]	Time 0.625	Data 0.000	Loss 2.3705	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.20199299 0.20196742 0.20194968 0.20194866 0.20195035 0.20191865
 0.2019144  0.20190361 0.2018916  0.20189382 0.20190744 0.20189444
 0.20187648 0.20188147 0.20186303 0.20184759 0.20183769 0.20182842
 0.20181529 0.20179351]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.20198658 0.20196617 0.20197398 0.20197077 0.20197185 0.201941
 0.20192396 0.20191405 0.2019109  0.20189505 0.20188953 0.2018885
 0.20186799 0.20186661 0.20186179 0.20183713 0.20181134 0.20180514
 0.20177732 0.2017496 ]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:74.12599420547485
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d731c0a0>
---------------------------------
SparseEpoch: [34][1/398]	Time 0.668	Data 0.000	Loss 2.7339	
SparseEpoch: [34][101/398]	Time 0.626	Data 0.000	Loss 2.9410	
SparseEpoch: [34][201/398]	Time 0.623	Data 0.000	Loss 3.1266	
SparseEpoch: [34][301/398]	Time 0.623	Data 0.000	Loss 2.9787	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.6592	
Epoch(adapt):{0} Loss 1.5809	
Epoch(adapt):{0} Loss 2.1848	
Epoch(adapt):{0} Loss 2.0178	
------------------the total time cost:1215.8039591312408
>>>>>meta updating
Epoch: 0034 | TRAIN: 1.0491 0.3426 0.6479 | 0.5065 0.5065 0.2505 | 0.1810 29.7209 25.7454 0.2014 0.4445 0.5815 ||TEST: 1.1747 0.3027 0.6109 | 0.5755 0.5755 0.2335 | 0.1736 29.0910 25.3036 0.2101 0.4527 0.5872 | 115.6950
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.95348716 0.95338474 0.95341142 0.95335303 0.95339174 0.95341136
 0.95333611 0.9533703  0.95334033 0.95331168 0.95324583 0.95326961
 0.95321938 0.95314323 0.95309959 0.95305894 0.95297126 0.95295331
 0.95286971 0.95286637]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.95330164 0.95329681 0.95328606 0.95325146 0.95326398 0.95328502
 0.95328563 0.95326203 0.95326639 0.95326906 0.95328419 0.95328104
 0.95329075 0.95327855 0.95328442 0.95327978 0.95327684 0.95325783
 0.95327786 0.95328348]
[0.  0.5 0. ]
-----------end of analyzing the loss ratio:74.0536003112793
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc41efe0>
---------------------------------
SparseEpoch: [35][1/398]	Time 0.607	Data 0.000	Loss 1.3498	
SparseEpoch: [35][101/398]	Time 0.626	Data 0.000	Loss 1.6378	
SparseEpoch: [35][201/398]	Time 0.627	Data 0.000	Loss 1.3535	
SparseEpoch: [35][301/398]	Time 0.626	Data 0.000	Loss 1.8336	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.7357505  0.73578868 0.73586409 0.73590444 0.73588559 0.73578549
 0.73587376 0.73576113 0.73572788 0.73574722 0.73575908 0.73570345
 0.73572859 0.73577376 0.73580319 0.73579621 0.73583683 0.73588972
 0.7359478  0.73594366]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.7357928  0.73579257 0.73574992 0.73575232 0.73573544 0.73575597
 0.73575034 0.73575503 0.73576365 0.73575647 0.7357777  0.73576871
 0.73577336 0.73575312 0.73573523 0.73570914 0.73571804 0.73569317
 0.73572101 0.73569914]
[0.07894737 0.         0.39473684]
-----------end of analyzing the loss ratio:74.03026127815247
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc42eb00>
---------------------------------
SparseEpoch: [35][1/398]	Time 0.607	Data 0.000	Loss 1.2840	
SparseEpoch: [35][101/398]	Time 0.623	Data 0.000	Loss 1.2281	
SparseEpoch: [35][201/398]	Time 0.626	Data 0.000	Loss 1.4779	
SparseEpoch: [35][301/398]	Time 0.626	Data 0.000	Loss 2.1535	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.18604858 0.1860303  0.18602806 0.18604776 0.18600515 0.18598374
 0.18595023 0.18592793 0.18592476 0.18590142 0.18587395 0.18585326
 0.18583736 0.18582077 0.1857945  0.18578818 0.18578042 0.1857709
 0.1857469  0.18572885]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.18589148 0.18589044 0.18589884 0.18590115 0.18590462 0.1859138
 0.18592336 0.18590658 0.18590398 0.18589221 0.18588976 0.18589156
 0.18589491 0.18590235 0.1859194  0.18591822 0.18588797 0.1858913
 0.18590191 0.18591865]
[0.5        0.34210526 0.        ]
-----------end of analyzing the loss ratio:73.96810507774353
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc1c5c60>
---------------------------------
SparseEpoch: [35][1/398]	Time 0.624	Data 0.000	Loss 2.5377	
SparseEpoch: [35][101/398]	Time 0.628	Data 0.000	Loss 4.1613	
SparseEpoch: [35][201/398]	Time 0.625	Data 0.000	Loss 2.7559	
SparseEpoch: [35][301/398]	Time 0.625	Data 0.000	Loss 1.8464	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 2.0537	
Epoch(adapt):{0} Loss 1.5806	
Epoch(adapt):{0} Loss 1.9990	
Epoch(adapt):{0} Loss 2.4912	
------------------the total time cost:1215.519701719284
>>>>>meta updating
Epoch: 0035 | TRAIN: 1.0520 0.3492 0.6455 | 0.4897 0.4897 0.2368 | 0.1774 29.3121 25.2073 0.2105 0.4529 0.5890 ||TEST: 1.1980 0.3047 0.5990 | 0.5791 0.5791 0.2321 | 0.1744 29.1406 25.4112 0.2139 0.4517 0.5841 | 115.5579
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.00229293 1.00226251 1.00227761 1.00225266 1.0023173  1.00235587
 1.00243968 1.00245347 1.00248247 1.00254149 1.00262188 1.00264953
 1.00257393 1.00263037 1.00261216 1.00269855 1.00272607 1.00266819
 1.00265592 1.00264938]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.00256978 1.00259587 1.00257993 1.00260218 1.00259928 1.00259842
 1.00259347 1.00256641 1.00258616 1.00259664 1.00257832 1.00260045
 1.00263169 1.0026387  1.00262267 1.00261242 1.00259668 1.00259889
 1.00262395 1.00260829]
[0. 0. 0.]
-----------end of analyzing the loss ratio:73.99632453918457
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d7372230>
---------------------------------
SparseEpoch: [36][1/398]	Time 0.604	Data 0.000	Loss 0.7009	
SparseEpoch: [36][101/398]	Time 0.622	Data 0.000	Loss 0.6956	
SparseEpoch: [36][201/398]	Time 0.621	Data 0.000	Loss 0.8420	
SparseEpoch: [36][301/398]	Time 0.619	Data 0.000	Loss 0.7281	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.68747291 0.68772075 0.68784434 0.68793277 0.68812233 0.68831697
 0.68844855 0.68853147 0.68872696 0.68896394 0.68901906 0.68911461
 0.68916151 0.68946835 0.68959161 0.68985892 0.69000555 0.69014525
 0.69027219 0.6904778 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.68893031 0.68892407 0.68895433 0.68892412 0.68894667 0.68896777
 0.68896966 0.68898804 0.68898606 0.68904952 0.68906826 0.68907638
 0.68908103 0.68906228 0.68906321 0.68912276 0.68911957 0.6890893
 0.68904901 0.68902774]
[0. 0. 0.]
-----------end of analyzing the loss ratio:74.03158235549927
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc5348b0>
---------------------------------
SparseEpoch: [36][1/398]	Time 0.607	Data 0.000	Loss 0.3831	
SparseEpoch: [36][101/398]	Time 0.621	Data 0.000	Loss 0.4174	
SparseEpoch: [36][201/398]	Time 0.621	Data 0.000	Loss 0.4472	
SparseEpoch: [36][301/398]	Time 0.623	Data 0.000	Loss 0.4199	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.21163589 0.21159799 0.21158022 0.21158638 0.21160168 0.21156764
 0.21155975 0.21152211 0.21152823 0.21152551 0.21151578 0.21151154
 0.21151761 0.21149192 0.21147892 0.21145532 0.21142697 0.21140561
 0.2113874  0.21136031]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.2115287  0.21154131 0.21155465 0.21151998 0.21152335 0.21151674
 0.2115107  0.21151647 0.21151994 0.21151855 0.21152509 0.21151835
 0.21152049 0.21152815 0.21152509 0.21152515 0.21152273 0.21152009
 0.21151304 0.21150579]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:74.24313974380493
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d7371570>
---------------------------------
SparseEpoch: [36][1/398]	Time 0.609	Data 0.000	Loss 4.2789	
SparseEpoch: [36][101/398]	Time 0.629	Data 0.000	Loss 3.8334	
SparseEpoch: [36][201/398]	Time 0.627	Data 0.000	Loss 3.0499	
SparseEpoch: [36][301/398]	Time 0.625	Data 0.000	Loss 3.9845	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.4135	
Epoch(adapt):{0} Loss 1.9172	
Epoch(adapt):{0} Loss 2.0808	
Epoch(adapt):{0} Loss 1.4236	
------------------the total time cost:1213.4384396076202
>>>>>meta updating
Epoch: 0036 | TRAIN: 1.0215 0.3584 0.6591 | 0.5052 0.5052 0.2335 | 0.1807 29.7168 25.8521 0.2043 0.4420 0.5769 ||TEST: 1.1677 0.3079 0.6153 | 0.6038 0.6038 0.2328 | 0.1762 29.3408 25.7190 0.2118 0.4464 0.5785 | 115.6563
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.82601496 0.82602985 0.82600478 0.82595546 0.82586995 0.82584394
 0.82578502 0.82581446 0.82577071 0.82575396 0.82580447 0.82580353
 0.82585136 0.8258378  0.82582074 0.82584494 0.82588443 0.8258757
 0.82593718 0.82594864]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.82574732 0.82578047 0.82577399 0.82577363 0.82577183 0.82576776
 0.82577561 0.82577276 0.82575752 0.82573329 0.82573066 0.82572803
 0.82573153 0.8257355  0.82573156 0.82574166 0.82575229 0.82577935
 0.8257807  0.82576243]
[0.         0.         0.07894737]
-----------end of analyzing the loss ratio:73.90105700492859
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc129780>
---------------------------------
SparseEpoch: [37][1/398]	Time 0.620	Data 0.000	Loss 1.4695	
SparseEpoch: [37][101/398]	Time 0.623	Data 0.000	Loss 1.1190	
SparseEpoch: [37][201/398]	Time 0.622	Data 0.000	Loss 1.1023	
SparseEpoch: [37][301/398]	Time 0.622	Data 0.000	Loss 1.6334	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.9846432  0.98459985 0.98462757 0.98462532 0.98453388 0.98447747
 0.98453439 0.98450378 0.98446972 0.9844056  0.98432051 0.98437471
 0.98424447 0.98422461 0.98408751 0.98405908 0.98399137 0.98399206
 0.98405156 0.98398621]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.98442164 0.98440303 0.98440818 0.98440505 0.98441298 0.98437916
 0.98434348 0.98434804 0.98435167 0.98433434 0.9843065  0.98432771
 0.98433612 0.98436053 0.9843539  0.98434684 0.98434098 0.98434716
 0.98434172 0.98441485]
[0.5        0.         0.02631579]
-----------end of analyzing the loss ratio:74.1603775024414
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444dc252c80>
---------------------------------
SparseEpoch: [37][1/398]	Time 0.604	Data 0.000	Loss 1.4728	
SparseEpoch: [37][101/398]	Time 0.621	Data 0.000	Loss 1.2775	
SparseEpoch: [37][201/398]	Time 0.624	Data 0.000	Loss 2.0601	
SparseEpoch: [37][301/398]	Time 0.625	Data 0.000	Loss 1.0126	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.19461885 0.19456654 0.19456869 0.19453805 0.19449893 0.19444977
 0.19441756 0.19436194 0.19432538 0.19427253 0.19429734 0.19428481
 0.19431709 0.19430309 0.19429824 0.19430442 0.19428855 0.19425553
 0.19422724 0.19422106]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.19449424 0.19448678 0.19445271 0.1944745  0.1944253  0.19440064
 0.19436904 0.19433382 0.1942999  0.19427775 0.19430944 0.19430822
 0.19431667 0.19431844 0.19432098 0.19431853 0.1942959  0.19429062
 0.19427301 0.19426746]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:74.10119891166687
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc1684f0>
---------------------------------
SparseEpoch: [37][1/398]	Time 0.606	Data 0.000	Loss 1.8859	
SparseEpoch: [37][101/398]	Time 0.626	Data 0.000	Loss 3.1156	
SparseEpoch: [37][201/398]	Time 0.626	Data 0.000	Loss 3.4918	
SparseEpoch: [37][301/398]	Time 0.625	Data 0.000	Loss 3.6479	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.7960	
Epoch(adapt):{0} Loss 1.2302	
Epoch(adapt):{0} Loss 2.3050	
Epoch(adapt):{0} Loss 2.0733	
------------------the total time cost:1216.6607925891876
>>>>>meta updating
Epoch: 0037 | TRAIN: 0.9978 0.3720 0.6677 | 0.4897 0.4897 0.2305 | 0.1821 29.7772 25.8067 0.2051 0.4435 0.5791 ||TEST: 1.1670 0.3121 0.6156 | 0.5790 0.5790 0.2297 | 0.1755 29.2687 25.5979 0.2120 0.4475 0.5805 | 115.2727
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.98758308 0.98755307 0.9875832  0.98766261 0.987702   0.98779092
 0.98785443 0.98786265 0.987872   0.98799896 0.9880518  0.9880091
 0.9879868  0.98804081 0.98800948 0.98813511 0.98814189 0.98809166
 0.98813059 0.98820325]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.9880523  0.9880499  0.98804292 0.98804341 0.98803549 0.98803085
 0.98801454 0.98801491 0.98801754 0.98801847 0.98802844 0.98802696
 0.98800951 0.98800275 0.98798811 0.98799936 0.98800196 0.98798199
 0.98796321 0.98794019]
[0.  0.  0.5]
-----------end of analyzing the loss ratio:74.14146161079407
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444dc250a00>
---------------------------------
SparseEpoch: [38][1/398]	Time 0.620	Data 0.000	Loss 2.7366	
SparseEpoch: [38][101/398]	Time 0.629	Data 0.000	Loss 2.1737	
SparseEpoch: [38][201/398]	Time 0.627	Data 0.000	Loss 2.6195	
SparseEpoch: [38][301/398]	Time 0.624	Data 0.000	Loss 1.9743	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.83705843 0.83696328 0.83687148 0.83678872 0.83656816 0.83650952
 0.83640375 0.83643637 0.83633664 0.83626407 0.83620228 0.83622226
 0.83609049 0.83603675 0.83599426 0.83593405 0.83578974 0.83578174
 0.83575609 0.83559652]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.8364199  0.83636079 0.83628955 0.83626966 0.83628827 0.83627289
 0.83624532 0.83628255 0.83625481 0.83624822 0.83623991 0.83617953
 0.83619352 0.83618087 0.8361843  0.83616242 0.83614796 0.83616142
 0.83613669 0.83614687]
[0.5        0.         0.44736842]
-----------end of analyzing the loss ratio:74.15143752098083
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc258340>
---------------------------------
SparseEpoch: [38][1/398]	Time 0.605	Data 0.000	Loss 1.7726	
SparseEpoch: [38][101/398]	Time 0.625	Data 0.000	Loss 1.5015	
SparseEpoch: [38][201/398]	Time 0.627	Data 0.000	Loss 1.7303	
SparseEpoch: [38][301/398]	Time 0.626	Data 0.000	Loss 1.7118	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.20085914 0.20086442 0.20086879 0.20086054 0.20085672 0.20084357
 0.20083992 0.20080018 0.20077809 0.20075117 0.20073144 0.2007194
 0.20074678 0.200754   0.20078482 0.20077527 0.20076696 0.20076418
 0.20075714 0.20074661]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.20079209 0.2007964  0.20081183 0.20081786 0.20080183 0.20079259
 0.20078701 0.20076879 0.20075772 0.20074093 0.20073501 0.20073713
 0.20076864 0.20079283 0.20079023 0.20080287 0.2007856  0.20078577
 0.20076956 0.20076292]
[0.07894737 0.02631579 0.        ]
-----------end of analyzing the loss ratio:74.12565183639526
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x74460925c2b0>
---------------------------------
SparseEpoch: [38][1/398]	Time 0.605	Data 0.000	Loss 2.2549	
SparseEpoch: [38][101/398]	Time 0.625	Data 0.000	Loss 1.6819	
SparseEpoch: [38][201/398]	Time 0.627	Data 0.000	Loss 1.0609	
SparseEpoch: [38][301/398]	Time 0.624	Data 0.000	Loss 1.8247	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 2.1563	
Epoch(adapt):{0} Loss 2.5825	
Epoch(adapt):{0} Loss 1.8025	
Epoch(adapt):{0} Loss 1.9501	
------------------the total time cost:1216.3041219711304
>>>>>meta updating
Epoch: 0038 | TRAIN: 0.9862 0.3771 0.6717 | 0.4916 0.4916 0.2245 | 0.1729 28.8124 24.4751 0.2161 0.4672 0.6033 ||TEST: 1.1518 0.3210 0.6193 | 0.5858 0.5858 0.2284 | 0.1683 28.5003 24.5957 0.2210 0.4657 0.5999 | 115.2652
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.92160227 0.92170834 0.92170927 0.92178588 0.92173154 0.92177164
 0.92177443 0.9218861  0.92191418 0.92201828 0.92210829 0.92230526
 0.92231508 0.92232291 0.92237633 0.92237329 0.92242401 0.92246732
 0.9225552  0.922583  ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.92218968 0.92214937 0.92212938 0.92210861 0.92208886 0.92207148
 0.92204479 0.9220701  0.92203916 0.92208679 0.92206807 0.9220451
 0.92201461 0.92195913 0.92190911 0.921942   0.92194959 0.92193384
 0.92193022 0.92189737]
[0.  0.  0.5]
-----------end of analyzing the loss ratio:74.26229166984558
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d72b9330>
---------------------------------
SparseEpoch: [39][1/398]	Time 0.627	Data 0.000	Loss 2.3157	
SparseEpoch: [39][101/398]	Time 0.627	Data 0.000	Loss 1.6013	
SparseEpoch: [39][201/398]	Time 0.626	Data 0.000	Loss 2.2786	
SparseEpoch: [39][301/398]	Time 0.626	Data 0.000	Loss 1.7083	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.75372805 0.75357973 0.75334351 0.75313134 0.75300584 0.7527534
 0.7526181  0.75248905 0.75233771 0.75224158 0.7521317  0.75208631
 0.7519699  0.75177708 0.75163277 0.75141178 0.75129377 0.75104003
 0.75081104 0.75068256]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.75226477 0.75230253 0.75227712 0.752244   0.75219122 0.75218086
 0.75219458 0.752194   0.75216134 0.75219199 0.75219377 0.75222163
 0.75221251 0.75214196 0.75215085 0.75217513 0.75217896 0.752188
 0.75221768 0.75217322]
[0.5        0.         0.18421053]
-----------end of analyzing the loss ratio:74.42533993721008
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d72b9bd0>
---------------------------------
SparseEpoch: [39][1/398]	Time 0.606	Data 0.000	Loss 0.9798	
SparseEpoch: [39][101/398]	Time 0.622	Data 0.000	Loss 1.0874	
SparseEpoch: [39][201/398]	Time 0.624	Data 0.000	Loss 1.2496	
SparseEpoch: [39][301/398]	Time 0.624	Data 0.000	Loss 1.0280	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.1716895  0.17167594 0.17163626 0.17160296 0.17159607 0.17154737
 0.17148817 0.17147788 0.1714563  0.17137449 0.17134656 0.17130123
 0.17128761 0.1712439  0.17119281 0.17115334 0.17110493 0.17105769
 0.1709918  0.17097357]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.17151917 0.17149618 0.17147521 0.17146734 0.17146839 0.17145329
 0.17144428 0.17142    0.17138835 0.17138036 0.17136496 0.17133816
 0.17133138 0.17130094 0.1712715  0.17124839 0.17122887 0.17119337
 0.17118381 0.17117783]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:74.07662749290466
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444dc318e80>
---------------------------------
SparseEpoch: [39][1/398]	Time 0.625	Data 0.000	Loss 3.0432	
SparseEpoch: [39][101/398]	Time 0.623	Data 0.000	Loss 3.5587	
SparseEpoch: [39][201/398]	Time 0.627	Data 0.000	Loss 3.4103	
SparseEpoch: [39][301/398]	Time 0.626	Data 0.000	Loss 2.2551	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.6164	
Epoch(adapt):{0} Loss 2.7210	
Epoch(adapt):{0} Loss 1.7270	
Epoch(adapt):{0} Loss 1.5745	
------------------the total time cost:1217.0284297466278
>>>>>meta updating
Epoch: 0039 | TRAIN: 0.9788 0.3730 0.6712 | 0.4847 0.4847 0.2304 | 0.1748 29.1651 25.1148 0.2042 0.4543 0.5932 ||TEST: 1.1615 0.3189 0.6163 | 0.5806 0.5806 0.2298 | 0.1715 28.9406 25.2095 0.2090 0.4533 0.5895 | 115.6393
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.97703276 0.97698515 0.97698077 0.97694344 0.97690711 0.97691501
 0.97686372 0.97684541 0.97682734 0.97685291 0.97687618 0.97685993
 0.97691497 0.97689164 0.97683883 0.97688234 0.97686424 0.97683023
 0.97682291 0.9768089 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.97688671 0.97686887 0.97684723 0.97685324 0.9768419  0.97686742
 0.97685831 0.97683154 0.97684191 0.97686132 0.97685701 0.97686736
 0.9768416  0.97682217 0.97683638 0.9768217  0.9768216  0.97680564
 0.97681743 0.9768042 ]
[0.  0.5 0.5]
-----------end of analyzing the loss ratio:74.36208200454712
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x744608680af0>
---------------------------------
SparseEpoch: [40][1/398]	Time 0.616	Data 0.000	Loss 2.3663	
SparseEpoch: [40][101/398]	Time 0.625	Data 0.000	Loss 2.0675	
SparseEpoch: [40][201/398]	Time 0.625	Data 0.000	Loss 2.4992	
SparseEpoch: [40][301/398]	Time 0.625	Data 0.000	Loss 2.4663	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.70305093 0.70306116 0.70303912 0.70302548 0.70305091 0.70304803
 0.70305951 0.70312823 0.70314656 0.70314333 0.70315356 0.70310892
 0.70316895 0.70315625 0.70317562 0.70309938 0.70311605 0.70307766
 0.70306315 0.70307888]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.70327296 0.70324143 0.70325332 0.70323311 0.70324669 0.70322466
 0.70322947 0.70315891 0.70312368 0.70311684 0.70315031 0.70311827
 0.70309908 0.70309989 0.70308179 0.70306721 0.70311206 0.70300878
 0.70300836 0.70296007]
[0.  0.  0.5]
-----------end of analyzing the loss ratio:74.2101686000824
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d731c850>
---------------------------------
SparseEpoch: [40][1/398]	Time 0.606	Data 0.000	Loss 1.3560	
SparseEpoch: [40][101/398]	Time 0.626	Data 0.000	Loss 1.3002	
SparseEpoch: [40][201/398]	Time 0.623	Data 0.000	Loss 1.4682	
SparseEpoch: [40][301/398]	Time 0.623	Data 0.000	Loss 2.1991	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.19104558 0.19102138 0.19098799 0.19095796 0.19095295 0.19094551
 0.19094322 0.19093985 0.19091691 0.19089957 0.19092698 0.19091741
 0.19090428 0.19085211 0.19081206 0.1907742  0.19073293 0.19071782
 0.19069151 0.19068586]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.19088379 0.19090277 0.19091957 0.19091219 0.19090341 0.19090088
 0.19093319 0.19093729 0.19093246 0.19091763 0.19089036 0.1908831
 0.19092991 0.19093485 0.19093494 0.19093485 0.19092024 0.19092971
 0.19092845 0.19091341]
[0.5        0.07894737 0.        ]
-----------end of analyzing the loss ratio:74.22196698188782
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x744609646470>
---------------------------------
SparseEpoch: [40][1/398]	Time 0.605	Data 0.000	Loss 1.9254	
SparseEpoch: [40][101/398]	Time 0.625	Data 0.000	Loss 2.5474	
SparseEpoch: [40][201/398]	Time 0.626	Data 0.000	Loss 2.0615	
SparseEpoch: [40][301/398]	Time 0.626	Data 0.000	Loss 2.6567	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.5762	
Epoch(adapt):{0} Loss 1.4319	
Epoch(adapt):{0} Loss 1.5400	
Epoch(adapt):{0} Loss 1.5294	
------------------the total time cost:1216.8516654968262
>>>>>meta updating
Epoch: 0040 | TRAIN: 0.9855 0.3912 0.6718 | 0.4850 0.4850 0.2284 | 0.1684 28.3625 23.9990 0.2186 0.4764 0.6144 ||TEST: 1.1635 0.3204 0.6143 | 0.6006 0.6006 0.2317 | 0.1654 28.2071 24.2093 0.2218 0.4725 0.6077 | 115.7814
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.84995987 0.84999157 0.84995558 0.85009285 0.85002421 0.85004029
 0.8499798  0.84997077 0.85004122 0.84994178 0.84997656 0.85000183
 0.85007635 0.84999969 0.85003192 0.85005761 0.84997216 0.84987543
 0.84996198 0.84991528]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.85002342 0.84998199 0.84997713 0.84998813 0.84999137 0.8499267
 0.84995753 0.84995403 0.849959   0.84997157 0.85000547 0.85000992
 0.8499935  0.85000639 0.85003111 0.85003396 0.85002704 0.85000929
 0.85000515 0.85002377]
[0.         0.39473684 0.        ]
-----------end of analyzing the loss ratio:74.24353098869324
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc12ac50>
---------------------------------
SparseEpoch: [41][1/398]	Time 0.683	Data 0.000	Loss 1.5894	
SparseEpoch: [41][101/398]	Time 0.623	Data 0.000	Loss 1.4016	
SparseEpoch: [41][201/398]	Time 0.623	Data 0.000	Loss 1.9185	
SparseEpoch: [41][301/398]	Time 0.622	Data 0.000	Loss 1.4362	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.53912646 0.53913433 0.53898597 0.53894333 0.53883194 0.5386976
 0.53866055 0.53868866 0.53871266 0.53870567 0.53866359 0.53862969
 0.53856152 0.53850556 0.53850942 0.53833646 0.53833791 0.53832198
 0.53823014 0.53828092]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.53869109 0.53868778 0.5386571  0.5386853  0.53871551 0.53871874
 0.5386793  0.5386852  0.538693   0.5386912  0.53861774 0.53865653
 0.53864432 0.53867379 0.53868994 0.53868122 0.53867494 0.53867806
 0.53865289 0.5386033 ]
[0.44736842 0.         0.5       ]
-----------end of analyzing the loss ratio:74.37633275985718
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7446095cc2e0>
---------------------------------
SparseEpoch: [41][1/398]	Time 0.615	Data 0.000	Loss 1.5593	
SparseEpoch: [41][101/398]	Time 0.621	Data 0.000	Loss 1.7610	
SparseEpoch: [41][201/398]	Time 0.621	Data 0.000	Loss 1.5743	
SparseEpoch: [41][301/398]	Time 0.622	Data 0.000	Loss 1.4117	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.19703256 0.19699229 0.19696804 0.19696128 0.1969234  0.19697006
 0.19694731 0.19689724 0.19687102 0.19685087 0.19678971 0.19676989
 0.19674927 0.19673772 0.19669632 0.19667141 0.19664623 0.19660701
 0.19657822 0.19655713]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.19691217 0.19687347 0.19688919 0.19686961 0.19688506 0.19688901
 0.1968883  0.19685777 0.19685484 0.19683784 0.19679703 0.19679537
 0.1967944  0.19678976 0.19676477 0.19672729 0.1967074  0.1967153
 0.19672467 0.19667328]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:74.41677856445312
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x744609945150>
---------------------------------
SparseEpoch: [41][1/398]	Time 0.639	Data 0.000	Loss 2.7474	
SparseEpoch: [41][101/398]	Time 0.624	Data 0.000	Loss 2.5133	
SparseEpoch: [41][201/398]	Time 0.625	Data 0.000	Loss 3.3291	
SparseEpoch: [41][301/398]	Time 0.624	Data 0.000	Loss 1.9801	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.7913	
Epoch(adapt):{0} Loss 1.2941	
Epoch(adapt):{0} Loss 1.7196	
Epoch(adapt):{0} Loss 1.5187	
------------------the total time cost:1215.6325039863586
>>>>>meta updating
Epoch: 0041 | TRAIN: 0.9804 0.3844 0.6748 | 0.5077 0.5077 0.2293 | 0.1760 29.3070 25.3800 0.2029 0.4502 0.5883 ||TEST: 1.1517 0.3204 0.6170 | 0.6074 0.6074 0.2310 | 0.1723 29.0749 25.5347 0.2068 0.4481 0.5842 | 115.2013
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.13139468 1.13134996 1.13133055 1.13124309 1.13133447 1.13116907
 1.13105037 1.13087309 1.13096188 1.13100111 1.13098527 1.1308737
 1.13076879 1.13078241 1.13056066 1.13050109 1.13040957 1.13029257
 1.13006691 1.13005186]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[1.13098148 1.13105607 1.13100907 1.1310248  1.13100271 1.13104375
 1.13099733 1.13097777 1.13097354 1.13101543 1.13100014 1.13100944
 1.1309848  1.13092752 1.13093898 1.13095152 1.13092742 1.13092951
 1.13095098 1.13093855]
[0.         0.5        0.34210526]
-----------end of analyzing the loss ratio:74.2716019153595
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d72d3700>
---------------------------------
SparseEpoch: [42][1/398]	Time 0.605	Data 0.000	Loss 2.3733	
SparseEpoch: [42][101/398]	Time 0.625	Data 0.000	Loss 1.9148	
SparseEpoch: [42][201/398]	Time 0.625	Data 0.000	Loss 1.5556	
SparseEpoch: [42][301/398]	Time 0.624	Data 0.000	Loss 2.1929	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.63680483 0.63665275 0.63661436 0.63636947 0.63623321 0.63608263
 0.63584228 0.63579036 0.6356008  0.63565753 0.63553648 0.63552104
 0.63541004 0.63529505 0.63512308 0.63506927 0.63491643 0.6349343
 0.63489109 0.63464842]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.63567802 0.63569611 0.6357007  0.63567688 0.63565305 0.6356355
 0.63565322 0.63570972 0.63563474 0.63557916 0.63557543 0.63558325
 0.63559229 0.63553475 0.63547041 0.63547634 0.63544964 0.63546402
 0.63543538 0.63544525]
[0.5        0.         0.44736842]
-----------end of analyzing the loss ratio:74.33087682723999
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d73250c0>
---------------------------------
SparseEpoch: [42][1/398]	Time 0.606	Data 0.000	Loss 1.9307	
SparseEpoch: [42][101/398]	Time 0.624	Data 0.000	Loss 1.1711	
SparseEpoch: [42][201/398]	Time 0.623	Data 0.000	Loss 2.3348	
SparseEpoch: [42][301/398]	Time 0.625	Data 0.000	Loss 1.9490	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.20733621 0.20729384 0.20727295 0.20728629 0.20729043 0.20730748
 0.20730661 0.20732957 0.20734326 0.20734061 0.20733333 0.20732929
 0.20733355 0.20732421 0.20732713 0.20732949 0.20732533 0.20731466
 0.20731885 0.20732751]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.20732372 0.20732961 0.2073306  0.20732118 0.20733229 0.20734161
 0.20734344 0.20734956 0.20733874 0.20734666 0.20733678 0.20733218
 0.20735074 0.2073373  0.20735196 0.20735189 0.20735683 0.20736505
 0.20735609 0.2073519 ]
[0. 0. 0.]
-----------end of analyzing the loss ratio:74.08306503295898
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc324910>
---------------------------------
SparseEpoch: [42][1/398]	Time 0.606	Data 0.000	Loss 1.6845	
SparseEpoch: [42][101/398]	Time 0.618	Data 0.000	Loss 1.7080	
SparseEpoch: [42][201/398]	Time 0.621	Data 0.000	Loss 1.4760	
SparseEpoch: [42][301/398]	Time 0.621	Data 0.000	Loss 2.3256	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 2.0204	
Epoch(adapt):{0} Loss 1.5946	
Epoch(adapt):{0} Loss 1.8952	
Epoch(adapt):{0} Loss 1.6967	
------------------the total time cost:1214.3159792423248
>>>>>meta updating
Epoch: 0042 | TRAIN: 0.9495 0.4106 0.6840 | 0.4669 0.4669 0.2172 | 0.1681 28.2217 23.7037 0.2265 0.4822 0.6175 ||TEST: 1.1383 0.3353 0.6268 | 0.5728 0.5728 0.2261 | 0.1629 27.8119 23.5995 0.2343 0.4847 0.6180 | 115.7501
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.94828312 0.94841677 0.94833989 0.94827363 0.94842257 0.94841954
 0.9485225  0.94854411 0.94860134 0.94879401 0.94879987 0.94878987
 0.94894712 0.94894804 0.94889006 0.94887516 0.94889292 0.94881079
 0.94881433 0.94886567]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.9488617  0.94886466 0.94886087 0.94884919 0.94885933 0.94886503
 0.94884031 0.94883566 0.94882202 0.94884418 0.94883931 0.94882388
 0.94882838 0.94883659 0.94883428 0.94883043 0.94882654 0.94882447
 0.94880789 0.94881608]
[0.         0.         0.44736842]
-----------end of analyzing the loss ratio:74.03766393661499
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x744609831b70>
---------------------------------
SparseEpoch: [43][1/398]	Time 0.605	Data 0.000	Loss 1.7410	
SparseEpoch: [43][101/398]	Time 0.623	Data 0.000	Loss 2.2275	
SparseEpoch: [43][201/398]	Time 0.623	Data 0.000	Loss 1.7503	
SparseEpoch: [43][301/398]	Time 0.623	Data 0.000	Loss 1.8390	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.64383919 0.64378743 0.64382046 0.64374918 0.64386927 0.64395115
 0.64400445 0.64398817 0.64391901 0.64394798 0.64399712 0.64395099
 0.64401131 0.64401766 0.64401915 0.64399485 0.64398991 0.64394598
 0.6440374  0.64408336]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.64382878 0.64381965 0.64388195 0.64382523 0.64382276 0.64383152
 0.64385983 0.64393072 0.64395189 0.64398798 0.64404715 0.64405673
 0.64405075 0.64406571 0.64408326 0.64408814 0.64408125 0.64411038
 0.64413375 0.64418987]
[0. 0. 0.]
-----------end of analyzing the loss ratio:74.064621925354
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc0010c0>
---------------------------------
SparseEpoch: [43][1/398]	Time 0.613	Data 0.000	Loss 0.4827	
SparseEpoch: [43][101/398]	Time 0.627	Data 0.000	Loss 0.7047	
SparseEpoch: [43][201/398]	Time 0.625	Data 0.000	Loss 0.7381	
SparseEpoch: [43][301/398]	Time 0.624	Data 0.000	Loss 0.5046	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.17777314 0.17775966 0.17776248 0.17777469 0.17776943 0.17777992
 0.17778485 0.17778264 0.1777728  0.17781056 0.17781354 0.17781088
 0.17784752 0.17784063 0.17782889 0.1778221  0.177816   0.17779523
 0.17778561 0.17776982]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.17785907 0.17785198 0.17784348 0.17783197 0.17782158 0.17780957
 0.1778057  0.17781832 0.17781156 0.17780065 0.17779648 0.1777864
 0.17778355 0.1777886  0.17778009 0.17776371 0.17777658 0.17776907
 0.17775837 0.17775102]
[0.  0.5 0. ]
-----------end of analyzing the loss ratio:74.19062662124634
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x74460925d480>
---------------------------------
SparseEpoch: [43][1/398]	Time 0.609	Data 0.000	Loss 1.6927	
SparseEpoch: [43][101/398]	Time 0.619	Data 0.000	Loss 2.1982	
SparseEpoch: [43][201/398]	Time 0.621	Data 0.000	Loss 2.0231	
SparseEpoch: [43][301/398]	Time 0.621	Data 0.000	Loss 2.8527	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.2443	
Epoch(adapt):{0} Loss 2.5001	
Epoch(adapt):{0} Loss 1.5823	
Epoch(adapt):{0} Loss 2.0421	
------------------the total time cost:1214.2706878185272
>>>>>meta updating
Epoch: 0043 | TRAIN: 0.9510 0.4069 0.6860 | 0.4628 0.4628 0.2323 | 0.1713 28.7233 24.4254 0.2117 0.4684 0.6064 ||TEST: 1.1579 0.3187 0.6174 | 0.5631 0.5631 0.2333 | 0.1682 28.5423 24.5529 0.2146 0.4650 0.6015 | 115.5009
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.98963577 0.9896652  0.98966959 0.98963902 0.98965551 0.98959907
 0.98966704 0.98971781 0.98975657 0.98973309 0.98972371 0.98969489
 0.98977554 0.98980884 0.98982481 0.98981929 0.98977584 0.98980309
 0.98985322 0.98980764]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.98978838 0.98974915 0.9897422  0.98973841 0.98972135 0.98973537
 0.98972006 0.98969661 0.98969911 0.98971372 0.98972284 0.98970698
 0.98970881 0.98970648 0.98969428 0.98969495 0.98969463 0.98968136
 0.98969226 0.98971881]
[0.         0.         0.39473684]
-----------end of analyzing the loss ratio:74.40922093391418
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444dc31acb0>
---------------------------------
SparseEpoch: [44][1/398]	Time 0.614	Data 0.000	Loss 2.2127	
SparseEpoch: [44][101/398]	Time 0.630	Data 0.000	Loss 1.5142	
SparseEpoch: [44][201/398]	Time 0.637	Data 0.000	Loss 1.4749	
SparseEpoch: [44][301/398]	Time 0.634	Data 0.000	Loss 1.5690	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.76064534 0.7607191  0.76085259 0.76097035 0.76106808 0.76110736
 0.76119272 0.76125454 0.76126608 0.76140779 0.76146478 0.76157418
 0.76165369 0.76162318 0.76170204 0.76177906 0.76196084 0.76198268
 0.76198547 0.76200536]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.76127496 0.76132911 0.76136285 0.76133754 0.76137452 0.76143548
 0.76142211 0.76146191 0.76146009 0.76145718 0.76146394 0.76148003
 0.76146597 0.76146666 0.76145027 0.76148183 0.76153525 0.76154835
 0.76157401 0.76160616]
[0. 0. 0.]
-----------end of analyzing the loss ratio:75.1107976436615
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d731c100>
---------------------------------
SparseEpoch: [44][1/398]	Time 0.611	Data 0.000	Loss 0.2819	
SparseEpoch: [44][101/398]	Time 0.640	Data 0.000	Loss 0.5158	
SparseEpoch: [44][201/398]	Time 0.635	Data 0.000	Loss 0.4264	
SparseEpoch: [44][301/398]	Time 0.630	Data 0.000	Loss 0.2700	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.19707005 0.19690697 0.19681168 0.19672144 0.19666116 0.19652087
 0.19643272 0.19643819 0.19632598 0.19629159 0.19628335 0.1962352
 0.19618441 0.1961623  0.19613714 0.19607943 0.19609803 0.19605291
 0.19603542 0.19597516]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.19647144 0.19648023 0.19647014 0.19644518 0.19643813 0.19640805
 0.19632614 0.19638106 0.19631903 0.19630934 0.19629091 0.19628612
 0.19623641 0.19621535 0.19622355 0.1961988  0.19617767 0.1961782
 0.19617209 0.19615095]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:74.66007494926453
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7446099fee00>
---------------------------------
SparseEpoch: [44][1/398]	Time 0.622	Data 0.000	Loss 1.7621	
SparseEpoch: [44][101/398]	Time 0.628	Data 0.000	Loss 3.0214	
SparseEpoch: [44][201/398]	Time 0.627	Data 0.000	Loss 3.2441	
SparseEpoch: [44][301/398]	Time 0.626	Data 0.000	Loss 2.5990	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.2816	
Epoch(adapt):{0} Loss 1.6100	
Epoch(adapt):{0} Loss 2.1183	
Epoch(adapt):{0} Loss 1.6159	
------------------the total time cost:1224.6506462097168
>>>>>meta updating
Epoch: 0044 | TRAIN: 0.9621 0.3974 0.6835 | 0.4665 0.4665 0.2324 | 0.1722 28.8492 24.7590 0.2102 0.4623 0.6011 ||TEST: 1.1469 0.3158 0.6242 | 0.5599 0.5599 0.2292 | 0.1675 28.4615 24.5860 0.2189 0.4656 0.6004 | 115.5742
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.98711185 0.98691089 0.98686115 0.98682244 0.9866639  0.98639323
 0.9864585  0.98634642 0.98624324 0.98636634 0.98621535 0.98626699
 0.98624494 0.98616925 0.98634557 0.98645695 0.9864976  0.98655542
 0.98665103 0.98668926]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.98626308 0.98626096 0.98628314 0.98629162 0.98630103 0.98631659
 0.98632081 0.98632131 0.98631575 0.98633592 0.98633855 0.98634037
 0.98636696 0.9863609  0.98638061 0.98640056 0.98638079 0.98637568
 0.98638325 0.98638147]
[0.         0.18421053 0.        ]
-----------end of analyzing the loss ratio:74.34767270088196
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc41c940>
---------------------------------
SparseEpoch: [45][1/398]	Time 0.605	Data 0.000	Loss 0.9283	
SparseEpoch: [45][101/398]	Time 0.623	Data 0.000	Loss 1.2836	
SparseEpoch: [45][201/398]	Time 0.625	Data 0.000	Loss 1.6620	
SparseEpoch: [45][301/398]	Time 0.624	Data 0.000	Loss 0.9022	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.84112921 0.84095434 0.84086015 0.84051453 0.84007884 0.83990337
 0.8397193  0.83950526 0.83931458 0.83925862 0.83914785 0.83892284
 0.83870978 0.83860917 0.83824725 0.83801873 0.8376992  0.83739353
 0.83709254 0.83688293]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.83909995 0.83914429 0.83914708 0.83917258 0.83919843 0.83923193
 0.83926625 0.83925169 0.83923793 0.83919276 0.83919413 0.83917429
 0.83915609 0.83920305 0.83915424 0.83916147 0.83912803 0.83901223
 0.83898873 0.83902655]
[0.5        0.         0.44736842]
-----------end of analyzing the loss ratio:74.55381917953491
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc38a170>
---------------------------------
SparseEpoch: [45][1/398]	Time 0.607	Data 0.000	Loss 1.7825	
SparseEpoch: [45][101/398]	Time 0.623	Data 0.000	Loss 1.8811	
SparseEpoch: [45][201/398]	Time 0.623	Data 0.000	Loss 1.6916	
SparseEpoch: [45][301/398]	Time 0.624	Data 0.000	Loss 1.5816	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.18369377 0.18370284 0.18367832 0.18364342 0.18365852 0.18365802
 0.18364362 0.18362134 0.18360876 0.18359827 0.18358936 0.18357875
 0.18356774 0.18356736 0.18354678 0.18355501 0.1835504  0.18353715
 0.18352024 0.18352152]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.18362885 0.18362765 0.18361815 0.1836133  0.18361367 0.18361157
 0.1836028  0.18359298 0.18359925 0.18359054 0.18358767 0.18359255
 0.18359463 0.18361817 0.1836341  0.18366764 0.18365174 0.18363547
 0.18363374 0.18362734]
[0.44736842 0.02631579 0.        ]
-----------end of analyzing the loss ratio:74.2780909538269
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444dc12c280>
---------------------------------
SparseEpoch: [45][1/398]	Time 0.609	Data 0.000	Loss 1.6045	
SparseEpoch: [45][101/398]	Time 0.623	Data 0.000	Loss 2.0429	
SparseEpoch: [45][201/398]	Time 0.625	Data 0.000	Loss 2.2640	
SparseEpoch: [45][301/398]	Time 0.625	Data 0.000	Loss 2.6243	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 2.1426	
Epoch(adapt):{0} Loss 1.5175	
Epoch(adapt):{0} Loss 1.9792	
Epoch(adapt):{0} Loss 2.2093	
------------------the total time cost:1216.313128232956
>>>>>meta updating
Epoch: 0045 | TRAIN: 0.9289 0.4134 0.6893 | 0.4670 0.4670 0.2215 | 0.1681 28.3563 24.0773 0.2198 0.4742 0.6120 ||TEST: 1.1490 0.3295 0.6215 | 0.5766 0.5766 0.2319 | 0.1663 28.3023 24.3793 0.2221 0.4693 0.6038 | 115.4438
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.99852488 0.99846168 0.9985409  0.99855094 0.99868096 0.99865199
 0.99865519 0.99856603 0.99853733 0.99849931 0.99853732 0.99857332
 0.99855248 0.99859219 0.9985515  0.99851428 0.99865554 0.99871792
 0.99873431 0.99878179]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.99860803 0.99860143 0.99859291 0.998607   0.99858404 0.99858704
 0.99858356 0.99857526 0.99854572 0.99855687 0.99853451 0.99848633
 0.99849623 0.99850819 0.99851427 0.99850603 0.99851435 0.99850135
 0.99848177 0.99849107]
[0.         0.         0.44736842]
-----------end of analyzing the loss ratio:74.32287669181824
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444dc3b76a0>
---------------------------------
SparseEpoch: [46][1/398]	Time 0.607	Data 0.000	Loss 2.4923	
SparseEpoch: [46][101/398]	Time 0.625	Data 0.000	Loss 1.7389	
SparseEpoch: [46][201/398]	Time 0.625	Data 0.000	Loss 2.7721	
SparseEpoch: [46][301/398]	Time 0.626	Data 0.000	Loss 2.2619	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.99814731 0.99812732 0.99819567 0.99815767 0.99822834 0.99839531
 0.99840722 0.99829354 0.99851385 0.99856867 0.99890701 0.99882748
 0.99887404 0.99881209 0.99896439 0.99910446 0.99923776 0.99914108
 0.99922457 0.99925852]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.99872568 0.99870278 0.99873927 0.99867646 0.99870015 0.99872
 0.99868308 0.99866116 0.9986859  0.99870938 0.99866572 0.99870201
 0.99866076 0.99862232 0.99864706 0.99862843 0.9987202  0.99870204
 0.99874274 0.99875044]
[0.         0.         0.18421053]
-----------end of analyzing the loss ratio:74.28610610961914
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc1c4ee0>
---------------------------------
SparseEpoch: [46][1/398]	Time 0.604	Data 0.000	Loss 0.9078	
SparseEpoch: [46][101/398]	Time 0.620	Data 0.000	Loss 0.8579	
SparseEpoch: [46][201/398]	Time 0.623	Data 0.000	Loss 1.2483	
SparseEpoch: [46][301/398]	Time 0.623	Data 0.000	Loss 0.8595	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.19305786 0.19297175 0.19289191 0.19284866 0.19281463 0.19279001
 0.19283159 0.19278492 0.19275137 0.19278333 0.19269673 0.19260225
 0.19252649 0.1924803  0.19237786 0.1922878  0.19227684 0.19217384
 0.19207841 0.19211971]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.19283236 0.19280703 0.19280666 0.19280521 0.19280849 0.19277943
 0.19277402 0.19278429 0.19277003 0.19274747 0.19270805 0.19268402
 0.19266081 0.19268169 0.19262138 0.19262356 0.19259584 0.19256709
 0.19254869 0.1925342 ]
[0.44736842 0.5        0.        ]
-----------end of analyzing the loss ratio:74.22200155258179
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7446095cc6d0>
---------------------------------
SparseEpoch: [46][1/398]	Time 0.626	Data 0.000	Loss 2.6112	
SparseEpoch: [46][101/398]	Time 0.626	Data 0.000	Loss 2.2560	
SparseEpoch: [46][201/398]	Time 0.625	Data 0.000	Loss 2.1933	
SparseEpoch: [46][301/398]	Time 0.625	Data 0.000	Loss 2.3605	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.9624	
Epoch(adapt):{0} Loss 1.2856	
Epoch(adapt):{0} Loss 1.9343	
Epoch(adapt):{0} Loss 1.6325	
------------------the total time cost:1216.6413877010345
>>>>>meta updating
Epoch: 0046 | TRAIN: 0.9253 0.4060 0.6919 | 0.4577 0.4577 0.2219 | 0.1667 28.2343 23.8535 0.2186 0.4781 0.6175 ||TEST: 1.1522 0.3255 0.6271 | 0.5677 0.5677 0.2262 | 0.1642 28.0697 23.9406 0.2231 0.4776 0.6126 | 115.7823
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.9528884  0.95293623 0.9529412  0.952965   0.95292698 0.95289618
 0.95280367 0.95275265 0.95278623 0.95276347 0.95272663 0.95269268
 0.95260045 0.95255687 0.95261302 0.95254805 0.95249774 0.95253397
 0.95254139 0.95251547]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.95271189 0.95271816 0.95273923 0.95272623 0.95271821 0.95272198
 0.95267778 0.95266279 0.95267351 0.95270156 0.9527283  0.95273252
 0.95272883 0.95271498 0.95272826 0.95271907 0.95271139 0.95270981
 0.95271637 0.9527028 ]
[0.         0.34210526 0.        ]
-----------end of analyzing the loss ratio:74.24090909957886
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc047dc0>
---------------------------------
SparseEpoch: [47][1/398]	Time 0.605	Data 0.000	Loss 1.1601	
SparseEpoch: [47][101/398]	Time 0.630	Data 0.000	Loss 1.4319	
SparseEpoch: [47][201/398]	Time 0.626	Data 0.000	Loss 1.0379	
SparseEpoch: [47][301/398]	Time 0.624	Data 0.000	Loss 1.1432	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.74506683 0.7449109  0.74480899 0.74469127 0.74473883 0.74476181
 0.74466799 0.74470881 0.74460888 0.74463    0.74456194 0.74461424
 0.74451188 0.74444634 0.74437074 0.74440947 0.74435083 0.74425157
 0.74438182 0.74428477]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.74461628 0.74461148 0.7445885  0.74460925 0.74459806 0.74465115
 0.74466111 0.7445963  0.74458547 0.74457812 0.74457032 0.7445654
 0.74454936 0.74456773 0.74456428 0.74451425 0.7445378  0.74453659
 0.74453143 0.7445317 ]
[0.39473684 0.         0.28947368]
-----------end of analyzing the loss ratio:74.25522065162659
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc0464a0>
---------------------------------
SparseEpoch: [47][1/398]	Time 0.606	Data 0.000	Loss 1.7988	
SparseEpoch: [47][101/398]	Time 0.620	Data 0.000	Loss 2.3462	
SparseEpoch: [47][201/398]	Time 0.622	Data 0.000	Loss 1.5117	
SparseEpoch: [47][301/398]	Time 0.621	Data 0.000	Loss 1.5273	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.18000441 0.18000379 0.18006828 0.18004493 0.18003765 0.18003874
 0.18005554 0.18009647 0.18019088 0.18023234 0.18026453 0.18027717
 0.18032171 0.18030434 0.18033097 0.18035076 0.18036425 0.18037564
 0.18036646 0.1803405 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.18018205 0.18019084 0.18020366 0.18019907 0.18021657 0.18022617
 0.18022871 0.18023627 0.18026002 0.18026962 0.18026277 0.18027833
 0.18027666 0.18025868 0.18026916 0.18027408 0.18027638 0.18028513
 0.18030112 0.18030139]
[0. 0. 0.]
-----------end of analyzing the loss ratio:74.1144027709961
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7446096c7b80>
---------------------------------
SparseEpoch: [47][1/398]	Time 0.605	Data 0.000	Loss 1.9060	
SparseEpoch: [47][101/398]	Time 0.624	Data 0.000	Loss 1.9118	
SparseEpoch: [47][201/398]	Time 0.622	Data 0.000	Loss 1.4794	
SparseEpoch: [47][301/398]	Time 0.624	Data 0.000	Loss 1.3134	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.4767	
Epoch(adapt):{0} Loss 0.9733	
Epoch(adapt):{0} Loss 1.6833	
Epoch(adapt):{0} Loss 2.3969	
------------------the total time cost:1213.8309371471405
>>>>>meta updating
Epoch: 0047 | TRAIN: 0.8961 0.4265 0.6989 | 0.4542 0.4542 0.2229 | 0.1688 28.4745 24.2269 0.2159 0.4707 0.6095 ||TEST: 1.1319 0.3459 0.6317 | 0.5583 0.5583 0.2290 | 0.1653 28.2194 24.2504 0.2207 0.4714 0.6071 | 115.4951
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.81287313 0.81275766 0.81275923 0.81277156 0.81277435 0.81267266
 0.8125928  0.81261511 0.81264624 0.81263714 0.81258613 0.81253568
 0.81254876 0.81260177 0.8125336  0.81254829 0.81263568 0.81262746
 0.81267605 0.81265537]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.81260286 0.812592   0.81259759 0.81263224 0.81263874 0.81262426
 0.81261543 0.81261286 0.81261185 0.81261971 0.81261947 0.81262624
 0.81260154 0.81263584 0.8126497  0.81261547 0.81261553 0.81260749
 0.81260556 0.81260913]
[0.         0.23684211 0.        ]
-----------end of analyzing the loss ratio:74.15448522567749
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x744609940820>
---------------------------------
SparseEpoch: [48][1/398]	Time 0.627	Data 0.000	Loss 0.7159	
SparseEpoch: [48][101/398]	Time 0.622	Data 0.000	Loss 1.7932	
SparseEpoch: [48][201/398]	Time 0.622	Data 0.000	Loss 1.8366	
SparseEpoch: [48][301/398]	Time 0.623	Data 0.000	Loss 0.8969	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.79012778 0.79021187 0.79025373 0.7902752  0.79031634 0.79034073
 0.79026715 0.79023063 0.79018576 0.79021814 0.79027066 0.79022403
 0.79024898 0.7902549  0.79025983 0.79029527 0.79033332 0.7903144
 0.79027101 0.79032656]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.79021528 0.79019918 0.79016685 0.79015034 0.79014571 0.790167
 0.79017559 0.79018933 0.79020378 0.79022299 0.7902764  0.79029132
 0.7902852  0.79026856 0.79028082 0.790268   0.7902727  0.79028723
 0.79029979 0.79030824]
[0. 0. 0.]
-----------end of analyzing the loss ratio:74.1509313583374
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc534970>
---------------------------------
SparseEpoch: [48][1/398]	Time 0.666	Data 0.000	Loss 0.4909	
SparseEpoch: [48][101/398]	Time 0.620	Data 0.000	Loss 0.3327	
SparseEpoch: [48][201/398]	Time 0.620	Data 0.000	Loss 0.8679	
SparseEpoch: [48][301/398]	Time 0.623	Data 0.000	Loss 0.3364	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.24131848 0.24121288 0.24118118 0.24112924 0.2410728  0.24098011
 0.24091886 0.24089479 0.24086099 0.24080604 0.24076152 0.24068863
 0.24065114 0.24061604 0.24055532 0.24048356 0.24043888 0.24035994
 0.24031056 0.24019787]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.24085285 0.24084536 0.2408098  0.24081734 0.24080652 0.24079276
 0.24080694 0.24081191 0.24079041 0.24079793 0.24078391 0.24077169
 0.24076692 0.24076041 0.24077165 0.24075881 0.24074035 0.24072381
 0.24070544 0.24069285]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:74.22625279426575
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444dc12c790>
---------------------------------
SparseEpoch: [48][1/398]	Time 0.605	Data 0.000	Loss 2.6672	
SparseEpoch: [48][101/398]	Time 0.624	Data 0.000	Loss 2.4882	
SparseEpoch: [48][201/398]	Time 0.624	Data 0.000	Loss 2.8133	
SparseEpoch: [48][301/398]	Time 0.623	Data 0.000	Loss 2.1207	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.8330	
Epoch(adapt):{0} Loss 1.6450	
Epoch(adapt):{0} Loss 1.9246	
Epoch(adapt):{0} Loss 1.4119	
------------------the total time cost:1213.5506570339203
>>>>>meta updating
Epoch: 0048 | TRAIN: 0.9009 0.4266 0.7004 | 0.4686 0.4686 0.2248 | 0.1721 28.8313 24.5515 0.2101 0.4645 0.6029 ||TEST: 1.1136 0.3391 0.6343 | 0.5665 0.5665 0.2229 | 0.1692 28.6366 24.7108 0.2149 0.4621 0.5981 | 115.7655
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.86523454 0.86523656 0.86528015 0.86527383 0.86528279 0.86530856
 0.86531057 0.86530076 0.86527546 0.86521335 0.86520349 0.86517669
 0.86520513 0.8651671  0.86522301 0.865273   0.86530532 0.86526124
 0.86525517 0.86524215]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.8652054  0.86518729 0.86518972 0.86522068 0.86524327 0.86524155
 0.86521074 0.86521379 0.86518409 0.8651803  0.86520048 0.86520672
 0.8651848  0.86519871 0.86523004 0.86522239 0.86524402 0.86526377
 0.86532503 0.86533544]
[0.         0.18421053 0.        ]
-----------end of analyzing the loss ratio:74.28459239006042
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc1c5210>
---------------------------------
SparseEpoch: [49][1/398]	Time 0.608	Data 0.000	Loss 0.9025	
SparseEpoch: [49][101/398]	Time 0.630	Data 0.000	Loss 1.1721	
SparseEpoch: [49][201/398]	Time 0.627	Data 0.000	Loss 1.5062	
SparseEpoch: [49][301/398]	Time 0.626	Data 0.000	Loss 0.8952	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.85052092 0.85046564 0.85034216 0.85024483 0.85026433 0.85021637
 0.85025246 0.85039226 0.85033925 0.85031075 0.85027112 0.85031748
 0.85015942 0.85013978 0.85018961 0.85026004 0.85025141 0.85018349
 0.85014775 0.85010428]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.85036156 0.85032386 0.85033413 0.85034518 0.8503234  0.85030295
 0.85030427 0.85030343 0.85031036 0.85032242 0.85032923 0.85030936
 0.85027799 0.85028955 0.85027369 0.85026739 0.85026593 0.85026754
 0.85026194 0.85027997]
[0.5        0.         0.44736842]
-----------end of analyzing the loss ratio:74.3806414604187
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x744608169210>
---------------------------------
SparseEpoch: [49][1/398]	Time 0.606	Data 0.000	Loss 2.4416	
SparseEpoch: [49][101/398]	Time 0.622	Data 0.000	Loss 1.9307	
SparseEpoch: [49][201/398]	Time 0.623	Data 0.000	Loss 1.4572	
SparseEpoch: [49][301/398]	Time 0.622	Data 0.000	Loss 1.8290	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.17408738 0.17408879 0.17409092 0.17408393 0.17408822 0.17407173
 0.17407284 0.1740552  0.17405173 0.17404361 0.17402952 0.17404016
 0.17405117 0.17405658 0.17405567 0.17403712 0.17404523 0.17405873
 0.17407334 0.17407027]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.17407133 0.17406796 0.17406904 0.17407374 0.1740675  0.17407544
 0.17406226 0.17405188 0.17403959 0.1740327  0.17404    0.17405252
 0.17404388 0.17403269 0.17403587 0.17403666 0.17403729 0.17404798
 0.17404788 0.17404117]
[0.02631579 0.18421053 0.        ]
-----------end of analyzing the loss ratio:74.1618595123291
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7446081557b0>
---------------------------------
SparseEpoch: [49][1/398]	Time 0.608	Data 0.000	Loss 2.5668	
SparseEpoch: [49][101/398]	Time 0.625	Data 0.000	Loss 2.0724	
SparseEpoch: [49][201/398]	Time 0.624	Data 0.000	Loss 1.7606	
SparseEpoch: [49][301/398]	Time 0.623	Data 0.000	Loss 1.5518	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.7720	
Epoch(adapt):{0} Loss 1.4987	
Epoch(adapt):{0} Loss 1.3924	
Epoch(adapt):{0} Loss 1.8438	
------------------the total time cost:1214.676488161087
>>>>>meta updating
Epoch: 0049 | TRAIN: 0.8775 0.4415 0.7114 | 0.4623 0.4623 0.2111 | 0.1672 28.3577 24.1580 0.2157 0.4718 0.6114 ||TEST: 1.1252 0.3399 0.6296 | 0.5810 0.5810 0.2264 | 0.1669 28.4184 24.4730 0.2162 0.4672 0.6029 | 115.9184
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.85302106 0.85310856 0.85315512 0.85315539 0.85318278 0.85314821
 0.85312722 0.8531378  0.85327156 0.85328815 0.85340271 0.85342922
 0.85337045 0.85335554 0.85334761 0.85332921 0.85327317 0.85324093
 0.8532743  0.85334622]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.85349908 0.85346878 0.8534482  0.85345858 0.85345853 0.85347735
 0.85344853 0.8534295  0.85339617 0.85333285 0.85329572 0.85326269
 0.85325978 0.85323669 0.85320734 0.85322013 0.85321863 0.85321583
 0.85318918 0.85313085]
[0.  0.  0.5]
-----------end of analyzing the loss ratio:74.49338579177856
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc58f010>
---------------------------------
SparseEpoch: [50][1/398]	Time 0.606	Data 0.000	Loss 1.8644	
SparseEpoch: [50][101/398]	Time 0.627	Data 0.000	Loss 2.8004	
SparseEpoch: [50][201/398]	Time 0.627	Data 0.000	Loss 2.4077	
SparseEpoch: [50][301/398]	Time 0.627	Data 0.000	Loss 2.4838	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.78041504 0.78026473 0.7801705  0.7801111  0.78016447 0.77999591
 0.77968535 0.77925934 0.77912778 0.77893375 0.77872782 0.77854992
 0.7785016  0.77837213 0.77821015 0.77809761 0.77791347 0.77781025
 0.77759562 0.77754043]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.77893437 0.7789208  0.77891012 0.77886378 0.77885965 0.77884774
 0.7788484  0.77881724 0.77881333 0.77879768 0.77874484 0.77874795
 0.77872145 0.77874976 0.77870782 0.7787242  0.77871876 0.77873409
 0.77873093 0.77869396]
[0.5 0.  0.5]
-----------end of analyzing the loss ratio:74.540611743927
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444dc3b67d0>
---------------------------------
SparseEpoch: [50][1/398]	Time 0.605	Data 0.000	Loss 2.2046	
SparseEpoch: [50][101/398]	Time 0.621	Data 0.000	Loss 2.7737	
SparseEpoch: [50][201/398]	Time 0.623	Data 0.000	Loss 1.4983	
SparseEpoch: [50][301/398]	Time 0.624	Data 0.000	Loss 2.5792	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.18404188 0.18398332 0.18396906 0.18393131 0.18393074 0.18384942
 0.18375772 0.18366374 0.18360554 0.18363073 0.1835632  0.18349653
 0.18342501 0.18340502 0.18329974 0.18327722 0.18320413 0.18314211
 0.18315812 0.18310189]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.18364195 0.18362169 0.18360054 0.18360522 0.18359767 0.18360319
 0.18361492 0.18361444 0.18361166 0.18361179 0.18359038 0.18356214
 0.18352373 0.18353018 0.18353052 0.18352289 0.18351152 0.18346062
 0.18344463 0.18344032]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:74.36155319213867
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc472860>
---------------------------------
SparseEpoch: [50][1/398]	Time 0.605	Data 0.000	Loss 2.9814	
SparseEpoch: [50][101/398]	Time 0.623	Data 0.000	Loss 1.5815	
SparseEpoch: [50][201/398]	Time 0.626	Data 0.000	Loss 2.1613	
SparseEpoch: [50][301/398]	Time 0.625	Data 0.000	Loss 2.0318	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.5103	
Epoch(adapt):{0} Loss 1.4372	
Epoch(adapt):{0} Loss 1.2145	
Epoch(adapt):{0} Loss 2.1070	
------------------the total time cost:1217.7470734119415
>>>>>meta updating
Epoch: 0050 | TRAIN: 0.8666 0.4362 0.7109 | 0.4569 0.4569 0.2131 | 0.1618 27.6364 23.0542 0.2295 0.4943 0.6326 ||TEST: 1.1057 0.3419 0.6363 | 0.5744 0.5744 0.2274 | 0.1611 27.6811 23.4155 0.2307 0.4873 0.6224 | 115.7946
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.71951447 0.71954788 0.71957555 0.71960171 0.71958808 0.71956774
 0.71952952 0.71956414 0.71958335 0.71958582 0.7196364  0.71969064
 0.71969147 0.71970392 0.71973234 0.71979564 0.71981578 0.71978671
 0.71977982 0.71981816]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.71971955 0.71972795 0.7196766  0.71966711 0.71965948 0.71963892
 0.71963258 0.71963065 0.7196181  0.71958586 0.71958203 0.71957329
 0.71959124 0.71959403 0.7196033  0.71957923 0.71960464 0.71960107
 0.71957332 0.71955741]
[0.  0.  0.5]
-----------end of analyzing the loss ratio:74.3263692855835
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7446091a1f30>
---------------------------------
SparseEpoch: [51][1/398]	Time 0.608	Data 0.000	Loss 1.8021	
SparseEpoch: [51][101/398]	Time 0.625	Data 0.000	Loss 2.0414	
SparseEpoch: [51][201/398]	Time 0.625	Data 0.000	Loss 1.3460	
SparseEpoch: [51][301/398]	Time 0.625	Data 0.000	Loss 2.2105	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.87048825 0.87045984 0.87028294 0.87013288 0.87003545 0.8699493
 0.86978326 0.86964297 0.86954766 0.86918032 0.86901194 0.86885453
 0.8685649  0.86840972 0.86821941 0.8679978  0.86780847 0.86763259
 0.8674254  0.867237  ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.86932164 0.86932055 0.86928425 0.86919539 0.86917745 0.86920886
 0.86917017 0.86915589 0.86911002 0.86904996 0.86906227 0.86905237
 0.86901662 0.86900409 0.86899061 0.86902105 0.86902353 0.86900559
 0.86898988 0.8689639 ]
[0.5 0.  0.5]
-----------end of analyzing the loss ratio:74.41810035705566
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x744609647cd0>
---------------------------------
SparseEpoch: [51][1/398]	Time 0.607	Data 0.000	Loss 1.8598	
SparseEpoch: [51][101/398]	Time 0.621	Data 0.000	Loss 2.1358	
SparseEpoch: [51][201/398]	Time 0.622	Data 0.000	Loss 1.2810	
SparseEpoch: [51][301/398]	Time 0.622	Data 0.000	Loss 1.3997	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.20031933 0.20025647 0.2002058  0.20020522 0.20017787 0.20010033
 0.20009251 0.20002611 0.19997169 0.19990566 0.1998594  0.19977229
 0.19967808 0.19963478 0.19962304 0.1995994  0.19961032 0.19952117
 0.19944028 0.19939898]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.19998531 0.19999328 0.19997837 0.19996349 0.19996473 0.19994333
 0.19995641 0.19994536 0.19990914 0.19987037 0.19986649 0.19984356
 0.19978787 0.19978082 0.19975736 0.19974174 0.19971125 0.19968981
 0.19967298 0.19968272]
[0.5        0.44736842 0.        ]
-----------end of analyzing the loss ratio:74.40550684928894
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc12eaa0>
---------------------------------
SparseEpoch: [51][1/398]	Time 0.688	Data 0.000	Loss 1.6297	
SparseEpoch: [51][101/398]	Time 0.630	Data 0.000	Loss 2.4819	
SparseEpoch: [51][201/398]	Time 0.627	Data 0.000	Loss 3.9755	
SparseEpoch: [51][301/398]	Time 0.626	Data 0.000	Loss 2.0856	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.3322	
Epoch(adapt):{0} Loss 1.1027	
Epoch(adapt):{0} Loss 2.3372	
Epoch(adapt):{0} Loss 1.2094	
------------------the total time cost:1215.6858539581299
>>>>>meta updating
Epoch: 0051 | TRAIN: 0.8644 0.4355 0.7099 | 0.4562 0.4562 0.2231 | 0.1615 27.7021 23.2716 0.2254 0.4897 0.6287 ||TEST: 1.1123 0.3448 0.6369 | 0.5595 0.5595 0.2266 | 0.1613 27.7873 23.6601 0.2259 0.4831 0.6189 | 115.3371
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.79716996 0.79718676 0.79725652 0.79725153 0.79723329 0.79722824
 0.79715104 0.79709822 0.79709069 0.79704986 0.79699214 0.79693335
 0.79692868 0.79696168 0.79688562 0.79681844 0.79681103 0.79687724
 0.79679787 0.79674272]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.79707819 0.79705829 0.79708201 0.79707756 0.79702561 0.79701948
 0.79699332 0.79701449 0.79702293 0.79705632 0.79706714 0.79706299
 0.79705532 0.79701326 0.79701542 0.79700691 0.79694371 0.79694691
 0.79696234 0.79694304]
[0.  0.5 0.5]
-----------end of analyzing the loss ratio:74.21519708633423
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc0449d0>
---------------------------------
SparseEpoch: [52][1/398]	Time 0.776	Data 0.000	Loss 2.1187	
SparseEpoch: [52][101/398]	Time 0.628	Data 0.000	Loss 2.4060	
SparseEpoch: [52][201/398]	Time 0.625	Data 0.000	Loss 2.2354	
SparseEpoch: [52][301/398]	Time 0.623	Data 0.000	Loss 1.8237	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.61202115 0.61178586 0.61140006 0.61119592 0.61107017 0.6107711
 0.61063266 0.61049602 0.61040797 0.61015285 0.60998214 0.60995783
 0.60977464 0.6097337  0.60963744 0.60963892 0.60963599 0.60955232
 0.60942511 0.60920474]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.61037857 0.61043864 0.61038873 0.61030047 0.61024031 0.61012874
 0.61013514 0.61019978 0.61015505 0.61020344 0.61014927 0.61012
 0.61000552 0.60992916 0.60992635 0.60991299 0.60987419 0.60989726
 0.60996728 0.60989326]
[0.5        0.         0.34210526]
-----------end of analyzing the loss ratio:74.21560144424438
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc2f6200>
---------------------------------
SparseEpoch: [52][1/398]	Time 0.612	Data 0.000	Loss 2.3102	
SparseEpoch: [52][101/398]	Time 0.625	Data 0.000	Loss 1.9483	
SparseEpoch: [52][201/398]	Time 0.626	Data 0.000	Loss 2.2635	
SparseEpoch: [52][301/398]	Time 0.626	Data 0.000	Loss 1.7219	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.17578775 0.17575969 0.1757506  0.17574936 0.17575336 0.17575676
 0.17575148 0.17572392 0.17571027 0.17572845 0.17569872 0.17574197
 0.17572615 0.17574642 0.17575429 0.17573828 0.17571567 0.17572206
 0.17568716 0.1756849 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.17579845 0.17579117 0.17581472 0.17580919 0.17577342 0.17576698
 0.17574857 0.17573992 0.17574937 0.17572981 0.17570992 0.17571632
 0.17572476 0.17572809 0.17573209 0.17574995 0.17574255 0.17573313
 0.17572606 0.1757084 ]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:74.36151599884033
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc42f550>
---------------------------------
SparseEpoch: [52][1/398]	Time 0.610	Data 0.000	Loss 2.5645	
SparseEpoch: [52][101/398]	Time 0.631	Data 0.000	Loss 1.9837	
SparseEpoch: [52][201/398]	Time 0.626	Data 0.000	Loss 2.9911	
SparseEpoch: [52][301/398]	Time 0.625	Data 0.000	Loss 3.3657	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.7524	
Epoch(adapt):{0} Loss 1.1085	
Epoch(adapt):{0} Loss 1.3344	
Epoch(adapt):{0} Loss 1.2361	
------------------the total time cost:1216.0124745368958
>>>>>meta updating
Epoch: 0052 | TRAIN: 0.8564 0.4592 0.7182 | 0.4439 0.4439 0.2066 | 0.1606 27.5952 23.1547 0.2265 0.4933 0.6316 ||TEST: 1.1173 0.3537 0.6380 | 0.5705 0.5705 0.2263 | 0.1610 27.7474 23.5763 0.2256 0.4844 0.6208 | 115.8661
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.88482324 0.8848671  0.88499002 0.88490066 0.88499953 0.88507737
 0.8852994  0.88534805 0.88523523 0.88521022 0.88524108 0.88527982
 0.88535842 0.88552039 0.88566061 0.88566045 0.88572536 0.88573772
 0.8858912  0.88591971]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.88514543 0.88515655 0.88516176 0.88516311 0.88517742 0.88519928
 0.88521795 0.88527023 0.8852464  0.88522264 0.88523348 0.88525621
 0.88525249 0.88523056 0.88524859 0.88523638 0.88524074 0.88521653
 0.88523041 0.88518593]
[0. 0. 0.]
-----------end of analyzing the loss ratio:74.48338317871094
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d7047bb0>
---------------------------------
SparseEpoch: [53][1/398]	Time 0.610	Data 0.000	Loss 1.0702	
SparseEpoch: [53][101/398]	Time 0.623	Data 0.000	Loss 1.0966	
SparseEpoch: [53][201/398]	Time 0.623	Data 0.000	Loss 1.2581	
SparseEpoch: [53][301/398]	Time 0.623	Data 0.000	Loss 1.0589	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.99438007 0.99432965 0.99422632 0.9943147  0.99441037 0.99442975
 0.99439346 0.99428386 0.99434478 0.99436709 0.99442598 0.99448254
 0.9944795  0.99443665 0.99432043 0.99437752 0.99438747 0.99441269
 0.99452273 0.99455773]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.99436755 0.99437513 0.99437609 0.99438035 0.9943505  0.99433422
 0.99435289 0.99434662 0.9943242  0.9943294  0.99432939 0.99434353
 0.99436201 0.99438007 0.99435346 0.9943568  0.99435204 0.99434326
 0.99433289 0.99433988]
[0. 0. 0.]
-----------end of analyzing the loss ratio:74.55027484893799
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d734c2e0>
---------------------------------
SparseEpoch: [53][1/398]	Time 0.604	Data 0.000	Loss 0.4512	
SparseEpoch: [53][101/398]	Time 0.623	Data 0.000	Loss 0.3191	
SparseEpoch: [53][201/398]	Time 0.624	Data 0.000	Loss 0.7140	
SparseEpoch: [53][301/398]	Time 0.622	Data 0.000	Loss 0.6038	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.15346376 0.15333198 0.15326856 0.15326405 0.15317312 0.15320357
 0.15320493 0.15320897 0.15321411 0.15319374 0.15318142 0.15320077
 0.15319268 0.1531194  0.1530128  0.15299212 0.15294844 0.15292386
 0.1528273  0.15278968]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.15329682 0.15329707 0.15334802 0.15330735 0.15328674 0.15327502
 0.15326422 0.15321038 0.15318306 0.15322815 0.15321463 0.15319106
 0.15318699 0.15313401 0.15312388 0.15311586 0.1531242  0.15312178
 0.15313233 0.15309127]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:74.41646671295166
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d722e6b0>
---------------------------------
SparseEpoch: [53][1/398]	Time 0.606	Data 0.000	Loss 1.6838	
SparseEpoch: [53][101/398]	Time 0.628	Data 0.000	Loss 2.8886	
SparseEpoch: [53][201/398]	Time 0.628	Data 0.000	Loss 2.5833	
SparseEpoch: [53][301/398]	Time 0.627	Data 0.000	Loss 2.7868	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.7814	
Epoch(adapt):{0} Loss 1.2143	
Epoch(adapt):{0} Loss 1.5231	
Epoch(adapt):{0} Loss 1.3166	
------------------the total time cost:1216.222897052765
>>>>>meta updating
Epoch: 0053 | TRAIN: 0.8516 0.4580 0.7194 | 0.4667 0.4667 0.2127 | 0.1639 27.9796 23.6937 0.2196 0.4815 0.6230 ||TEST: 1.1112 0.3419 0.6389 | 0.5858 0.5858 0.2229 | 0.1630 27.9869 23.9700 0.2218 0.4766 0.6141 | 115.9742
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.86106556 0.86101058 0.86100126 0.86099463 0.86105919 0.86110372
 0.86114941 0.86120577 0.86118627 0.86123883 0.86120759 0.86121204
 0.86129352 0.86130229 0.8613348  0.86134845 0.86133389 0.86138155
 0.86144986 0.86147228]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.86117795 0.86118988 0.86117937 0.86122231 0.86123926 0.86124389
 0.86125242 0.8612355  0.86125124 0.86124855 0.86126218 0.86123598
 0.86122634 0.8612148  0.86120263 0.86119848 0.86115156 0.86114616
 0.86112669 0.8611066 ]
[0.  0.  0.5]
-----------end of analyzing the loss ratio:74.36211562156677
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc5fec20>
---------------------------------
SparseEpoch: [54][1/398]	Time 0.614	Data 0.000	Loss 1.9706	
SparseEpoch: [54][101/398]	Time 0.625	Data 0.000	Loss 1.5788	
SparseEpoch: [54][201/398]	Time 0.626	Data 0.000	Loss 1.6426	
SparseEpoch: [54][301/398]	Time 0.625	Data 0.000	Loss 2.1531	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.64576413 0.64523967 0.64489576 0.64438085 0.64396431 0.64349802
 0.64304092 0.64263573 0.64218552 0.64175961 0.64129057 0.64073178
 0.64013122 0.63969026 0.63914594 0.63855352 0.63810292 0.6376861
 0.6374475  0.63700437]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.64182381 0.64188003 0.64180305 0.64171668 0.64171599 0.64160121
 0.64154115 0.64151621 0.64153406 0.64149355 0.64146976 0.64144475
 0.64141438 0.64134431 0.64128725 0.64127602 0.64125281 0.64123785
 0.64117415 0.64108382]
[0.5 0.  0.5]
-----------end of analyzing the loss ratio:74.29834222793579
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444dc341a20>
---------------------------------
SparseEpoch: [54][1/398]	Time 0.606	Data 0.000	Loss 1.9526	
SparseEpoch: [54][101/398]	Time 0.626	Data 0.000	Loss 2.1538	
SparseEpoch: [54][201/398]	Time 0.624	Data 0.000	Loss 1.6624	
SparseEpoch: [54][301/398]	Time 0.626	Data 0.000	Loss 1.8342	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.20093696 0.20085458 0.20077606 0.20078625 0.20072595 0.20066398
 0.2005981  0.20056942 0.20052528 0.20044929 0.20036083 0.20031275
 0.20028962 0.2002396  0.20014563 0.20007146 0.20004422 0.19995605
 0.19991091 0.19987103]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.20067027 0.2006393  0.20060545 0.20060039 0.20057415 0.20054435
 0.20054368 0.20050656 0.20046908 0.20042874 0.20037379 0.20032135
 0.20029653 0.20029426 0.20030202 0.20028203 0.20026048 0.20024108
 0.20017996 0.20016223]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:74.20766806602478
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc56e4d0>
---------------------------------
SparseEpoch: [54][1/398]	Time 0.609	Data 0.000	Loss 2.2832	
SparseEpoch: [54][101/398]	Time 0.629	Data 0.000	Loss 1.4069	
SparseEpoch: [54][201/398]	Time 0.628	Data 0.000	Loss 2.6759	
SparseEpoch: [54][301/398]	Time 0.626	Data 0.000	Loss 1.6879	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 2.1292	
Epoch(adapt):{0} Loss 1.8602	
Epoch(adapt):{0} Loss 1.3137	
Epoch(adapt):{0} Loss 1.2592	
------------------the total time cost:1218.1438779830933
>>>>>meta updating
Epoch: 0054 | TRAIN: 0.8112 0.4675 0.7300 | 0.4382 0.4382 0.2163 | 0.1568 27.0519 22.4548 0.2408 0.5082 0.6443 ||TEST: 1.1142 0.3561 0.6415 | 0.5491 0.5491 0.2253 | 0.1578 27.3080 23.0666 0.2384 0.4953 0.6295 | 116.0951
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.99721597 0.99708362 0.99709889 0.99706621 0.99698431 0.99705397
 0.99698805 0.99702163 0.99706039 0.99708486 0.99708018 0.99703602
 0.99701529 0.99699889 0.99696662 0.99706357 0.99695947 0.99698818
 0.99699276 0.99707056]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.99706975 0.99707761 0.99707503 0.99709398 0.99705197 0.99708941
 0.99707546 0.99708826 0.99708227 0.997101   0.997073   0.99708171
 0.99705609 0.997057   0.99705747 0.99702787 0.99702557 0.9970233
 0.9970203  0.99700956]
[0.         0.34210526 0.5       ]
-----------end of analyzing the loss ratio:74.3677613735199
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444dc31b2b0>
---------------------------------
SparseEpoch: [55][1/398]	Time 0.611	Data 0.000	Loss 1.8392	
SparseEpoch: [55][101/398]	Time 0.624	Data 0.000	Loss 1.2861	
SparseEpoch: [55][201/398]	Time 0.627	Data 0.000	Loss 2.4049	
SparseEpoch: [55][301/398]	Time 0.625	Data 0.000	Loss 1.8617	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.46694643 0.46679969 0.46660524 0.46655438 0.46652824 0.46640884
 0.46632996 0.46628937 0.46622527 0.46627324 0.46617961 0.4660775
 0.46592342 0.46583484 0.46554514 0.46551023 0.46538876 0.46528232
 0.46526194 0.46510727]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.4662332  0.46624533 0.46624322 0.46622784 0.46620873 0.4662202
 0.46620957 0.46618261 0.4661774  0.46616501 0.46613412 0.4661331
 0.46614268 0.46617173 0.4661673  0.46618593 0.46619231 0.46617149
 0.4661581  0.46613117]
[0.5 0.  0.5]
-----------end of analyzing the loss ratio:74.34634208679199
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc5ebc70>
---------------------------------
SparseEpoch: [55][1/398]	Time 0.608	Data 0.000	Loss 1.6900	
SparseEpoch: [55][101/398]	Time 0.627	Data 0.000	Loss 2.4100	
SparseEpoch: [55][201/398]	Time 0.625	Data 0.000	Loss 1.5140	
SparseEpoch: [55][301/398]	Time 0.625	Data 0.000	Loss 2.6256	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.18316709 0.18315453 0.18314726 0.18315586 0.18314524 0.18312668
 0.18312032 0.18311968 0.18310922 0.18309985 0.18310047 0.1831068
 0.18311605 0.1831199  0.18312954 0.18313501 0.18313113 0.18313847
 0.18313979 0.18313586]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.18315083 0.18314486 0.18315688 0.18315586 0.18314705 0.18314314
 0.18312534 0.18312142 0.18311995 0.18309793 0.18309516 0.18311915
 0.18313034 0.18312244 0.18311486 0.18311118 0.18308901 0.18310487
 0.18310003 0.18311913]
[0.         0.34210526 0.        ]
-----------end of analyzing the loss ratio:74.38512992858887
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d72d3970>
---------------------------------
SparseEpoch: [55][1/398]	Time 0.605	Data 0.000	Loss 1.5562	
SparseEpoch: [55][101/398]	Time 0.624	Data 0.000	Loss 2.8978	
SparseEpoch: [55][201/398]	Time 0.625	Data 0.000	Loss 1.7667	
SparseEpoch: [55][301/398]	Time 0.624	Data 0.000	Loss 1.3745	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.4555	
Epoch(adapt):{0} Loss 0.9658	
Epoch(adapt):{0} Loss 1.1414	
Epoch(adapt):{0} Loss 1.2933	
------------------the total time cost:1217.7076215744019
>>>>>meta updating
Epoch: 0055 | TRAIN: 0.8241 0.4646 0.7279 | 0.4332 0.4332 0.2100 | 0.1547 26.8054 22.0669 0.2465 0.5142 0.6494 ||TEST: 1.1208 0.3531 0.6412 | 0.5550 0.5550 0.2292 | 0.1570 27.1792 22.7949 0.2417 0.4998 0.6336 | 115.8241
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.78471509 0.78471334 0.7847175  0.7847618  0.78458985 0.78465887
 0.78471321 0.78476652 0.78483037 0.78479657 0.78479357 0.78483169
 0.78485497 0.78480942 0.78481518 0.7847314  0.78461225 0.78459662
 0.78451872 0.78449458]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.7846974  0.78471526 0.78474892 0.78471718 0.78472359 0.78472185
 0.78470786 0.78474974 0.78477741 0.78476615 0.7847557  0.78477034
 0.78478611 0.78491967 0.78498221 0.78491316 0.78494315 0.78491732
 0.78492389 0.78489486]
[0.  0.5 0. ]
-----------end of analyzing the loss ratio:74.38651776313782
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444dc2b8790>
---------------------------------
SparseEpoch: [56][1/398]	Time 0.606	Data 0.000	Loss 0.9878	
SparseEpoch: [56][101/398]	Time 0.623	Data 0.000	Loss 1.2609	
SparseEpoch: [56][201/398]	Time 0.625	Data 0.000	Loss 1.1520	
SparseEpoch: [56][301/398]	Time 0.626	Data 0.000	Loss 1.6786	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.56601809 0.56574731 0.56534992 0.56523514 0.56521716 0.5649737
 0.56460715 0.56448308 0.56433011 0.56414669 0.56414133 0.56406766
 0.56382808 0.56352899 0.56339025 0.5632667  0.5631564  0.56295426
 0.5626988  0.56261751]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.56415414 0.56415049 0.56413532 0.564117   0.56410943 0.5641055
 0.56412671 0.56409417 0.56407162 0.56404656 0.56405931 0.56405127
 0.56404752 0.56407066 0.56410654 0.56412982 0.5641649  0.56418926
 0.5641758  0.56416715]
[0.5 0.  0. ]
-----------end of analyzing the loss ratio:74.27609086036682
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444dc3191b0>
---------------------------------
SparseEpoch: [56][1/398]	Time 0.608	Data 0.000	Loss 1.2269	
SparseEpoch: [56][101/398]	Time 0.625	Data 0.000	Loss 0.9522	
SparseEpoch: [56][201/398]	Time 0.624	Data 0.000	Loss 1.0987	
SparseEpoch: [56][301/398]	Time 0.624	Data 0.000	Loss 1.1237	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.16702341 0.16706604 0.16700194 0.16702228 0.16704854 0.1670632
 0.16708682 0.16704696 0.16706806 0.16709204 0.16708645 0.1670679
 0.16704653 0.16707381 0.1670571  0.16701241 0.16700023 0.16698989
 0.16696765 0.16694345]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.16711214 0.16709093 0.16710668 0.16710269 0.16710883 0.1671093
 0.16711218 0.16708521 0.16706834 0.16707621 0.16707457 0.1670732
 0.16707439 0.1670781  0.16705703 0.16704137 0.1670217  0.16703498
 0.1670463  0.16704694]
[0.5        0.34210526 0.        ]
-----------end of analyzing the loss ratio:74.45917582511902
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x744609944670>
---------------------------------
SparseEpoch: [56][1/398]	Time 0.606	Data 0.000	Loss 2.3960	
SparseEpoch: [56][101/398]	Time 0.624	Data 0.000	Loss 2.0254	
SparseEpoch: [56][201/398]	Time 0.623	Data 0.000	Loss 2.4479	
SparseEpoch: [56][301/398]	Time 0.622	Data 0.000	Loss 3.2457	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 2.2014	
Epoch(adapt):{0} Loss 1.2705	
Epoch(adapt):{0} Loss 1.6096	
Epoch(adapt):{0} Loss 1.5400	
------------------the total time cost:1215.935779094696
>>>>>meta updating
Epoch: 0056 | TRAIN: 0.8044 0.4727 0.7312 | 0.4254 0.4254 0.2092 | 0.1652 28.1773 23.9881 0.2158 0.4752 0.6162 ||TEST: 1.1262 0.3606 0.6386 | 0.5463 0.5463 0.2207 | 0.1658 28.3718 24.5630 0.2159 0.4647 0.6018 | 115.6897
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.72270539 0.72270172 0.72270915 0.7226265  0.72256563 0.72252165
 0.72254356 0.72252769 0.72245674 0.72239097 0.72244331 0.72245432
 0.72246199 0.72241797 0.72237418 0.72234425 0.72232727 0.72237079
 0.72241838 0.72241554]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.72246113 0.72244253 0.72244572 0.72247278 0.72245245 0.72247051
 0.72245512 0.72243441 0.72241534 0.72242381 0.72242614 0.72243753
 0.72245272 0.72243457 0.72239593 0.72241203 0.72240829 0.72239954
 0.72239572 0.72239999]
[0.         0.34210526 0.44736842]
-----------end of analyzing the loss ratio:74.38905215263367
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc128940>
---------------------------------
SparseEpoch: [57][1/398]	Time 0.609	Data 0.000	Loss 1.6206	
SparseEpoch: [57][101/398]	Time 0.626	Data 0.000	Loss 1.4044	
SparseEpoch: [57][201/398]	Time 0.626	Data 0.000	Loss 2.4525	
SparseEpoch: [57][301/398]	Time 0.627	Data 0.000	Loss 2.1101	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.56291238 0.56241911 0.56179093 0.56119603 0.56056501 0.559866
 0.55942372 0.5586934  0.55795208 0.55741662 0.55684514 0.5564515
 0.55600299 0.55537469 0.55470192 0.55399576 0.5534985  0.55304729
 0.55255924 0.55189396]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.55720457 0.55719309 0.55720867 0.55722278 0.55723594 0.55718768
 0.55718862 0.55717811 0.55717072 0.55716238 0.55713129 0.55709914
 0.55708609 0.5570788  0.55703217 0.5570282  0.55701777 0.55702391
 0.55700695 0.5569826 ]
[0.5 0.  0.5]
-----------end of analyzing the loss ratio:74.49940013885498
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7446099460b0>
---------------------------------
SparseEpoch: [57][1/398]	Time 0.613	Data 0.000	Loss 1.5044	
SparseEpoch: [57][101/398]	Time 0.622	Data 0.000	Loss 2.0340	
SparseEpoch: [57][201/398]	Time 0.623	Data 0.000	Loss 2.2692	
SparseEpoch: [57][301/398]	Time 0.623	Data 0.000	Loss 1.5244	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.20304585 0.20296467 0.20292577 0.20290787 0.20288204 0.20285433
 0.20286776 0.20281243 0.20276625 0.2027266  0.20267575 0.20263206
 0.2025599  0.20251192 0.20247871 0.20243317 0.20237964 0.20230986
 0.20224121 0.20218998]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.20277731 0.20276566 0.20275766 0.20274004 0.20274504 0.20275451
 0.20274571 0.20273612 0.20273267 0.20272387 0.20270107 0.2026908
 0.20267474 0.20268297 0.20268666 0.20268236 0.20267626 0.20265493
 0.20265172 0.20263451]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:74.32676959037781
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d73242e0>
---------------------------------
SparseEpoch: [57][1/398]	Time 0.606	Data 0.000	Loss 1.7727	
SparseEpoch: [57][101/398]	Time 0.623	Data 0.000	Loss 2.5240	
SparseEpoch: [57][201/398]	Time 0.623	Data 0.000	Loss 1.6804	
SparseEpoch: [57][301/398]	Time 0.623	Data 0.000	Loss 1.9872	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 2.1294	
Epoch(adapt):{0} Loss 1.3745	
Epoch(adapt):{0} Loss 1.1759	
Epoch(adapt):{0} Loss 1.2446	
------------------the total time cost:1216.8848662376404
>>>>>meta updating
Epoch: 0057 | TRAIN: 0.8109 0.4713 0.7299 | 0.4269 0.4269 0.2029 | 0.1591 27.3664 22.7891 0.2338 0.5003 0.6370 ||TEST: 1.1233 0.3536 0.6399 | 0.5580 0.5580 0.2225 | 0.1596 27.5719 23.3350 0.2305 0.4897 0.6242 | 115.8429
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.9487801  0.94890178 0.94878751 0.94871281 0.94882526 0.9488628
 0.94894571 0.9490052  0.94912904 0.94920273 0.94919289 0.94928681
 0.94938545 0.94936345 0.94954126 0.94953668 0.9495306  0.94954203
 0.94970765 0.94975137]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.94910281 0.94909558 0.94911024 0.94912063 0.94916193 0.94916542
 0.94919909 0.94922544 0.94921999 0.9492358  0.94921235 0.94919679
 0.94921463 0.94922076 0.94921691 0.94923444 0.94922861 0.94925817
 0.94926105 0.94920606]
[0. 0. 0.]
-----------end of analyzing the loss ratio:74.55314826965332
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc1295a0>
---------------------------------
SparseEpoch: [58][1/398]	Time 0.603	Data 0.000	Loss 0.6128	
SparseEpoch: [58][101/398]	Time 0.626	Data 0.000	Loss 0.9253	
SparseEpoch: [58][201/398]	Time 0.624	Data 0.000	Loss 0.8831	
SparseEpoch: [58][301/398]	Time 0.624	Data 0.000	Loss 0.4716	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.78438394 0.78436431 0.78411847 0.78400552 0.78383067 0.78392309
 0.78378662 0.78373648 0.78354083 0.78321094 0.78298233 0.78297147
 0.78292688 0.78275628 0.78266779 0.78253506 0.78232604 0.78227503
 0.78195896 0.78183696]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.78317067 0.78315215 0.78315446 0.78313887 0.78312493 0.78311817
 0.78309458 0.78303744 0.78303091 0.78300735 0.78301187 0.78301488
 0.783016   0.78307593 0.78308559 0.78310616 0.78313301 0.7831432
 0.78311072 0.78310341]
[0.5 0.  0. ]
-----------end of analyzing the loss ratio:74.45551252365112
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x744608138670>
---------------------------------
SparseEpoch: [58][1/398]	Time 0.606	Data 0.000	Loss 0.7522	
SparseEpoch: [58][101/398]	Time 0.624	Data 0.000	Loss 1.0703	
SparseEpoch: [58][201/398]	Time 0.624	Data 0.000	Loss 0.9342	
SparseEpoch: [58][301/398]	Time 0.624	Data 0.000	Loss 0.8795	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.18211433 0.18214546 0.1821326  0.18209522 0.18205656 0.18206537
 0.18201967 0.18195429 0.18191692 0.18189546 0.18186159 0.18176574
 0.18175926 0.18177754 0.18170515 0.1816585  0.18169761 0.18164464
 0.18163059 0.18153311]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.18204415 0.18203001 0.18197489 0.18197027 0.18197036 0.18195738
 0.18190932 0.18188568 0.18188165 0.18187268 0.18185381 0.18184918
 0.18179363 0.18181164 0.18178734 0.18177952 0.18176444 0.18176438
 0.1817592  0.18174254]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:74.55704474449158
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc42c7f0>
---------------------------------
SparseEpoch: [58][1/398]	Time 0.605	Data 0.000	Loss 2.5658	
SparseEpoch: [58][101/398]	Time 0.626	Data 0.000	Loss 2.7888	
SparseEpoch: [58][201/398]	Time 0.625	Data 0.000	Loss 2.7520	
SparseEpoch: [58][301/398]	Time 0.625	Data 0.000	Loss 2.4264	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.5764	
Epoch(adapt):{0} Loss 2.1816	
Epoch(adapt):{0} Loss 2.8440	
Epoch(adapt):{0} Loss 1.4576	
------------------the total time cost:1216.583794593811
>>>>>meta updating
Epoch: 0058 | TRAIN: 0.7705 0.4910 0.7433 | 0.4256 0.4256 0.2137 | 0.1614 27.6854 23.3726 0.2281 0.4871 0.6259 ||TEST: 1.1109 0.3693 0.6451 | 0.5468 0.5468 0.2291 | 0.1630 27.9716 23.9554 0.2247 0.4768 0.6129 | 115.7179
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.64621601 0.64616433 0.6461038  0.64604812 0.64598288 0.64594623
 0.64585088 0.64584671 0.64577963 0.64592227 0.64592643 0.64586401
 0.64582612 0.6458457  0.64583179 0.64589131 0.64584783 0.64581906
 0.64573769 0.6456865 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.64606153 0.64604214 0.64600113 0.64597368 0.64597012 0.64593421
 0.64591721 0.645916   0.64589272 0.6459285  0.64589674 0.64586836
 0.64583321 0.64579517 0.64577095 0.64579302 0.64580915 0.64582852
 0.64579547 0.64579374]
[0.         0.5        0.23684211]
-----------end of analyzing the loss ratio:74.35448408126831
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc047a00>
---------------------------------
SparseEpoch: [59][1/398]	Time 0.606	Data 0.000	Loss 1.5677	
SparseEpoch: [59][101/398]	Time 0.626	Data 0.000	Loss 1.3800	
SparseEpoch: [59][201/398]	Time 0.626	Data 0.000	Loss 1.4480	
SparseEpoch: [59][301/398]	Time 0.624	Data 0.000	Loss 1.5397	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.62759777 0.62740197 0.62730051 0.62717575 0.62716229 0.62722454
 0.62708238 0.62691851 0.62694786 0.62685002 0.62690703 0.62689478
 0.62690225 0.62686959 0.62689076 0.62676172 0.62692936 0.6269009
 0.62683701 0.62677866]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.62695321 0.62703318 0.62703352 0.6269721  0.62692239 0.62688166
 0.62683996 0.62687871 0.62684718 0.62687488 0.62686752 0.62690462
 0.62691905 0.62687618 0.62696103 0.62693957 0.62694343 0.62691312
 0.62693289 0.62691257]
[0.28947368 0.         0.        ]
-----------end of analyzing the loss ratio:74.44791150093079
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d7325bd0>
---------------------------------
SparseEpoch: [59][1/398]	Time 0.605	Data 0.000	Loss 0.6589	
SparseEpoch: [59][101/398]	Time 0.623	Data 0.000	Loss 0.7572	
SparseEpoch: [59][201/398]	Time 0.623	Data 0.000	Loss 0.6677	
SparseEpoch: [59][301/398]	Time 0.621	Data 0.000	Loss 0.7041	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.17119194 0.17113181 0.17111549 0.17112417 0.17107949 0.17104871
 0.17105157 0.17101812 0.17097647 0.17097697 0.17091764 0.1708944
 0.17086551 0.17084571 0.17081302 0.17080587 0.17076521 0.1707831
 0.17075964 0.17071393]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.17105223 0.17105061 0.17103698 0.17100314 0.17098519 0.17096811
 0.17097435 0.17098719 0.17095389 0.17095141 0.17093709 0.17092344
 0.1709072  0.17088866 0.1708713  0.17087883 0.17089589 0.17087693
 0.17088544 0.17087129]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:74.43842840194702
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc5527d0>
---------------------------------
SparseEpoch: [59][1/398]	Time 0.609	Data 0.000	Loss 3.1398	
SparseEpoch: [59][101/398]	Time 0.629	Data 0.000	Loss 1.9185	
SparseEpoch: [59][201/398]	Time 0.627	Data 0.000	Loss 2.0314	
SparseEpoch: [59][301/398]	Time 0.625	Data 0.000	Loss 2.3182	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.7544	
Epoch(adapt):{0} Loss 1.2788	
Epoch(adapt):{0} Loss 1.5612	
Epoch(adapt):{0} Loss 1.2028	
------------------the total time cost:1216.5168929100037
>>>>>meta updating
Epoch: 0059 | TRAIN: 0.7665 0.5024 0.7484 | 0.4139 0.4139 0.1947 | 0.1579 27.1983 22.5574 0.2373 0.5039 0.6406 ||TEST: 1.1143 0.3589 0.6455 | 0.5497 0.5497 0.2167 | 0.1591 27.4665 23.2116 0.2343 0.4917 0.6266 | 115.7694
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.70752948 0.70756731 0.70753592 0.70753062 0.70751354 0.70749126
 0.70755586 0.70751185 0.70754869 0.70756471 0.70753437 0.70748858
 0.70746233 0.70747092 0.70744792 0.70748316 0.70745782 0.70740341
 0.70740033 0.70745514]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.70755045 0.7075286  0.70752603 0.70754189 0.70753883 0.70754879
 0.70755162 0.70754083 0.70756205 0.70757104 0.70757069 0.70756712
 0.70756794 0.7075566  0.70752933 0.70754194 0.70752806 0.70749274
 0.70751232 0.70748123]
[0.         0.44736842 0.5       ]
-----------end of analyzing the loss ratio:74.37322568893433
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d731f850>
---------------------------------
SparseEpoch: [60][1/398]	Time 0.607	Data 0.000	Loss 1.6246	
SparseEpoch: [60][101/398]	Time 0.625	Data 0.000	Loss 1.3064	
SparseEpoch: [60][201/398]	Time 0.624	Data 0.000	Loss 3.0000	
SparseEpoch: [60][301/398]	Time 0.625	Data 0.000	Loss 2.0165	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.49989055 0.49976684 0.49968107 0.49970576 0.49955714 0.49940211
 0.49936717 0.49919401 0.4991075  0.49905653 0.4989667  0.49871048
 0.49862256 0.49846648 0.49846303 0.49825379 0.49808538 0.49808101
 0.49798902 0.49781387]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.49915437 0.49913883 0.49912975 0.49909792 0.49907064 0.49904629
 0.49905437 0.49902225 0.49907074 0.49907998 0.4990445  0.4989735
 0.49893913 0.49891178 0.49892242 0.49881557 0.49882761 0.49878213
 0.49877338 0.49876938]
[0.5 0.  0.5]
-----------end of analyzing the loss ratio:74.41732740402222
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc001810>
---------------------------------
SparseEpoch: [60][1/398]	Time 0.608	Data 0.000	Loss 1.5897	
SparseEpoch: [60][101/398]	Time 0.623	Data 0.000	Loss 1.7246	
SparseEpoch: [60][201/398]	Time 0.625	Data 0.000	Loss 2.2944	
SparseEpoch: [60][301/398]	Time 0.625	Data 0.000	Loss 1.5046	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.1981647  0.19813094 0.19806399 0.19808266 0.19800749 0.19800348
 0.19800005 0.1979289  0.19794933 0.19793115 0.19785829 0.19782655
 0.19776562 0.19779037 0.19782279 0.19786212 0.19780194 0.19776773
 0.19774853 0.19771726]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.19799081 0.19798455 0.19796631 0.19797269 0.19794809 0.19794202
 0.1979228  0.19792447 0.19793934 0.19793678 0.19790519 0.19787809
 0.19785637 0.19781844 0.19783088 0.19781965 0.19783367 0.19779463
 0.19779268 0.19778218]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:74.44798707962036
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc58c190>
---------------------------------
SparseEpoch: [60][1/398]	Time 0.608	Data 0.000	Loss 1.5057	
SparseEpoch: [60][101/398]	Time 0.633	Data 0.000	Loss 2.1440	
SparseEpoch: [60][201/398]	Time 0.628	Data 0.000	Loss 2.4151	
SparseEpoch: [60][301/398]	Time 0.627	Data 0.000	Loss 2.5994	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.1990	
Epoch(adapt):{0} Loss 1.2963	
Epoch(adapt):{0} Loss 1.1220	
Epoch(adapt):{0} Loss 1.5770	
------------------the total time cost:1217.0683529376984
>>>>>meta updating
Epoch: 0060 | TRAIN: 0.7763 0.4941 0.7479 | 0.4531 0.4531 0.1963 | 0.1562 27.0754 22.4026 0.2336 0.5087 0.6465 ||TEST: 1.0963 0.3565 0.6462 | 0.5937 0.5937 0.2222 | 0.1571 27.3058 22.9858 0.2311 0.4963 0.6328 | 115.7486
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.71916918 0.71908095 0.71914542 0.71918327 0.71920748 0.71919994
 0.71918321 0.71920501 0.71928861 0.71938218 0.71944859 0.719394
 0.71943727 0.71940471 0.71948259 0.71943362 0.71939712 0.71948107
 0.71944312 0.71941812]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.7193978  0.71939618 0.71938752 0.71939463 0.71940813 0.7193945
 0.71939034 0.71939266 0.71941093 0.71941637 0.71941036 0.71943282
 0.71942852 0.7194286  0.71942219 0.71942873 0.71942692 0.71941889
 0.71942076 0.71942849]
[0. 0. 0.]
-----------end of analyzing the loss ratio:74.51164388656616
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc045030>
---------------------------------
SparseEpoch: [61][1/398]	Time 0.605	Data 0.000	Loss 0.8330	
SparseEpoch: [61][101/398]	Time 0.630	Data 0.000	Loss 0.9589	
SparseEpoch: [61][201/398]	Time 0.626	Data 0.000	Loss 1.2578	
SparseEpoch: [61][301/398]	Time 0.627	Data 0.000	Loss 0.5815	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.67936436 0.67950474 0.67957452 0.67966587 0.67983625 0.67990212
 0.67983842 0.67985052 0.67981867 0.67978775 0.67997433 0.68002578
 0.68003785 0.68004402 0.68001924 0.68021368 0.6803968  0.68039072
 0.68029503 0.68040777]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.6799374  0.67991928 0.67989099 0.67985575 0.67985677 0.67983789
 0.67986581 0.67987548 0.67986524 0.67988111 0.67988737 0.679945
 0.67995792 0.67990344 0.67990555 0.67995331 0.68001434 0.67997657
 0.67996092 0.67996319]
[0. 0. 0.]
-----------end of analyzing the loss ratio:74.3948016166687
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444dc341cc0>
---------------------------------
SparseEpoch: [61][1/398]	Time 0.612	Data 0.000	Loss 0.2876	
SparseEpoch: [61][101/398]	Time 0.622	Data 0.000	Loss 0.4090	
SparseEpoch: [61][201/398]	Time 0.624	Data 0.000	Loss 0.5303	
SparseEpoch: [61][301/398]	Time 0.623	Data 0.000	Loss 0.3313	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.18017631 0.18016203 0.18015289 0.18011677 0.18009005 0.18008635
 0.18002779 0.1800075  0.18002928 0.18000635 0.18003008 0.18002581
 0.18006058 0.18001268 0.1799739  0.18003723 0.18000983 0.17997014
 0.17995747 0.17991124]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.18004072 0.18004736 0.18003499 0.18003286 0.18003765 0.18004459
 0.18003584 0.1800119  0.18001051 0.18002136 0.18003286 0.18002931
 0.18001352 0.18001431 0.18004434 0.18004663 0.18003663 0.18003376
 0.18004858 0.18006249]
[0.5 0.  0. ]
-----------end of analyzing the loss ratio:74.47614908218384
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc27aef0>
---------------------------------
SparseEpoch: [61][1/398]	Time 0.608	Data 0.000	Loss 1.9544	
SparseEpoch: [61][101/398]	Time 0.625	Data 0.000	Loss 2.0394	
SparseEpoch: [61][201/398]	Time 0.624	Data 0.000	Loss 2.6743	
SparseEpoch: [61][301/398]	Time 0.623	Data 0.000	Loss 2.1115	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.4631	
Epoch(adapt):{0} Loss 1.0269	
Epoch(adapt):{0} Loss 1.4077	
Epoch(adapt):{0} Loss 1.8131	
------------------the total time cost:1217.2149198055267
>>>>>meta updating
Epoch: 0061 | TRAIN: 0.7564 0.5012 0.7499 | 0.4103 0.4103 0.1979 | 0.1582 27.3244 22.9148 0.2322 0.4976 0.6367 ||TEST: 1.1139 0.3604 0.6443 | 0.5480 0.5480 0.2214 | 0.1614 27.7981 23.7591 0.2271 0.4806 0.6163 | 115.9808
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.72300765 0.72301424 0.723017   0.72307743 0.72303187 0.72316585
 0.72324824 0.72327076 0.72319476 0.72317713 0.72321085 0.72308109
 0.72301333 0.72312397 0.72309997 0.72310003 0.72312391 0.7231212
 0.72317041 0.72332022]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.72318791 0.72317575 0.72320204 0.72319004 0.72320056 0.72318099
 0.72319652 0.72322006 0.72325293 0.72327642 0.72324136 0.72322499
 0.72323089 0.72324659 0.72325207 0.72323606 0.72329069 0.7232773
 0.72327925 0.72330069]
[0. 0. 0.]
-----------end of analyzing the loss ratio:74.45069670677185
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6e7ba00>
---------------------------------
SparseEpoch: [62][1/398]	Time 0.604	Data 0.000	Loss 0.8976	
SparseEpoch: [62][101/398]	Time 0.623	Data 0.000	Loss 1.1280	
SparseEpoch: [62][201/398]	Time 0.624	Data 0.000	Loss 0.7501	
SparseEpoch: [62][301/398]	Time 0.622	Data 0.000	Loss 1.3038	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.85067709 0.85053353 0.85053801 0.85041015 0.85037786 0.85032723
 0.85019131 0.85020001 0.85014127 0.85002409 0.84984546 0.84952601
 0.84929123 0.84900506 0.84902963 0.84886587 0.84865062 0.84866623
 0.84856532 0.84843107]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.85009295 0.8501059  0.85009197 0.85010626 0.85008587 0.85008437
 0.85002934 0.84998771 0.84993864 0.84993089 0.84991094 0.84981979
 0.84976668 0.84977078 0.84980528 0.84976438 0.8497656  0.84973216
 0.84967233 0.84962936]
[0.5 0.  0.5]
-----------end of analyzing the loss ratio:74.48507380485535
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x744609691510>
---------------------------------
SparseEpoch: [62][1/398]	Time 0.610	Data 0.000	Loss 1.3813	
SparseEpoch: [62][101/398]	Time 0.625	Data 0.000	Loss 1.5876	
SparseEpoch: [62][201/398]	Time 0.627	Data 0.000	Loss 1.5343	
SparseEpoch: [62][301/398]	Time 0.625	Data 0.000	Loss 1.8427	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.18270026 0.18268666 0.18267505 0.18269086 0.18268432 0.18267455
 0.18268609 0.18269652 0.18270743 0.18269981 0.18269752 0.18269638
 0.18267598 0.18265969 0.18266895 0.18266898 0.18263343 0.18261784
 0.18260608 0.18262284]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.18274025 0.18272551 0.18271853 0.1827318  0.18272583 0.18273048
 0.18273406 0.1827277  0.18270452 0.18269638 0.18269196 0.18266542
 0.18264632 0.18263734 0.18265672 0.18266882 0.18269473 0.18271353
 0.18273362 0.18274242]
[0.44736842 0.18421053 0.        ]
-----------end of analyzing the loss ratio:74.65284442901611
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d73706d0>
---------------------------------
SparseEpoch: [62][1/398]	Time 0.613	Data 0.000	Loss 1.4581	
SparseEpoch: [62][101/398]	Time 0.627	Data 0.000	Loss 2.0645	
SparseEpoch: [62][201/398]	Time 0.625	Data 0.000	Loss 2.2827	
SparseEpoch: [62][301/398]	Time 0.625	Data 0.000	Loss 1.7725	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.1093	
Epoch(adapt):{0} Loss 0.8033	
Epoch(adapt):{0} Loss 1.0606	
Epoch(adapt):{0} Loss 1.7686	
------------------the total time cost:1218.3832800388336
>>>>>meta updating
Epoch: 0062 | TRAIN: 0.7317 0.5168 0.7618 | 0.4193 0.4193 0.2041 | 0.1563 27.0903 22.5822 0.2366 0.5041 0.6422 ||TEST: 1.0920 0.3753 0.6502 | 0.5389 0.5389 0.2184 | 0.1590 27.5303 23.3898 0.2304 0.4882 0.6243 | 115.6599
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.77920678 0.77913764 0.77915244 0.77902068 0.77886942 0.7787394
 0.7787239  0.77849872 0.77844098 0.77836672 0.7782432  0.77837836
 0.77840263 0.77828802 0.77812651 0.77802565 0.77797894 0.77781906
 0.77750019 0.77728825]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.77843592 0.77844189 0.77841056 0.77836476 0.77838699 0.77835266
 0.77831504 0.7783888  0.77838282 0.77839856 0.77842371 0.77832026
 0.77825989 0.77826779 0.77823574 0.77826678 0.77820372 0.77815503
 0.77816153 0.77823598]
[0.         0.5        0.39473684]
-----------end of analyzing the loss ratio:74.53064703941345
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc42cfd0>
---------------------------------
SparseEpoch: [63][1/398]	Time 0.605	Data 0.000	Loss 1.5424	
SparseEpoch: [63][101/398]	Time 0.624	Data 0.000	Loss 2.3376	
SparseEpoch: [63][201/398]	Time 0.625	Data 0.000	Loss 2.5303	
SparseEpoch: [63][301/398]	Time 0.626	Data 0.000	Loss 2.2566	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.75728668 0.75701916 0.75656368 0.75611352 0.75574423 0.75546101
 0.75499412 0.75471099 0.75434296 0.75379626 0.75332733 0.75291415
 0.75277687 0.75237955 0.75201937 0.75158782 0.75114195 0.75076318
 0.75017546 0.74981189]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.75339794 0.75347426 0.75347337 0.75345079 0.75347922 0.75345148
 0.7534632  0.7534366  0.7534371  0.75346529 0.75351676 0.75351345
 0.75352534 0.75352913 0.75354926 0.75354351 0.75354882 0.75351167
 0.75349417 0.7534946 ]
[0.5 0.  0. ]
-----------end of analyzing the loss ratio:74.48436713218689
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x744609944280>
---------------------------------
SparseEpoch: [63][1/398]	Time 0.607	Data 0.000	Loss 1.1035	
SparseEpoch: [63][101/398]	Time 0.625	Data 0.000	Loss 1.0599	
SparseEpoch: [63][201/398]	Time 0.623	Data 0.000	Loss 1.4118	
SparseEpoch: [63][301/398]	Time 0.622	Data 0.000	Loss 0.7769	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.17542459 0.1754047  0.1753481  0.17532975 0.1753122  0.17530157
 0.17529004 0.17530547 0.17527055 0.17529093 0.17532293 0.17530653
 0.1753043  0.1752728  0.17526854 0.1752776  0.17527034 0.17525697
 0.1752606  0.17521738]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.17529734 0.17529168 0.1752871  0.1752807  0.17529992 0.17530736
 0.17529737 0.17530484 0.1753172  0.17531312 0.17530492 0.17532529
 0.17533236 0.17532253 0.17530217 0.17530417 0.17530823 0.17530702
 0.17532653 0.17534425]
[0.5 0.  0. ]
-----------end of analyzing the loss ratio:74.71077299118042
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc0ecb50>
---------------------------------
SparseEpoch: [63][1/398]	Time 0.672	Data 0.000	Loss 1.6542	
SparseEpoch: [63][101/398]	Time 0.618	Data 0.000	Loss 1.7367	
SparseEpoch: [63][201/398]	Time 0.621	Data 0.000	Loss 3.6371	
SparseEpoch: [63][301/398]	Time 0.622	Data 0.000	Loss 2.5833	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.0570	
Epoch(adapt):{0} Loss 1.1803	
Epoch(adapt):{0} Loss 0.9571	
Epoch(adapt):{0} Loss 1.6590	
------------------the total time cost:1215.4832074642181
>>>>>meta updating
Epoch: 0063 | TRAIN: 0.7176 0.5247 0.7651 | 0.4141 0.4141 0.2112 | 0.1546 26.8414 22.2306 0.2416 0.5128 0.6501 ||TEST: 1.1068 0.3750 0.6511 | 0.5440 0.5440 0.2272 | 0.1560 27.1598 22.8257 0.2368 0.4992 0.6346 | 115.5815
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.72834496 0.7283375  0.72836983 0.72837629 0.72839423 0.72835405
 0.72840031 0.72841005 0.72840393 0.72836924 0.72838422 0.72841061
 0.72838157 0.72839121 0.72836746 0.72836438 0.72834027 0.72833871
 0.72833732 0.72830761]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.72832901 0.72835535 0.72832137 0.72833823 0.72832794 0.72830494
 0.72831078 0.72834388 0.72834514 0.72835951 0.72837259 0.72840593
 0.7284215  0.72841555 0.72838829 0.72838719 0.72841665 0.7284175
 0.72840408 0.72840936]
[0.  0.5 0. ]
-----------end of analyzing the loss ratio:74.60525631904602
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x74460925d270>
---------------------------------
SparseEpoch: [64][1/398]	Time 0.606	Data 0.000	Loss 0.8181	
SparseEpoch: [64][101/398]	Time 0.626	Data 0.000	Loss 1.3979	
SparseEpoch: [64][201/398]	Time 0.624	Data 0.000	Loss 0.8688	
SparseEpoch: [64][301/398]	Time 0.626	Data 0.000	Loss 1.3622	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.45664612 0.45641077 0.4559275  0.45578756 0.45566643 0.45547806
 0.45492582 0.45458148 0.4542298  0.4538794  0.45348758 0.45296401
 0.45277147 0.45260102 0.4522224  0.451722   0.45137662 0.4509532
 0.45075055 0.45056632]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.45395117 0.45397095 0.4539663  0.45393323 0.45391492 0.45388425
 0.4538791  0.45383809 0.45383817 0.45381265 0.45381747 0.45382155
 0.45382345 0.45382264 0.45375616 0.45372129 0.45366243 0.45364576
 0.45364955 0.453655  ]
[0.5        0.         0.39473684]
-----------end of analyzing the loss ratio:74.65743947029114
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc537670>
---------------------------------
SparseEpoch: [64][1/398]	Time 0.605	Data 0.000	Loss 1.3836	
SparseEpoch: [64][101/398]	Time 0.624	Data 0.000	Loss 1.8336	
SparseEpoch: [64][201/398]	Time 0.625	Data 0.000	Loss 1.7674	
SparseEpoch: [64][301/398]	Time 0.625	Data 0.000	Loss 1.4429	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.17853103 0.17849298 0.17846891 0.17839819 0.17837516 0.17833333
 0.17833756 0.17833232 0.17831333 0.17822269 0.17821292 0.17818801
 0.17815394 0.17816746 0.17815573 0.17812605 0.1781042  0.17805958
 0.17801294 0.17803459]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.17822119 0.17822657 0.17823167 0.17822814 0.17821267 0.17821741
 0.17821584 0.17821713 0.17822068 0.17822126 0.17821643 0.17822194
 0.17820632 0.1782072  0.17820745 0.17819468 0.17820467 0.17820086
 0.17819823 0.17817824]
[0.44736842 0.5        0.        ]
-----------end of analyzing the loss ratio:74.45416522026062
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc38b8e0>
---------------------------------
SparseEpoch: [64][1/398]	Time 0.613	Data 0.000	Loss 2.0017	
SparseEpoch: [64][101/398]	Time 0.623	Data 0.000	Loss 2.6635	
SparseEpoch: [64][201/398]	Time 0.625	Data 0.000	Loss 2.4641	
SparseEpoch: [64][301/398]	Time 0.625	Data 0.000	Loss 2.4911	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.4773	
Epoch(adapt):{0} Loss 0.8593	
Epoch(adapt):{0} Loss 1.2156	
Epoch(adapt):{0} Loss 1.2113	
------------------the total time cost:1218.6391062736511
>>>>>meta updating
Epoch: 0064 | TRAIN: 0.7281 0.5209 0.7625 | 0.4272 0.4272 0.1932 | 0.1572 27.2552 22.8292 0.2301 0.4989 0.6392 ||TEST: 1.0886 0.3725 0.6521 | 0.5585 0.5585 0.2142 | 0.1583 27.4897 23.3444 0.2289 0.4884 0.6257 | 116.0699
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.63198701 0.63207649 0.63209126 0.63198586 0.63213077 0.63210678
 0.63228382 0.63228624 0.63241929 0.63249055 0.63250099 0.63249984
 0.63263989 0.63273284 0.63280688 0.6328239  0.63289675 0.63295144
 0.63297065 0.63312283]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.63254863 0.63257085 0.63256025 0.63259713 0.63257752 0.63256165
 0.63253866 0.63251652 0.63247531 0.63250016 0.63249658 0.6324841
 0.63247708 0.63244363 0.6324847  0.63249375 0.63248582 0.63253817
 0.63253748 0.63250525]
[0.         0.         0.18421053]
-----------end of analyzing the loss ratio:74.499502658844
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc58fe20>
---------------------------------
SparseEpoch: [65][1/398]	Time 0.604	Data 0.000	Loss 0.8942	
SparseEpoch: [65][101/398]	Time 0.623	Data 0.000	Loss 1.5530	
SparseEpoch: [65][201/398]	Time 0.624	Data 0.000	Loss 1.4540	
SparseEpoch: [65][301/398]	Time 0.622	Data 0.000	Loss 1.0451	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.84542597 0.84551403 0.84550101 0.84554918 0.84558524 0.84551733
 0.84562985 0.84566326 0.8456072  0.84556172 0.84556692 0.84551847
 0.84556121 0.84570789 0.84562452 0.84568542 0.84581707 0.84597688
 0.84597428 0.84587907]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.84558093 0.84558113 0.84554372 0.84551544 0.84552743 0.84550866
 0.84551859 0.84558929 0.84559065 0.84557177 0.84558312 0.84557894
 0.84558207 0.84556977 0.84556994 0.84557511 0.84555181 0.84558118
 0.84555717 0.84557819]
[0. 0. 0.]
-----------end of analyzing the loss ratio:74.33056735992432
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x74460810aa40>
---------------------------------
SparseEpoch: [65][1/398]	Time 0.604	Data 0.000	Loss 0.3155	
SparseEpoch: [65][101/398]	Time 0.619	Data 0.000	Loss 0.5440	
SparseEpoch: [65][201/398]	Time 0.621	Data 0.000	Loss 0.4564	
SparseEpoch: [65][301/398]	Time 0.623	Data 0.000	Loss 0.3001	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.17809542 0.17805958 0.17807764 0.1780515  0.17795194 0.1779272
 0.17790323 0.1778623  0.17788469 0.17784303 0.17780069 0.17778683
 0.17778718 0.1777034  0.17769229 0.17767101 0.17764238 0.1776325
 0.17756823 0.17754286]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.17793298 0.17791165 0.17789061 0.17787951 0.17787909 0.17785263
 0.17785076 0.17785203 0.17783157 0.17781235 0.17781856 0.17781298
 0.17781197 0.17781073 0.1778025  0.17779386 0.17779415 0.17780592
 0.17780042 0.17779518]
[0.5        0.28947368 0.        ]
-----------end of analyzing the loss ratio:74.44037342071533
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444dc342bf0>
---------------------------------
SparseEpoch: [65][1/398]	Time 0.605	Data 0.000	Loss 2.3177	
SparseEpoch: [65][101/398]	Time 0.624	Data 0.000	Loss 2.5302	
SparseEpoch: [65][201/398]	Time 0.624	Data 0.000	Loss 2.2374	
SparseEpoch: [65][301/398]	Time 0.625	Data 0.000	Loss 1.7666	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.2587	
Epoch(adapt):{0} Loss 1.2334	
Epoch(adapt):{0} Loss 1.0441	
Epoch(adapt):{0} Loss 1.6347	
------------------the total time cost:1216.0542557239532
>>>>>meta updating
Epoch: 0065 | TRAIN: 0.7142 0.5212 0.7676 | 0.4113 0.4113 0.1948 | 0.1552 27.0130 22.5419 0.2359 0.5050 0.6443 ||TEST: 1.0922 0.3687 0.6493 | 0.5463 0.5463 0.2170 | 0.1587 27.5447 23.4362 0.2275 0.4869 0.6243 | 115.6128
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.6738647  0.67384717 0.67386994 0.67383255 0.67386802 0.67380791
 0.67380396 0.67378969 0.67378487 0.67374617 0.67372964 0.67375847
 0.67373965 0.67376886 0.67378993 0.67379781 0.67378688 0.67376509
 0.67374991 0.67370767]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.67382313 0.67383821 0.6738062  0.67380825 0.67379546 0.67379468
 0.67378977 0.6737699  0.67376944 0.67375801 0.67373797 0.67371879
 0.67373285 0.6737109  0.67372524 0.67371146 0.67372389 0.6737421
 0.67376283 0.6737475 ]
[0.         0.5        0.18421053]
-----------end of analyzing the loss ratio:74.465092420578
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc56d6c0>
---------------------------------
SparseEpoch: [66][1/398]	Time 0.605	Data 0.000	Loss 1.6919	
SparseEpoch: [66][101/398]	Time 0.619	Data 0.000	Loss 1.1623	
SparseEpoch: [66][201/398]	Time 0.621	Data 0.000	Loss 1.2532	
SparseEpoch: [66][301/398]	Time 0.624	Data 0.000	Loss 1.4133	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.55326262 0.55327769 0.5532137  0.55304386 0.55308511 0.55280032
 0.55272474 0.55266826 0.55263984 0.55253735 0.55235412 0.55230365
 0.55232113 0.55222004 0.55213683 0.55218811 0.55216606 0.55212216
 0.55212129 0.55203485]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.55246649 0.55243802 0.55243163 0.55243039 0.55241055 0.55239677
 0.55238331 0.55235402 0.5523725  0.55236404 0.55239187 0.55239128
 0.55241236 0.55239796 0.55239283 0.55239466 0.55242    0.55241565
 0.55242602 0.55242035]
[0.5 0.  0. ]
-----------end of analyzing the loss ratio:74.58626389503479
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x744608168d00>
---------------------------------
SparseEpoch: [66][1/398]	Time 0.612	Data 0.000	Loss 0.9868	
SparseEpoch: [66][101/398]	Time 0.624	Data 0.000	Loss 0.8906	
SparseEpoch: [66][201/398]	Time 0.623	Data 0.000	Loss 0.8460	
SparseEpoch: [66][301/398]	Time 0.625	Data 0.000	Loss 0.7908	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.17631891 0.17632407 0.17632712 0.17631366 0.17631808 0.17630442
 0.17629288 0.17629328 0.17629549 0.17628139 0.17627532 0.17627303
 0.1762798  0.17627884 0.17625617 0.17624047 0.17621694 0.17621049
 0.1761875  0.17618637]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.17629092 0.17628074 0.1762973  0.17630115 0.17630625 0.17630343
 0.17630485 0.17629597 0.1762973  0.17628365 0.17626538 0.17627225
 0.1762825  0.17626509 0.17625598 0.17625266 0.17623897 0.1762248
 0.17622074 0.17622284]
[0.5        0.44736842 0.        ]
-----------end of analyzing the loss ratio:74.42306303977966
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444dc3b6d10>
---------------------------------
SparseEpoch: [66][1/398]	Time 0.606	Data 0.000	Loss 1.3019	
SparseEpoch: [66][101/398]	Time 0.625	Data 0.000	Loss 2.8584	
SparseEpoch: [66][201/398]	Time 0.625	Data 0.000	Loss 4.3611	
SparseEpoch: [66][301/398]	Time 0.624	Data 0.000	Loss 2.3220	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.4087	
Epoch(adapt):{0} Loss 1.5446	
Epoch(adapt):{0} Loss 0.9118	
Epoch(adapt):{0} Loss 1.9400	
------------------the total time cost:1216.515308856964
>>>>>meta updating
Epoch: 0066 | TRAIN: 0.7078 0.5246 0.7710 | 0.4086 0.4086 0.1906 | 0.1555 27.0958 22.6887 0.2313 0.5017 0.6429 ||TEST: 1.0976 0.3736 0.6499 | 0.5521 0.5521 0.2179 | 0.1592 27.6367 23.5837 0.2231 0.4839 0.6230 | 115.6698
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.62898282 0.62893153 0.62888756 0.62886895 0.62884696 0.62888236
 0.62887209 0.62880326 0.62879552 0.62872084 0.6286948  0.62866935
 0.6286514  0.62857892 0.62858482 0.62864239 0.62866359 0.62857106
 0.62854547 0.62853634]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.62876636 0.62875147 0.62870475 0.62869531 0.62870685 0.62871255
 0.62869197 0.62866795 0.6286701  0.62871465 0.62868921 0.62869284
 0.6286884  0.62868852 0.62872096 0.62870017 0.62868582 0.62868814
 0.62866868 0.62862244]
[0.  0.5 0.5]
-----------end of analyzing the loss ratio:74.54780745506287
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc5fc8e0>
---------------------------------
SparseEpoch: [67][1/398]	Time 0.608	Data 0.000	Loss 1.6708	
SparseEpoch: [67][101/398]	Time 0.623	Data 0.000	Loss 2.1400	
SparseEpoch: [67][201/398]	Time 0.626	Data 0.000	Loss 1.8776	
SparseEpoch: [67][301/398]	Time 0.626	Data 0.000	Loss 1.9399	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.57990959 0.57979253 0.57972282 0.57954039 0.57919372 0.57894581
 0.57879074 0.57846258 0.57832348 0.57805789 0.57783839 0.57750035
 0.5773413  0.57710956 0.57697157 0.57681154 0.57676651 0.57664391
 0.57658848 0.57634067]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.57821301 0.57816959 0.57816478 0.57809899 0.57806186 0.57802874
 0.57800542 0.57800841 0.57799694 0.57800634 0.57794098 0.57796117
 0.57787226 0.57781847 0.57780305 0.5778257  0.57778924 0.57780104
 0.57776427 0.57770219]
[0.5 0.  0.5]
-----------end of analyzing the loss ratio:74.639324426651
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc42c0a0>
---------------------------------
SparseEpoch: [67][1/398]	Time 0.605	Data 0.000	Loss 1.2118	
SparseEpoch: [67][101/398]	Time 0.624	Data 0.000	Loss 2.3930	
SparseEpoch: [67][201/398]	Time 0.623	Data 0.000	Loss 1.8720	
SparseEpoch: [67][301/398]	Time 0.624	Data 0.000	Loss 1.4801	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.16575872 0.16575465 0.16574439 0.16576141 0.16573611 0.16574313
 0.16573415 0.16572959 0.16572834 0.1657244  0.16574309 0.1657353
 0.16572279 0.16574308 0.16573203 0.16572062 0.16572613 0.16576039
 0.16575138 0.16575796]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.16573929 0.16573668 0.16574625 0.16573629 0.16573822 0.16575621
 0.1657465  0.16575218 0.1657447  0.16575097 0.16572864 0.16572416
 0.1657342  0.16572754 0.16573211 0.16572698 0.1657362  0.16573727
 0.16575072 0.16574343]
[0.28947368 0.07894737 0.        ]
-----------end of analyzing the loss ratio:74.52327632904053
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7446099fca00>
---------------------------------
SparseEpoch: [67][1/398]	Time 0.605	Data 0.000	Loss 2.1823	
SparseEpoch: [67][101/398]	Time 0.623	Data 0.000	Loss 2.0907	
SparseEpoch: [67][201/398]	Time 0.624	Data 0.000	Loss 1.7535	
SparseEpoch: [67][301/398]	Time 0.624	Data 0.000	Loss 1.6262	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.1045	
Epoch(adapt):{0} Loss 1.8712	
Epoch(adapt):{0} Loss 2.0349	
Epoch(adapt):{0} Loss 1.4495	
------------------the total time cost:1219.0641708374023
>>>>>meta updating
Epoch: 0067 | TRAIN: 0.6926 0.5374 0.7738 | 0.3936 0.3936 0.1869 | 0.1507 26.3966 21.7057 0.2491 0.5242 0.6602 ||TEST: 1.1117 0.3765 0.6510 | 0.5413 0.5413 0.2167 | 0.1541 26.9225 22.5421 0.2414 0.5058 0.6407 | 115.7435
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.75729738 0.75726427 0.75728336 0.75733177 0.75738618 0.75733174
 0.75726657 0.75725832 0.75722413 0.75720314 0.75715998 0.75707642
 0.75713231 0.75715214 0.75712997 0.7570835  0.7570532  0.75699014
 0.75702533 0.7570695 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.75713648 0.75716284 0.757223   0.75721674 0.75718635 0.75718589
 0.7571447  0.75718204 0.75719462 0.75720868 0.75718579 0.75724797
 0.75717911 0.75718849 0.7572105  0.75719289 0.7571996  0.75721326
 0.75719095 0.75721772]
[0.         0.39473684 0.        ]
-----------end of analyzing the loss ratio:74.60546374320984
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7446095cf5e0>
---------------------------------
SparseEpoch: [68][1/398]	Time 0.605	Data 0.000	Loss 0.7362	
SparseEpoch: [68][101/398]	Time 0.624	Data 0.000	Loss 1.5410	
SparseEpoch: [68][201/398]	Time 0.623	Data 0.000	Loss 1.4941	
SparseEpoch: [68][301/398]	Time 0.622	Data 0.000	Loss 2.7585	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.44674017 0.44667098 0.44679099 0.44665164 0.44664075 0.44658633
 0.44656129 0.44659127 0.44652188 0.44650325 0.44634148 0.44623276
 0.44623412 0.44622989 0.44610179 0.44597988 0.44590691 0.44591302
 0.44572837 0.44573266]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.44655362 0.44654811 0.44655519 0.44654904 0.44652753 0.44651614
 0.446504   0.44646899 0.44646132 0.44645419 0.44637645 0.44637252
 0.44638252 0.44638016 0.44636925 0.44636686 0.44633496 0.44632941
 0.4463249  0.446313  ]
[0.44736842 0.         0.5       ]
-----------end of analyzing the loss ratio:74.60776901245117
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444dc150550>
---------------------------------
SparseEpoch: [68][1/398]	Time 0.605	Data 0.000	Loss 1.5976	
SparseEpoch: [68][101/398]	Time 0.622	Data 0.000	Loss 1.8156	
SparseEpoch: [68][201/398]	Time 0.623	Data 0.000	Loss 1.4422	
SparseEpoch: [68][301/398]	Time 0.625	Data 0.000	Loss 1.4630	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.16497411 0.16497613 0.16495706 0.16494327 0.16492572 0.16487381
 0.16485451 0.16486136 0.16485205 0.16491523 0.1649076  0.16488605
 0.16486401 0.16487749 0.1648586  0.16483483 0.16481297 0.16484829
 0.1648357  0.16481492]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.16491901 0.16491854 0.16492007 0.1649072  0.16489352 0.16488777
 0.16489362 0.1648953  0.16490423 0.16490272 0.16490968 0.16489273
 0.16488461 0.16486352 0.1648728  0.16488656 0.16490256 0.16488056
 0.16489443 0.16488762]
[0.34210526 0.18421053 0.        ]
-----------end of analyzing the loss ratio:74.62371635437012
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x74460925dc00>
---------------------------------
SparseEpoch: [68][1/398]	Time 0.613	Data 0.000	Loss 1.8742	
SparseEpoch: [68][101/398]	Time 0.625	Data 0.000	Loss 1.8454	
SparseEpoch: [68][201/398]	Time 0.625	Data 0.000	Loss 1.2782	
SparseEpoch: [68][301/398]	Time 0.625	Data 0.000	Loss 1.4489	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.8667	
Epoch(adapt):{0} Loss 1.1150	
Epoch(adapt):{0} Loss 1.4105	
Epoch(adapt):{0} Loss 1.0557	
------------------the total time cost:1217.311560869217
>>>>>meta updating
Epoch: 0068 | TRAIN: 0.6882 0.5435 0.7757 | 0.4016 0.4016 0.1930 | 0.1526 26.6410 22.0590 0.2456 0.5151 0.6522 ||TEST: 1.1165 0.3797 0.6507 | 0.5465 0.5465 0.2171 | 0.1559 27.1428 22.9052 0.2377 0.4984 0.6336 | 116.0520
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.71962053 0.71957972 0.71957325 0.71956332 0.71962284 0.71962186
 0.71964328 0.71965616 0.71970718 0.7196705  0.71960352 0.71960504
 0.71960032 0.71959187 0.71955374 0.71952141 0.71960196 0.71964106
 0.71963224 0.71964828]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.7195927  0.71962186 0.71963607 0.71962971 0.71963428 0.71960972
 0.71964622 0.71966925 0.71964545 0.71963238 0.71963178 0.71967822
 0.71971345 0.71972338 0.71970828 0.71970162 0.71961125 0.7195875
 0.71959502 0.71956454]
[0.         0.28947368 0.5       ]
-----------end of analyzing the loss ratio:74.68861699104309
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d72d2470>
---------------------------------
SparseEpoch: [69][1/398]	Time 0.605	Data 0.000	Loss 1.1542	
SparseEpoch: [69][101/398]	Time 0.624	Data 0.000	Loss 1.8900	
SparseEpoch: [69][201/398]	Time 0.625	Data 0.000	Loss 1.4614	
SparseEpoch: [69][301/398]	Time 0.624	Data 0.000	Loss 1.7876	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.61319065 0.61286562 0.61272666 0.61262056 0.61243914 0.61238984
 0.61222449 0.61212968 0.6119556  0.61182862 0.61186759 0.6118469
 0.61179282 0.61151713 0.61133715 0.61133241 0.61129678 0.61095125
 0.61073405 0.61087685]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.61181228 0.611803   0.61182247 0.61183645 0.61182715 0.61185161
 0.61182714 0.6118686  0.61189366 0.61189441 0.61189228 0.61186346
 0.61182558 0.61187098 0.61186692 0.61183895 0.61182456 0.61180211
 0.61179247 0.6117824 ]
[0.44736842 0.         0.5       ]
-----------end of analyzing the loss ratio:74.40766930580139
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc471ab0>
---------------------------------
SparseEpoch: [69][1/398]	Time 0.609	Data 0.000	Loss 1.1709	
SparseEpoch: [69][101/398]	Time 0.622	Data 0.000	Loss 1.3544	
SparseEpoch: [69][201/398]	Time 0.622	Data 0.000	Loss 1.2463	
SparseEpoch: [69][301/398]	Time 0.622	Data 0.000	Loss 1.4701	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.16235794 0.16229358 0.16227953 0.16219807 0.16211812 0.16201009
 0.16195225 0.16191324 0.1617852  0.16170879 0.16165378 0.16157336
 0.16151552 0.16143003 0.16138475 0.16129293 0.16122056 0.16112422
 0.16104686 0.16095117]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.16200602 0.16196289 0.16192477 0.16189085 0.16183849 0.16180831
 0.16178522 0.16174386 0.16171551 0.16173993 0.16169323 0.16165615
 0.161605   0.1615893  0.16157081 0.16156754 0.16151797 0.16151127
 0.16148472 0.16143124]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:74.54911279678345
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d72d2c20>
---------------------------------
SparseEpoch: [69][1/398]	Time 0.606	Data 0.000	Loss 2.3882	
SparseEpoch: [69][101/398]	Time 0.625	Data 0.000	Loss 1.7393	
SparseEpoch: [69][201/398]	Time 0.626	Data 0.000	Loss 2.7708	
SparseEpoch: [69][301/398]	Time 0.626	Data 0.000	Loss 1.7293	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.1788	
Epoch(adapt):{0} Loss 1.1046	
Epoch(adapt):{0} Loss 0.9186	
Epoch(adapt):{0} Loss 0.9746	
------------------the total time cost:1217.0337793827057
>>>>>meta updating
Epoch: 0069 | TRAIN: 0.6801 0.5481 0.7812 | 0.4015 0.4015 0.1937 | 0.1480 26.1232 21.3329 0.2509 0.5307 0.6679 ||TEST: 1.1141 0.3765 0.6526 | 0.5402 0.5402 0.2162 | 0.1530 26.8436 22.4202 0.2381 0.5083 0.6440 | 116.1381
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.76288868 0.76286494 0.76290632 0.76289639 0.76295558 0.76290441
 0.76284182 0.76279847 0.76272941 0.76272342 0.76261808 0.76259781
 0.76267341 0.76266566 0.76275015 0.7627782  0.76278743 0.76274372
 0.76284557 0.76275423]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.76267414 0.76267849 0.76267836 0.76271663 0.76269277 0.7626263
 0.76263382 0.76263736 0.76264809 0.76263491 0.76263832 0.76270121
 0.76267571 0.76271567 0.76272544 0.76271069 0.76271732 0.76273301
 0.7627354  0.76272506]
[0.         0.07894737 0.        ]
-----------end of analyzing the loss ratio:74.5557553768158
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d72b8af0>
---------------------------------
SparseEpoch: [70][1/398]	Time 0.605	Data 0.000	Loss 0.6846	
SparseEpoch: [70][101/398]	Time 0.625	Data 0.000	Loss 0.8211	
SparseEpoch: [70][201/398]	Time 0.624	Data 0.000	Loss 0.8191	
SparseEpoch: [70][301/398]	Time 0.624	Data 0.000	Loss 0.9061	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.77247633 0.77252279 0.77237532 0.7722311  0.77197431 0.7718811
 0.77186356 0.77177701 0.77166175 0.77172783 0.77189708 0.77193242
 0.77187216 0.77192138 0.77216916 0.77231045 0.77233947 0.77250662
 0.77242603 0.77260199]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.77191184 0.77190854 0.77193092 0.77191333 0.77189394 0.77189635
 0.77185691 0.77183779 0.7718494  0.77183806 0.77178144 0.77179604
 0.77179433 0.77178817 0.77175731 0.77182535 0.77183282 0.77186434
 0.77185811 0.77183904]
[0.         0.         0.23684211]
-----------end of analyzing the loss ratio:74.77073431015015
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6f94070>
---------------------------------
SparseEpoch: [70][1/398]	Time 0.604	Data 0.000	Loss 0.8407	
SparseEpoch: [70][101/398]	Time 0.627	Data 0.000	Loss 0.7781	
SparseEpoch: [70][201/398]	Time 0.627	Data 0.000	Loss 1.3587	
SparseEpoch: [70][301/398]	Time 0.627	Data 0.000	Loss 0.5638	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.15519165 0.15518751 0.15514662 0.15511652 0.15512485 0.15510039
 0.15508358 0.15507039 0.15507056 0.1550779  0.1550637  0.1550327
 0.15498472 0.15497416 0.15496069 0.15495924 0.15493552 0.15492705
 0.15491093 0.15488573]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.15501192 0.15500457 0.15500053 0.15498841 0.15499727 0.15500844
 0.15502838 0.15504135 0.15505252 0.1550723  0.15508732 0.15508195
 0.15507557 0.15506804 0.15508376 0.15509931 0.15508437 0.15507097
 0.15507647 0.15508789]
[0.5 0.  0. ]
-----------end of analyzing the loss ratio:74.57471203804016
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6d91f00>
---------------------------------
SparseEpoch: [70][1/398]	Time 0.604	Data 0.000	Loss 1.8011	
SparseEpoch: [70][101/398]	Time 0.625	Data 0.000	Loss 1.8272	
SparseEpoch: [70][201/398]	Time 0.626	Data 0.000	Loss 2.8475	
SparseEpoch: [70][301/398]	Time 0.626	Data 0.000	Loss 1.7625	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.3516	
Epoch(adapt):{0} Loss 2.2651	
Epoch(adapt):{0} Loss 1.2615	
Epoch(adapt):{0} Loss 1.2482	
------------------the total time cost:1218.9286530017853
>>>>>meta updating
Epoch: 0070 | TRAIN: 0.6769 0.5522 0.7820 | 0.4082 0.4082 0.1933 | 0.1499 26.3160 21.5567 0.2497 0.5257 0.6636 ||TEST: 1.1056 0.3772 0.6526 | 0.5529 0.5529 0.2194 | 0.1550 26.9991 22.5600 0.2402 0.5049 0.6401 | 115.7146
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.59438663 0.59436107 0.59436525 0.59443373 0.59451997 0.59452334
 0.59454908 0.59465466 0.59469044 0.59463958 0.59470058 0.59472145
 0.59479196 0.59477444 0.59479465 0.594867   0.59497256 0.59494437
 0.59497776 0.59497749]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.59471412 0.59470547 0.5946869  0.59466338 0.59467938 0.59468742
 0.59467927 0.59467188 0.59469854 0.59465702 0.59465023 0.59466808
 0.59465274 0.59465265 0.59461911 0.59461122 0.59461765 0.59463677
 0.59462461 0.5946742 ]
[0.         0.         0.28947368]
-----------end of analyzing the loss ratio:74.6905665397644
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc0024a0>
---------------------------------
SparseEpoch: [71][1/398]	Time 0.607	Data 0.000	Loss 1.3729	
SparseEpoch: [71][101/398]	Time 0.623	Data 0.000	Loss 1.2061	
SparseEpoch: [71][201/398]	Time 0.623	Data 0.000	Loss 1.2210	
SparseEpoch: [71][301/398]	Time 0.623	Data 0.000	Loss 0.9952	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.57457665 0.57427221 0.57416663 0.57414484 0.573998   0.57381972
 0.57370788 0.57357691 0.57346807 0.57341123 0.57327715 0.57318321
 0.57301728 0.5728645  0.57271509 0.57253751 0.57246509 0.57246821
 0.57227713 0.57219673]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.57340667 0.5734338  0.57342743 0.57341428 0.57341887 0.57340846
 0.57341655 0.57338428 0.57339039 0.57340159 0.57339577 0.57338951
 0.5733997  0.57337167 0.57332385 0.57332572 0.5733144  0.57330402
 0.5733189  0.57330151]
[0.5 0.  0.5]
-----------end of analyzing the loss ratio:74.60574245452881
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444dc3b4130>
---------------------------------
SparseEpoch: [71][1/398]	Time 0.606	Data 0.000	Loss 1.2074	
SparseEpoch: [71][101/398]	Time 0.625	Data 0.000	Loss 1.9977	
SparseEpoch: [71][201/398]	Time 0.625	Data 0.000	Loss 1.9756	
SparseEpoch: [71][301/398]	Time 0.624	Data 0.000	Loss 1.4207	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.16487002 0.16484435 0.16482264 0.16482966 0.16480326 0.16479701
 0.16481473 0.16477669 0.16475369 0.16472488 0.16476592 0.16473327
 0.16471653 0.1646747  0.16471009 0.16466001 0.164647   0.16462743
 0.16460528 0.16461568]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.16476603 0.16474433 0.16473841 0.16473556 0.16474016 0.16474549
 0.16473489 0.16471215 0.1647175  0.16474136 0.16473553 0.16475033
 0.16476237 0.16475214 0.16472552 0.16471893 0.16471927 0.16472242
 0.16470562 0.16470665]
[0.44736842 0.44736842 0.        ]
-----------end of analyzing the loss ratio:74.4834303855896
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d734f8e0>
---------------------------------
SparseEpoch: [71][1/398]	Time 0.606	Data 0.000	Loss 1.9351	
SparseEpoch: [71][101/398]	Time 0.625	Data 0.000	Loss 2.1419	
SparseEpoch: [71][201/398]	Time 0.626	Data 0.000	Loss 2.8273	
SparseEpoch: [71][301/398]	Time 0.625	Data 0.000	Loss 2.3550	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.8307	
Epoch(adapt):{0} Loss 0.7781	
Epoch(adapt):{0} Loss 1.1670	
Epoch(adapt):{0} Loss 1.1028	
------------------the total time cost:1215.9422633647919
>>>>>meta updating
Epoch: 0071 | TRAIN: 0.6584 0.5543 0.7880 | 0.4024 0.4024 0.1929 | 0.1460 25.8229 20.9065 0.2598 0.5410 0.6753 ||TEST: 1.1416 0.3743 0.6534 | 0.5417 0.5417 0.2165 | 0.1518 26.5671 21.9399 0.2496 0.5181 0.6511 | 116.0667
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.62437211 0.6242544  0.62433372 0.6242979  0.62423794 0.62427575
 0.62419142 0.62416694 0.62420609 0.62418144 0.62400234 0.62395854
 0.62391227 0.6238856  0.62387513 0.62387142 0.62395953 0.62409925
 0.62418801 0.62419945]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.62417494 0.62419465 0.62428184 0.62417536 0.6241524  0.6241753
 0.62419604 0.62421751 0.62415311 0.62412897 0.62406203 0.62403707
 0.6240242  0.62405622 0.62400748 0.62400008 0.62406591 0.62406439
 0.62402645 0.62402664]
[0.         0.28947368 0.28947368]
-----------end of analyzing the loss ratio:74.9144446849823
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d7076c50>
---------------------------------
SparseEpoch: [72][1/398]	Time 0.608	Data 0.000	Loss 0.9959	
SparseEpoch: [72][101/398]	Time 0.629	Data 0.000	Loss 1.3375	
SparseEpoch: [72][201/398]	Time 0.628	Data 0.000	Loss 2.2219	
SparseEpoch: [72][301/398]	Time 0.628	Data 0.000	Loss 1.8979	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.54881905 0.54878534 0.54869873 0.54865535 0.54870897 0.54870262
 0.54872369 0.54875626 0.54881623 0.54883503 0.5488121  0.54885789
 0.54883364 0.54885099 0.54880499 0.5488594  0.5489615  0.54898012
 0.54897066 0.54897591]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.54885188 0.54885755 0.54887904 0.54887094 0.54890079 0.54891707
 0.54890917 0.54890891 0.54886654 0.54886661 0.54884165 0.54882015
 0.54882523 0.54882532 0.54882428 0.54880802 0.54878983 0.54879753
 0.54877735 0.54876609]
[0.  0.  0.5]
-----------end of analyzing the loss ratio:74.64492797851562
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7446096ebd60>
---------------------------------
SparseEpoch: [72][1/398]	Time 0.606	Data 0.000	Loss 0.8843	
SparseEpoch: [72][101/398]	Time 0.623	Data 0.000	Loss 0.9543	
SparseEpoch: [72][201/398]	Time 0.621	Data 0.000	Loss 1.3007	
SparseEpoch: [72][301/398]	Time 0.621	Data 0.000	Loss 1.2654	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.18420843 0.18418598 0.18413653 0.1841144  0.1840734  0.1841006
 0.1840861  0.18405216 0.18403862 0.18402678 0.1840096  0.18400248
 0.18402335 0.18399199 0.18396676 0.18394436 0.18392543 0.18393091
 0.18391057 0.1838858 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.184061   0.18407041 0.18409302 0.18406454 0.18405693 0.18405734
 0.1840233  0.18400646 0.18400165 0.18401443 0.18402821 0.1840349
 0.18402106 0.18403171 0.18401469 0.18400804 0.18400944 0.18399852
 0.18400117 0.18401047]
[0.5        0.39473684 0.        ]
-----------end of analyzing the loss ratio:74.5303385257721
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc37d990>
---------------------------------
SparseEpoch: [72][1/398]	Time 0.617	Data 0.000	Loss 2.4429	
SparseEpoch: [72][101/398]	Time 0.621	Data 0.000	Loss 2.7441	
SparseEpoch: [72][201/398]	Time 0.625	Data 0.000	Loss 2.3312	
SparseEpoch: [72][301/398]	Time 0.624	Data 0.000	Loss 2.1785	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.8770	
Epoch(adapt):{0} Loss 1.5557	
Epoch(adapt):{0} Loss 1.5908	
Epoch(adapt):{0} Loss 0.8734	
------------------the total time cost:1219.2666504383087
>>>>>meta updating
Epoch: 0072 | TRAIN: 0.6677 0.5628 0.7878 | 0.3893 0.3893 0.1876 | 0.1453 25.8149 21.0327 0.2587 0.5380 0.6731 ||TEST: 1.1035 0.3826 0.6511 | 0.5388 0.5388 0.2148 | 0.1520 26.6546 22.1787 0.2468 0.5128 0.6469 | 116.1374
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.74823907 0.74817707 0.74826123 0.74832909 0.74830759 0.74835152
 0.74829089 0.74830989 0.74827361 0.74825554 0.74829518 0.74831476
 0.74831446 0.74825968 0.74819295 0.7481208  0.74794902 0.74794299
 0.74784697 0.7479396 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.74819563 0.74819961 0.74822783 0.74820344 0.74817483 0.7482415
 0.7482887  0.7482935  0.74829617 0.74830098 0.74832015 0.7483008
 0.7483121  0.74834046 0.74835691 0.74834585 0.74835007 0.74834724
 0.74838773 0.74839234]
[0.         0.44736842 0.        ]
-----------end of analyzing the loss ratio:74.47738909721375
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d72b92d0>
---------------------------------
SparseEpoch: [73][1/398]	Time 0.615	Data 0.000	Loss 0.7700	
SparseEpoch: [73][101/398]	Time 0.626	Data 0.000	Loss 1.3516	
SparseEpoch: [73][201/398]	Time 0.626	Data 0.000	Loss 1.1408	
SparseEpoch: [73][301/398]	Time 0.626	Data 0.000	Loss 1.4584	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.52309543 0.52269756 0.52265649 0.52283983 0.52250292 0.52227944
 0.52213699 0.52180621 0.52152267 0.52145245 0.52118264 0.52097692
 0.52070633 0.52032219 0.51998701 0.52009727 0.52002632 0.51996799
 0.52005042 0.51975473]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.52134936 0.52133545 0.52131025 0.52130105 0.52128712 0.52127352
 0.52127445 0.52125203 0.52128991 0.52129357 0.52127632 0.52130503
 0.52127616 0.52127679 0.52126416 0.52127579 0.52128494 0.52132266
 0.52131522 0.52127787]
[0.5 0.  0. ]
-----------end of analyzing the loss ratio:74.48766469955444
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc35e620>
---------------------------------
SparseEpoch: [73][1/398]	Time 0.624	Data 0.000	Loss 0.6597	
SparseEpoch: [73][101/398]	Time 0.626	Data 0.000	Loss 1.3185	
SparseEpoch: [73][201/398]	Time 0.625	Data 0.000	Loss 0.7468	
SparseEpoch: [73][301/398]	Time 0.622	Data 0.000	Loss 0.8186	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.16936578 0.16933957 0.1693208  0.16935691 0.1693279  0.16929715
 0.16927859 0.16928386 0.16927114 0.16922136 0.16923569 0.1691622
 0.16915143 0.1691529  0.16916524 0.16913567 0.16913307 0.16909719
 0.1691021  0.16904604]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.16929804 0.16928002 0.16928234 0.16926873 0.16925282 0.16924889
 0.16926528 0.16922406 0.16920965 0.16920668 0.16919513 0.16919789
 0.16919973 0.16918636 0.16917956 0.16917082 0.16917221 0.16917883
 0.16916819 0.16915714]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:74.66866207122803
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc5507c0>
---------------------------------
SparseEpoch: [73][1/398]	Time 0.605	Data 0.000	Loss 2.1839	
SparseEpoch: [73][101/398]	Time 0.622	Data 0.000	Loss 2.0253	
SparseEpoch: [73][201/398]	Time 0.623	Data 0.000	Loss 2.3259	
SparseEpoch: [73][301/398]	Time 0.625	Data 0.000	Loss 3.1235	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.4379	
Epoch(adapt):{0} Loss 0.9848	
Epoch(adapt):{0} Loss 1.1558	
Epoch(adapt):{0} Loss 1.6459	
------------------the total time cost:1217.3667278289795
>>>>>meta updating
Epoch: 0073 | TRAIN: 0.6394 0.5672 0.7966 | 0.4141 0.4141 0.1857 | 0.1517 26.6549 22.2398 0.2405 0.5117 0.6511 ||TEST: 1.0949 0.3855 0.6554 | 0.5672 0.5672 0.2192 | 0.1573 27.3735 23.2446 0.2309 0.4908 0.6278 | 115.9769
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.7425062  0.74251536 0.74244098 0.74237531 0.74246752 0.74245883
 0.74247269 0.74247168 0.74256189 0.74256143 0.74256223 0.74255514
 0.74256062 0.74259054 0.74256359 0.74262508 0.74261146 0.74265092
 0.74257571 0.74260234]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.74255671 0.74255678 0.74255575 0.74255309 0.74255805 0.74254453
 0.74255973 0.74254186 0.74253115 0.74254186 0.74258521 0.74259626
 0.74257665 0.74257836 0.74257551 0.74255984 0.74255138 0.74256243
 0.74255406 0.74256721]
[0. 0. 0.]
-----------end of analyzing the loss ratio:74.79792785644531
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc325720>
---------------------------------
SparseEpoch: [74][1/398]	Time 0.608	Data 0.000	Loss 0.5661	
SparseEpoch: [74][101/398]	Time 0.627	Data 0.000	Loss 0.8804	
SparseEpoch: [74][201/398]	Time 0.626	Data 0.000	Loss 1.0649	
SparseEpoch: [74][301/398]	Time 0.624	Data 0.000	Loss 0.4831	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.63531996 0.63543055 0.63554977 0.63549286 0.63543095 0.63559296
 0.63566295 0.63588465 0.63606739 0.63629699 0.63644312 0.6364663
 0.63663878 0.63670524 0.63677387 0.63687066 0.63691033 0.63705141
 0.63716143 0.63709845]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.63625955 0.63627045 0.63625253 0.63623571 0.63624126 0.63623946
 0.63626195 0.63629163 0.63628649 0.63629933 0.63630838 0.63632526
 0.63630978 0.63630468 0.63630157 0.63633537 0.63634341 0.63636527
 0.63638813 0.63641573]
[0. 0. 0.]
-----------end of analyzing the loss ratio:74.5805881023407
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7446096901f0>
---------------------------------
SparseEpoch: [74][1/398]	Time 0.612	Data 0.000	Loss 0.4549	
SparseEpoch: [74][101/398]	Time 0.622	Data 0.000	Loss 0.4046	
SparseEpoch: [74][201/398]	Time 0.622	Data 0.000	Loss 0.4294	
SparseEpoch: [74][301/398]	Time 0.621	Data 0.000	Loss 0.3059	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.22393715 0.22380848 0.22370282 0.2236268  0.22358166 0.22353393
 0.22347438 0.22341126 0.22336372 0.22333677 0.22331337 0.22330313
 0.22324913 0.22318079 0.22303667 0.22297865 0.22283255 0.22270603
 0.22267992 0.22256937]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.22340854 0.22340157 0.22337622 0.22337027 0.22335548 0.22331283
 0.22332764 0.22333977 0.22332618 0.22332927 0.22336013 0.2233236
 0.22332635 0.22333229 0.22332429 0.22337111 0.2232869  0.22322989
 0.22322587 0.22317965]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:74.70003890991211
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc0ed540>
---------------------------------
SparseEpoch: [74][1/398]	Time 0.606	Data 0.000	Loss 1.5380	
SparseEpoch: [74][101/398]	Time 0.624	Data 0.000	Loss 1.8227	
SparseEpoch: [74][201/398]	Time 0.624	Data 0.000	Loss 1.3854	
SparseEpoch: [74][301/398]	Time 0.625	Data 0.000	Loss 2.5591	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.6719	
Epoch(adapt):{0} Loss 1.2995	
Epoch(adapt):{0} Loss 1.0241	
Epoch(adapt):{0} Loss 1.2458	
------------------the total time cost:1217.799883365631
>>>>>meta updating
Epoch: 0074 | TRAIN: 0.6344 0.5644 0.7942 | 0.3902 0.3902 0.1879 | 0.1502 26.3436 21.6667 0.2511 0.5246 0.6602 ||TEST: 1.1192 0.3765 0.6533 | 0.5337 0.5337 0.2164 | 0.1555 27.0415 22.6303 0.2414 0.5034 0.6377 | 116.0994
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.632649   0.6326696  0.63259872 0.63244869 0.63253742 0.63263958
 0.63263563 0.63261626 0.63264757 0.63267048 0.63258156 0.63260612
 0.63255616 0.63255788 0.63258143 0.63277178 0.63267641 0.63274987
 0.63269988 0.63266655]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.63260536 0.63259249 0.63258663 0.63258162 0.63258376 0.63257219
 0.63255108 0.63257455 0.63258604 0.6325881  0.63257052 0.63259025
 0.6326154  0.63262341 0.63258843 0.63259523 0.6326012  0.63262447
 0.63265797 0.63266183]
[0. 0. 0.]
-----------end of analyzing the loss ratio:74.72487354278564
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d722fdc0>
---------------------------------
SparseEpoch: [75][1/398]	Time 0.604	Data 0.000	Loss 0.5669	
SparseEpoch: [75][101/398]	Time 0.619	Data 0.000	Loss 1.2500	
SparseEpoch: [75][201/398]	Time 0.619	Data 0.000	Loss 0.3863	
SparseEpoch: [75][301/398]	Time 0.621	Data 0.000	Loss 0.8311	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.64337249 0.64347277 0.64347304 0.64345354 0.64355382 0.64366069
 0.64353718 0.64353729 0.64368929 0.64377891 0.64370742 0.6436451
 0.64361282 0.64367741 0.64371768 0.64351397 0.64368636 0.64368669
 0.64347892 0.64353904]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.64374975 0.64374007 0.64375497 0.64375067 0.64380915 0.64380911
 0.64378537 0.64380682 0.64383259 0.64380854 0.64379904 0.64378023
 0.64374307 0.64371695 0.64368636 0.64367988 0.64370578 0.64366135
 0.64367435 0.64366557]
[0.         0.         0.39473684]
-----------end of analyzing the loss ratio:74.62614822387695
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc3cf5e0>
---------------------------------
SparseEpoch: [75][1/398]	Time 0.623	Data 0.000	Loss 0.7966	
SparseEpoch: [75][101/398]	Time 0.622	Data 0.000	Loss 0.7703	
SparseEpoch: [75][201/398]	Time 0.624	Data 0.000	Loss 0.7617	
SparseEpoch: [75][301/398]	Time 0.624	Data 0.000	Loss 0.7592	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.17418281 0.17411832 0.17402322 0.1739824  0.17396102 0.17393305
 0.17389764 0.17387365 0.17381003 0.17378512 0.17372649 0.17369378
 0.17368099 0.17362836 0.17362188 0.17360857 0.17356766 0.17352885
 0.17345384 0.17338297]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.17383782 0.17381217 0.17378839 0.17378148 0.17382163 0.17382254
 0.17379104 0.17378389 0.17378134 0.17376304 0.17376348 0.17370757
 0.17372965 0.17373482 0.17374825 0.17371905 0.17369332 0.17370999
 0.17370368 0.17368427]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:74.94077324867249
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x74460961c460>
---------------------------------
SparseEpoch: [75][1/398]	Time 0.606	Data 0.000	Loss 2.6871	
SparseEpoch: [75][101/398]	Time 0.625	Data 0.000	Loss 2.4180	
SparseEpoch: [75][201/398]	Time 0.624	Data 0.000	Loss 3.1772	
SparseEpoch: [75][301/398]	Time 0.625	Data 0.000	Loss 2.7989	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.8879	
Epoch(adapt):{0} Loss 1.5813	
Epoch(adapt):{0} Loss 1.4610	
Epoch(adapt):{0} Loss 1.3647	
------------------the total time cost:1216.453486442566
>>>>>meta updating
Epoch: 0075 | TRAIN: 0.6589 0.5652 0.7890 | 0.3938 0.3938 0.1912 | 0.1486 26.0647 21.2460 0.2600 0.5346 0.6677 ||TEST: 1.1318 0.3823 0.6506 | 0.5402 0.5402 0.2179 | 0.1544 26.8114 22.2038 0.2502 0.5120 0.6435 | 116.2067
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.68937567 0.68933475 0.68945166 0.68939364 0.68936174 0.68937486
 0.68931076 0.68927561 0.68920019 0.68924413 0.68923329 0.68929746
 0.68932136 0.68933188 0.68933571 0.68929497 0.68932444 0.68929504
 0.68929234 0.68930681]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.68935225 0.68935962 0.6893465  0.6893362  0.68932198 0.68926569
 0.68927269 0.68923515 0.68925769 0.68924615 0.68922384 0.68922593
 0.68922641 0.68921119 0.68925681 0.68926821 0.68930992 0.68926777
 0.68924164 0.68925254]
[0.         0.         0.18421053]
-----------end of analyzing the loss ratio:74.5855963230133
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc37e350>
---------------------------------
SparseEpoch: [76][1/398]	Time 0.608	Data 0.000	Loss 0.8850	
SparseEpoch: [76][101/398]	Time 0.630	Data 0.000	Loss 1.1164	
SparseEpoch: [76][201/398]	Time 0.627	Data 0.000	Loss 1.4295	
SparseEpoch: [76][301/398]	Time 0.625	Data 0.000	Loss 1.1697	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.54020122 0.54018131 0.54028078 0.54034184 0.54042041 0.54026308
 0.5401319  0.5403813  0.54033364 0.54043948 0.54040954 0.54047482
 0.54039929 0.54038552 0.54047955 0.54045572 0.54047552 0.54062445
 0.54101194 0.54078563]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.54038091 0.54037333 0.54035075 0.54032311 0.54030351 0.54032936
 0.54033263 0.54034493 0.54034793 0.54036076 0.54030653 0.54031062
 0.54027197 0.54029253 0.54028323 0.54030459 0.5403358  0.54030465
 0.54028821 0.54029891]
[0.         0.         0.13157895]
-----------end of analyzing the loss ratio:74.64753866195679
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444dc151150>
---------------------------------
SparseEpoch: [76][1/398]	Time 0.604	Data 0.000	Loss 0.4895	
SparseEpoch: [76][101/398]	Time 0.627	Data 0.000	Loss 0.6225	
SparseEpoch: [76][201/398]	Time 0.623	Data 0.000	Loss 0.6990	
SparseEpoch: [76][301/398]	Time 0.623	Data 0.000	Loss 0.5244	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.17639397 0.1764395  0.17643108 0.17639464 0.17643704 0.17644235
 0.17641878 0.17644593 0.17646079 0.17644455 0.17644458 0.17645959
 0.1764534  0.17646137 0.17643069 0.17639058 0.17641169 0.17640554
 0.17639733 0.17638175]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.17643155 0.17642722 0.17644255 0.17645842 0.17646286 0.17644864
 0.17645181 0.17646166 0.17645842 0.1764744  0.17643595 0.17642645
 0.17643225 0.17643772 0.17640637 0.17642329 0.17641858 0.17639312
 0.17640347 0.17642572]
[0.5        0.39473684 0.        ]
-----------end of analyzing the loss ratio:74.51046943664551
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x744609942200>
---------------------------------
SparseEpoch: [76][1/398]	Time 0.606	Data 0.000	Loss 1.8607	
SparseEpoch: [76][101/398]	Time 0.626	Data 0.000	Loss 2.2086	
SparseEpoch: [76][201/398]	Time 0.626	Data 0.000	Loss 2.0969	
SparseEpoch: [76][301/398]	Time 0.625	Data 0.000	Loss 2.1106	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.2171	
Epoch(adapt):{0} Loss 1.5771	
Epoch(adapt):{0} Loss 1.7598	
Epoch(adapt):{0} Loss 1.2315	
------------------the total time cost:1217.7238023281097
>>>>>meta updating
Epoch: 0076 | TRAIN: 0.6613 0.5671 0.7946 | 0.4285 0.4285 0.1972 | 0.1492 26.3484 21.6855 0.2442 0.5236 0.6623 ||TEST: 1.0886 0.3847 0.6544 | 0.5772 0.5772 0.2221 | 0.1544 27.0230 22.6428 0.2356 0.5035 0.6394 | 115.7383
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.68983508 0.68977249 0.68956347 0.68944578 0.68929839 0.68921256
 0.68914651 0.68912154 0.68910171 0.68899056 0.68907773 0.6891841
 0.68918126 0.68900605 0.68896109 0.68893148 0.68892916 0.68895712
 0.68887598 0.6888993 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.68904435 0.68901553 0.68906597 0.68904267 0.68910428 0.68906603
 0.68903466 0.68900297 0.68901224 0.68906677 0.68903566 0.68905568
 0.68909554 0.68907609 0.68909139 0.68914204 0.68919047 0.6891255
 0.68915223 0.68919972]
[0.         0.44736842 0.        ]
-----------end of analyzing the loss ratio:74.58373713493347
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc42fa00>
---------------------------------
SparseEpoch: [77][1/398]	Time 0.606	Data 0.000	Loss 0.9374	
SparseEpoch: [77][101/398]	Time 0.624	Data 0.000	Loss 1.0687	
SparseEpoch: [77][201/398]	Time 0.627	Data 0.000	Loss 0.7619	
SparseEpoch: [77][301/398]	Time 0.627	Data 0.000	Loss 1.0179	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.4564042  0.45607335 0.45600372 0.45565372 0.45529209 0.45499914
 0.45468304 0.4545265  0.45438151 0.45423942 0.45406025 0.45385627
 0.45362285 0.4534692  0.45330374 0.45291931 0.45274672 0.45259054
 0.45244047 0.45234877]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.45424665 0.4542458  0.45424005 0.4542313  0.45423262 0.45426023
 0.45428846 0.45427951 0.4543123  0.45426967 0.45424731 0.45421441
 0.45416431 0.45416948 0.45415591 0.45412256 0.45402885 0.45398906
 0.45400969 0.45397471]
[0.5 0.  0.5]
-----------end of analyzing the loss ratio:74.7128918170929
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6e790f0>
---------------------------------
SparseEpoch: [77][1/398]	Time 0.605	Data 0.000	Loss 1.1620	
SparseEpoch: [77][101/398]	Time 0.622	Data 0.000	Loss 1.7195	
SparseEpoch: [77][201/398]	Time 0.624	Data 0.000	Loss 1.7787	
SparseEpoch: [77][301/398]	Time 0.624	Data 0.000	Loss 1.8727	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.16231797 0.16229566 0.16226532 0.1622693  0.16220163 0.16214876
 0.16211454 0.16212277 0.1621018  0.16208176 0.16203484 0.16201175
 0.16206095 0.16200701 0.16200573 0.16199417 0.16196654 0.16194217
 0.16196482 0.16192861]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.16212627 0.16211251 0.16211613 0.16210523 0.16208199 0.16212223
 0.16211438 0.16209902 0.16209494 0.16208532 0.16203766 0.16202648
 0.1620333  0.16203726 0.16203871 0.16202817 0.16205403 0.16204156
 0.16205099 0.1620318 ]
[0.5        0.07894737 0.        ]
-----------end of analyzing the loss ratio:74.73614358901978
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6fe8130>
---------------------------------
SparseEpoch: [77][1/398]	Time 0.616	Data 0.000	Loss 1.9504	
SparseEpoch: [77][101/398]	Time 0.622	Data 0.000	Loss 2.4585	
SparseEpoch: [77][201/398]	Time 0.623	Data 0.000	Loss 2.2684	
SparseEpoch: [77][301/398]	Time 0.624	Data 0.000	Loss 2.7300	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.4378	
Epoch(adapt):{0} Loss 1.8553	
Epoch(adapt):{0} Loss 1.5625	
Epoch(adapt):{0} Loss 1.1557	
------------------the total time cost:1218.4893090724945
>>>>>meta updating
Epoch: 0077 | TRAIN: 0.6303 0.5708 0.7970 | 0.4167 0.4167 0.1904 | 0.1491 26.3490 21.8763 0.2464 0.5197 0.6584 ||TEST: 1.1198 0.3781 0.6535 | 0.5772 0.5772 0.2203 | 0.1564 27.2430 22.9901 0.2335 0.4963 0.6324 | 116.1262
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.57547166 0.57541054 0.5751698  0.57525947 0.57526788 0.57534555
 0.57534426 0.57547318 0.57546969 0.57549421 0.57551289 0.57529719
 0.57533362 0.5754762  0.57558396 0.57544605 0.57545075 0.57550025
 0.57561969 0.57558024]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.57560422 0.57558472 0.57556677 0.57557341 0.57550973 0.57547856
 0.57549104 0.57546394 0.57546304 0.57547244 0.57545687 0.5754876
 0.575477   0.5754938  0.57548559 0.57547714 0.5755192  0.57555845
 0.57555666 0.57557665]
[0.         0.         0.02631579]
-----------end of analyzing the loss ratio:74.84710669517517
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc42e5f0>
---------------------------------
SparseEpoch: [78][1/398]	Time 0.605	Data 0.000	Loss 0.8002	
SparseEpoch: [78][101/398]	Time 0.623	Data 0.000	Loss 0.5607	
SparseEpoch: [78][201/398]	Time 0.624	Data 0.000	Loss 0.8899	
SparseEpoch: [78][301/398]	Time 0.624	Data 0.000	Loss 0.5826	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.52784713 0.52785403 0.52789839 0.52805204 0.52791949 0.52793317
 0.52790778 0.5279184  0.52796062 0.5280568  0.52815193 0.52813011
 0.52808706 0.52799789 0.52801095 0.52813453 0.5280938  0.5279474
 0.52807379 0.52820051]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.52799613 0.52800229 0.52800999 0.52798413 0.52802344 0.52804484
 0.52807415 0.52805198 0.52808383 0.52808854 0.52810539 0.52810941
 0.52816029 0.52818554 0.52818794 0.52817665 0.52815243 0.52812984
 0.52814775 0.52812894]
[0. 0. 0.]
-----------end of analyzing the loss ratio:74.68052816390991
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc3ce5c0>
---------------------------------
SparseEpoch: [78][1/398]	Time 0.609	Data 0.000	Loss 0.5232	
SparseEpoch: [78][101/398]	Time 0.622	Data 0.000	Loss 0.5205	
SparseEpoch: [78][201/398]	Time 0.622	Data 0.000	Loss 0.3117	
SparseEpoch: [78][301/398]	Time 0.622	Data 0.000	Loss 0.4283	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.18387991 0.18388018 0.18384652 0.18392123 0.1838891  0.18387241
 0.18385267 0.18384758 0.18388415 0.18386289 0.18386145 0.18386298
 0.18384194 0.18381378 0.18379349 0.1837941  0.18381774 0.18380845
 0.18381197 0.18386   ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.18396756 0.18396223 0.18394734 0.1839471  0.18395399 0.18393692
 0.18393025 0.18391871 0.18387956 0.18388785 0.18385234 0.18384324
 0.18382614 0.18381492 0.18381683 0.18380677 0.18377306 0.18375818
 0.18373765 0.18376144]
[0.23684211 0.44736842 0.        ]
-----------end of analyzing the loss ratio:74.4847800731659
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc3cd810>
---------------------------------
SparseEpoch: [78][1/398]	Time 0.612	Data 0.000	Loss 1.3494	
SparseEpoch: [78][101/398]	Time 0.629	Data 0.000	Loss 1.7287	
SparseEpoch: [78][201/398]	Time 0.626	Data 0.000	Loss 3.0181	
SparseEpoch: [78][301/398]	Time 0.627	Data 0.000	Loss 1.9897	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.0507	
Epoch(adapt):{0} Loss 0.8926	
Epoch(adapt):{0} Loss 0.9150	
Epoch(adapt):{0} Loss 1.4600	
------------------the total time cost:1216.087483406067
>>>>>meta updating
Epoch: 0078 | TRAIN: 0.6413 0.5712 0.7985 | 0.3906 0.3906 0.1858 | 0.1481 26.2862 21.7456 0.2420 0.5221 0.6636 ||TEST: 1.0880 0.3786 0.6544 | 0.5413 0.5413 0.2147 | 0.1553 27.1430 22.8485 0.2323 0.4996 0.6369 | 116.0395
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.75180291 0.75166915 0.75161333 0.75172387 0.75198331 0.75194357
 0.75203579 0.75192865 0.75204684 0.75232312 0.75245231 0.75235313
 0.75225148 0.752177   0.75214548 0.75208439 0.75204953 0.7520892
 0.75221216 0.75233396]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.75228619 0.75228068 0.75229162 0.75224933 0.75225959 0.75227828
 0.75230735 0.75232883 0.75235201 0.75241086 0.75237087 0.7523762
 0.75234998 0.75236273 0.7524085  0.75242324 0.75241909 0.75242785
 0.75242671 0.75240646]
[0. 0. 0.]
-----------end of analyzing the loss ratio:74.58564066886902
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc2f54b0>
---------------------------------
SparseEpoch: [79][1/398]	Time 0.607	Data 0.000	Loss 0.7069	
SparseEpoch: [79][101/398]	Time 0.619	Data 0.000	Loss 1.0155	
SparseEpoch: [79][201/398]	Time 0.620	Data 0.000	Loss 1.2504	
SparseEpoch: [79][301/398]	Time 0.621	Data 0.000	Loss 0.6357	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.66527813 0.66453391 0.66380857 0.66324912 0.66259782 0.6620004
 0.66149608 0.66106592 0.66043365 0.6597928  0.65918407 0.65864845
 0.65807955 0.65719297 0.65667428 0.65635596 0.65574265 0.65538648
 0.65474954 0.65378334]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.65967812 0.65969184 0.65966342 0.65962554 0.65963269 0.65957139
 0.65952281 0.65953312 0.65943739 0.65942001 0.65941719 0.65937281
 0.65925042 0.65924386 0.6592205  0.6592165  0.65920509 0.65927471
 0.65919831 0.65919129]
[0.5 0.  0.5]
-----------end of analyzing the loss ratio:74.59580779075623
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc5eb700>
---------------------------------
SparseEpoch: [79][1/398]	Time 0.605	Data 0.000	Loss 1.2174	
SparseEpoch: [79][101/398]	Time 0.626	Data 0.000	Loss 1.4497	
SparseEpoch: [79][201/398]	Time 0.623	Data 0.000	Loss 1.5652	
SparseEpoch: [79][301/398]	Time 0.623	Data 0.000	Loss 1.5417	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.24278015 0.24275749 0.24278587 0.24276087 0.24281436 0.24283334
 0.24276022 0.24273525 0.24271467 0.2427038  0.24265906 0.24269208
 0.24266192 0.24264742 0.24265867 0.24269421 0.24273698 0.24274004
 0.24267014 0.24264734]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.2427503  0.24274749 0.24271259 0.24271563 0.24270178 0.24267915
 0.24268371 0.24268079 0.24267612 0.24267669 0.24267377 0.24267341
 0.24267919 0.24268926 0.24269156 0.24268993 0.2426888  0.24266379
 0.24264766 0.24263679]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:74.7599127292633
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d72d2d10>
---------------------------------
SparseEpoch: [79][1/398]	Time 0.614	Data 0.000	Loss 3.0912	
SparseEpoch: [79][101/398]	Time 0.629	Data 0.000	Loss 1.3253	
SparseEpoch: [79][201/398]	Time 0.626	Data 0.000	Loss 2.0851	
SparseEpoch: [79][301/398]	Time 0.625	Data 0.000	Loss 2.0104	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.4274	
Epoch(adapt):{0} Loss 2.1723	
Epoch(adapt):{0} Loss 1.7727	
Epoch(adapt):{0} Loss 1.2748	
------------------the total time cost:1216.9934878349304
>>>>>meta updating
Epoch: 0079 | TRAIN: 0.5939 0.5900 0.8089 | 0.3861 0.3861 0.1816 | 0.1463 25.8975 21.2100 0.2590 0.5338 0.6702 ||TEST: 1.1140 0.3896 0.6577 | 0.5369 0.5369 0.2132 | 0.1535 26.7776 22.3853 0.2469 0.5092 0.6440 | 116.0474
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.41856181 0.41856117 0.41858976 0.41863105 0.41864685 0.41873188
 0.41870622 0.41869892 0.41870204 0.41884865 0.4188806  0.4189271
 0.4189822  0.41906123 0.41905285 0.41906638 0.41919676 0.41932228
 0.41933825 0.41942559]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.41889399 0.4188897  0.4188794  0.41886829 0.41888973 0.41890136
 0.41889807 0.41888168 0.4188717  0.41888454 0.41887031 0.4188672
 0.41886724 0.41885173 0.41882579 0.41881818 0.4187967  0.41881464
 0.41880669 0.41879765]
[0.         0.         0.34210526]
-----------end of analyzing the loss ratio:74.67293119430542
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444dc340070>
---------------------------------
SparseEpoch: [80][1/398]	Time 0.608	Data 0.000	Loss 1.0294	
SparseEpoch: [80][101/398]	Time 0.624	Data 0.000	Loss 1.5730	
SparseEpoch: [80][201/398]	Time 0.623	Data 0.000	Loss 1.2193	
SparseEpoch: [80][301/398]	Time 0.624	Data 0.000	Loss 1.8443	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.58651408 0.58578448 0.58509155 0.58424412 0.58324873 0.58227378
 0.58150824 0.58037077 0.57925254 0.57829682 0.57754481 0.57676995
 0.5760718  0.57497682 0.57427967 0.57340641 0.57260471 0.57167874
 0.57090531 0.5700424 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.57847874 0.57842288 0.57833663 0.57827048 0.57824252 0.57816944
 0.57810615 0.57797021 0.57788359 0.57784073 0.57779341 0.57783156
 0.57775688 0.57776828 0.57771172 0.57763163 0.57761138 0.57760957
 0.57754713 0.57758019]
[0.5        0.         0.44736842]
-----------end of analyzing the loss ratio:74.59997701644897
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc41d330>
---------------------------------
SparseEpoch: [80][1/398]	Time 0.606	Data 0.000	Loss 1.2327	
SparseEpoch: [80][101/398]	Time 0.625	Data 0.000	Loss 1.5787	
SparseEpoch: [80][201/398]	Time 0.624	Data 0.000	Loss 1.4834	
SparseEpoch: [80][301/398]	Time 0.623	Data 0.000	Loss 1.2234	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.15812929 0.15814359 0.15812757 0.15808553 0.1580121  0.15801085
 0.15799824 0.15798521 0.15800368 0.15795597 0.15803812 0.15811055
 0.15812912 0.15814065 0.15817155 0.15811898 0.15815427 0.15813595
 0.15820152 0.15824902]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.15795318 0.15796655 0.15799224 0.15798883 0.15795794 0.1579779
 0.15796958 0.15797704 0.15799733 0.15799656 0.15801895 0.15801104
 0.15803831 0.15808376 0.15806764 0.15807988 0.15810586 0.15811251
 0.15813183 0.15816064]
[0. 0. 0.]
-----------end of analyzing the loss ratio:74.79040312767029
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc536770>
---------------------------------
SparseEpoch: [80][1/398]	Time 0.605	Data 0.000	Loss 1.2333	
SparseEpoch: [80][101/398]	Time 0.626	Data 0.000	Loss 0.8195	
SparseEpoch: [80][201/398]	Time 0.625	Data 0.000	Loss 1.6861	
SparseEpoch: [80][301/398]	Time 0.626	Data 0.000	Loss 1.9331	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.0693	
Epoch(adapt):{0} Loss 1.2788	
Epoch(adapt):{0} Loss 0.9757	
Epoch(adapt):{0} Loss 1.5250	
------------------the total time cost:1219.0948956012726
>>>>>meta updating
Epoch: 0080 | TRAIN: 0.5917 0.5881 0.8080 | 0.4088 0.4088 0.1875 | 0.1449 25.8023 21.1220 0.2561 0.5369 0.6741 ||TEST: 1.1115 0.3762 0.6555 | 0.5637 0.5637 0.2159 | 0.1516 26.6283 22.2225 0.2468 0.5126 0.6470 | 115.8119
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.60933495 0.60924848 0.60927176 0.60933192 0.60934437 0.60929629
 0.60926309 0.6092728  0.60933331 0.60937296 0.60942325 0.6094909
 0.60949406 0.6095013  0.60956185 0.60952959 0.60952238 0.60953524
 0.60955099 0.60953993]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.60922572 0.60921334 0.60927975 0.60927629 0.60929695 0.60933387
 0.60935418 0.60937867 0.60936934 0.60937174 0.60943117 0.60942453
 0.6094676  0.60943883 0.60945588 0.6094549  0.60947025 0.60948076
 0.60953022 0.60956554]
[0. 0. 0.]
-----------end of analyzing the loss ratio:74.70310020446777
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d7077610>
---------------------------------
SparseEpoch: [81][1/398]	Time 0.608	Data 0.000	Loss 1.5067	
SparseEpoch: [81][101/398]	Time 0.626	Data 0.000	Loss 0.7179	
SparseEpoch: [81][201/398]	Time 0.622	Data 0.000	Loss 0.6820	
SparseEpoch: [81][301/398]	Time 0.622	Data 0.000	Loss 1.0081	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.55389582 0.55407231 0.5540794  0.55415745 0.55426494 0.55442766
 0.55447632 0.55459598 0.55459449 0.55472845 0.55477189 0.55475149
 0.5549019  0.55486369 0.55485078 0.55488172 0.55493966 0.5549499
 0.55484559 0.55470169]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.5545623  0.5545315  0.55458751 0.55463402 0.55466031 0.55468045
 0.55468132 0.5546506  0.55466858 0.55472034 0.55474178 0.55475912
 0.55474524 0.55478504 0.55478774 0.5547904  0.55482416 0.55483127
 0.55481177 0.55480311]
[0. 0. 0.]
-----------end of analyzing the loss ratio:74.61973738670349
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d71a1a20>
---------------------------------
SparseEpoch: [81][1/398]	Time 0.603	Data 0.000	Loss 0.2994	
SparseEpoch: [81][101/398]	Time 0.627	Data 0.000	Loss 0.2783	
SparseEpoch: [81][201/398]	Time 0.624	Data 0.000	Loss 0.4828	
SparseEpoch: [81][301/398]	Time 0.625	Data 0.000	Loss 0.4146	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.15917816 0.15919746 0.15917289 0.15918252 0.15919501 0.15918685
 0.15915906 0.15916114 0.15917826 0.15914234 0.15911407 0.15913547
 0.15914418 0.15914815 0.15912868 0.15912424 0.15908891 0.15910127
 0.15910283 0.15910779]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.15931379 0.15932412 0.15927953 0.15924064 0.15924227 0.15922862
 0.15921629 0.1591704  0.15915822 0.15912637 0.15913704 0.15912507
 0.15911604 0.15912068 0.15907711 0.15906942 0.15907654 0.15906963
 0.1590046  0.15894963]
[0.34210526 0.5        0.        ]
-----------end of analyzing the loss ratio:74.76771688461304
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d71f0130>
---------------------------------
SparseEpoch: [81][1/398]	Time 0.608	Data 0.000	Loss 2.7551	
SparseEpoch: [81][101/398]	Time 0.620	Data 0.000	Loss 1.5419	
SparseEpoch: [81][201/398]	Time 0.621	Data 0.000	Loss 1.7709	
SparseEpoch: [81][301/398]	Time 0.621	Data 0.000	Loss 2.3359	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.0076	
Epoch(adapt):{0} Loss 2.0162	
Epoch(adapt):{0} Loss 2.7512	
Epoch(adapt):{0} Loss 1.3371	
------------------the total time cost:1216.2269949913025
>>>>>meta updating
Epoch: 0081 | TRAIN: 0.5942 0.5858 0.8111 | 0.3839 0.3839 0.1841 | 0.1474 26.0829 21.3937 0.2521 0.5300 0.6673 ||TEST: 1.1114 0.3835 0.6601 | 0.5397 0.5397 0.2139 | 0.1538 26.8913 22.4742 0.2414 0.5071 0.6419 | 115.7254
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.57830253 0.57816804 0.57808762 0.57799645 0.57807982 0.57807358
 0.57817908 0.57821992 0.578251   0.57811032 0.57805849 0.5779835
 0.57780686 0.57773889 0.57778941 0.57786698 0.57781225 0.57773055
 0.57776965 0.5777469 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.57816722 0.57819711 0.57822247 0.57821671 0.57823749 0.57821279
 0.57819054 0.57814917 0.5781089  0.57808037 0.57806984 0.57805279
 0.5780927  0.57806979 0.57800623 0.57798827 0.57798812 0.57799215
 0.57798857 0.57798082]
[0.         0.39473684 0.5       ]
-----------end of analyzing the loss ratio:74.77259039878845
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d7096ad0>
---------------------------------
SparseEpoch: [82][1/398]	Time 0.605	Data 0.000	Loss 2.1136	
SparseEpoch: [82][101/398]	Time 0.628	Data 0.000	Loss 2.0447	
SparseEpoch: [82][201/398]	Time 0.623	Data 0.000	Loss 2.5093	
SparseEpoch: [82][301/398]	Time 0.625	Data 0.000	Loss 1.5374	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.61585928 0.61593485 0.6159494  0.61594954 0.61593247 0.61589762
 0.61593742 0.61582026 0.61581056 0.61583717 0.61594011 0.6158552
 0.61583321 0.61579462 0.61572106 0.61569471 0.615672   0.61568107
 0.61573825 0.61575486]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.61605192 0.61603412 0.61600612 0.61598861 0.61593387 0.61592135
 0.61591436 0.61589459 0.61589978 0.61588512 0.61587865 0.6158577
 0.61583888 0.61579717 0.6157076  0.61569676 0.6156872  0.61566037
 0.61562547 0.61562631]
[0.34210526 0.         0.44736842]
-----------end of analyzing the loss ratio:74.60965704917908
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc168e50>
---------------------------------
SparseEpoch: [82][1/398]	Time 0.605	Data 0.000	Loss 1.0737	
SparseEpoch: [82][101/398]	Time 0.624	Data 0.000	Loss 1.4770	
SparseEpoch: [82][201/398]	Time 0.622	Data 0.000	Loss 1.1081	
SparseEpoch: [82][301/398]	Time 0.623	Data 0.000	Loss 1.3256	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.20634626 0.20633421 0.20634185 0.20631014 0.20628964 0.20625578
 0.20620849 0.20616295 0.20613823 0.20605339 0.20601507 0.20600257
 0.20597681 0.20593992 0.20589691 0.20583146 0.20577509 0.20571139
 0.20562832 0.20563396]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.20606349 0.20605637 0.20604554 0.20606087 0.20606987 0.20605304
 0.20603552 0.20604364 0.2060334  0.20604797 0.20603178 0.20603956
 0.20602652 0.20600925 0.20599701 0.20600625 0.20601093 0.206017
 0.20601467 0.20602175]
[0.44736842 0.23684211 0.        ]
-----------end of analyzing the loss ratio:74.61745977401733
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc1682b0>
---------------------------------
SparseEpoch: [82][1/398]	Time 0.604	Data 0.000	Loss 2.0510	
SparseEpoch: [82][101/398]	Time 0.629	Data 0.000	Loss 2.2159	
SparseEpoch: [82][201/398]	Time 0.628	Data 0.000	Loss 2.8652	
SparseEpoch: [82][301/398]	Time 0.627	Data 0.000	Loss 1.6561	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.7711	
Epoch(adapt):{0} Loss 0.7194	
Epoch(adapt):{0} Loss 0.8329	
Epoch(adapt):{0} Loss 1.8081	
------------------the total time cost:1218.284784078598
>>>>>meta updating
Epoch: 0082 | TRAIN: 0.5872 0.6034 0.8145 | 0.3800 0.3800 0.1829 | 0.1434 25.6402 20.8666 0.2570 0.5426 0.6798 ||TEST: 1.1108 0.3931 0.6624 | 0.5365 0.5365 0.2164 | 0.1506 26.5361 21.9891 0.2454 0.5171 0.6516 | 116.2664
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.55000431 0.54998069 0.54998917 0.54997373 0.54996846 0.5499164
 0.54987142 0.54987482 0.54987423 0.54991259 0.54997815 0.5499342
 0.54984675 0.54983787 0.54988903 0.54987415 0.54984657 0.54992775
 0.5499074  0.54993607]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.54990369 0.54993245 0.54993808 0.54993877 0.5499249  0.54986399
 0.54989532 0.54990012 0.54990084 0.54991249 0.54994263 0.54993937
 0.54994746 0.54996352 0.5500027  0.54998569 0.54996048 0.54996172
 0.54998959 0.54999227]
[0.         0.18421053 0.        ]
-----------end of analyzing the loss ratio:74.7135820388794
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc1a63e0>
---------------------------------
SparseEpoch: [83][1/398]	Time 0.626	Data 0.000	Loss 0.5117	
SparseEpoch: [83][101/398]	Time 0.628	Data 0.000	Loss 0.4859	
SparseEpoch: [83][201/398]	Time 0.626	Data 0.000	Loss 0.9756	
SparseEpoch: [83][301/398]	Time 0.625	Data 0.000	Loss 0.8719	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.7678325  0.76781788 0.76776862 0.76775953 0.76774148 0.76769544
 0.76767495 0.76756995 0.76751634 0.76745282 0.76733497 0.76727088
 0.76743076 0.76730121 0.76725047 0.76724237 0.76723156 0.76723641
 0.76722547 0.76704918]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.76749619 0.76745082 0.76743663 0.76742564 0.76741873 0.76742649
 0.76742555 0.76742199 0.7673823  0.76735986 0.76734681 0.76737545
 0.76736665 0.76740751 0.76743985 0.76742384 0.76748282 0.767491
 0.76750677 0.76750317]
[0.5        0.         0.02631579]
-----------end of analyzing the loss ratio:75.11148715019226
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc42ea70>
---------------------------------
SparseEpoch: [83][1/398]	Time 0.605	Data 0.000	Loss 0.7621	
SparseEpoch: [83][101/398]	Time 0.626	Data 0.000	Loss 0.9842	
SparseEpoch: [83][201/398]	Time 0.626	Data 0.000	Loss 0.6781	
SparseEpoch: [83][301/398]	Time 0.625	Data 0.000	Loss 0.9670	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.16952213 0.1695282  0.16946538 0.16949717 0.16949455 0.1694361
 0.16947255 0.16949803 0.16952161 0.16954404 0.16955606 0.16954114
 0.16959086 0.16961142 0.1696099  0.1696188  0.16960737 0.16960496
 0.16961951 0.16963977]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.1694472  0.16941903 0.16942896 0.16940752 0.16943621 0.169467
 0.16950908 0.16950259 0.16951369 0.16953067 0.16954792 0.1695531
 0.16955822 0.16958197 0.16959345 0.16963185 0.16964294 0.16964306
 0.16964925 0.16963831]
[0. 0. 0.]
-----------end of analyzing the loss ratio:75.03005504608154
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444dc3b7100>
---------------------------------
SparseEpoch: [83][1/398]	Time 0.603	Data 0.000	Loss 0.8033	
SparseEpoch: [83][101/398]	Time 0.619	Data 0.000	Loss 1.2345	
SparseEpoch: [83][201/398]	Time 0.623	Data 0.000	Loss 1.2229	
SparseEpoch: [83][301/398]	Time 0.624	Data 0.000	Loss 1.1200	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.5784	
Epoch(adapt):{0} Loss 0.9551	
Epoch(adapt):{0} Loss 0.9698	
Epoch(adapt):{0} Loss 1.2354	
------------------the total time cost:1218.5735816955566
>>>>>meta updating
Epoch: 0083 | TRAIN: 0.6250 0.5825 0.7999 | 0.3834 0.3834 0.1806 | 0.1484 26.2258 21.7483 0.2481 0.5240 0.6627 ||TEST: 1.1271 0.3854 0.6493 | 0.5538 0.5538 0.2183 | 0.1558 27.1271 22.8733 0.2369 0.4993 0.6360 | 116.1396
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.46554001 0.4656055  0.46562384 0.46563052 0.46566538 0.46568833
 0.4656767  0.46567098 0.46566712 0.46575184 0.46572251 0.46573786
 0.46578384 0.46580705 0.46584782 0.46588643 0.46593055 0.46588661
 0.46583106 0.46583771]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.4659003  0.46586522 0.46586572 0.46579819 0.46580319 0.46577763
 0.46577977 0.46574279 0.46574211 0.46573593 0.46570759 0.46571965
 0.46569543 0.46567607 0.46564667 0.46563698 0.46566188 0.46563652
 0.46563222 0.46561302]
[0.  0.  0.5]
-----------end of analyzing the loss ratio:74.77807188034058
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x74460925ce20>
---------------------------------
SparseEpoch: [84][1/398]	Time 0.605	Data 0.000	Loss 0.9209	
SparseEpoch: [84][101/398]	Time 0.626	Data 0.000	Loss 1.8864	
SparseEpoch: [84][201/398]	Time 0.625	Data 0.000	Loss 1.7379	
SparseEpoch: [84][301/398]	Time 0.625	Data 0.000	Loss 1.6816	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.75571445 0.75558286 0.75559834 0.75543876 0.75562382 0.75562942
 0.75556145 0.75537965 0.75565044 0.75567693 0.75536265 0.75526851
 0.75535479 0.75506046 0.75488455 0.75476081 0.75472606 0.75443401
 0.75439726 0.754092  ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.75554439 0.7555086  0.75552211 0.75550591 0.755529   0.75551805
 0.75549552 0.75547627 0.75549079 0.75549295 0.7555033  0.75551324
 0.75555354 0.75550765 0.75552063 0.75550002 0.75549753 0.75550917
 0.75547459 0.75549022]
[0.5        0.         0.44736842]
-----------end of analyzing the loss ratio:74.87991261482239
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6e10190>
---------------------------------
SparseEpoch: [84][1/398]	Time 0.614	Data 0.000	Loss 1.0055	
SparseEpoch: [84][101/398]	Time 0.625	Data 0.000	Loss 1.5992	
SparseEpoch: [84][201/398]	Time 0.625	Data 0.000	Loss 0.9940	
SparseEpoch: [84][301/398]	Time 0.625	Data 0.000	Loss 1.1350	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.18391672 0.18388181 0.18389953 0.1839232  0.18389234 0.18385034
 0.18381835 0.18375782 0.18370994 0.18366511 0.18363822 0.18363509
 0.18362002 0.18358243 0.18358638 0.18360575 0.18358535 0.18356507
 0.18355744 0.18358734]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.18385111 0.18383314 0.18381218 0.18378003 0.18374038 0.18370221
 0.1837067  0.18370391 0.18368041 0.18366289 0.18365206 0.18364911
 0.18364938 0.18363313 0.18364112 0.18364456 0.18362895 0.18363849
 0.18363495 0.18363777]
[0.44736842 0.34210526 0.        ]
-----------end of analyzing the loss ratio:74.77575254440308
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6f95e40>
---------------------------------
SparseEpoch: [84][1/398]	Time 0.628	Data 0.000	Loss 1.6134	
SparseEpoch: [84][101/398]	Time 0.630	Data 0.000	Loss 2.2569	
SparseEpoch: [84][201/398]	Time 0.627	Data 0.000	Loss 3.1544	
SparseEpoch: [84][301/398]	Time 0.626	Data 0.000	Loss 2.2037	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.0741	
Epoch(adapt):{0} Loss 1.4711	
Epoch(adapt):{0} Loss 1.3078	
Epoch(adapt):{0} Loss 0.7950	
------------------the total time cost:1218.534215927124
>>>>>meta updating
Epoch: 0084 | TRAIN: 0.5858 0.6069 0.8122 | 0.3746 0.3746 0.1792 | 0.1412 25.3319 20.4840 0.2667 0.5503 0.6848 ||TEST: 1.1412 0.3960 0.6560 | 0.5404 0.5404 0.2153 | 0.1500 26.4083 21.8737 0.2511 0.5196 0.6533 | 116.2807
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.61972923 0.61976682 0.61980122 0.61981499 0.61985201 0.61980835
 0.61981235 0.61991441 0.61993458 0.61988957 0.61982722 0.61978666
 0.6197932  0.61982369 0.6198461  0.61997803 0.62002701 0.61999275
 0.61983729 0.61976334]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.61983618 0.61985303 0.61984012 0.61985883 0.61985362 0.61985998
 0.61988116 0.61985756 0.61987445 0.6198826  0.61986379 0.6199082
 0.61990869 0.61987506 0.61988457 0.61987915 0.61986964 0.61986913
 0.61986165 0.61986037]
[0. 0. 0.]
-----------end of analyzing the loss ratio:74.85015439987183
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc12a890>
---------------------------------
SparseEpoch: [85][1/398]	Time 0.605	Data 0.000	Loss 0.6891	
SparseEpoch: [85][101/398]	Time 0.622	Data 0.000	Loss 0.8533	
SparseEpoch: [85][201/398]	Time 0.623	Data 0.000	Loss 1.0184	
SparseEpoch: [85][301/398]	Time 0.622	Data 0.000	Loss 0.7005	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.8886849  0.88794571 0.88731931 0.88681076 0.88624217 0.88548177
 0.88481138 0.88394297 0.88344023 0.88261479 0.8819815  0.88126101
 0.88039558 0.87972912 0.8790248  0.87832152 0.87759395 0.87654415
 0.87578676 0.87486176]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.88226677 0.88223237 0.88217037 0.88222088 0.88222653 0.88225755
 0.88217553 0.88212276 0.8821104  0.8820996  0.88204989 0.88201005
 0.88202516 0.88203121 0.88197617 0.88203321 0.88204508 0.88203664
 0.88196242 0.88186442]
[0.5 0.  0.5]
-----------end of analyzing the loss ratio:74.9726128578186
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x744609645180>
---------------------------------
SparseEpoch: [85][1/398]	Time 0.608	Data 0.000	Loss 1.5585	
SparseEpoch: [85][101/398]	Time 0.625	Data 0.000	Loss 1.8248	
SparseEpoch: [85][201/398]	Time 0.625	Data 0.000	Loss 1.8845	
SparseEpoch: [85][301/398]	Time 0.625	Data 0.000	Loss 1.3699	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.16375809 0.1638046  0.16376499 0.1637803  0.16375968 0.16376132
 0.16370425 0.16370383 0.16366268 0.1636218  0.16359701 0.16359969
 0.1635644  0.16353657 0.1634833  0.1634894  0.16345055 0.16342798
 0.16339638 0.16335286]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.16372306 0.16372767 0.16372049 0.16370504 0.16371421 0.16367454
 0.16365615 0.16365051 0.16363227 0.16363037 0.16362522 0.16362114
 0.16357953 0.1635661  0.16357874 0.16357504 0.16352583 0.1635276
 0.16352816 0.16347835]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:74.78434777259827
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d71beec0>
---------------------------------
SparseEpoch: [85][1/398]	Time 0.607	Data 0.000	Loss 1.4988	
SparseEpoch: [85][101/398]	Time 0.626	Data 0.000	Loss 2.2033	
SparseEpoch: [85][201/398]	Time 0.627	Data 0.000	Loss 2.2900	
SparseEpoch: [85][301/398]	Time 0.627	Data 0.000	Loss 2.5889	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.5995	
Epoch(adapt):{0} Loss 0.8316	
Epoch(adapt):{0} Loss 0.9678	
Epoch(adapt):{0} Loss 0.9970	
------------------the total time cost:1219.5529873371124
>>>>>meta updating
Epoch: 0085 | TRAIN: 0.5577 0.6171 0.8240 | 0.3793 0.3793 0.1822 | 0.1452 25.7582 21.0194 0.2619 0.5387 0.6738 ||TEST: 1.1173 0.3971 0.6626 | 0.5389 0.5389 0.2157 | 0.1537 26.8207 22.3673 0.2457 0.5089 0.6433 | 116.4907
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.56006673 0.56022912 0.56016811 0.56017055 0.56009203 0.5599238
 0.55989164 0.55997588 0.5599942  0.55994337 0.55979703 0.55979324
 0.5599208  0.55979356 0.55967104 0.55969182 0.55957576 0.55958356
 0.55955348 0.55949209]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.5598507  0.55986964 0.55985471 0.55984866 0.55983874 0.55984497
 0.55984224 0.55982649 0.55980576 0.55980997 0.55979784 0.55976844
 0.55976682 0.55978596 0.5597968  0.55974776 0.55974947 0.55975004
 0.55973485 0.55973778]
[0.         0.5        0.44736842]
-----------end of analyzing the loss ratio:74.77107954025269
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6f519c0>
---------------------------------
SparseEpoch: [86][1/398]	Time 0.606	Data 0.000	Loss 1.7604	
SparseEpoch: [86][101/398]	Time 0.626	Data 0.000	Loss 2.5405	
SparseEpoch: [86][201/398]	Time 0.628	Data 0.000	Loss 1.6667	
SparseEpoch: [86][301/398]	Time 0.628	Data 0.000	Loss 1.5126	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.49299332 0.49278344 0.4926539  0.49256329 0.49220155 0.49210621
 0.49178946 0.49153392 0.49122734 0.49120652 0.49105935 0.49077021
 0.49095421 0.49071252 0.49062547 0.49027342 0.4902537  0.49017918
 0.48993294 0.48970829]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.49121245 0.49123135 0.49121845 0.49123192 0.49122055 0.49122471
 0.49122675 0.49121884 0.49120757 0.49115885 0.49119258 0.49120973
 0.49119798 0.49124893 0.49126484 0.49122956 0.49122784 0.49123852
 0.4912231  0.49121758]
[0.5 0.  0. ]
-----------end of analyzing the loss ratio:74.8819751739502
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444dc31bb20>
---------------------------------
SparseEpoch: [86][1/398]	Time 0.683	Data 0.000	Loss 0.6816	
SparseEpoch: [86][101/398]	Time 0.626	Data 0.000	Loss 1.1709	
SparseEpoch: [86][201/398]	Time 0.624	Data 0.000	Loss 1.0069	
SparseEpoch: [86][301/398]	Time 0.623	Data 0.000	Loss 0.6966	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.148344   0.14834266 0.14826256 0.14824021 0.14812562 0.14807862
 0.1480412  0.1479812  0.14791563 0.147808   0.14778744 0.1477529
 0.14771894 0.14767753 0.14756685 0.14766167 0.14763783 0.14766707
 0.1476414  0.14760068]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.14783769 0.14783868 0.14783868 0.14784247 0.14782879 0.14784195
 0.14783212 0.1478103  0.1478197  0.14781303 0.147824   0.14781511
 0.14778824 0.14779565 0.14779025 0.14781569 0.14783211 0.14782344
 0.14781916 0.14781355]
[0.23684211 0.13157895 0.        ]
-----------end of analyzing the loss ratio:75.15191841125488
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc1a4f10>
---------------------------------
SparseEpoch: [86][1/398]	Time 0.613	Data 0.000	Loss 2.0259	
SparseEpoch: [86][101/398]	Time 0.626	Data 0.000	Loss 1.4445	
SparseEpoch: [86][201/398]	Time 0.628	Data 0.000	Loss 1.9302	
SparseEpoch: [86][301/398]	Time 0.627	Data 0.000	Loss 1.7443	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.4238	
Epoch(adapt):{0} Loss 1.2091	
Epoch(adapt):{0} Loss 1.5033	
Epoch(adapt):{0} Loss 1.0393	
------------------the total time cost:1221.3999464511871
>>>>>meta updating
Epoch: 0086 | TRAIN: 0.5640 0.6145 0.8217 | 0.3690 0.3690 0.1727 | 0.1436 25.6140 20.9507 0.2626 0.5403 0.6763 ||TEST: 1.1467 0.3901 0.6576 | 0.5382 0.5382 0.2123 | 0.1522 26.6669 22.2225 0.2469 0.5125 0.6473 | 116.2822
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.55513965 0.55514464 0.55514106 0.55516378 0.55518708 0.55513798
 0.55498538 0.55489652 0.55482923 0.55476865 0.55484844 0.55495264
 0.55506787 0.55516076 0.55519176 0.55515324 0.55518731 0.55519926
 0.55530642 0.55533893]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.55492262 0.55493363 0.55494585 0.5549391  0.5549161  0.55486509
 0.55480689 0.55482122 0.55483415 0.55485898 0.55485325 0.55479013
 0.55478961 0.55479234 0.5547915  0.5548352  0.55483306 0.55483054
 0.55484595 0.55485805]
[0.         0.         0.13157895]
-----------end of analyzing the loss ratio:74.66940951347351
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc27bee0>
---------------------------------
SparseEpoch: [87][1/398]	Time 0.607	Data 0.000	Loss 1.9884	
SparseEpoch: [87][101/398]	Time 0.617	Data 0.000	Loss 0.7554	
SparseEpoch: [87][201/398]	Time 0.620	Data 0.000	Loss 0.8154	
SparseEpoch: [87][301/398]	Time 0.622	Data 0.000	Loss 0.9058	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.64985906 0.64921392 0.64881765 0.64845608 0.64783092 0.64750818
 0.64689303 0.64663026 0.64621047 0.64590513 0.64539006 0.64508888
 0.64468517 0.64417648 0.64368248 0.6433325  0.64316451 0.64262779
 0.64225032 0.64216146]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.64589746 0.64588963 0.64591476 0.64598527 0.64590813 0.64585851
 0.64583203 0.64578314 0.64575399 0.64572069 0.64565443 0.64562429
 0.64547649 0.64536288 0.64535207 0.64536195 0.64539323 0.64533272
 0.64531479 0.64532191]
[0.5        0.         0.44736842]
-----------end of analyzing the loss ratio:74.66600227355957
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc550310>
---------------------------------
SparseEpoch: [87][1/398]	Time 0.618	Data 0.000	Loss 1.1734	
SparseEpoch: [87][101/398]	Time 0.618	Data 0.000	Loss 1.4936	
SparseEpoch: [87][201/398]	Time 0.617	Data 0.000	Loss 1.4038	
SparseEpoch: [87][301/398]	Time 0.619	Data 0.000	Loss 1.5313	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.19455593 0.19440358 0.19436812 0.1943108  0.19427393 0.19426044
 0.19426128 0.19428329 0.19435467 0.1942329  0.19422837 0.19420027
 0.19411994 0.19408371 0.19409872 0.19406708 0.19404551 0.1940524
 0.19404942 0.19410077]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.1941577  0.19420039 0.19415781 0.19415092 0.19416516 0.19414449
 0.19422339 0.19427856 0.19426838 0.1942142  0.19420141 0.19425118
 0.19427076 0.19422554 0.19421012 0.19419225 0.19417128 0.19412474
 0.19414988 0.19415876]
[0.34210526 0.39473684 0.        ]
-----------end of analyzing the loss ratio:75.00977325439453
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6f97190>
---------------------------------
SparseEpoch: [87][1/398]	Time 0.610	Data 0.000	Loss 1.3718	
SparseEpoch: [87][101/398]	Time 0.625	Data 0.000	Loss 1.9357	
SparseEpoch: [87][201/398]	Time 0.626	Data 0.000	Loss 1.8245	
SparseEpoch: [87][301/398]	Time 0.625	Data 0.000	Loss 2.1964	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.4365	
Epoch(adapt):{0} Loss 1.0520	
Epoch(adapt):{0} Loss 1.1286	
Epoch(adapt):{0} Loss 1.2009	
------------------the total time cost:1215.889513015747
>>>>>meta updating
Epoch: 0087 | TRAIN: 0.5481 0.6205 0.8239 | 0.3935 0.3935 0.1784 | 0.1414 25.3504 20.4906 0.2663 0.5495 0.6846 ||TEST: 1.1407 0.3961 0.6580 | 0.5600 0.5600 0.2172 | 0.1501 26.3596 21.7193 0.2547 0.5229 0.6550 | 116.0513
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.5678464  0.56791319 0.56764639 0.5676488  0.56742396 0.56740709
 0.56731338 0.56709403 0.56695746 0.56679858 0.56675538 0.56665337
 0.56653295 0.56649798 0.56659542 0.56667376 0.56655853 0.56619753
 0.56593727 0.56590255]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.5667604  0.56678778 0.56678491 0.56684529 0.56684474 0.5668467
 0.56683474 0.56683764 0.56683607 0.56686653 0.56682388 0.56681361
 0.56678717 0.56678098 0.56677453 0.56672453 0.56674047 0.56675847
 0.56676123 0.56674203]
[0.         0.5        0.28947368]
-----------end of analyzing the loss ratio:74.86629891395569
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d7096830>
---------------------------------
SparseEpoch: [88][1/398]	Time 0.606	Data 0.000	Loss 1.6187	
SparseEpoch: [88][101/398]	Time 0.625	Data 0.000	Loss 1.3443	
SparseEpoch: [88][201/398]	Time 0.624	Data 0.000	Loss 1.1970	
SparseEpoch: [88][301/398]	Time 0.624	Data 0.000	Loss 0.9383	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.3950799  0.39517269 0.39517447 0.3951642  0.39518042 0.39512055
 0.39506174 0.39501426 0.39494102 0.39484372 0.39483488 0.39480669
 0.39475998 0.39471766 0.39467517 0.39465916 0.39464062 0.39460807
 0.3944126  0.39443506]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.39478589 0.39480012 0.39480275 0.39481158 0.39480996 0.39481632
 0.39482608 0.39483297 0.394835   0.39480884 0.39480703 0.39481237
 0.39481676 0.39480556 0.39480843 0.39480792 0.39485132 0.39484036
 0.39485269 0.39484808]
[0.44736842 0.         0.        ]
-----------end of analyzing the loss ratio:74.68217778205872
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc58fac0>
---------------------------------
SparseEpoch: [88][1/398]	Time 0.616	Data 0.000	Loss 0.6425	
SparseEpoch: [88][101/398]	Time 0.627	Data 0.000	Loss 1.0173	
SparseEpoch: [88][201/398]	Time 0.624	Data 0.000	Loss 1.3742	
SparseEpoch: [88][301/398]	Time 0.624	Data 0.000	Loss 0.7126	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.14704728 0.14696348 0.14695033 0.14676462 0.14672893 0.14667393
 0.14669446 0.14672788 0.14663605 0.14657828 0.14647847 0.14638934
 0.14635004 0.14631615 0.14626464 0.14624908 0.14635041 0.14639048
 0.14633869 0.14637844]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.14667965 0.14661845 0.14663134 0.14662344 0.14658055 0.14658877
 0.14658958 0.14657195 0.14653826 0.14651266 0.14650037 0.14651579
 0.14647191 0.14644857 0.14644638 0.14638939 0.1463656  0.14638453
 0.14638126 0.1463425 ]
[0.28947368 0.5        0.        ]
-----------end of analyzing the loss ratio:74.66836953163147
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d73728f0>
---------------------------------
SparseEpoch: [88][1/398]	Time 0.607	Data 0.000	Loss 2.1639	
SparseEpoch: [88][101/398]	Time 0.619	Data 0.000	Loss 1.1696	
SparseEpoch: [88][201/398]	Time 0.624	Data 0.000	Loss 1.4870	
SparseEpoch: [88][301/398]	Time 0.624	Data 0.000	Loss 1.8537	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.5446	
Epoch(adapt):{0} Loss 1.2114	
Epoch(adapt):{0} Loss 0.8460	
Epoch(adapt):{0} Loss 1.3046	
------------------the total time cost:1216.9770638942719
>>>>>meta updating
Epoch: 0088 | TRAIN: 0.5514 0.6206 0.8261 | 0.3723 0.3723 0.1745 | 0.1446 25.6294 20.6910 0.2645 0.5447 0.6795 ||TEST: 1.1337 0.3930 0.6549 | 0.5418 0.5418 0.2125 | 0.1530 26.6056 21.9568 0.2535 0.5184 0.6504 | 116.6097
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.59570206 0.59565375 0.5956413  0.5955853  0.59556125 0.59538279
 0.59524223 0.59516162 0.59501759 0.5950524  0.59504192 0.59495374
 0.59485374 0.59486386 0.5949025  0.59488844 0.59477903 0.59453614
 0.59456812 0.59445849]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.59505884 0.59504448 0.59499489 0.59500152 0.59499707 0.59496568
 0.59498536 0.59502618 0.59500608 0.59503759 0.59505669 0.59505919
 0.59505239 0.59504292 0.59507025 0.59507192 0.59507003 0.59505176
 0.59505112 0.59502046]
[0.  0.5 0. ]
-----------end of analyzing the loss ratio:74.6116349697113
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6e97a90>
---------------------------------
SparseEpoch: [89][1/398]	Time 0.606	Data 0.000	Loss 0.9592	
SparseEpoch: [89][101/398]	Time 0.626	Data 0.000	Loss 1.5673	
SparseEpoch: [89][201/398]	Time 0.624	Data 0.000	Loss 0.8752	
SparseEpoch: [89][301/398]	Time 0.624	Data 0.000	Loss 1.0343	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.61535534 0.61526028 0.61514703 0.6149955  0.6148489  0.61469739
 0.61469918 0.61455667 0.61419862 0.61405875 0.61364581 0.61356875
 0.6135238  0.61368574 0.61357217 0.61336106 0.61328786 0.61312283
 0.6129706  0.61280938]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.61419061 0.61418098 0.61408811 0.61406341 0.61408115 0.61403001
 0.61402684 0.61402702 0.61402882 0.61393233 0.61382844 0.6137563
 0.61373334 0.6137361  0.61369732 0.61366441 0.61358788 0.61356206
 0.61362575 0.61361065]
[0.5        0.         0.39473684]
-----------end of analyzing the loss ratio:74.75420236587524
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc471300>
---------------------------------
SparseEpoch: [89][1/398]	Time 0.627	Data 0.000	Loss 1.3124	
SparseEpoch: [89][101/398]	Time 0.625	Data 0.000	Loss 1.4027	
SparseEpoch: [89][201/398]	Time 0.624	Data 0.000	Loss 1.1167	
SparseEpoch: [89][301/398]	Time 0.625	Data 0.000	Loss 1.0669	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.18467857 0.18463777 0.18457313 0.18456846 0.18447098 0.18444049
 0.18441415 0.18440403 0.18439403 0.18438349 0.18436971 0.18432032
 0.18429462 0.18428363 0.18427791 0.18422804 0.18422267 0.18419246
 0.18416564 0.18417506]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.18440344 0.18440669 0.18441299 0.18439835 0.18439457 0.18439537
 0.18440124 0.18438855 0.18438043 0.18436567 0.18437407 0.18438002
 0.18437614 0.18437141 0.1843727  0.18438348 0.18434626 0.18436452
 0.18435941 0.18434356]
[0.44736842 0.5        0.        ]
-----------end of analyzing the loss ratio:74.81581521034241
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc35d3f0>
---------------------------------
SparseEpoch: [89][1/398]	Time 0.607	Data 0.000	Loss 1.3725	
SparseEpoch: [89][101/398]	Time 0.621	Data 0.000	Loss 2.0954	
SparseEpoch: [89][201/398]	Time 0.621	Data 0.000	Loss 3.2454	
SparseEpoch: [89][301/398]	Time 0.622	Data 0.000	Loss 1.4985	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.1642	
Epoch(adapt):{0} Loss 1.0012	
Epoch(adapt):{0} Loss 0.8919	
Epoch(adapt):{0} Loss 0.8894	
------------------the total time cost:1215.4983785152435
>>>>>meta updating
Epoch: 0089 | TRAIN: 0.5472 0.6232 0.8282 | 0.3854 0.3854 0.1754 | 0.1424 25.6186 20.9991 0.2550 0.5385 0.6775 ||TEST: 1.1364 0.3876 0.6554 | 0.5529 0.5529 0.2151 | 0.1538 26.9360 22.6103 0.2372 0.5041 0.6413 | 115.9290
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.59078893 0.5907778  0.59070625 0.59061032 0.5906659  0.59066064
 0.59065597 0.59060773 0.59068915 0.59068519 0.59059959 0.59053271
 0.59053684 0.59068398 0.59067908 0.59064198 0.59061897 0.5905907
 0.59063818 0.59059602]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.59073181 0.59072343 0.59072586 0.59073006 0.59071068 0.59073264
 0.59073131 0.59071007 0.59064845 0.59067016 0.59064186 0.59062255
 0.59063097 0.59063145 0.59063837 0.59061972 0.59064967 0.59063127
 0.59063018 0.5906375 ]
[0.         0.07894737 0.28947368]
-----------end of analyzing the loss ratio:74.89723086357117
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6f978e0>
---------------------------------
SparseEpoch: [90][1/398]	Time 0.608	Data 0.000	Loss 1.0664	
SparseEpoch: [90][101/398]	Time 0.627	Data 0.000	Loss 0.8916	
SparseEpoch: [90][201/398]	Time 0.626	Data 0.000	Loss 1.3331	
SparseEpoch: [90][301/398]	Time 0.624	Data 0.000	Loss 1.4340	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.71474591 0.71476181 0.71484035 0.71480243 0.71477622 0.71480215
 0.71474098 0.71468337 0.71466075 0.7146831  0.71471625 0.71483297
 0.71488126 0.71475447 0.71484323 0.71485235 0.7148179  0.71476483
 0.71470546 0.71462092]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.71461836 0.71464293 0.71463662 0.71460719 0.71463832 0.71464018
 0.71461038 0.71462228 0.71461957 0.71464886 0.71465041 0.71467039
 0.71469299 0.71472369 0.71471551 0.71475196 0.71473125 0.71470842
 0.71472131 0.71474455]
[0.5 0.  0. ]
-----------end of analyzing the loss ratio:74.72428512573242
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x74460925f640>
---------------------------------
SparseEpoch: [90][1/398]	Time 0.624	Data 0.000	Loss 0.7692	
SparseEpoch: [90][101/398]	Time 0.628	Data 0.000	Loss 0.6476	
SparseEpoch: [90][201/398]	Time 0.624	Data 0.000	Loss 0.5881	
SparseEpoch: [90][301/398]	Time 0.623	Data 0.000	Loss 0.8810	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.1741622  0.17407528 0.17397907 0.17388511 0.17382801 0.17378193
 0.17364936 0.17361085 0.17357543 0.17348696 0.17345209 0.17344186
 0.17343689 0.17335895 0.17330807 0.17324489 0.17317539 0.17320128
 0.17311762 0.17303789]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.17358692 0.17354523 0.17353802 0.17353286 0.17349637 0.17350491
 0.17348208 0.17347116 0.17346987 0.17347989 0.17348284 0.17346287
 0.17346284 0.17346761 0.17343257 0.17339671 0.1733977  0.17338316
 0.17340585 0.17338836]
[0.5        0.39473684 0.        ]
-----------end of analyzing the loss ratio:75.0124351978302
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc3246a0>
---------------------------------
SparseEpoch: [90][1/398]	Time 0.612	Data 0.000	Loss 2.4503	
SparseEpoch: [90][101/398]	Time 0.624	Data 0.000	Loss 1.9146	
SparseEpoch: [90][201/398]	Time 0.623	Data 0.000	Loss 1.3957	
SparseEpoch: [90][301/398]	Time 0.625	Data 0.000	Loss 1.7325	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.7305	
Epoch(adapt):{0} Loss 0.9648	
Epoch(adapt):{0} Loss 1.2552	
Epoch(adapt):{0} Loss 0.9142	
------------------the total time cost:1217.6309010982513
>>>>>meta updating
Epoch: 0090 | TRAIN: 0.5286 0.6384 0.8343 | 0.3702 0.3702 0.1786 | 0.1442 25.7575 21.1285 0.2549 0.5373 0.6750 ||TEST: 1.1438 0.3923 0.6584 | 0.5351 0.5351 0.2151 | 0.1537 26.8533 22.4570 0.2429 0.5076 0.6429 | 116.2527
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.56896099 0.56900501 0.56899342 0.56904351 0.56909028 0.56922013
 0.56914248 0.56915801 0.56910225 0.56910032 0.56911149 0.56913293
 0.5691637  0.56923449 0.56930406 0.56913023 0.56912383 0.56916518
 0.56916808 0.56907218]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.56929998 0.56928523 0.56925766 0.56926696 0.56926384 0.56918534
 0.56919155 0.56916396 0.5691577  0.56910622 0.56909927 0.56914623
 0.56913383 0.56912777 0.56917425 0.56920381 0.56918213 0.56913238
 0.56913722 0.56913284]
[0.         0.         0.02631579]
-----------end of analyzing the loss ratio:74.67456150054932
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc12dfc0>
---------------------------------
SparseEpoch: [91][1/398]	Time 0.604	Data 0.000	Loss 0.4837	
SparseEpoch: [91][101/398]	Time 0.627	Data 0.000	Loss 0.4429	
SparseEpoch: [91][201/398]	Time 0.627	Data 0.000	Loss 0.9773	
SparseEpoch: [91][301/398]	Time 0.626	Data 0.000	Loss 0.6878	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.53717077 0.53728572 0.5373923  0.53738397 0.53737107 0.53746607
 0.53732767 0.53748521 0.53737668 0.53751047 0.53766274 0.5374585
 0.53763832 0.53768886 0.53786551 0.53772407 0.53775468 0.53788953
 0.53814188 0.53831204]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.53761893 0.53764591 0.5376279  0.53769861 0.53765863 0.5375989
 0.5376025  0.53763332 0.53763115 0.53764284 0.53763087 0.53768103
 0.53773916 0.5376966  0.53768982 0.53769109 0.53771082 0.5377278
 0.53770188 0.53770748]
[0. 0. 0.]
-----------end of analyzing the loss ratio:74.9512677192688
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6f518a0>
---------------------------------
SparseEpoch: [91][1/398]	Time 0.606	Data 0.000	Loss 0.4544	
SparseEpoch: [91][101/398]	Time 0.624	Data 0.000	Loss 0.3812	
SparseEpoch: [91][201/398]	Time 0.623	Data 0.000	Loss 0.3002	
SparseEpoch: [91][301/398]	Time 0.623	Data 0.000	Loss 0.3998	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.14530563 0.14527163 0.14525779 0.14526356 0.14534163 0.14530191
 0.14528291 0.14526265 0.14529186 0.14530679 0.14527222 0.14524989
 0.14517487 0.14517246 0.1451887  0.14517584 0.14516469 0.14516008
 0.14513814 0.14515746]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.14529151 0.14529175 0.14529389 0.1453052  0.14531438 0.14531869
 0.14531665 0.14530866 0.14530982 0.14530106 0.14529399 0.14526814
 0.14528583 0.14527081 0.14525443 0.14524519 0.14521928 0.14522267
 0.14521773 0.14521366]
[0.44736842 0.5        0.        ]
-----------end of analyzing the loss ratio:74.79105710983276
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6d92cb0>
---------------------------------
SparseEpoch: [91][1/398]	Time 0.605	Data 0.000	Loss 1.4511	
SparseEpoch: [91][101/398]	Time 0.622	Data 0.000	Loss 3.2388	
SparseEpoch: [91][201/398]	Time 0.626	Data 0.000	Loss 2.5391	
SparseEpoch: [91][301/398]	Time 0.626	Data 0.000	Loss 2.9506	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.0884	
Epoch(adapt):{0} Loss 1.0524	
Epoch(adapt):{0} Loss 0.9721	
Epoch(adapt):{0} Loss 1.1858	
------------------the total time cost:1218.51615524292
>>>>>meta updating
Epoch: 0091 | TRAIN: 0.5301 0.6385 0.8369 | 0.3934 0.3934 0.1750 | 0.1439 25.7897 21.1724 0.2517 0.5356 0.6742 ||TEST: 1.1025 0.3898 0.6580 | 0.5688 0.5688 0.2168 | 0.1547 26.9780 22.5175 0.2396 0.5056 0.6409 | 116.1489
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.6780634  0.67803328 0.67796524 0.67795765 0.67797646 0.67800986
 0.67803772 0.67800454 0.67806258 0.67809791 0.67809414 0.67806659
 0.67810083 0.67805159 0.67810299 0.67807623 0.67806801 0.67808105
 0.67807476 0.67811302]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.67805118 0.67804897 0.67803396 0.67803366 0.67804107 0.67802602
 0.67805583 0.67807374 0.67809105 0.67811302 0.67810672 0.67811693
 0.67808166 0.6780715  0.67809223 0.6781071  0.67812116 0.67809428
 0.67809899 0.67810016]
[0. 0. 0.]
-----------end of analyzing the loss ratio:74.76554727554321
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7446096c7790>
---------------------------------
SparseEpoch: [92][1/398]	Time 0.612	Data 0.000	Loss 0.4922	
SparseEpoch: [92][101/398]	Time 0.623	Data 0.000	Loss 1.0062	
SparseEpoch: [92][201/398]	Time 0.623	Data 0.000	Loss 0.8655	
SparseEpoch: [92][301/398]	Time 0.624	Data 0.000	Loss 0.5645	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.95043261 0.94996455 0.94945185 0.94893939 0.94823517 0.94800579
 0.94787979 0.94752647 0.94749972 0.94753507 0.94714239 0.94692877
 0.94675567 0.94710135 0.94668931 0.94651778 0.94620754 0.94619377
 0.94603361 0.94616213]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.94772553 0.94765771 0.94763652 0.94756103 0.94751689 0.94749112
 0.94746617 0.94741871 0.94728979 0.94727193 0.94724161 0.94724776
 0.94722012 0.94720464 0.94718983 0.94717476 0.94709684 0.94714032
 0.94703783 0.94698542]
[0.44736842 0.         0.5       ]
-----------end of analyzing the loss ratio:74.8409378528595
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc072680>
---------------------------------
SparseEpoch: [92][1/398]	Time 0.606	Data 0.000	Loss 1.4885	
SparseEpoch: [92][101/398]	Time 0.627	Data 0.000	Loss 1.4673	
SparseEpoch: [92][201/398]	Time 0.628	Data 0.000	Loss 1.4022	
SparseEpoch: [92][301/398]	Time 0.626	Data 0.000	Loss 1.1406	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.15140206 0.15137705 0.15135822 0.15134466 0.15131778 0.15131998
 0.15134153 0.15132446 0.15132003 0.15129734 0.15129046 0.15129552
 0.15132206 0.15132088 0.1513     0.15132615 0.15133308 0.15132729
 0.15134243 0.1513158 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.15139898 0.15140736 0.15138041 0.15136982 0.1513635  0.1513528
 0.15136183 0.15132812 0.15130873 0.15127389 0.15128382 0.15131513
 0.15130522 0.15130319 0.15130974 0.15130926 0.15130573 0.15132589
 0.15132688 0.15133939]
[0.02631579 0.         0.        ]
-----------end of analyzing the loss ratio:75.09145498275757
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x74460925e0e0>
---------------------------------
SparseEpoch: [92][1/398]	Time 0.604	Data 0.000	Loss 1.3430	
SparseEpoch: [92][101/398]	Time 0.626	Data 0.000	Loss 2.1123	
SparseEpoch: [92][201/398]	Time 0.626	Data 0.000	Loss 1.5359	
SparseEpoch: [92][301/398]	Time 0.627	Data 0.000	Loss 1.1706	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.8187	
Epoch(adapt):{0} Loss 0.7586	
Epoch(adapt):{0} Loss 0.9917	
Epoch(adapt):{0} Loss 0.9282	
------------------the total time cost:1219.455253124237
>>>>>meta updating
Epoch: 0092 | TRAIN: 0.5193 0.6385 0.8362 | 0.3729 0.3729 0.1779 | 0.1436 25.6568 20.9915 0.2598 0.5401 0.6760 ||TEST: 1.1383 0.3892 0.6614 | 0.5361 0.5361 0.2115 | 0.1518 26.6587 22.2697 0.2459 0.5112 0.6465 | 115.7312
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.42302506 0.42306986 0.42309909 0.4231807  0.4231037  0.4230641
 0.42308617 0.42303631 0.42292161 0.42298936 0.42295533 0.42289108
 0.42283004 0.4227909  0.42277187 0.42277578 0.42279292 0.4228439
 0.42287687 0.42289511]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.42300167 0.42295881 0.42296675 0.4229745  0.42294154 0.42296057
 0.42301084 0.42291726 0.42296021 0.42294093 0.42292771 0.42291214
 0.42294206 0.42289314 0.42289872 0.42290202 0.42284008 0.42289247
 0.42286289 0.42285394]
[0.         0.23684211 0.34210526]
-----------end of analyzing the loss ratio:74.90355348587036
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc35e920>
---------------------------------
SparseEpoch: [93][1/398]	Time 0.608	Data 0.000	Loss 1.7690	
SparseEpoch: [93][101/398]	Time 0.618	Data 0.000	Loss 0.9393	
SparseEpoch: [93][201/398]	Time 0.618	Data 0.000	Loss 1.6575	
SparseEpoch: [93][301/398]	Time 0.621	Data 0.000	Loss 1.1709	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.70356782 0.70336458 0.7030304  0.70263624 0.70247917 0.70230742
 0.70214567 0.70184797 0.70171931 0.70155637 0.70134656 0.70113122
 0.70071148 0.70060719 0.70039356 0.70036986 0.70014049 0.70022273
 0.70017492 0.70006903]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.70158174 0.70153062 0.70149126 0.70144344 0.70144488 0.7014181
 0.70148189 0.70153577 0.70148498 0.70142514 0.70148315 0.70143424
 0.7014381  0.70142261 0.70143613 0.70139065 0.70131864 0.70131519
 0.70131037 0.70132178]
[0.5        0.         0.44736842]
-----------end of analyzing the loss ratio:75.17983055114746
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x744608680070>
---------------------------------
SparseEpoch: [93][1/398]	Time 0.611	Data 0.000	Loss 1.4285	
SparseEpoch: [93][101/398]	Time 0.626	Data 0.000	Loss 1.3004	
SparseEpoch: [93][201/398]	Time 0.627	Data 0.000	Loss 1.6900	
SparseEpoch: [93][301/398]	Time 0.625	Data 0.000	Loss 1.2184	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.17716876 0.17714952 0.17714447 0.17715519 0.177172   0.17716157
 0.17709705 0.17711614 0.17716263 0.17717432 0.17711909 0.17701591
 0.17701181 0.17696405 0.17695457 0.17691207 0.17692754 0.17694102
 0.17692769 0.17692648]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.17713879 0.17715949 0.17715703 0.17716004 0.17714443 0.17714425
 0.17715404 0.17716889 0.17715898 0.1771674  0.17713602 0.17710857
 0.1770277  0.17699673 0.17699366 0.17699229 0.17699846 0.17695953
 0.17695887 0.17693526]
[0.28947368 0.5        0.        ]
-----------end of analyzing the loss ratio:75.02867245674133
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc264c70>
---------------------------------
SparseEpoch: [93][1/398]	Time 0.606	Data 0.000	Loss 2.1216	
SparseEpoch: [93][101/398]	Time 0.626	Data 0.000	Loss 1.4895	
SparseEpoch: [93][201/398]	Time 0.625	Data 0.000	Loss 2.7169	
SparseEpoch: [93][301/398]	Time 0.625	Data 0.000	Loss 1.9539	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.2394	
Epoch(adapt):{0} Loss 1.4256	
Epoch(adapt):{0} Loss 1.1411	
Epoch(adapt):{0} Loss 1.1056	
------------------the total time cost:1217.1800382137299
>>>>>meta updating
Epoch: 0093 | TRAIN: 0.5123 0.6479 0.8389 | 0.3558 0.3558 0.1747 | 0.1385 24.9157 19.9160 0.2787 0.5630 0.6950 ||TEST: 1.1554 0.4031 0.6573 | 0.5300 0.5300 0.2174 | 0.1490 26.1972 21.4846 0.2582 0.5279 0.6596 | 116.1406
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.56119403 0.561223   0.5612651  0.56120754 0.56129622 0.56149279
 0.5613474  0.56120068 0.56118692 0.56118025 0.56132564 0.56138429
 0.56125842 0.56113458 0.56120473 0.56104793 0.56098762 0.5607453
 0.56079945 0.56093185]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.56125388 0.56136654 0.5613245  0.56128369 0.56132928 0.56141084
 0.56136808 0.561355   0.56127777 0.56125488 0.56121665 0.5611965
 0.56109109 0.56111274 0.56115388 0.56112233 0.56115911 0.5611742
 0.56119216 0.56121142]
[0.         0.39473684 0.13157895]
-----------end of analyzing the loss ratio:74.93056654930115
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d7192d70>
---------------------------------
SparseEpoch: [94][1/398]	Time 0.606	Data 0.000	Loss 1.2093	
SparseEpoch: [94][101/398]	Time 0.622	Data 0.000	Loss 0.9397	
SparseEpoch: [94][201/398]	Time 0.623	Data 0.000	Loss 1.5126	
SparseEpoch: [94][301/398]	Time 0.625	Data 0.000	Loss 1.8300	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.68787943 0.68703134 0.68578895 0.68480987 0.68415964 0.68326378
 0.68231629 0.68108777 0.68023678 0.67901133 0.67813278 0.67754043
 0.67632275 0.67557071 0.67428875 0.67306214 0.67204493 0.67065571
 0.66959837 0.66893622]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.67893852 0.67897846 0.67896615 0.67890013 0.67891337 0.67885739
 0.67884476 0.67874865 0.67866324 0.67866198 0.67851323 0.67847808
 0.67842103 0.6783603  0.67828693 0.67827919 0.67827201 0.67822745
 0.67820649 0.67816654]
[0.5 0.  0.5]
-----------end of analyzing the loss ratio:74.85503768920898
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc388730>
---------------------------------
SparseEpoch: [94][1/398]	Time 0.613	Data 0.000	Loss 1.3588	
SparseEpoch: [94][101/398]	Time 0.629	Data 0.000	Loss 1.4233	
SparseEpoch: [94][201/398]	Time 0.627	Data 0.000	Loss 1.3087	
SparseEpoch: [94][301/398]	Time 0.626	Data 0.000	Loss 1.2048	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.17187871 0.17183071 0.17184427 0.1718192  0.17177523 0.17175881
 0.17177125 0.17173125 0.17173574 0.17175831 0.17173429 0.17172186
 0.17169914 0.17168254 0.17168851 0.17169108 0.17165861 0.17164429
 0.17164298 0.17163906]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.17190111 0.17187353 0.17185909 0.17184227 0.17180696 0.17179106
 0.17180556 0.17179083 0.17175216 0.17176911 0.17174135 0.1717072
 0.17168921 0.17163196 0.17163732 0.1716324  0.1716278  0.1716215
 0.1715974  0.17160509]
[0.5        0.44736842 0.        ]
-----------end of analyzing the loss ratio:74.9773166179657
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6fe8e50>
---------------------------------
SparseEpoch: [94][1/398]	Time 0.607	Data 0.000	Loss 1.7510	
SparseEpoch: [94][101/398]	Time 0.623	Data 0.000	Loss 2.1290	
SparseEpoch: [94][201/398]	Time 0.626	Data 0.000	Loss 1.9048	
SparseEpoch: [94][301/398]	Time 0.626	Data 0.000	Loss 3.3407	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.6506	
Epoch(adapt):{0} Loss 1.1485	
Epoch(adapt):{0} Loss 0.8027	
Epoch(adapt):{0} Loss 0.8088	
------------------the total time cost:1219.0453522205353
>>>>>meta updating
Epoch: 0094 | TRAIN: 0.5031 0.6540 0.8423 | 0.3739 0.3739 0.1720 | 0.1407 25.3469 20.6372 0.2616 0.5488 0.6861 ||TEST: 1.1376 0.3981 0.6614 | 0.5473 0.5473 0.2130 | 0.1499 26.4536 21.9699 0.2466 0.5179 0.6535 | 116.2565
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.45123808 0.45124359 0.45126442 0.45129195 0.45133976 0.45135928
 0.45137429 0.45137903 0.45140066 0.4513676  0.45139676 0.45152641
 0.4514981  0.451539   0.45153741 0.45150366 0.4515587  0.45162096
 0.45157446 0.45166884]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.45153599 0.45155947 0.45153447 0.45150698 0.45148242 0.45147249
 0.45139713 0.45137087 0.45138296 0.45138259 0.45139514 0.45136659
 0.45138876 0.45141639 0.45140501 0.45139631 0.4513904  0.45137132
 0.45136316 0.45134822]
[0.  0.  0.5]
-----------end of analyzing the loss ratio:75.01317024230957
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d71a1690>
---------------------------------
SparseEpoch: [95][1/398]	Time 0.605	Data 0.000	Loss 1.0389	
SparseEpoch: [95][101/398]	Time 0.620	Data 0.000	Loss 1.7410	
SparseEpoch: [95][201/398]	Time 0.623	Data 0.000	Loss 1.2845	
SparseEpoch: [95][301/398]	Time 0.624	Data 0.000	Loss 1.7914	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.50510648 0.50474276 0.50456371 0.50427782 0.50387006 0.50358567
 0.5033003  0.50306731 0.5028167  0.50266413 0.50260549 0.50234425
 0.50212475 0.50179592 0.50126306 0.50114763 0.50095989 0.50080924
 0.5005955  0.50006875]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.50267563 0.50267201 0.50264666 0.50267123 0.50262385 0.50264825
 0.50269788 0.50272471 0.50272542 0.50268931 0.50266592 0.50263925
 0.50265398 0.50263951 0.50260909 0.50260509 0.50255083 0.50256847
 0.50253811 0.50252735]
[0.5 0.  0.5]
-----------end of analyzing the loss ratio:74.86552286148071
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7446086827d0>
---------------------------------
SparseEpoch: [95][1/398]	Time 0.607	Data 0.000	Loss 1.1355	
SparseEpoch: [95][101/398]	Time 0.621	Data 0.000	Loss 1.7985	
SparseEpoch: [95][201/398]	Time 0.624	Data 0.000	Loss 1.4423	
SparseEpoch: [95][301/398]	Time 0.623	Data 0.000	Loss 1.8499	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.13516217 0.135129   0.1351058  0.13507532 0.13506401 0.13499104
 0.13500068 0.13495085 0.13493286 0.13488545 0.13485517 0.13481246
 0.13477629 0.13473709 0.13471836 0.13470064 0.13470767 0.134685
 0.13467831 0.13464338]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.13498484 0.13497785 0.1349745  0.13496279 0.13497918 0.1349459
 0.13492545 0.13491828 0.1348842  0.13486549 0.13486513 0.13484927
 0.13482511 0.13480832 0.13480402 0.13481952 0.13480577 0.13479196
 0.13475704 0.13475493]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:74.87657356262207
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc389450>
---------------------------------
SparseEpoch: [95][1/398]	Time 0.605	Data 0.000	Loss 1.9098	
SparseEpoch: [95][101/398]	Time 0.624	Data 0.000	Loss 2.2391	
SparseEpoch: [95][201/398]	Time 0.623	Data 0.000	Loss 1.9755	
SparseEpoch: [95][301/398]	Time 0.624	Data 0.000	Loss 2.1398	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.9969	
Epoch(adapt):{0} Loss 0.9169	
Epoch(adapt):{0} Loss 1.0554	
Epoch(adapt):{0} Loss 1.1056	
------------------the total time cost:1216.2868633270264
>>>>>meta updating
Epoch: 0095 | TRAIN: 0.5041 0.6537 0.8419 | 0.3726 0.3726 0.1797 | 0.1401 25.1911 20.3336 0.2682 0.5553 0.6895 ||TEST: 1.1444 0.3987 0.6639 | 0.5482 0.5482 0.2183 | 0.1496 26.3541 21.7768 0.2517 0.5219 0.6558 | 116.4899
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.55300089 0.5530145  0.55308982 0.55314724 0.55300198 0.5531123
 0.5531364  0.55320362 0.55317971 0.55330807 0.55323232 0.55322841
 0.55314873 0.55313036 0.55323747 0.55321044 0.55321056 0.55317464
 0.55317467 0.55326622]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.55322283 0.55321916 0.55324588 0.55326264 0.55325766 0.55327197
 0.55326718 0.55324752 0.55325376 0.55323227 0.55325545 0.55326871
 0.55326528 0.55327824 0.55314279 0.55312662 0.55313194 0.55312994
 0.55312435 0.55313286]
[0.         0.         0.44736842]
-----------end of analyzing the loss ratio:74.91466546058655
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc0ec370>
---------------------------------
SparseEpoch: [96][1/398]	Time 0.609	Data 0.000	Loss 0.5912	
SparseEpoch: [96][101/398]	Time 0.621	Data 0.000	Loss 0.9636	
SparseEpoch: [96][201/398]	Time 0.622	Data 0.000	Loss 1.3339	
SparseEpoch: [96][301/398]	Time 0.623	Data 0.000	Loss 1.1174	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.5449481  0.54515893 0.54529255 0.54541384 0.54526476 0.54534213
 0.5452288  0.54527265 0.54513256 0.54518318 0.54495051 0.54489315
 0.54502864 0.54494816 0.5449477  0.54493566 0.54502597 0.54490262
 0.54461589 0.54446403]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.54504841 0.54506405 0.54509598 0.54508574 0.54507667 0.54505433
 0.54504687 0.54502794 0.54504114 0.54501624 0.54501779 0.54502287
 0.54503314 0.54506016 0.54505152 0.5450505  0.54505465 0.54504034
 0.54505061 0.54504718]
[0.5 0.  0. ]
-----------end of analyzing the loss ratio:74.9109194278717
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444dc178b20>
---------------------------------
SparseEpoch: [96][1/398]	Time 0.604	Data 0.000	Loss 0.6039	
SparseEpoch: [96][101/398]	Time 0.625	Data 0.000	Loss 0.6550	
SparseEpoch: [96][201/398]	Time 0.625	Data 0.000	Loss 1.1911	
SparseEpoch: [96][301/398]	Time 0.624	Data 0.000	Loss 1.0190	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.14420023 0.14418776 0.14416059 0.14414592 0.14417219 0.14417844
 0.14413971 0.14410082 0.14407098 0.14407481 0.14405172 0.14404953
 0.14406066 0.14402305 0.14399804 0.14399772 0.1439835  0.14398858
 0.1439831  0.14393301]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.14417983 0.1441687  0.14415045 0.14415837 0.14412431 0.14409983
 0.14407759 0.1440721  0.14408342 0.14404856 0.14408456 0.14405059
 0.144058   0.14406811 0.14403178 0.14401928 0.14403952 0.14401193
 0.14399087 0.1439956 ]
[0.5        0.44736842 0.        ]
-----------end of analyzing the loss ratio:74.97403931617737
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444dc31b070>
---------------------------------
SparseEpoch: [96][1/398]	Time 0.607	Data 0.000	Loss 2.3549	
SparseEpoch: [96][101/398]	Time 0.625	Data 0.000	Loss 1.8380	
SparseEpoch: [96][201/398]	Time 0.627	Data 0.000	Loss 2.1355	
SparseEpoch: [96][301/398]	Time 0.626	Data 0.000	Loss 1.3192	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.0888	
Epoch(adapt):{0} Loss 0.9598	
Epoch(adapt):{0} Loss 1.1088	
Epoch(adapt):{0} Loss 0.8153	
------------------the total time cost:1217.729117155075
>>>>>meta updating
Epoch: 0096 | TRAIN: 0.4914 0.6633 0.8443 | 0.3709 0.3709 0.1730 | 0.1382 25.0579 20.2970 0.2652 0.5561 0.6933 ||TEST: 1.1491 0.4029 0.6588 | 0.5441 0.5441 0.2132 | 0.1497 26.4385 21.9733 0.2462 0.5177 0.6541 | 116.3058
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.41993162 0.41992823 0.41977979 0.41975594 0.41962682 0.41960513
 0.41965642 0.4195825  0.41950972 0.41954261 0.4195522  0.41953609
 0.41941162 0.41932229 0.41931581 0.41940735 0.41936762 0.41930867
 0.41926571 0.41924722]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.41957318 0.41954028 0.41955489 0.41955644 0.41952104 0.41952659
 0.41951942 0.4195918  0.41957271 0.41957771 0.41956657 0.41955223
 0.41950972 0.41950509 0.4195071  0.41948835 0.4194926  0.41950914
 0.41948557 0.41951039]
[0.         0.5        0.44736842]
-----------end of analyzing the loss ratio:75.10228943824768
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444dc25e9e0>
---------------------------------
SparseEpoch: [97][1/398]	Time 0.606	Data 0.000	Loss 1.4373	
SparseEpoch: [97][101/398]	Time 0.630	Data 0.000	Loss 2.2616	
SparseEpoch: [97][201/398]	Time 0.627	Data 0.000	Loss 1.8824	
SparseEpoch: [97][301/398]	Time 0.627	Data 0.000	Loss 1.7662	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.54733843 0.54732746 0.54707692 0.54720235 0.54705867 0.54660215
 0.54664923 0.54628043 0.54598966 0.5458342  0.54559657 0.54535494
 0.54503162 0.54515064 0.54500596 0.54477866 0.5446102  0.54440153
 0.54435918 0.54438621]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.54605314 0.54600773 0.54586963 0.54581131 0.54583156 0.54582114
 0.54579032 0.54579319 0.5457272  0.54572361 0.5456429  0.54564513
 0.54558396 0.54551839 0.54556602 0.54545818 0.54548618 0.54545826
 0.54540178 0.54535507]
[0.44736842 0.         0.5       ]
-----------end of analyzing the loss ratio:74.77748584747314
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d72b8cd0>
---------------------------------
SparseEpoch: [97][1/398]	Time 0.605	Data 0.000	Loss 1.2985	
SparseEpoch: [97][101/398]	Time 0.623	Data 0.000	Loss 1.3364	
SparseEpoch: [97][201/398]	Time 0.625	Data 0.000	Loss 1.5442	
SparseEpoch: [97][301/398]	Time 0.624	Data 0.000	Loss 1.3867	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.17115698 0.17114716 0.17114732 0.17114794 0.17109447 0.17113449
 0.17113515 0.17115972 0.17118193 0.17118324 0.17114441 0.17111981
 0.17109762 0.17108456 0.17108194 0.17110146 0.17110634 0.17109421
 0.17108494 0.17108217]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.17111114 0.17112218 0.17110057 0.17110399 0.17110993 0.17114672
 0.17114624 0.17117068 0.17119053 0.17118341 0.17117028 0.171105
 0.17112079 0.17112426 0.17113601 0.17111484 0.17113668 0.17111512
 0.1711018  0.17111562]
[0.23684211 0.         0.        ]
-----------end of analyzing the loss ratio:74.69309449195862
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6d937f0>
---------------------------------
SparseEpoch: [97][1/398]	Time 0.605	Data 0.000	Loss 2.0944	
SparseEpoch: [97][101/398]	Time 0.623	Data 0.000	Loss 2.0332	
SparseEpoch: [97][201/398]	Time 0.622	Data 0.000	Loss 2.2855	
SparseEpoch: [97][301/398]	Time 0.625	Data 0.000	Loss 1.3054	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.4861	
Epoch(adapt):{0} Loss 0.8640	
Epoch(adapt):{0} Loss 1.3284	
Epoch(adapt):{0} Loss 1.0550	
------------------the total time cost:1217.7070333957672
>>>>>meta updating
Epoch: 0097 | TRAIN: 0.4874 0.6535 0.8467 | 0.3762 0.3762 0.1729 | 0.1362 24.7271 19.7703 0.2786 0.5663 0.6992 ||TEST: 1.1391 0.4030 0.6613 | 0.5456 0.5456 0.2121 | 0.1491 26.2663 21.6601 0.2554 0.5246 0.6572 | 116.1907
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.55382276 0.55372576 0.55382384 0.55382356 0.55387523 0.55390238
 0.55380661 0.55381456 0.55400161 0.55388689 0.55401166 0.55395875
 0.5539075  0.55401883 0.55406079 0.55403639 0.55406659 0.55418598
 0.55418259 0.5541738 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.55408431 0.55406705 0.55405622 0.55400504 0.55397218 0.55399863
 0.55402223 0.55400414 0.55400475 0.55400154 0.5539906  0.55397058
 0.5539423  0.55387777 0.55388465 0.55390998 0.55386299 0.553828
 0.55377672 0.55375061]
[0.  0.  0.5]
-----------end of analyzing the loss ratio:75.13514924049377
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d72b94e0>
---------------------------------
SparseEpoch: [98][1/398]	Time 0.608	Data 0.000	Loss 1.4657	
SparseEpoch: [98][101/398]	Time 0.619	Data 0.000	Loss 1.8030	
SparseEpoch: [98][201/398]	Time 0.621	Data 0.000	Loss 1.4650	
SparseEpoch: [98][301/398]	Time 0.622	Data 0.000	Loss 1.1558	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.68544586 0.6856557  0.68549972 0.68551286 0.68563971 0.68561878
 0.68560503 0.68552991 0.68537477 0.68506311 0.68503115 0.68482094
 0.68464888 0.68466042 0.68458191 0.68479439 0.68456593 0.68461949
 0.68462008 0.68452989]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.68523314 0.68520519 0.68523051 0.68518041 0.68520745 0.6851864
 0.68520864 0.68520246 0.68520362 0.68517348 0.68506019 0.68500809
 0.68500267 0.68497528 0.68496789 0.68497775 0.68496062 0.68495784
 0.6849403  0.68495629]
[0.5        0.         0.44736842]
-----------end of analyzing the loss ratio:74.82076454162598
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6e95c30>
---------------------------------
SparseEpoch: [98][1/398]	Time 0.608	Data 0.000	Loss 0.9896	
SparseEpoch: [98][101/398]	Time 0.625	Data 0.000	Loss 1.5015	
SparseEpoch: [98][201/398]	Time 0.625	Data 0.000	Loss 1.4671	
SparseEpoch: [98][301/398]	Time 0.624	Data 0.000	Loss 1.2426	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.19229581 0.19228858 0.19219753 0.19223145 0.19221547 0.19220238
 0.19217913 0.19223044 0.19226131 0.19223481 0.19212277 0.19212051
 0.19214237 0.19204798 0.19199191 0.19199327 0.19202497 0.19198188
 0.19190104 0.19185382]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.19231558 0.19231331 0.19231609 0.19227794 0.19231501 0.19231915
 0.19232354 0.19229392 0.19225975 0.19220718 0.19217906 0.19210922
 0.19207961 0.19209216 0.19209204 0.19207449 0.1920083  0.19198223
 0.19195061 0.19192694]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:74.93746614456177
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444dc25f280>
---------------------------------
SparseEpoch: [98][1/398]	Time 0.606	Data 0.000	Loss 1.2426	
SparseEpoch: [98][101/398]	Time 0.624	Data 0.000	Loss 1.9334	
SparseEpoch: [98][201/398]	Time 0.624	Data 0.000	Loss 1.5664	
SparseEpoch: [98][301/398]	Time 0.624	Data 0.000	Loss 1.2431	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.2718	
Epoch(adapt):{0} Loss 0.7473	
Epoch(adapt):{0} Loss 1.2826	
Epoch(adapt):{0} Loss 0.5806	
------------------the total time cost:1216.7955355644226
>>>>>meta updating
Epoch: 0098 | TRAIN: 0.4795 0.6707 0.8509 | 0.3701 0.3701 0.1762 | 0.1361 24.8063 19.9871 0.2713 0.5632 0.6989 ||TEST: 1.1281 0.4052 0.6617 | 0.5395 0.5395 0.2120 | 0.1485 26.2710 21.7010 0.2506 0.5231 0.6578 | 116.3505
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.4713275  0.47129207 0.47124623 0.47118824 0.47114177 0.47103728
 0.47104308 0.47105094 0.47101118 0.47101239 0.47101438 0.4709825
 0.47103357 0.47098925 0.4709952  0.47098411 0.47099817 0.47098006
 0.47094356 0.47089961]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.47105898 0.47102468 0.47099557 0.471021   0.47102992 0.47104009
 0.47103478 0.47102805 0.47103758 0.47101204 0.471028   0.47104117
 0.47101543 0.4710068  0.47096719 0.47097273 0.4710171  0.47103787
 0.47105039 0.47107456]
[0.         0.5        0.23684211]
-----------end of analyzing the loss ratio:74.92490816116333
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d734e9b0>
---------------------------------
SparseEpoch: [99][1/398]	Time 0.609	Data 0.000	Loss 0.9765	
SparseEpoch: [99][101/398]	Time 0.627	Data 0.000	Loss 0.9326	
SparseEpoch: [99][201/398]	Time 0.624	Data 0.000	Loss 0.8438	
SparseEpoch: [99][301/398]	Time 0.625	Data 0.000	Loss 1.1510	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.44545303 0.44546809 0.44545131 0.44544873 0.44536557 0.44540095
 0.44532903 0.44518832 0.44518917 0.44522868 0.44534252 0.44545831
 0.4453356  0.4454948  0.44544579 0.44540014 0.44545205 0.44552473
 0.4453503  0.44544457]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.44518537 0.44518528 0.44520431 0.44525627 0.44526629 0.44526882
 0.44525784 0.44527678 0.44530484 0.4452886  0.44531013 0.44532019
 0.44534766 0.44535024 0.44532994 0.4453491  0.44538419 0.44541748
 0.44542152 0.44540292]
[0. 0. 0.]
-----------end of analyzing the loss ratio:74.96363759040833
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc151f30>
---------------------------------
SparseEpoch: [99][1/398]	Time 0.604	Data 0.000	Loss 0.3970	
SparseEpoch: [99][101/398]	Time 0.622	Data 0.000	Loss 0.5324	
SparseEpoch: [99][201/398]	Time 0.623	Data 0.000	Loss 0.3288	
SparseEpoch: [99][301/398]	Time 0.623	Data 0.000	Loss 0.3601	
lr:0.0001
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.15917002 0.15917965 0.15916951 0.1591287  0.1591657  0.1590986
 0.15908383 0.1591014  0.15899606 0.1589981  0.15894989 0.15886955
 0.15880191 0.15881198 0.15873314 0.15872717 0.15867186 0.15865178
 0.15859761 0.15851744]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.15909794 0.15910693 0.15915023 0.15910487 0.15906141 0.15906496
 0.15909033 0.15905745 0.1589844  0.15900174 0.15895824 0.15890307
 0.15887841 0.15884775 0.1588166  0.15879271 0.15879933 0.15879311
 0.15876091 0.15873969]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:75.1052885055542
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6d903a0>
---------------------------------
SparseEpoch: [99][1/398]	Time 0.606	Data 0.000	Loss 1.5353	
SparseEpoch: [99][101/398]	Time 0.628	Data 0.000	Loss 1.6682	
SparseEpoch: [99][201/398]	Time 0.626	Data 0.000	Loss 1.7558	
SparseEpoch: [99][301/398]	Time 0.625	Data 0.000	Loss 1.9724	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.0826	
Epoch(adapt):{0} Loss 1.0744	
Epoch(adapt):{0} Loss 0.9798	
Epoch(adapt):{0} Loss 1.4878	
------------------the total time cost:1217.3326547145844
>>>>>meta updating
Epoch: 0099 | TRAIN: 0.5348 0.6379 0.8328 | 0.3979 0.3979 0.1791 | 0.1398 25.3645 20.7663 0.2562 0.5451 0.6851 ||TEST: 1.1251 0.3897 0.6543 | 0.5666 0.5666 0.2149 | 0.1524 26.8358 22.5152 0.2356 0.5064 0.6446 | 116.1296
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.54604865 0.54600533 0.5459848  0.54596822 0.54595867 0.54596617
 0.54593929 0.5459851  0.54602971 0.54606062 0.54608422 0.5461287
 0.54614353 0.54616112 0.54619119 0.54625028 0.54624766 0.5462413
 0.54623373 0.54621714]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.54602727 0.54602507 0.54603732 0.54603015 0.54605823 0.54606282
 0.54606588 0.54607532 0.54607052 0.54607367 0.54606448 0.5460712
 0.54606606 0.54607317 0.54609101 0.54609917 0.54610579 0.54609366
 0.54609653 0.54609563]
[0. 0. 0.]
-----------end of analyzing the loss ratio:75.09539818763733
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6e96500>
---------------------------------
SparseEpoch: [100][1/398]	Time 0.577	Data 0.000	Loss 0.5183	
SparseEpoch: [100][101/398]	Time 0.580	Data 0.000	Loss 0.6059	
SparseEpoch: [100][201/398]	Time 0.580	Data 0.000	Loss 1.5551	
SparseEpoch: [100][301/398]	Time 0.580	Data 0.000	Loss 0.5533	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.81408212 0.81409526 0.81363074 0.81358805 0.81346093 0.81321074
 0.81289939 0.81280022 0.81265156 0.81260115 0.81233425 0.81212909
 0.81225523 0.81243674 0.81247362 0.81242015 0.81248225 0.81251882
 0.8126592  0.81282172]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.81253381 0.81252618 0.81254283 0.81250039 0.81244788 0.8124764
 0.81248317 0.81245385 0.81243514 0.81245795 0.81239293 0.8124026
 0.81235518 0.81233869 0.812387   0.81240001 0.81238503 0.81235198
 0.81237277 0.81241667]
[0.07894737 0.         0.18421053]
-----------end of analyzing the loss ratio:74.8577892780304
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc001e70>
---------------------------------
SparseEpoch: [100][1/398]	Time 0.579	Data 0.000	Loss 0.5509	
SparseEpoch: [100][101/398]	Time 0.582	Data 0.000	Loss 0.5337	
SparseEpoch: [100][201/398]	Time 0.581	Data 0.000	Loss 0.7495	
SparseEpoch: [100][301/398]	Time 0.581	Data 0.000	Loss 0.8229	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.15983071 0.15982673 0.15983324 0.15982541 0.15980168 0.15979832
 0.15979164 0.15977103 0.15975826 0.15975354 0.15974422 0.15974542
 0.15971689 0.15970347 0.1596983  0.15970426 0.1597017  0.15969939
 0.15968449 0.15968808]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.15972919 0.15971515 0.15971375 0.15972362 0.15972025 0.15973338
 0.15973386 0.15974077 0.15975634 0.1597372  0.15976977 0.15975446
 0.15973794 0.15975661 0.15976081 0.15976503 0.15976382 0.15974128
 0.15973129 0.15972865]
[0.44736842 0.         0.        ]
-----------end of analyzing the loss ratio:75.0882318019867
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc2f64a0>
---------------------------------
SparseEpoch: [100][1/398]	Time 0.578	Data 0.000	Loss 1.8050	
SparseEpoch: [100][101/398]	Time 0.580	Data 0.000	Loss 1.6464	
SparseEpoch: [100][201/398]	Time 0.580	Data 0.000	Loss 1.8003	
SparseEpoch: [100][301/398]	Time 0.580	Data 0.000	Loss 1.3569	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.8819	
Epoch(adapt):{0} Loss 1.1606	
Epoch(adapt):{0} Loss 0.7512	
Epoch(adapt):{0} Loss 1.1285	
------------------the total time cost:1164.9909093379974
>>>>>meta updating
Epoch: 0100 | TRAIN: 0.4992 0.6543 0.8423 | 0.3677 0.3677 0.1828 | 0.1343 24.3760 19.2904 0.2914 0.5769 0.7058 ||TEST: 1.1775 0.4038 0.6622 | 0.5365 0.5365 0.2153 | 0.1459 25.7373 20.8721 0.2727 0.5406 0.6689 | 116.3082
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.49857726 0.49853105 0.49861656 0.49875506 0.49878568 0.49877737
 0.49866569 0.49880253 0.49876643 0.49868848 0.49875031 0.49868949
 0.49861182 0.4986884  0.49867112 0.49861629 0.49865889 0.49862139
 0.49874928 0.49889948]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.49872351 0.49871594 0.49869966 0.49865537 0.49868095 0.4986625
 0.49864639 0.49866931 0.49867651 0.49867852 0.49871702 0.49871641
 0.4987361  0.49871323 0.49872579 0.49871633 0.49871515 0.49872218
 0.49871571 0.49870941]
[0. 0. 0.]
-----------end of analyzing the loss ratio:75.00407409667969
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d731f460>
---------------------------------
SparseEpoch: [101][1/398]	Time 0.578	Data 0.000	Loss 0.4612	
SparseEpoch: [101][101/398]	Time 0.579	Data 0.000	Loss 0.6659	
SparseEpoch: [101][201/398]	Time 0.579	Data 0.000	Loss 0.9401	
SparseEpoch: [101][301/398]	Time 0.579	Data 0.000	Loss 0.2737	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.56775711 0.56772563 0.56790199 0.56800924 0.56802425 0.5681891
 0.56821638 0.56827929 0.56844309 0.56842891 0.56854224 0.56850809
 0.5684737  0.56844065 0.56835815 0.56835575 0.56830725 0.56830224
 0.56822276 0.56824254]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.56851202 0.5685057  0.56850762 0.56849553 0.56850555 0.56850261
 0.56850827 0.56851213 0.56851238 0.56851895 0.56849579 0.5684844
 0.56847308 0.56847208 0.56846466 0.5684408  0.56845497 0.56846444
 0.56846426 0.56848502]
[0.         0.         0.28947368]
-----------end of analyzing the loss ratio:75.00500440597534
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc2ad390>
---------------------------------
SparseEpoch: [101][1/398]	Time 0.583	Data 0.000	Loss 1.0438	
SparseEpoch: [101][101/398]	Time 0.580	Data 0.000	Loss 1.3764	
SparseEpoch: [101][201/398]	Time 0.580	Data 0.000	Loss 0.5463	
SparseEpoch: [101][301/398]	Time 0.580	Data 0.000	Loss 0.5254	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.14697816 0.14696954 0.14695359 0.1469723  0.14697967 0.14695795
 0.14695755 0.14696506 0.14696813 0.14698334 0.14696327 0.14698184
 0.14695328 0.14694709 0.14693371 0.14694229 0.14693956 0.14691853
 0.14687955 0.14687222]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.14700811 0.14700894 0.14701137 0.14702089 0.14700636 0.14698597
 0.14694697 0.14692928 0.14696024 0.14697064 0.14695752 0.14696386
 0.14694554 0.14693971 0.14693878 0.14693962 0.14690837 0.14691267
 0.14689021 0.14686667]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:74.9001898765564
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x744609646aa0>
---------------------------------
SparseEpoch: [101][1/398]	Time 0.578	Data 0.000	Loss 1.9728	
SparseEpoch: [101][101/398]	Time 0.580	Data 0.000	Loss 2.4361	
SparseEpoch: [101][201/398]	Time 0.581	Data 0.000	Loss 1.8573	
SparseEpoch: [101][301/398]	Time 0.581	Data 0.000	Loss 1.8289	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.9939	
Epoch(adapt):{0} Loss 1.0301	
Epoch(adapt):{0} Loss 1.0440	
Epoch(adapt):{0} Loss 1.0023	
------------------the total time cost:1163.8928806781769
>>>>>meta updating
Epoch: 0101 | TRAIN: 0.4817 0.6651 0.8481 | 0.3670 0.3670 0.1718 | 0.1307 24.0059 18.9849 0.2952 0.5857 0.7151 ||TEST: 1.1452 0.4050 0.6650 | 0.5379 0.5379 0.2119 | 0.1458 25.7252 20.8832 0.2721 0.5405 0.6695 | 116.2615
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.47714422 0.47714532 0.47717633 0.47717184 0.47718487 0.47718155
 0.47721025 0.47718711 0.47721724 0.47721345 0.47723144 0.47723675
 0.47723361 0.47718969 0.47724347 0.4772362  0.47728025 0.47726598
 0.47729974 0.47728914]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.47727767 0.47729669 0.47728349 0.47728057 0.47728371 0.4772856
 0.47726146 0.4772478  0.47724677 0.47723406 0.47722962 0.47723015
 0.47721862 0.47720504 0.47720256 0.47721447 0.47722056 0.47721665
 0.47721793 0.47720633]
[0.         0.         0.23684211]
-----------end of analyzing the loss ratio:75.00625491142273
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc5fed40>
---------------------------------
SparseEpoch: [102][1/398]	Time 0.580	Data 0.000	Loss 0.5522	
SparseEpoch: [102][101/398]	Time 0.580	Data 0.000	Loss 0.7970	
SparseEpoch: [102][201/398]	Time 0.580	Data 0.000	Loss 0.8282	
SparseEpoch: [102][301/398]	Time 0.580	Data 0.000	Loss 1.1195	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.51730621 0.5172855  0.51724451 0.5172656  0.51726448 0.51723923
 0.51724543 0.51716153 0.51716746 0.51718696 0.51722275 0.51718712
 0.51723808 0.5172298  0.51719633 0.51723326 0.5172057  0.51719317
 0.51717201 0.51710046]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.51717965 0.51717276 0.51717294 0.51717729 0.51718239 0.51718079
 0.51718012 0.51719872 0.51718243 0.51717916 0.51718457 0.51718698
 0.5171888  0.51719321 0.51718824 0.51718794 0.51720056 0.51720518
 0.51722001 0.51722376]
[0.5 0.  0. ]
-----------end of analyzing the loss ratio:75.31976366043091
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc2acd00>
---------------------------------
SparseEpoch: [102][1/398]	Time 0.579	Data 0.000	Loss 0.6928	
SparseEpoch: [102][101/398]	Time 0.580	Data 0.000	Loss 0.7325	
SparseEpoch: [102][201/398]	Time 0.580	Data 0.000	Loss 0.5006	
SparseEpoch: [102][301/398]	Time 0.580	Data 0.000	Loss 0.8073	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.13055302 0.13056778 0.13052878 0.13048012 0.13044738 0.13038441
 0.13040106 0.13035355 0.13030153 0.13028764 0.13026128 0.13024799
 0.13021804 0.1301984  0.13020359 0.1301919  0.13018551 0.130155
 0.13013982 0.13015396]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.13022034 0.13019306 0.13021631 0.13022729 0.13023114 0.13021529
 0.13022327 0.13022887 0.1302577  0.13025815 0.13026294 0.13024061
 0.13025194 0.13023879 0.13024057 0.13025557 0.13027433 0.13028525
 0.13029187 0.13031095]
[0.44736842 0.         0.        ]
-----------end of analyzing the loss ratio:74.8642578125
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc128730>
---------------------------------
SparseEpoch: [102][1/398]	Time 0.578	Data 0.000	Loss 1.7199	
SparseEpoch: [102][101/398]	Time 0.580	Data 0.000	Loss 1.3826	
SparseEpoch: [102][201/398]	Time 0.580	Data 0.000	Loss 1.2074	
SparseEpoch: [102][301/398]	Time 0.580	Data 0.000	Loss 2.0236	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.7064	
Epoch(adapt):{0} Loss 1.0089	
Epoch(adapt):{0} Loss 0.8580	
Epoch(adapt):{0} Loss 1.4528	
------------------the total time cost:1165.0817301273346
>>>>>meta updating
Epoch: 0102 | TRAIN: 0.4731 0.6700 0.8491 | 0.3881 0.3881 0.1937 | 0.1315 24.0884 19.0642 0.2956 0.5832 0.7129 ||TEST: 1.1639 0.4059 0.6665 | 0.5382 0.5382 0.2190 | 0.1444 25.6518 20.8479 0.2696 0.5410 0.6710 | 116.1207
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.43735907 0.43726487 0.437351   0.43735238 0.43737276 0.43738101
 0.43729133 0.43723713 0.43727199 0.43723317 0.43722484 0.43721377
 0.43722976 0.43719149 0.43716056 0.43712364 0.43719124 0.43719379
 0.4371857  0.43723385]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.43717213 0.43717173 0.43716834 0.43714883 0.4371693  0.43719932
 0.4372294  0.43723095 0.43722023 0.4372352  0.43721343 0.4372284
 0.43724464 0.43725886 0.43725704 0.43729228 0.4373028  0.43728114
 0.43725936 0.43721912]
[0.         0.28947368 0.        ]
-----------end of analyzing the loss ratio:75.00366306304932
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc2ad930>
---------------------------------
SparseEpoch: [103][1/398]	Time 0.585	Data 0.000	Loss 0.3972	
SparseEpoch: [103][101/398]	Time 0.580	Data 0.000	Loss 0.4262	
SparseEpoch: [103][201/398]	Time 0.580	Data 0.000	Loss 0.6814	
SparseEpoch: [103][301/398]	Time 0.580	Data 0.000	Loss 1.0640	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.39447383 0.39447834 0.39450837 0.39441702 0.39449718 0.39445941
 0.39432154 0.39442018 0.39426493 0.39414136 0.39415719 0.39416651
 0.39413634 0.39418461 0.39417515 0.39420395 0.39417726 0.39417293
 0.39403198 0.39392698]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.39411661 0.39411275 0.39411178 0.39414449 0.3941221  0.39411317
 0.39409825 0.39410497 0.39411323 0.39413267 0.39412952 0.39413394
 0.39412476 0.3941216  0.39411026 0.39412168 0.3941173  0.39413714
 0.39414726 0.39415254]
[0.5 0.  0. ]
-----------end of analyzing the loss ratio:75.10383105278015
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc5ff760>
---------------------------------
SparseEpoch: [103][1/398]	Time 0.578	Data 0.000	Loss 0.7772	
SparseEpoch: [103][101/398]	Time 0.580	Data 0.000	Loss 0.5334	
SparseEpoch: [103][201/398]	Time 0.581	Data 0.000	Loss 0.7945	
SparseEpoch: [103][301/398]	Time 0.580	Data 0.000	Loss 0.6063	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.13089644 0.13087407 0.1308813  0.13088508 0.1309123  0.13090746
 0.13088188 0.13087857 0.13083168 0.1308169  0.13080897 0.13078161
 0.1307841  0.13079042 0.13076907 0.13075148 0.13075204 0.13074575
 0.13072886 0.13072757]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.13083087 0.13083037 0.13084027 0.13082775 0.13082557 0.13080587
 0.13082009 0.13081219 0.13080261 0.1308168  0.13081603 0.1308174
 0.13080881 0.13081279 0.13081945 0.13082603 0.13082607 0.13083653
 0.13083164 0.13083293]
[0.5 0.  0. ]
-----------end of analyzing the loss ratio:74.91903591156006
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7446096467d0>
---------------------------------
SparseEpoch: [103][1/398]	Time 0.577	Data 0.000	Loss 1.1587	
SparseEpoch: [103][101/398]	Time 0.580	Data 0.000	Loss 1.6354	
SparseEpoch: [103][201/398]	Time 0.580	Data 0.000	Loss 1.4946	
SparseEpoch: [103][301/398]	Time 0.580	Data 0.000	Loss 1.1305	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.0035	
Epoch(adapt):{0} Loss 0.8313	
Epoch(adapt):{0} Loss 0.8792	
Epoch(adapt):{0} Loss 0.7226	
------------------the total time cost:1163.8498578071594
>>>>>meta updating
Epoch: 0103 | TRAIN: 0.4558 0.6806 0.8595 | 0.3709 0.3709 0.1716 | 0.1324 24.3081 19.4535 0.2861 0.5743 0.7070 ||TEST: 1.1437 0.4072 0.6655 | 0.5485 0.5485 0.2150 | 0.1470 26.0165 21.4488 0.2616 0.5282 0.6609 | 116.5019
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.48552774 0.4854629  0.48532833 0.48534336 0.4853522  0.48534388
 0.48541666 0.48545271 0.48549677 0.48543644 0.48544436 0.48547542
 0.48546205 0.48543849 0.48552206 0.48549448 0.48544223 0.48535217
 0.48541048 0.48542475]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.48547323 0.48541549 0.4854414  0.48546663 0.48545275 0.48546466
 0.48546168 0.4854437  0.48544727 0.4854399  0.48543395 0.48543429
 0.48544553 0.48544827 0.48548961 0.48549263 0.48547848 0.48546053
 0.48548447 0.48545389]
[0. 0. 0.]
-----------end of analyzing the loss ratio:75.28423619270325
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d722ffd0>
---------------------------------
SparseEpoch: [104][1/398]	Time 0.576	Data 0.000	Loss 0.6106	
SparseEpoch: [104][101/398]	Time 0.579	Data 0.000	Loss 0.9298	
SparseEpoch: [104][201/398]	Time 0.579	Data 0.000	Loss 0.8318	
SparseEpoch: [104][301/398]	Time 0.579	Data 0.000	Loss 0.5095	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.46091048 0.46083199 0.46086558 0.46074926 0.46073478 0.46066279
 0.46060832 0.46046479 0.46048805 0.46043995 0.46031477 0.46026565
 0.46023539 0.46024932 0.46027366 0.46023844 0.4601949  0.46016828
 0.46009142 0.46008369]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.46043551 0.46042328 0.46042537 0.46040994 0.46040779 0.46040195
 0.46039374 0.46039413 0.46034186 0.4603553  0.46035513 0.46034706
 0.46033744 0.46034474 0.46034755 0.46034042 0.46034333 0.4603498
 0.46036254 0.46037224]
[0.5        0.         0.13157895]
-----------end of analyzing the loss ratio:75.1024580001831
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6d92d10>
---------------------------------
SparseEpoch: [104][1/398]	Time 0.578	Data 0.000	Loss 0.6428	
SparseEpoch: [104][101/398]	Time 0.580	Data 0.000	Loss 0.5801	
SparseEpoch: [104][201/398]	Time 0.580	Data 0.000	Loss 0.8280	
SparseEpoch: [104][301/398]	Time 0.580	Data 0.000	Loss 0.9095	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.1431596  0.14318491 0.14321415 0.14323913 0.14324375 0.14321844
 0.1432155  0.1432282  0.14322895 0.14321999 0.1432503  0.14325369
 0.14328203 0.14324671 0.14324709 0.14322949 0.14324142 0.1432318
 0.14323575 0.14324726]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.14324282 0.14324356 0.14324073 0.14324516 0.14325423 0.14324565
 0.14326682 0.14326164 0.14324936 0.14324727 0.14324623 0.14324712
 0.14325404 0.14323975 0.14323102 0.14320366 0.14321815 0.14320582
 0.14320972 0.14322163]
[0.         0.28947368 0.        ]
-----------end of analyzing the loss ratio:75.07168292999268
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc045ae0>
---------------------------------
SparseEpoch: [104][1/398]	Time 0.578	Data 0.000	Loss 1.1602	
SparseEpoch: [104][101/398]	Time 0.580	Data 0.000	Loss 0.9364	
SparseEpoch: [104][201/398]	Time 0.580	Data 0.000	Loss 1.6637	
SparseEpoch: [104][301/398]	Time 0.580	Data 0.000	Loss 1.1189	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.9727	
Epoch(adapt):{0} Loss 1.1197	
Epoch(adapt):{0} Loss 1.0623	
Epoch(adapt):{0} Loss 0.7255	
------------------the total time cost:1165.387386083603
>>>>>meta updating
Epoch: 0104 | TRAIN: 0.4498 0.6878 0.8586 | 0.3541 0.3541 0.1718 | 0.1329 24.3228 19.5022 0.2869 0.5743 0.7068 ||TEST: 1.1880 0.4120 0.6669 | 0.5272 0.5272 0.2106 | 0.1457 25.7609 21.0734 0.2715 0.5360 0.6666 | 116.1797
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.48437135 0.484313   0.48440883 0.48440668 0.48429085 0.4842729
 0.48423032 0.4842076  0.48418756 0.4842475  0.48424148 0.48429402
 0.48428464 0.48420213 0.48421233 0.48418894 0.48411805 0.48411954
 0.4840912  0.48406141]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.48422178 0.48424103 0.48422379 0.48423866 0.48424821 0.48423812
 0.48423321 0.48423169 0.4842369  0.48424293 0.48425046 0.4842533
 0.48424651 0.48425638 0.48425342 0.48426163 0.48425149 0.48424566
 0.48426864 0.48427582]
[0.  0.5 0. ]
-----------end of analyzing the loss ratio:75.04234004020691
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc35e2c0>
---------------------------------
SparseEpoch: [105][1/398]	Time 0.578	Data 0.000	Loss 0.3703	
SparseEpoch: [105][101/398]	Time 0.580	Data 0.000	Loss 0.7108	
SparseEpoch: [105][201/398]	Time 0.580	Data 0.000	Loss 0.7350	
SparseEpoch: [105][301/398]	Time 0.580	Data 0.000	Loss 0.7925	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.365621   0.36557417 0.36553468 0.36533184 0.36541722 0.36524054
 0.36502421 0.36501094 0.36473164 0.3644976  0.36447322 0.36441823
 0.36422865 0.36425649 0.36421761 0.36417894 0.36421317 0.36413821
 0.36404923 0.36391784]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.36444474 0.36444424 0.36445044 0.36446505 0.36445772 0.36447165
 0.3644799  0.36448139 0.36447299 0.36447636 0.36447758 0.36445452
 0.36444307 0.36444399 0.36441289 0.36442215 0.36443052 0.3644289
 0.36443038 0.36443607]
[0.5        0.         0.23684211]
-----------end of analyzing the loss ratio:74.92535471916199
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d72b9ab0>
---------------------------------
SparseEpoch: [105][1/398]	Time 0.599	Data 0.000	Loss 0.8689	
SparseEpoch: [105][101/398]	Time 0.581	Data 0.000	Loss 0.9183	
SparseEpoch: [105][201/398]	Time 0.581	Data 0.000	Loss 1.2188	
SparseEpoch: [105][301/398]	Time 0.581	Data 0.000	Loss 0.7509	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.13207951 0.13205232 0.13204785 0.13203464 0.13203703 0.13205807
 0.13206206 0.13207301 0.13203881 0.13202718 0.13200167 0.13201589
 0.13200657 0.13198372 0.13196248 0.13196203 0.13194282 0.13194621
 0.13194744 0.13193216]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.13196083 0.13196468 0.13196098 0.13195848 0.13196508 0.1319675
 0.13199572 0.13199521 0.13201298 0.13200884 0.13201982 0.13203323
 0.13205488 0.13207145 0.13204491 0.1320351  0.13202121 0.13201627
 0.13202079 0.13202307]
[0.5 0.  0. ]
-----------end of analyzing the loss ratio:75.05119848251343
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc27b880>
---------------------------------
SparseEpoch: [105][1/398]	Time 0.578	Data 0.000	Loss 1.5559	
SparseEpoch: [105][101/398]	Time 0.580	Data 0.000	Loss 1.3499	
SparseEpoch: [105][201/398]	Time 0.580	Data 0.000	Loss 1.5722	
SparseEpoch: [105][301/398]	Time 0.580	Data 0.000	Loss 1.0825	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.0127	
Epoch(adapt):{0} Loss 1.3661	
Epoch(adapt):{0} Loss 0.9542	
Epoch(adapt):{0} Loss 1.3798	
------------------the total time cost:1166.5239634513855
>>>>>meta updating
Epoch: 0105 | TRAIN: 0.4311 0.6950 0.8639 | 0.3598 0.3598 0.1678 | 0.1296 23.9704 19.1105 0.2928 0.5831 0.7151 ||TEST: 1.1585 0.4086 0.6667 | 0.5322 0.5322 0.2112 | 0.1443 25.6807 20.9799 0.2679 0.5382 0.6694 | 116.2579
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.43339838 0.43334938 0.43330046 0.43318928 0.43311586 0.433043
 0.43302917 0.43304729 0.43310097 0.43309861 0.43305923 0.43304248
 0.43298648 0.43290703 0.43291924 0.43294756 0.43295714 0.432983
 0.4330333  0.43293068]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.43306714 0.43307322 0.43308359 0.43307694 0.4330399  0.43304259
 0.43302616 0.43306187 0.43306341 0.43305912 0.43305149 0.43308378
 0.43306788 0.43306865 0.4330729  0.43307716 0.43307503 0.43301514
 0.43302405 0.43303206]
[0.         0.18421053 0.39473684]
-----------end of analyzing the loss ratio:75.04309749603271
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6f94b20>
---------------------------------
SparseEpoch: [106][1/398]	Time 0.579	Data 0.000	Loss 0.7538	
SparseEpoch: [106][101/398]	Time 0.581	Data 0.000	Loss 1.0942	
SparseEpoch: [106][201/398]	Time 0.581	Data 0.000	Loss 0.7976	
SparseEpoch: [106][301/398]	Time 0.581	Data 0.000	Loss 1.0551	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.35727793 0.35722476 0.35718241 0.3572564  0.35724717 0.35727545
 0.35727999 0.35730534 0.35726391 0.3572656  0.35724886 0.35719593
 0.35726732 0.35727377 0.35720206 0.35717502 0.35721111 0.35713607
 0.35708463 0.35696985]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.35726104 0.3572765  0.35727196 0.35725554 0.35723641 0.35726108
 0.35724881 0.3572505  0.3572564  0.35727927 0.35727763 0.35726009
 0.35726932 0.35727473 0.35725584 0.35725435 0.357266   0.35725276
 0.35725206 0.35726602]
[0.5 0.  0. ]
-----------end of analyzing the loss ratio:75.13266277313232
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444dc1796c0>
---------------------------------
SparseEpoch: [106][1/398]	Time 0.584	Data 0.000	Loss 0.5838	
SparseEpoch: [106][101/398]	Time 0.580	Data 0.000	Loss 0.4803	
SparseEpoch: [106][201/398]	Time 0.580	Data 0.000	Loss 0.7646	
SparseEpoch: [106][301/398]	Time 0.580	Data 0.000	Loss 0.6039	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.12310178 0.1231015  0.12310182 0.1231068  0.12310014 0.12310044
 0.12309617 0.12309782 0.1230974  0.12310016 0.12309825 0.1230979
 0.12309921 0.12310235 0.12310418 0.12310343 0.1231006  0.12309906
 0.12310013 0.12310227]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.12311526 0.12311353 0.12311191 0.12311109 0.12310858 0.12310187
 0.12311294 0.12311313 0.12310179 0.12309923 0.12309279 0.12308678
 0.12308785 0.12309781 0.12309609 0.12308933 0.1230851  0.12307891
 0.12307726 0.12308207]
[0.         0.44736842 0.        ]
-----------end of analyzing the loss ratio:75.04516291618347
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc534700>
---------------------------------
SparseEpoch: [106][1/398]	Time 0.578	Data 0.000	Loss 1.2987	
SparseEpoch: [106][101/398]	Time 0.581	Data 0.000	Loss 2.4100	
SparseEpoch: [106][201/398]	Time 0.580	Data 0.000	Loss 1.2188	
SparseEpoch: [106][301/398]	Time 0.580	Data 0.000	Loss 1.5800	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.7775	
Epoch(adapt):{0} Loss 0.8257	
Epoch(adapt):{0} Loss 0.9205	
Epoch(adapt):{0} Loss 0.9817	
------------------the total time cost:1166.1677911281586
>>>>>meta updating
Epoch: 0106 | TRAIN: 0.4482 0.6798 0.8612 | 0.3668 0.3668 0.1636 | 0.1287 23.8242 18.8706 0.2972 0.5888 0.7187 ||TEST: 1.1699 0.4067 0.6629 | 0.5502 0.5502 0.2111 | 0.1440 25.6303 20.9092 0.2692 0.5402 0.6713 | 116.9091
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.42668839 0.42672679 0.42679037 0.4267213  0.42675282 0.42676853
 0.42675877 0.42672963 0.42672528 0.42668445 0.42669086 0.42673623
 0.42671374 0.42666773 0.42664589 0.4267698  0.42676142 0.42679644
 0.42676117 0.4267983 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.42656987 0.42657258 0.42659413 0.42660831 0.42661588 0.42657631
 0.42663863 0.42664908 0.42668419 0.42668117 0.42670953 0.42672851
 0.42675123 0.42677288 0.4267995  0.42680804 0.42680336 0.42677134
 0.42681409 0.42682474]
[0.         0.23684211 0.        ]
-----------end of analyzing the loss ratio:74.9403932094574
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444dc1531c0>
---------------------------------
SparseEpoch: [107][1/398]	Time 0.579	Data 0.000	Loss 0.6376	
SparseEpoch: [107][101/398]	Time 0.581	Data 0.000	Loss 0.6649	
SparseEpoch: [107][201/398]	Time 0.580	Data 0.000	Loss 0.5147	
SparseEpoch: [107][301/398]	Time 0.580	Data 0.000	Loss 1.3653	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.45064155 0.4494287  0.44895492 0.44788607 0.4471016  0.44628133
 0.44531131 0.44481816 0.44355919 0.44287721 0.44213298 0.44140739
 0.44081431 0.4403382  0.43992782 0.43934866 0.43912084 0.43876267
 0.43883866 0.43822713]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.44261076 0.4425516  0.44250498 0.44245298 0.44242784 0.44246366
 0.44246725 0.44243252 0.44244971 0.44246755 0.4423872  0.44244941
 0.44250017 0.4424839  0.44235733 0.44234855 0.44238797 0.44234516
 0.44239    0.44238233]
[0.5        0.         0.39473684]
-----------end of analyzing the loss ratio:74.95246291160583
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc42d720>
---------------------------------
SparseEpoch: [107][1/398]	Time 0.589	Data 0.000	Loss 1.0240	
SparseEpoch: [107][101/398]	Time 0.581	Data 0.000	Loss 1.6826	
SparseEpoch: [107][201/398]	Time 0.581	Data 0.000	Loss 0.9031	
SparseEpoch: [107][301/398]	Time 0.581	Data 0.000	Loss 0.8134	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.13709167 0.13708816 0.13708059 0.1370727  0.13707839 0.13708115
 0.13706685 0.13706716 0.13706233 0.13704605 0.13705504 0.1370576
 0.13704749 0.13703856 0.13705571 0.13706152 0.13703483 0.13702424
 0.13702189 0.13702316]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.13702405 0.13702462 0.1370316  0.13703795 0.13704814 0.13705217
 0.13704874 0.13705366 0.13704168 0.13704867 0.13704582 0.13706092
 0.13707184 0.13707894 0.13710659 0.1371143  0.13710251 0.13710983
 0.13710846 0.13710123]
[0.44736842 0.         0.        ]
-----------end of analyzing the loss ratio:75.15095543861389
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d73272e0>
---------------------------------
SparseEpoch: [107][1/398]	Time 0.580	Data 0.000	Loss 1.5655	
SparseEpoch: [107][101/398]	Time 0.580	Data 0.000	Loss 1.7476	
SparseEpoch: [107][201/398]	Time 0.580	Data 0.000	Loss 2.0332	
SparseEpoch: [107][301/398]	Time 0.580	Data 0.000	Loss 1.7853	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.2264	
Epoch(adapt):{0} Loss 1.0135	
Epoch(adapt):{0} Loss 1.5112	
Epoch(adapt):{0} Loss 0.7372	
------------------the total time cost:1164.901094198227
>>>>>meta updating
Epoch: 0107 | TRAIN: 0.4520 0.6816 0.8594 | 0.3519 0.3519 0.1739 | 0.1294 23.8183 18.7658 0.2999 0.5919 0.7203 ||TEST: 1.1859 0.4049 0.6624 | 0.5300 0.5300 0.2120 | 0.1444 25.6081 20.7737 0.2712 0.5431 0.6734 | 116.3714
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.43777482 0.43776872 0.43777393 0.43778896 0.43778276 0.43777032
 0.43775343 0.43772783 0.43768158 0.43766009 0.43765788 0.43765973
 0.43767297 0.43765869 0.43765423 0.43755484 0.43756086 0.43752567
 0.43751054 0.4375135 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.43769116 0.43768387 0.43768799 0.43766958 0.4376533  0.43764919
 0.43765214 0.43766395 0.43764845 0.43765393 0.4376362  0.43765118
 0.43766511 0.43765483 0.43765566 0.43759686 0.43761019 0.43758567
 0.43758613 0.4375951 ]
[0.         0.44736842 0.39473684]
-----------end of analyzing the loss ratio:75.16945505142212
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc35e230>
---------------------------------
SparseEpoch: [108][1/398]	Time 0.579	Data 0.000	Loss 1.0841	
SparseEpoch: [108][101/398]	Time 0.581	Data 0.000	Loss 0.9472	
SparseEpoch: [108][201/398]	Time 0.581	Data 0.000	Loss 1.0321	
SparseEpoch: [108][301/398]	Time 0.581	Data 0.000	Loss 0.8984	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.35936714 0.35936364 0.3592305  0.35917514 0.3592143  0.35919124
 0.35920273 0.35909656 0.35903267 0.35899683 0.35895382 0.35891343
 0.35891069 0.35881754 0.35872818 0.35863389 0.35857311 0.35848645
 0.35847726 0.35847853]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.35895662 0.35892915 0.35892496 0.35892394 0.35891287 0.35889536
 0.35890886 0.35891357 0.35892453 0.35893019 0.35892687 0.35892722
 0.35894467 0.35896865 0.35896283 0.35895815 0.35896022 0.35896119
 0.35898027 0.35896436]
[0.44736842 0.         0.        ]
-----------end of analyzing the loss ratio:75.0986819267273
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x744608680d30>
---------------------------------
SparseEpoch: [108][1/398]	Time 0.579	Data 0.000	Loss 0.5975	
SparseEpoch: [108][101/398]	Time 0.580	Data 0.000	Loss 0.7307	
SparseEpoch: [108][201/398]	Time 0.580	Data 0.000	Loss 0.7197	
SparseEpoch: [108][301/398]	Time 0.580	Data 0.000	Loss 0.7305	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.1454036  0.14540951 0.14539743 0.14539624 0.14538619 0.14538059
 0.14536015 0.14537734 0.14537178 0.14534391 0.14534074 0.14531388
 0.1453217  0.14530802 0.14531967 0.14531423 0.14530867 0.14531627
 0.14529775 0.14531412]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.14538653 0.14538149 0.14536719 0.14536318 0.14535571 0.1453506
 0.14534439 0.14535792 0.14534265 0.14533492 0.14533314 0.14533694
 0.14533699 0.14532115 0.1453076  0.14533038 0.14531692 0.14533659
 0.14531517 0.14530531]
[0.44736842 0.5        0.        ]
-----------end of analyzing the loss ratio:75.11935114860535
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc509060>
---------------------------------
SparseEpoch: [108][1/398]	Time 0.579	Data 0.000	Loss 1.1271	
SparseEpoch: [108][101/398]	Time 0.580	Data 0.000	Loss 2.1680	
SparseEpoch: [108][201/398]	Time 0.581	Data 0.000	Loss 2.0741	
SparseEpoch: [108][301/398]	Time 0.581	Data 0.000	Loss 1.3826	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.6111	
Epoch(adapt):{0} Loss 0.8172	
Epoch(adapt):{0} Loss 0.6921	
Epoch(adapt):{0} Loss 0.7818	
------------------the total time cost:1165.9207036495209
>>>>>meta updating
Epoch: 0108 | TRAIN: 0.4213 0.6920 0.8647 | 0.3508 0.3508 0.1652 | 0.1287 23.8636 18.9643 0.2951 0.5858 0.7174 ||TEST: 1.2277 0.4023 0.6653 | 0.5324 0.5324 0.2075 | 0.1439 25.6313 20.9297 0.2693 0.5394 0.6704 | 116.9995
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.35622456 0.35628523 0.356245   0.35627645 0.35623599 0.35625514
 0.35619196 0.35622091 0.35629268 0.35634459 0.35634513 0.35639724
 0.35638122 0.35642914 0.35642475 0.35641325 0.35645442 0.35643122
 0.35644512 0.35649198]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.3563014  0.35629411 0.35632768 0.35631835 0.35631807 0.35634114
 0.35632404 0.35632675 0.3563349  0.3563464  0.35633287 0.35635215
 0.35634192 0.35634465 0.3563454  0.35636306 0.35635732 0.35634132
 0.35634304 0.35634628]
[0. 0. 0.]
-----------end of analyzing the loss ratio:75.05398893356323
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444dc152e30>
---------------------------------
SparseEpoch: [109][1/398]	Time 0.577	Data 0.000	Loss 0.5606	
SparseEpoch: [109][101/398]	Time 0.579	Data 0.000	Loss 0.3693	
SparseEpoch: [109][201/398]	Time 0.579	Data 0.000	Loss 0.5324	
SparseEpoch: [109][301/398]	Time 0.579	Data 0.000	Loss 0.5670	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.38531025 0.38526881 0.38503206 0.38482775 0.38468414 0.38450805
 0.38453051 0.38444225 0.38408468 0.38390124 0.38372558 0.38354474
 0.38332494 0.38319474 0.38282454 0.3826964  0.38271877 0.38258917
 0.38239443 0.38216993]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.38392668 0.38391666 0.38390942 0.38388562 0.3839275  0.38390681
 0.38389137 0.38389748 0.38386168 0.3838236  0.38379471 0.38379227
 0.38379425 0.38381287 0.383857   0.38383786 0.38382279 0.38378777
 0.3837664  0.3837213 ]
[0.5 0.  0.5]
-----------end of analyzing the loss ratio:75.15945315361023
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444dc178d90>
---------------------------------
SparseEpoch: [109][1/398]	Time 0.579	Data 0.000	Loss 1.1983	
SparseEpoch: [109][101/398]	Time 0.582	Data 0.000	Loss 1.0548	
SparseEpoch: [109][201/398]	Time 0.581	Data 0.000	Loss 1.0121	
SparseEpoch: [109][301/398]	Time 0.581	Data 0.000	Loss 1.0942	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.15063688 0.15061008 0.15062422 0.1506194  0.15061244 0.15061519
 0.15062714 0.1506219  0.15060339 0.15059299 0.15059834 0.15061727
 0.15061474 0.15061238 0.15061052 0.15059758 0.15059773 0.15058905
 0.15057109 0.15057053]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.15061405 0.15061995 0.15062689 0.15063961 0.15061974 0.15061681
 0.15060067 0.15060138 0.15059029 0.15059119 0.15059153 0.15060076
 0.15061234 0.15060245 0.15061764 0.15060558 0.15058866 0.15058184
 0.15057819 0.15057837]
[0.5        0.44736842 0.        ]
-----------end of analyzing the loss ratio:75.20651960372925
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6fe9ae0>
---------------------------------
SparseEpoch: [109][1/398]	Time 0.578	Data 0.000	Loss 2.1210	
SparseEpoch: [109][101/398]	Time 0.579	Data 0.000	Loss 1.8502	
SparseEpoch: [109][201/398]	Time 0.580	Data 0.000	Loss 1.7999	
SparseEpoch: [109][301/398]	Time 0.581	Data 0.000	Loss 1.9772	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.7403	
Epoch(adapt):{0} Loss 1.1282	
Epoch(adapt):{0} Loss 0.7712	
Epoch(adapt):{0} Loss 0.9492	
------------------the total time cost:1165.9925563335419
>>>>>meta updating
Epoch: 0109 | TRAIN: 0.4275 0.7048 0.8661 | 0.3557 0.3557 0.1654 | 0.1289 23.8290 18.8489 0.2963 0.5901 0.7202 ||TEST: 1.2011 0.4105 0.6641 | 0.5423 0.5423 0.2117 | 0.1446 25.6095 20.7953 0.2731 0.5434 0.6728 | 116.8343
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.42255217 0.42255408 0.42251463 0.42256139 0.42252378 0.42245438
 0.42248036 0.42248722 0.4224629  0.42245445 0.4224052  0.42230964
 0.42229342 0.42229565 0.422262   0.42225841 0.42224757 0.42227889
 0.42227637 0.42223256]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.42250513 0.42248581 0.42248219 0.42248039 0.42246135 0.42248032
 0.42249965 0.42246138 0.42245835 0.42241896 0.42242664 0.42243306
 0.42244016 0.42240808 0.42241669 0.42240361 0.42239528 0.4223251
 0.42232643 0.42230287]
[0.  0.5 0.5]
-----------end of analyzing the loss ratio:75.27117466926575
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6e94340>
---------------------------------
SparseEpoch: [110][1/398]	Time 0.580	Data 0.000	Loss 1.5564	
SparseEpoch: [110][101/398]	Time 0.582	Data 0.000	Loss 1.1038	
SparseEpoch: [110][201/398]	Time 0.582	Data 0.000	Loss 1.2249	
SparseEpoch: [110][301/398]	Time 0.581	Data 0.000	Loss 0.8063	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.38469598 0.38466154 0.38466217 0.38461748 0.38462009 0.38458169
 0.38457881 0.38466946 0.3846763  0.3846156  0.38459749 0.38462645
 0.3846304  0.38461828 0.38459129 0.38461212 0.38456929 0.38456373
 0.3845323  0.38452456]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.3845767  0.38458642 0.38458889 0.38460634 0.38461824 0.38461626
 0.38462461 0.38457898 0.38460438 0.38457822 0.38455469 0.38457153
 0.3846105  0.38458695 0.38458807 0.38459186 0.38460121 0.38460794
 0.38457375 0.38460214]
[0.5        0.         0.02631579]
-----------end of analyzing the loss ratio:74.97160291671753
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc152d70>
---------------------------------
SparseEpoch: [110][1/398]	Time 0.579	Data 0.000	Loss 0.5034	
SparseEpoch: [110][101/398]	Time 0.580	Data 0.000	Loss 0.3796	
SparseEpoch: [110][201/398]	Time 0.581	Data 0.000	Loss 0.5990	
SparseEpoch: [110][301/398]	Time 0.581	Data 0.000	Loss 0.8562	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.12567646 0.1256623  0.1256481  0.12563032 0.12562659 0.12557535
 0.1256021  0.12558603 0.12557973 0.12556843 0.12554143 0.12552803
 0.12552227 0.12551771 0.12553495 0.12552584 0.12550071 0.12549188
 0.12549238 0.12545211]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.12555249 0.12555247 0.12552119 0.12553268 0.12552325 0.12552904
 0.12552457 0.12550699 0.12553905 0.12553876 0.12554531 0.12554166
 0.12551864 0.12556049 0.12559087 0.12552292 0.12550048 0.125497
 0.12551791 0.12551807]
[0.5        0.39473684 0.        ]
-----------end of analyzing the loss ratio:74.96889662742615
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc047dc0>
---------------------------------
SparseEpoch: [110][1/398]	Time 0.581	Data 0.000	Loss 1.6386	
SparseEpoch: [110][101/398]	Time 0.581	Data 0.000	Loss 2.2896	
SparseEpoch: [110][201/398]	Time 0.581	Data 0.000	Loss 1.3398	
SparseEpoch: [110][301/398]	Time 0.581	Data 0.000	Loss 1.5592	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.0840	
Epoch(adapt):{0} Loss 1.0139	
Epoch(adapt):{0} Loss 0.5174	
Epoch(adapt):{0} Loss 1.0618	
------------------the total time cost:1166.629493713379
>>>>>meta updating
Epoch: 0110 | TRAIN: 0.4160 0.7048 0.8709 | 0.3578 0.3578 0.1654 | 0.1277 23.6953 18.6290 0.2997 0.5932 0.7224 ||TEST: 1.1925 0.4068 0.6657 | 0.5522 0.5522 0.2128 | 0.1443 25.6647 20.8838 0.2671 0.5410 0.6719 | 116.5759
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.37669289 0.3766501  0.37663206 0.37667736 0.37668745 0.37668349
 0.37666699 0.37667849 0.37668385 0.37667768 0.37667118 0.37667853
 0.37670392 0.37664945 0.37670492 0.37675513 0.37668322 0.37669389
 0.37670725 0.37662063]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.37665681 0.37665718 0.37665987 0.37666445 0.37665502 0.37666605
 0.37669117 0.37670126 0.37669351 0.37668538 0.37668788 0.37668906
 0.37668029 0.37667754 0.37668064 0.37668526 0.3766983  0.37669565
 0.37668649 0.37669698]
[0.  0.5 0. ]
-----------end of analyzing the loss ratio:75.33833384513855
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d73244f0>
---------------------------------
SparseEpoch: [111][1/398]	Time 0.583	Data 0.000	Loss 0.6012	
SparseEpoch: [111][101/398]	Time 0.580	Data 0.000	Loss 0.8287	
SparseEpoch: [111][201/398]	Time 0.580	Data 0.000	Loss 0.7648	
SparseEpoch: [111][301/398]	Time 0.580	Data 0.000	Loss 0.8770	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.34408282 0.34406433 0.34394685 0.3439325  0.34384006 0.3438641
 0.3438273  0.3438291  0.34388593 0.34400764 0.34400307 0.34393667
 0.34395014 0.34390111 0.34382897 0.34393835 0.34383386 0.34383419
 0.34371684 0.34354608]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.34398678 0.34398575 0.343986   0.34398273 0.34399378 0.34400051
 0.34400921 0.344012   0.34399472 0.3440057  0.34401664 0.34401584
 0.34399357 0.34399837 0.34399832 0.34400958 0.34400766 0.34400576
 0.34398583 0.34398811]
[0.5 0.  0. ]
-----------end of analyzing the loss ratio:75.16101932525635
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc1a6d40>
---------------------------------
SparseEpoch: [111][1/398]	Time 0.578	Data 0.000	Loss 0.5177	
SparseEpoch: [111][101/398]	Time 0.580	Data 0.000	Loss 0.4421	
SparseEpoch: [111][201/398]	Time 0.580	Data 0.000	Loss 0.6586	
SparseEpoch: [111][301/398]	Time 0.580	Data 0.000	Loss 0.5872	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.14621627 0.1462288  0.14618073 0.14618924 0.14620971 0.14620931
 0.14623482 0.14623528 0.14623571 0.14622092 0.14623508 0.14618717
 0.14617541 0.14608828 0.14612327 0.14613547 0.14614695 0.14604872
 0.14605963 0.14606765]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.14621213 0.14621398 0.14620605 0.14621224 0.14623159 0.14624166
 0.14624361 0.14623048 0.14621927 0.14622664 0.14622886 0.14625925
 0.14626918 0.1462598  0.14624528 0.14621761 0.14621216 0.14619429
 0.14616858 0.14618484]
[0.39473684 0.44736842 0.        ]
-----------end of analyzing the loss ratio:75.24271774291992
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x74460961c6a0>
---------------------------------
SparseEpoch: [111][1/398]	Time 0.578	Data 0.000	Loss 1.1935	
SparseEpoch: [111][101/398]	Time 0.581	Data 0.000	Loss 1.6208	
SparseEpoch: [111][201/398]	Time 0.581	Data 0.000	Loss 1.8709	
SparseEpoch: [111][301/398]	Time 0.581	Data 0.000	Loss 1.6312	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.1454	
Epoch(adapt):{0} Loss 0.8134	
Epoch(adapt):{0} Loss 0.7032	
Epoch(adapt):{0} Loss 1.5869	
------------------the total time cost:1165.5152218341827
>>>>>meta updating
Epoch: 0111 | TRAIN: 0.4009 0.7164 0.8736 | 0.3515 0.3515 0.1639 | 0.1290 23.8617 18.9367 0.2967 0.5862 0.7170 ||TEST: 1.1820 0.4091 0.6660 | 0.5445 0.5445 0.2129 | 0.1462 25.8205 21.0954 0.2695 0.5357 0.6657 | 116.2396
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.29384398 0.29380358 0.2937845  0.29378315 0.29373781 0.29368197
 0.2937019  0.29369751 0.29371808 0.29370837 0.29367784 0.29370324
 0.29368104 0.29369035 0.29371945 0.29370669 0.29370338 0.29361997
 0.29362648 0.29354497]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.29367772 0.29369425 0.29369406 0.29368637 0.29369087 0.2936926
 0.29371244 0.29370857 0.29369995 0.29369399 0.29368496 0.29370097
 0.29371864 0.29370908 0.29369152 0.29369042 0.29367897 0.29367358
 0.29368164 0.29370568]
[0.         0.5        0.39473684]
-----------end of analyzing the loss ratio:75.01912140846252
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444dc153ee0>
---------------------------------
SparseEpoch: [112][1/398]	Time 0.578	Data 0.000	Loss 0.8737	
SparseEpoch: [112][101/398]	Time 0.581	Data 0.000	Loss 1.1263	
SparseEpoch: [112][201/398]	Time 0.581	Data 0.000	Loss 1.0295	
SparseEpoch: [112][301/398]	Time 0.581	Data 0.000	Loss 0.9161	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.33964248 0.33957566 0.33957885 0.33955132 0.33950492 0.33952636
 0.33953602 0.33953469 0.33941188 0.33931098 0.33931566 0.3392461
 0.33920853 0.33921122 0.33913339 0.33910771 0.3390744  0.33903239
 0.33904308 0.33899057]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.33933591 0.33933453 0.33931768 0.33930808 0.33930918 0.3393187
 0.33930333 0.33932049 0.33932876 0.33935289 0.33934085 0.33931298
 0.3393583  0.33934206 0.33933211 0.33936462 0.33936804 0.33936254
 0.33935498 0.33932437]
[0.5 0.  0. ]
-----------end of analyzing the loss ratio:75.20701289176941
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7446096ea3b0>
---------------------------------
SparseEpoch: [112][1/398]	Time 0.584	Data 0.000	Loss 0.5642	
SparseEpoch: [112][101/398]	Time 0.582	Data 0.000	Loss 0.4265	
SparseEpoch: [112][201/398]	Time 0.582	Data 0.000	Loss 0.3771	
SparseEpoch: [112][301/398]	Time 0.581	Data 0.000	Loss 0.4627	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11860651 0.11857846 0.11861656 0.11862978 0.11866111 0.11864395
 0.11859371 0.11855008 0.11854756 0.11854835 0.11852405 0.11854182
 0.11855527 0.11849876 0.1185122  0.11845735 0.11848539 0.1184729
 0.11845648 0.11846408]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11855829 0.11855374 0.11855108 0.11855941 0.1185605  0.11856936
 0.11857059 0.11855451 0.11854224 0.11853768 0.11852863 0.11851836
 0.11851981 0.1185261  0.11852595 0.11854283 0.11854628 0.11855395
 0.11855637 0.11856368]
[0.44736842 0.07894737 0.        ]
-----------end of analyzing the loss ratio:75.07178688049316
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d71f1d20>
---------------------------------
SparseEpoch: [112][1/398]	Time 0.586	Data 0.000	Loss 1.0626	
SparseEpoch: [112][101/398]	Time 0.581	Data 0.000	Loss 2.0244	
SparseEpoch: [112][201/398]	Time 0.581	Data 0.000	Loss 2.1333	
SparseEpoch: [112][301/398]	Time 0.581	Data 0.000	Loss 1.6767	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.2016	
Epoch(adapt):{0} Loss 0.8116	
Epoch(adapt):{0} Loss 1.4005	
Epoch(adapt):{0} Loss 0.8454	
------------------the total time cost:1166.1051619052887
>>>>>meta updating
Epoch: 0112 | TRAIN: 0.4109 0.7024 0.8688 | 0.3498 0.3498 0.1585 | 0.1274 23.6499 18.6430 0.3016 0.5938 0.7229 ||TEST: 1.2045 0.4047 0.6671 | 0.5354 0.5354 0.2065 | 0.1439 25.5751 20.7774 0.2715 0.5430 0.6729 | 116.7034
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.37980249 0.37987216 0.37984272 0.37987088 0.37995755 0.37998854
 0.37999963 0.37991659 0.37982287 0.37973614 0.37961279 0.37947794
 0.37945404 0.37937303 0.37931727 0.37918897 0.37922046 0.37920827
 0.37924332 0.37916601]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.37953685 0.37954372 0.37955841 0.37951687 0.3795313  0.37955409
 0.37958466 0.3795941  0.37969589 0.37970361 0.37971911 0.37970947
 0.37974533 0.37974389 0.37974011 0.37974528 0.37976891 0.37977263
 0.37976976 0.37975354]
[0.  0.5 0. ]
-----------end of analyzing the loss ratio:75.2345118522644
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6d064a0>
---------------------------------
SparseEpoch: [113][1/398]	Time 0.580	Data 0.000	Loss 0.4852	
SparseEpoch: [113][101/398]	Time 0.580	Data 0.000	Loss 0.6643	
SparseEpoch: [113][201/398]	Time 0.580	Data 0.000	Loss 0.8469	
SparseEpoch: [113][301/398]	Time 0.580	Data 0.000	Loss 0.5172	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.35262674 0.3526685  0.35261131 0.35257408 0.35260278 0.35259313
 0.35260377 0.35261856 0.3525276  0.35254592 0.35264249 0.35264149
 0.35258131 0.35250398 0.35253804 0.35247393 0.35246961 0.3525085
 0.35247297 0.35249557]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.35261507 0.35261659 0.35260756 0.35261427 0.35261172 0.35261545
 0.35260892 0.35261162 0.3526227  0.35263876 0.35262639 0.3526265
 0.3526283  0.35261257 0.35260911 0.3526013  0.3525974  0.35259206
 0.35259006 0.35258796]
[0.34210526 0.         0.5       ]
-----------end of analyzing the loss ratio:75.07160711288452
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6fd7370>
---------------------------------
SparseEpoch: [113][1/398]	Time 0.588	Data 0.000	Loss 1.1315	
SparseEpoch: [113][101/398]	Time 0.581	Data 0.000	Loss 1.2017	
SparseEpoch: [113][201/398]	Time 0.581	Data 0.000	Loss 0.9574	
SparseEpoch: [113][301/398]	Time 0.581	Data 0.000	Loss 1.0564	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11371911 0.11370441 0.11370075 0.11369901 0.11370078 0.11370617
 0.11370896 0.11371509 0.11371983 0.11371412 0.11371279 0.1137128
 0.11370603 0.11370361 0.11370378 0.11370382 0.11370273 0.11370616
 0.11371139 0.11370874]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11370881 0.11371924 0.11370473 0.11370383 0.11371292 0.11370659
 0.11369451 0.11370743 0.11371522 0.11370844 0.11371006 0.11371037
 0.11370553 0.11369971 0.11370822 0.11371017 0.11369573 0.11368914
 0.11369739 0.11368844]
[0.  0.5 0. ]
-----------end of analyzing the loss ratio:75.04101848602295
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d7193640>
---------------------------------
SparseEpoch: [113][1/398]	Time 0.578	Data 0.000	Loss 1.3322	
SparseEpoch: [113][101/398]	Time 0.580	Data 0.000	Loss 1.1540	
SparseEpoch: [113][201/398]	Time 0.580	Data 0.000	Loss 2.3734	
SparseEpoch: [113][301/398]	Time 0.581	Data 0.000	Loss 1.3478	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.5521	
Epoch(adapt):{0} Loss 0.6062	
Epoch(adapt):{0} Loss 0.9487	
Epoch(adapt):{0} Loss 0.8744	
------------------the total time cost:1165.0394032001495
>>>>>meta updating
Epoch: 0113 | TRAIN: 0.4120 0.7057 0.8688 | 0.3350 0.3350 0.1566 | 0.1258 23.4574 18.5138 0.3058 0.5975 0.7268 ||TEST: 1.2418 0.4071 0.6638 | 0.5299 0.5299 0.2099 | 0.1435 25.4913 20.6940 0.2756 0.5449 0.6741 | 116.2676
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.36453657 0.36457675 0.36460082 0.36455289 0.36450765 0.3644506
 0.36450789 0.36453147 0.36452282 0.36455324 0.36461761 0.36463003
 0.36463998 0.36479708 0.36474088 0.36474939 0.36475749 0.36470966
 0.36467869 0.36479338]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.36458914 0.36459631 0.36458815 0.36457851 0.36457731 0.36456366
 0.36456707 0.364555   0.36457638 0.36457949 0.36457467 0.36459766
 0.3645975  0.36458795 0.36461431 0.36460147 0.36459983 0.36459302
 0.36459427 0.3645819 ]
[0. 0. 0.]
-----------end of analyzing the loss ratio:75.16205358505249
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6e977c0>
---------------------------------
SparseEpoch: [114][1/398]	Time 0.577	Data 0.000	Loss 0.4504	
SparseEpoch: [114][101/398]	Time 0.580	Data 0.000	Loss 0.6237	
SparseEpoch: [114][201/398]	Time 0.580	Data 0.000	Loss 1.0393	
SparseEpoch: [114][301/398]	Time 0.580	Data 0.000	Loss 0.4372	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.61594858 0.61589809 0.61588244 0.61582329 0.61577772 0.61571758
 0.61574451 0.61572742 0.61566802 0.61566326 0.61577177 0.61572085
 0.61579328 0.61571316 0.61575801 0.61576368 0.61574937 0.61562201
 0.61553346 0.61557961]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.61564693 0.61563829 0.6156413  0.61563348 0.61563158 0.61563337
 0.61563314 0.61563633 0.61564166 0.61563664 0.61564097 0.61563925
 0.61564841 0.61565355 0.61565217 0.61565401 0.61564907 0.61565818
 0.61565326 0.615657  ]
[0.44736842 0.         0.        ]
-----------end of analyzing the loss ratio:75.16635036468506
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d731e1a0>
---------------------------------
SparseEpoch: [114][1/398]	Time 0.578	Data 0.000	Loss 0.4672	
SparseEpoch: [114][101/398]	Time 0.580	Data 0.000	Loss 0.6750	
SparseEpoch: [114][201/398]	Time 0.580	Data 0.000	Loss 0.5625	
SparseEpoch: [114][301/398]	Time 0.580	Data 0.000	Loss 0.5740	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.13200096 0.13199665 0.13203449 0.13200915 0.13202145 0.13198457
 0.13196952 0.13195344 0.13195636 0.13196796 0.13197273 0.13199351
 0.13202479 0.13202386 0.13203769 0.13203409 0.13199884 0.13197191
 0.13198054 0.13193659]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.13200417 0.13200238 0.13199496 0.13199348 0.13199174 0.13197873
 0.13197151 0.13197045 0.13197596 0.13196861 0.13196985 0.13197459
 0.13197705 0.13198096 0.13198988 0.13199121 0.13200138 0.13199215
 0.13198203 0.13197985]
[0.5 0.  0. ]
-----------end of analyzing the loss ratio:75.0767776966095
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc0ec2e0>
---------------------------------
SparseEpoch: [114][1/398]	Time 0.580	Data 0.000	Loss 1.8570	
SparseEpoch: [114][101/398]	Time 0.581	Data 0.000	Loss 1.6671	
SparseEpoch: [114][201/398]	Time 0.581	Data 0.000	Loss 1.1607	
SparseEpoch: [114][301/398]	Time 0.581	Data 0.000	Loss 1.7074	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.7876	
Epoch(adapt):{0} Loss 0.8576	
Epoch(adapt):{0} Loss 0.7163	
Epoch(adapt):{0} Loss 1.3157	
------------------the total time cost:1166.17862534523
>>>>>meta updating
Epoch: 0114 | TRAIN: 0.4006 0.7203 0.8761 | 0.3406 0.3406 0.1640 | 0.1262 23.5187 18.5194 0.3042 0.5951 0.7246 ||TEST: 1.2133 0.4131 0.6686 | 0.5311 0.5311 0.2121 | 0.1449 25.6679 20.9320 0.2727 0.5391 0.6689 | 116.6416
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.36084384 0.36085672 0.36082895 0.36081944 0.36082359 0.36085711
 0.36078958 0.36076128 0.36070656 0.36075361 0.36083231 0.36073992
 0.36069889 0.36067682 0.36066301 0.36071972 0.36057227 0.36057533
 0.360603   0.36062616]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.36075241 0.36076009 0.36074142 0.36075238 0.36074899 0.36075145
 0.3607425  0.36074136 0.36078568 0.36079164 0.36085091 0.36083667
 0.3608434  0.3608211  0.36079185 0.36078712 0.3607916  0.36080735
 0.3608316  0.3608141 ]
[0.         0.34210526 0.        ]
-----------end of analyzing the loss ratio:75.0991563796997
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc045ea0>
---------------------------------
SparseEpoch: [115][1/398]	Time 0.578	Data 0.000	Loss 0.4253	
SparseEpoch: [115][101/398]	Time 0.581	Data 0.000	Loss 0.4320	
SparseEpoch: [115][201/398]	Time 0.581	Data 0.000	Loss 0.5751	
SparseEpoch: [115][301/398]	Time 0.580	Data 0.000	Loss 0.8532	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.37987907 0.37990116 0.37986456 0.37983446 0.37971175 0.37970132
 0.37961388 0.37958236 0.37960022 0.37956267 0.37953622 0.37953744
 0.37953158 0.37952016 0.3795126  0.37950552 0.379478   0.37946795
 0.37939793 0.37927724]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.37958086 0.37957459 0.37957955 0.37959869 0.3796131  0.37960257
 0.37958227 0.37958941 0.37955222 0.37953928 0.37953076 0.37955856
 0.3795669  0.37956026 0.37953684 0.37950825 0.37951294 0.3795441
 0.37953057 0.37952424]
[0.5        0.         0.28947368]
-----------end of analyzing the loss ratio:75.21668314933777
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d72b8460>
---------------------------------
SparseEpoch: [115][1/398]	Time 0.579	Data 0.000	Loss 0.9527	
SparseEpoch: [115][101/398]	Time 0.581	Data 0.000	Loss 0.7695	
SparseEpoch: [115][201/398]	Time 0.581	Data 0.000	Loss 1.2974	
SparseEpoch: [115][301/398]	Time 0.581	Data 0.000	Loss 0.9271	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11843159 0.11842687 0.11842974 0.11839962 0.11839898 0.1183897
 0.1183845  0.11838018 0.1183784  0.11835715 0.11832932 0.11833202
 0.11830366 0.11828259 0.11827601 0.11828484 0.11826954 0.11826321
 0.11824951 0.11827919]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.118483   0.11845085 0.11840554 0.11839272 0.11838151 0.11838951
 0.11838132 0.11839544 0.11837781 0.11835472 0.1183327  0.11832567
 0.11830812 0.11827151 0.11826664 0.11826952 0.11828282 0.11826885
 0.11825888 0.11826164]
[0.44736842 0.44736842 0.        ]
-----------end of analyzing the loss ratio:75.0977611541748
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6f53a90>
---------------------------------
SparseEpoch: [115][1/398]	Time 0.583	Data 0.000	Loss 2.1797	
SparseEpoch: [115][101/398]	Time 0.580	Data 0.000	Loss 1.7879	
SparseEpoch: [115][201/398]	Time 0.580	Data 0.000	Loss 1.2658	
SparseEpoch: [115][301/398]	Time 0.580	Data 0.000	Loss 1.3769	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.8736	
Epoch(adapt):{0} Loss 0.6605	
Epoch(adapt):{0} Loss 1.0382	
Epoch(adapt):{0} Loss 1.2220	
------------------the total time cost:1164.8974783420563
>>>>>meta updating
Epoch: 0115 | TRAIN: 0.3871 0.7152 0.8782 | 0.3421 0.3421 0.1569 | 0.1261 23.6090 18.6989 0.2967 0.5933 0.7243 ||TEST: 1.1849 0.4059 0.6685 | 0.5363 0.5363 0.2121 | 0.1455 25.8294 21.1125 0.2643 0.5354 0.6671 | 116.8505
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.41719105 0.41711372 0.41714272 0.41716751 0.41715623 0.41719586
 0.41719425 0.41720258 0.41719662 0.41719868 0.41719327 0.41724817
 0.4172486  0.41726689 0.4172605  0.4172728  0.41727432 0.41730405
 0.41727567 0.41726307]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.41721263 0.41719708 0.41720712 0.41720733 0.41719144 0.41719012
 0.41715687 0.41717224 0.41722098 0.41721579 0.41721238 0.41721677
 0.41721976 0.41720804 0.41719628 0.41719399 0.41720418 0.41720959
 0.41721289 0.4172066 ]
[0. 0. 0.]
-----------end of analyzing the loss ratio:75.15909552574158
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc41ca60>
---------------------------------
SparseEpoch: [116][1/398]	Time 0.578	Data 0.000	Loss 0.3458	
SparseEpoch: [116][101/398]	Time 0.580	Data 0.000	Loss 0.4017	
SparseEpoch: [116][201/398]	Time 0.579	Data 0.000	Loss 0.2896	
SparseEpoch: [116][301/398]	Time 0.579	Data 0.000	Loss 0.4496	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.59187365 0.59196681 0.59194668 0.59189852 0.59183465 0.59184386
 0.59177799 0.59184072 0.59186459 0.59187985 0.59183266 0.59178874
 0.5917756  0.59170673 0.59169363 0.59172451 0.59171273 0.59169135
 0.59171084 0.59156458]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.59187638 0.59189253 0.59189579 0.59187727 0.59189295 0.5918959
 0.59190915 0.59190508 0.59188784 0.59189012 0.5918588  0.5918477
 0.59182369 0.5918239  0.59182096 0.59182104 0.59180834 0.59180623
 0.59181454 0.59180799]
[0.5        0.         0.39473684]
-----------end of analyzing the loss ratio:75.05473375320435
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc11e740>
---------------------------------
SparseEpoch: [116][1/398]	Time 0.578	Data 0.000	Loss 1.1071	
SparseEpoch: [116][101/398]	Time 0.580	Data 0.000	Loss 0.8965	
SparseEpoch: [116][201/398]	Time 0.581	Data 0.000	Loss 1.7982	
SparseEpoch: [116][301/398]	Time 0.581	Data 0.000	Loss 1.0203	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.12565044 0.12564496 0.1256323  0.12564793 0.12562466 0.12559745
 0.12559773 0.12554064 0.1255483  0.12554655 0.1255361  0.12553941
 0.12553667 0.12557513 0.12556117 0.12557307 0.12554176 0.12557353
 0.12557907 0.12555975]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.12555733 0.12555257 0.12555231 0.12554941 0.12555512 0.12555764
 0.1255527  0.12554352 0.12554579 0.12554137 0.12552344 0.12552901
 0.12551499 0.12550895 0.12550394 0.12551051 0.12550917 0.1255166
 0.12551965 0.12550686]
[0.02631579 0.23684211 0.        ]
-----------end of analyzing the loss ratio:75.0776596069336
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6cda140>
---------------------------------
SparseEpoch: [116][1/398]	Time 0.579	Data 0.000	Loss 1.1022	
SparseEpoch: [116][101/398]	Time 0.580	Data 0.000	Loss 1.1422	
SparseEpoch: [116][201/398]	Time 0.580	Data 0.000	Loss 1.2638	
SparseEpoch: [116][301/398]	Time 0.580	Data 0.000	Loss 1.6899	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.9408	
Epoch(adapt):{0} Loss 0.6890	
Epoch(adapt):{0} Loss 0.9390	
Epoch(adapt):{0} Loss 0.7507	
------------------the total time cost:1165.1260170936584
>>>>>meta updating
Epoch: 0116 | TRAIN: 0.3961 0.7167 0.8746 | 0.3481 0.3481 0.1618 | 0.1252 23.4026 18.4179 0.3041 0.6002 0.7291 ||TEST: 1.2348 0.4122 0.6649 | 0.5433 0.5433 0.2088 | 0.1436 25.5382 20.8025 0.2739 0.5418 0.6729 | 116.6898
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.37982993 0.37983553 0.37983879 0.37983859 0.37990599 0.37985559
 0.3798526  0.37984174 0.37981127 0.379838   0.37988348 0.37988805
 0.37991209 0.37990092 0.37987618 0.37989583 0.37987848 0.37984516
 0.37983665 0.37983599]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.37991877 0.37990317 0.379893   0.379907   0.37989618 0.37989596
 0.37987504 0.37988051 0.3798559  0.37983492 0.37984715 0.37982302
 0.37981238 0.37980089 0.37979159 0.37982251 0.37980967 0.37982484
 0.37980996 0.37980755]
[0.         0.         0.23684211]
-----------end of analyzing the loss ratio:75.10974502563477
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc534d90>
---------------------------------
SparseEpoch: [117][1/398]	Time 0.578	Data 0.000	Loss 0.4203	
SparseEpoch: [117][101/398]	Time 0.581	Data 0.000	Loss 0.5648	
SparseEpoch: [117][201/398]	Time 0.581	Data 0.000	Loss 1.0571	
SparseEpoch: [117][301/398]	Time 0.581	Data 0.000	Loss 1.4624	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.29932648 0.29936107 0.29936965 0.29931942 0.29935536 0.2993208
 0.29932956 0.29930932 0.29933985 0.29925438 0.29923402 0.29925377
 0.29923888 0.29923775 0.29931745 0.2992607  0.2992468  0.29927014
 0.29924252 0.29925517]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.29930661 0.29929873 0.29926831 0.29929736 0.29924936 0.29925358
 0.29924956 0.2992318  0.29923167 0.29924338 0.29921926 0.29923243
 0.29926925 0.29923066 0.29923355 0.29923277 0.29922917 0.29923221
 0.29924363 0.29926769]
[0.02631579 0.         0.02631579]
-----------end of analyzing the loss ratio:75.15744662284851
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc3257e0>
---------------------------------
SparseEpoch: [117][1/398]	Time 0.586	Data 0.000	Loss 0.2342	
SparseEpoch: [117][101/398]	Time 0.581	Data 0.000	Loss 0.6958	
SparseEpoch: [117][201/398]	Time 0.582	Data 0.000	Loss 0.3965	
SparseEpoch: [117][301/398]	Time 0.581	Data 0.000	Loss 0.4229	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11893576 0.11893322 0.11896539 0.11895061 0.11891755 0.1189119
 0.11885857 0.11885853 0.11879296 0.11875824 0.11873753 0.1186868
 0.11865107 0.11867211 0.11866985 0.11867691 0.11863721 0.11861849
 0.11862718 0.11862171]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11879952 0.11878833 0.11875983 0.11876536 0.11876246 0.11877154
 0.11876985 0.11875724 0.11874579 0.11875118 0.11873894 0.11873434
 0.11872413 0.1187079  0.11870298 0.11871346 0.11871023 0.1187031
 0.11870011 0.11871566]
[0.39473684 0.44736842 0.        ]
-----------end of analyzing the loss ratio:75.22235155105591
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc389d80>
---------------------------------
SparseEpoch: [117][1/398]	Time 0.580	Data 0.000	Loss 1.5321	
SparseEpoch: [117][101/398]	Time 0.580	Data 0.000	Loss 1.6062	
SparseEpoch: [117][201/398]	Time 0.580	Data 0.000	Loss 1.4494	
SparseEpoch: [117][301/398]	Time 0.580	Data 0.000	Loss 2.2692	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.8227	
Epoch(adapt):{0} Loss 0.9788	
Epoch(adapt):{0} Loss 0.7842	
Epoch(adapt):{0} Loss 0.6522	
------------------the total time cost:1166.5230288505554
>>>>>meta updating
Epoch: 0117 | TRAIN: 0.3914 0.7189 0.8755 | 0.3415 0.3415 0.1676 | 0.1230 23.0443 17.8849 0.3163 0.6118 0.7368 ||TEST: 1.3034 0.4111 0.6648 | 0.5330 0.5330 0.2135 | 0.1427 25.3237 20.3316 0.2800 0.5524 0.6805 | 116.9946
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.441312   0.44143728 0.44141821 0.44140981 0.44139723 0.44139596
 0.44142853 0.44139291 0.441484   0.44145627 0.44136209 0.44133686
 0.44135912 0.44141437 0.44135323 0.44136038 0.44137864 0.44133329
 0.44128545 0.44122778]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.44143139 0.44141814 0.44143131 0.44150212 0.44147643 0.44148101
 0.44144692 0.44150015 0.44146424 0.44151435 0.44144854 0.44135349
 0.44138387 0.44141532 0.44138907 0.44138051 0.44140877 0.4413974
 0.44140587 0.44136769]
[0.         0.5        0.07894737]
-----------end of analyzing the loss ratio:75.25572943687439
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6e94040>
---------------------------------
SparseEpoch: [118][1/398]	Time 0.585	Data 0.000	Loss 0.6069	
SparseEpoch: [118][101/398]	Time 0.581	Data 0.000	Loss 0.5565	
SparseEpoch: [118][201/398]	Time 0.580	Data 0.000	Loss 0.7561	
SparseEpoch: [118][301/398]	Time 0.581	Data 0.000	Loss 0.8351	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.40660851 0.40593624 0.40555826 0.40509022 0.40455863 0.40420154
 0.40381982 0.40346206 0.40317888 0.40285163 0.40244895 0.40208873
 0.40175631 0.40137423 0.40107413 0.40081817 0.40048185 0.40022385
 0.39982066 0.39948822]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.4027833  0.40278724 0.40281319 0.40280913 0.40277805 0.40275325
 0.40276225 0.40277078 0.40275813 0.40272098 0.40271937 0.40269346
 0.40266925 0.40268105 0.40262293 0.40262357 0.40259521 0.40258447
 0.40256409 0.40254731]
[0.5 0.  0.5]
-----------end of analyzing the loss ratio:75.19932222366333
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6aa0a60>
---------------------------------
SparseEpoch: [118][1/398]	Time 0.579	Data 0.000	Loss 0.8448	
SparseEpoch: [118][101/398]	Time 0.580	Data 0.000	Loss 1.4057	
SparseEpoch: [118][201/398]	Time 0.581	Data 0.000	Loss 1.4864	
SparseEpoch: [118][301/398]	Time 0.581	Data 0.000	Loss 1.5915	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.12650519 0.12648982 0.12649548 0.12651536 0.1264679  0.12646847
 0.12645986 0.12646286 0.12644894 0.12645677 0.12645586 0.1264614
 0.12647415 0.12647177 0.12649941 0.12647842 0.12646745 0.12646948
 0.12646056 0.12647697]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.12655914 0.12655073 0.12652674 0.12649854 0.12650458 0.12648217
 0.12648333 0.12645107 0.12646117 0.12645636 0.12645347 0.12646734
 0.12651019 0.12646961 0.12645806 0.12648715 0.12645382 0.12644701
 0.12643418 0.12643691]
[0.         0.44736842 0.        ]
-----------end of analyzing the loss ratio:75.34056830406189
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc41fe50>
---------------------------------
SparseEpoch: [118][1/398]	Time 0.578	Data 0.000	Loss 1.7155	
SparseEpoch: [118][101/398]	Time 0.581	Data 0.000	Loss 2.0758	
SparseEpoch: [118][201/398]	Time 0.581	Data 0.000	Loss 1.1690	
SparseEpoch: [118][301/398]	Time 0.581	Data 0.000	Loss 1.3966	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.6952	
Epoch(adapt):{0} Loss 0.6601	
Epoch(adapt):{0} Loss 0.8174	
Epoch(adapt):{0} Loss 0.6379	
------------------the total time cost:1167.1248800754547
>>>>>meta updating
Epoch: 0118 | TRAIN: 0.3866 0.7267 0.8796 | 0.3270 0.3270 0.1532 | 0.1223 22.9755 17.8009 0.3176 0.6140 0.7380 ||TEST: 1.2372 0.4112 0.6648 | 0.5348 0.5348 0.2134 | 0.1424 25.2875 20.3023 0.2814 0.5532 0.6806 | 116.4093
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.35384179 0.35386617 0.35391797 0.35398367 0.3539259  0.35393832
 0.35390764 0.35382545 0.35385239 0.35385253 0.35390223 0.35395145
 0.35395249 0.3539346  0.3539981  0.35394755 0.35394431 0.35399826
 0.35396037 0.35395994]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.35394672 0.35394576 0.35391178 0.35391578 0.35391736 0.35391568
 0.35390828 0.35390485 0.35388169 0.35387178 0.35386874 0.35387167
 0.35387281 0.35388269 0.35387277 0.35387738 0.35387562 0.35387388
 0.353844   0.3538526 ]
[0.         0.         0.44736842]
-----------end of analyzing the loss ratio:75.10181331634521
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc047790>
---------------------------------
SparseEpoch: [119][1/398]	Time 0.578	Data 0.000	Loss 0.7118	
SparseEpoch: [119][101/398]	Time 0.580	Data 0.000	Loss 0.8347	
SparseEpoch: [119][201/398]	Time 0.580	Data 0.000	Loss 0.7411	
SparseEpoch: [119][301/398]	Time 0.579	Data 0.000	Loss 1.3294	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.37756336 0.37755268 0.37746867 0.37737086 0.37736987 0.3773105
 0.37719145 0.37711884 0.3771693  0.37720987 0.37721997 0.37726093
 0.37726205 0.37720609 0.37724246 0.37726977 0.37731041 0.3772769
 0.37722465 0.37719258]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.37721167 0.377223   0.37723512 0.37724909 0.37723291 0.37719044
 0.37720914 0.3772034  0.37720773 0.37724489 0.37723224 0.37721858
 0.37720824 0.3772122  0.37721798 0.37723575 0.37720696 0.37721091
 0.37719468 0.37717114]
[0.  0.  0.5]
-----------end of analyzing the loss ratio:75.09621858596802
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc12d780>
---------------------------------
SparseEpoch: [119][1/398]	Time 0.578	Data 0.000	Loss 0.9047	
SparseEpoch: [119][101/398]	Time 0.580	Data 0.000	Loss 0.8383	
SparseEpoch: [119][201/398]	Time 0.580	Data 0.000	Loss 0.8031	
SparseEpoch: [119][301/398]	Time 0.580	Data 0.000	Loss 0.9417	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.1169875  0.11700654 0.11700768 0.11699907 0.11698489 0.116996
 0.11700931 0.11702077 0.1170153  0.11701717 0.11701871 0.1169963
 0.11698816 0.11699357 0.11697679 0.11695811 0.1169454  0.11692752
 0.1169081  0.11690189]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.1169076  0.11693203 0.11694581 0.1169469  0.11696526 0.11698105
 0.11699354 0.11700361 0.11701593 0.11700832 0.11701598 0.11702058
 0.11699099 0.11698041 0.11697174 0.11697521 0.11696118 0.11696482
 0.11697094 0.11698946]
[0.5 0.  0. ]
-----------end of analyzing the loss ratio:75.1931700706482
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7446096c74f0>
---------------------------------
SparseEpoch: [119][1/398]	Time 0.586	Data 0.000	Loss 0.8858	
SparseEpoch: [119][101/398]	Time 0.580	Data 0.000	Loss 0.8463	
SparseEpoch: [119][201/398]	Time 0.580	Data 0.000	Loss 2.3025	
SparseEpoch: [119][301/398]	Time 0.580	Data 0.000	Loss 1.6025	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.8717	
Epoch(adapt):{0} Loss 1.0272	
Epoch(adapt):{0} Loss 1.3158	
Epoch(adapt):{0} Loss 0.5699	
------------------the total time cost:1164.7959463596344
>>>>>meta updating
Epoch: 0119 | TRAIN: 0.3840 0.7315 0.8804 | 0.3501 0.3501 0.1573 | 0.1227 23.1404 18.1997 0.3085 0.6067 0.7347 ||TEST: 1.1814 0.4150 0.6644 | 0.5505 0.5505 0.2112 | 0.1424 25.3965 20.5537 0.2755 0.5478 0.6776 | 116.8696
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.35964857 0.35968103 0.35969172 0.35970015 0.35966717 0.35965288
 0.35965954 0.35963805 0.35959204 0.35955848 0.35954741 0.3595953
 0.35954788 0.35956815 0.35959069 0.35957787 0.35964143 0.35963652
 0.35965267 0.35963675]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.35956251 0.35956202 0.35957398 0.35956817 0.35955617 0.3595589
 0.35955331 0.35955565 0.35955316 0.35958229 0.359563   0.35957613
 0.3595594  0.35956252 0.35954412 0.35954862 0.35955656 0.35957279
 0.35957346 0.35957864]
[0.         0.02631579 0.23684211]
-----------end of analyzing the loss ratio:75.31742215156555
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc0bcbb0>
---------------------------------
SparseEpoch: [120][1/398]	Time 0.578	Data 0.000	Loss 1.0132	
SparseEpoch: [120][101/398]	Time 0.580	Data 0.000	Loss 0.7976	
SparseEpoch: [120][201/398]	Time 0.581	Data 0.000	Loss 0.7910	
SparseEpoch: [120][301/398]	Time 0.581	Data 0.000	Loss 0.5498	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.38019226 0.38022029 0.38020867 0.38025204 0.38025706 0.38026502
 0.38026004 0.38026716 0.38025331 0.38021408 0.38022886 0.38019792
 0.38019277 0.38018213 0.38019879 0.38020223 0.38021236 0.38021635
 0.38020518 0.3801946 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.38022777 0.38022513 0.38023352 0.38023748 0.38024778 0.38024263
 0.38023453 0.38023532 0.38023396 0.38023447 0.38022603 0.38021392
 0.38020946 0.38022308 0.38023932 0.38024911 0.38024061 0.38024326
 0.38023753 0.38023698]
[0.18421053 0.         0.13157895]
-----------end of analyzing the loss ratio:75.28632020950317
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x74460925e890>
---------------------------------
SparseEpoch: [120][1/398]	Time 0.580	Data 0.000	Loss 0.5452	
SparseEpoch: [120][101/398]	Time 0.581	Data 0.000	Loss 0.7224	
SparseEpoch: [120][201/398]	Time 0.581	Data 0.000	Loss 0.6589	
SparseEpoch: [120][301/398]	Time 0.581	Data 0.000	Loss 0.5743	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11569071 0.11565046 0.11562399 0.11560148 0.11558394 0.11557695
 0.11553404 0.115543   0.11553962 0.11551141 0.11547921 0.11545812
 0.11543722 0.11544869 0.11544361 0.11544235 0.11541747 0.11541464
 0.11537151 0.1153539 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11555403 0.11554063 0.1155345  0.11553683 0.11553352 0.11551899
 0.11551564 0.11550649 0.11551053 0.11550515 0.1154856  0.11549056
 0.1154696  0.11546947 0.11546648 0.11545036 0.11544126 0.11544198
 0.11543898 0.11542308]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:75.37359881401062
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6d90c10>
---------------------------------
SparseEpoch: [120][1/398]	Time 0.579	Data 0.000	Loss 1.9136	
SparseEpoch: [120][101/398]	Time 0.581	Data 0.000	Loss 2.1645	
SparseEpoch: [120][201/398]	Time 0.581	Data 0.000	Loss 1.8158	
SparseEpoch: [120][301/398]	Time 0.581	Data 0.000	Loss 1.3354	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.5544	
Epoch(adapt):{0} Loss 0.7387	
Epoch(adapt):{0} Loss 0.7215	
Epoch(adapt):{0} Loss 0.6935	
------------------the total time cost:1166.3942680358887
>>>>>meta updating
Epoch: 0120 | TRAIN: 0.3752 0.7360 0.8822 | 0.3309 0.3309 0.1651 | 0.1220 22.9437 17.7848 0.3172 0.6153 0.7400 ||TEST: 1.2832 0.4118 0.6630 | 0.5265 0.5265 0.2142 | 0.1413 25.1701 20.1482 0.2835 0.5558 0.6832 | 116.6520
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.31165185 0.31164252 0.31165402 0.31166804 0.31160121 0.31166188
 0.31165359 0.311613   0.31160052 0.31161996 0.31163031 0.31171417
 0.31173788 0.31179682 0.31181297 0.31181918 0.31186319 0.31179447
 0.31186628 0.31197833]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.31187095 0.311711   0.31163427 0.31163781 0.31164084 0.31165622
 0.31164851 0.31164508 0.31162579 0.31160782 0.31160634 0.31161317
 0.31160865 0.31160254 0.31160316 0.3116265  0.31163223 0.3116224
 0.31163004 0.31159783]
[0.  0.  0.5]
-----------end of analyzing the loss ratio:75.30494451522827
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc024fd0>
---------------------------------
SparseEpoch: [121][1/398]	Time 0.579	Data 0.000	Loss 0.9653	
SparseEpoch: [121][101/398]	Time 0.581	Data 0.000	Loss 0.9685	
SparseEpoch: [121][201/398]	Time 0.581	Data 0.000	Loss 1.1614	
SparseEpoch: [121][301/398]	Time 0.581	Data 0.000	Loss 1.4512	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.50342969 0.50341754 0.50335645 0.50328643 0.5033489  0.50328605
 0.50334557 0.50327544 0.50316036 0.50315341 0.50315272 0.50313975
 0.50312634 0.50313954 0.50317451 0.50314725 0.5031514  0.5031421
 0.50313673 0.50314558]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.50322243 0.50323226 0.50324238 0.50322546 0.50320551 0.50316175
 0.50314376 0.50316272 0.50314348 0.50313979 0.50315019 0.50315056
 0.5031303  0.50306657 0.50308248 0.50309271 0.50309988 0.50310912
 0.50311124 0.50311652]
[0.13157895 0.         0.18421053]
-----------end of analyzing the loss ratio:75.27873277664185
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444dc3188b0>
---------------------------------
SparseEpoch: [121][1/398]	Time 0.579	Data 0.000	Loss 0.7211	
SparseEpoch: [121][101/398]	Time 0.582	Data 0.000	Loss 0.6780	
SparseEpoch: [121][201/398]	Time 0.582	Data 0.000	Loss 0.4869	
SparseEpoch: [121][301/398]	Time 0.582	Data 0.000	Loss 0.4353	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11961932 0.119622   0.11961853 0.11962107 0.11961974 0.1196199
 0.11962227 0.11962649 0.11963151 0.11962869 0.11962444 0.11962596
 0.11962762 0.11962758 0.11963038 0.11963441 0.11963075 0.11962729
 0.11962698 0.1196304 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11965557 0.11964445 0.1196417  0.11964017 0.11964308 0.11964313
 0.11964327 0.11964998 0.11964813 0.11963096 0.11962305 0.1196225
 0.11962046 0.11961129 0.11962158 0.1196138  0.11959927 0.11959732
 0.11960248 0.11959831]
[0.         0.39473684 0.        ]
-----------end of analyzing the loss ratio:75.29872798919678
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6e97880>
---------------------------------
SparseEpoch: [121][1/398]	Time 0.578	Data 0.000	Loss 1.1161	
SparseEpoch: [121][101/398]	Time 0.580	Data 0.000	Loss 1.2889	
SparseEpoch: [121][201/398]	Time 0.580	Data 0.000	Loss 1.2475	
SparseEpoch: [121][301/398]	Time 0.580	Data 0.000	Loss 1.5414	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.6945	
Epoch(adapt):{0} Loss 0.8628	
Epoch(adapt):{0} Loss 1.2457	
Epoch(adapt):{0} Loss 0.5530	
------------------the total time cost:1165.5925278663635
>>>>>meta updating
Epoch: 0121 | TRAIN: 0.3776 0.7250 0.8816 | 0.3273 0.3273 0.1567 | 0.1194 22.6627 17.5575 0.3219 0.6203 0.7448 ||TEST: 1.2661 0.4136 0.6668 | 0.5241 0.5241 0.2112 | 0.1408 25.1085 20.0853 0.2847 0.5573 0.6844 | 116.9067
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.38071608 0.3807413  0.38073732 0.38072775 0.38073058 0.38073228
 0.38069698 0.38069621 0.38068053 0.38071367 0.38070263 0.38068666
 0.38072388 0.38073755 0.38075299 0.38071448 0.38072423 0.38070222
 0.38073986 0.38075192]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.3806694  0.38068522 0.38069427 0.38070071 0.38068691 0.3806778
 0.38069255 0.38069916 0.38070241 0.38072324 0.38071601 0.38071574
 0.38071323 0.38070786 0.38071    0.38071276 0.38069466 0.38069518
 0.3806987  0.38069642]
[0. 0. 0.]
-----------end of analyzing the loss ratio:75.35407328605652
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6f95fc0>
---------------------------------
SparseEpoch: [122][1/398]	Time 0.577	Data 0.000	Loss 0.4117	
SparseEpoch: [122][101/398]	Time 0.580	Data 0.000	Loss 0.6386	
SparseEpoch: [122][201/398]	Time 0.580	Data 0.000	Loss 0.3209	
SparseEpoch: [122][301/398]	Time 0.580	Data 0.000	Loss 0.3403	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.3991253  0.39904812 0.39906121 0.39902833 0.39902966 0.39897999
 0.39877248 0.39869263 0.39863454 0.39857175 0.39844104 0.39852661
 0.39856    0.39848517 0.39852871 0.3985061  0.39837002 0.3983716
 0.39831576 0.39829925]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.39855027 0.39852349 0.3985208  0.39851649 0.3985055  0.39848648
 0.39848157 0.39848222 0.39848008 0.3984783  0.39849117 0.39848988
 0.39848834 0.39848161 0.39847592 0.39847875 0.39848693 0.39849445
 0.3985133  0.39851274]
[0.5        0.         0.23684211]
-----------end of analyzing the loss ratio:75.29109287261963
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x744608188910>
---------------------------------
SparseEpoch: [122][1/398]	Time 0.582	Data 0.000	Loss 0.7169	
SparseEpoch: [122][101/398]	Time 0.581	Data 0.000	Loss 0.7369	
SparseEpoch: [122][201/398]	Time 0.581	Data 0.000	Loss 0.7859	
SparseEpoch: [122][301/398]	Time 0.581	Data 0.000	Loss 0.5789	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.1240613  0.12405199 0.12404317 0.12404413 0.12404726 0.12406328
 0.12405831 0.12407415 0.12407014 0.12406867 0.12405477 0.12402187
 0.12402087 0.12399412 0.12398285 0.12396919 0.12392861 0.12392242
 0.12389578 0.12389005]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.12402133 0.12403613 0.12404007 0.12402435 0.12402809 0.12403935
 0.12403814 0.12405431 0.12406049 0.12406858 0.12407138 0.12406984
 0.12405132 0.12406622 0.12405721 0.12403837 0.12403485 0.12403823
 0.1240338  0.12403767]
[0.5 0.  0. ]
-----------end of analyzing the loss ratio:75.03620195388794
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6e950c0>
---------------------------------
SparseEpoch: [122][1/398]	Time 0.584	Data 0.000	Loss 0.9616	
SparseEpoch: [122][101/398]	Time 0.580	Data 0.000	Loss 1.5393	
SparseEpoch: [122][201/398]	Time 0.580	Data 0.000	Loss 1.3195	
SparseEpoch: [122][301/398]	Time 0.580	Data 0.000	Loss 0.9530	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.6854	
Epoch(adapt):{0} Loss 0.8691	
Epoch(adapt):{0} Loss 0.5744	
Epoch(adapt):{0} Loss 0.9459	
------------------the total time cost:1165.8666651248932
>>>>>meta updating
Epoch: 0122 | TRAIN: 0.3637 0.7380 0.8852 | 0.3276 0.3276 0.1556 | 0.1229 23.1166 18.1625 0.3126 0.6058 0.7336 ||TEST: 1.2942 0.4159 0.6662 | 0.5295 0.5295 0.2126 | 0.1427 25.3352 20.4151 0.2815 0.5500 0.6777 | 116.9597
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.33164009 0.33164456 0.33164137 0.33170124 0.3316614  0.33167067
 0.33163875 0.33159133 0.33162009 0.33167541 0.33175362 0.33178644
 0.33182632 0.33186168 0.33187362 0.3319204  0.3319096  0.33190743
 0.33188166 0.33185753]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.33172049 0.33173642 0.33170478 0.33168012 0.33169032 0.33168551
 0.33169714 0.33169475 0.33170542 0.33173863 0.33172675 0.33170191
 0.33170259 0.33170419 0.33172113 0.33171185 0.33174077 0.33172509
 0.33172604 0.33173173]
[0. 0. 0.]
-----------end of analyzing the loss ratio:75.05216217041016
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc2aceb0>
---------------------------------
SparseEpoch: [123][1/398]	Time 0.583	Data 0.000	Loss 0.5286	
SparseEpoch: [123][101/398]	Time 0.581	Data 0.000	Loss 1.1676	
SparseEpoch: [123][201/398]	Time 0.580	Data 0.000	Loss 0.5329	
SparseEpoch: [123][301/398]	Time 0.580	Data 0.000	Loss 0.4509	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.4252678  0.42523428 0.42514925 0.42515758 0.42520827 0.42521967
 0.42527704 0.42523619 0.42519981 0.4251838  0.42521098 0.42520628
 0.42520982 0.42518408 0.42514627 0.4251898  0.42516337 0.42514594
 0.42512741 0.42513873]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.42517854 0.4251929  0.42518328 0.42518685 0.42517804 0.42516257
 0.42517039 0.42516836 0.42516444 0.42517414 0.42516521 0.4252142
 0.42520506 0.42520806 0.42519656 0.42518762 0.42518823 0.42518571
 0.42517927 0.42520241]
[0.44736842 0.         0.        ]
-----------end of analyzing the loss ratio:75.49375605583191
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6f51660>
---------------------------------
SparseEpoch: [123][1/398]	Time 0.581	Data 0.000	Loss 0.4787	
SparseEpoch: [123][101/398]	Time 0.582	Data 0.000	Loss 0.5250	
SparseEpoch: [123][201/398]	Time 0.582	Data 0.000	Loss 0.4818	
SparseEpoch: [123][301/398]	Time 0.581	Data 0.000	Loss 0.4054	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.12137401 0.12138121 0.12141788 0.12144228 0.1214345  0.12142334
 0.12143591 0.12140926 0.12139972 0.12142169 0.1214266  0.12145244
 0.12144454 0.12143158 0.12142463 0.1214012  0.12140861 0.12139691
 0.12139552 0.12140372]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.12138089 0.12136081 0.12136561 0.12134583 0.1213632  0.12136474
 0.12139    0.12142965 0.12143403 0.12138743 0.12141013 0.12144605
 0.12144978 0.12146178 0.12143044 0.12142574 0.1214053  0.12138944
 0.12135129 0.12131647]
[0.  0.5 0. ]
-----------end of analyzing the loss ratio:75.45419216156006
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc0272e0>
---------------------------------
SparseEpoch: [123][1/398]	Time 0.580	Data 0.000	Loss 1.7627	
SparseEpoch: [123][101/398]	Time 0.580	Data 0.000	Loss 1.2079	
SparseEpoch: [123][201/398]	Time 0.580	Data 0.000	Loss 1.2507	
SparseEpoch: [123][301/398]	Time 0.580	Data 0.000	Loss 1.4495	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.3979	
Epoch(adapt):{0} Loss 0.6908	
Epoch(adapt):{0} Loss 1.1362	
Epoch(adapt):{0} Loss 0.6291	
------------------the total time cost:1166.3846139907837
>>>>>meta updating
Epoch: 0123 | TRAIN: 0.3620 0.7342 0.8849 | 0.3319 0.3319 0.1490 | 0.1234 23.2410 18.3463 0.3053 0.6028 0.7328 ||TEST: 1.2649 0.4126 0.6656 | 0.5429 0.5429 0.2093 | 0.1453 25.7281 21.0320 0.2701 0.5377 0.6687 | 116.9487
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.28436165 0.28441464 0.28444819 0.28446214 0.2844029  0.28444828
 0.28444051 0.28442592 0.28435916 0.28431501 0.28425686 0.28423805
 0.28430396 0.28433719 0.28426123 0.28428471 0.28429124 0.28422688
 0.28424771 0.28429438]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.28436904 0.28434988 0.28432187 0.28430341 0.28429847 0.28428917
 0.28428726 0.28429689 0.28429248 0.28426895 0.284284   0.28427382
 0.28427102 0.28426255 0.28428259 0.28427449 0.2842642  0.28425795
 0.28426334 0.2842713 ]
[0.         0.39473684 0.39473684]
-----------end of analyzing the loss ratio:75.1903464794159
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6fd56f0>
---------------------------------
SparseEpoch: [124][1/398]	Time 0.587	Data 0.000	Loss 1.3457	
SparseEpoch: [124][101/398]	Time 0.581	Data 0.000	Loss 0.8452	
SparseEpoch: [124][201/398]	Time 0.581	Data 0.000	Loss 1.0941	
SparseEpoch: [124][301/398]	Time 0.581	Data 0.000	Loss 0.6569	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.33692779 0.33681882 0.33674621 0.33653607 0.33644115 0.33635007
 0.33633489 0.33629238 0.33618096 0.33597972 0.33589788 0.3358657
 0.33582382 0.33583284 0.33580101 0.33582923 0.33576    0.33571053
 0.33559286 0.33559915]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.33593331 0.33595103 0.33592872 0.33592687 0.33592348 0.3359211
 0.3359292  0.33591242 0.33591788 0.33591643 0.33592884 0.33592278
 0.33592342 0.33592484 0.33594971 0.33594648 0.33591664 0.33592154
 0.33593158 0.33592181]
[0.44736842 0.         0.        ]
-----------end of analyzing the loss ratio:75.16046714782715
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7446096e8370>
---------------------------------
SparseEpoch: [124][1/398]	Time 0.578	Data 0.000	Loss 0.3022	
SparseEpoch: [124][101/398]	Time 0.581	Data 0.000	Loss 0.6089	
SparseEpoch: [124][201/398]	Time 0.581	Data 0.000	Loss 0.6286	
SparseEpoch: [124][301/398]	Time 0.581	Data 0.000	Loss 0.5280	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.13610317 0.13611687 0.13614477 0.13615454 0.13615623 0.13616815
 0.13617662 0.13618191 0.13619002 0.1361947  0.13618142 0.13620189
 0.13621353 0.13622251 0.1362039  0.13618894 0.1361752  0.13615417
 0.13615555 0.13615785]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.13616034 0.13616288 0.13616804 0.13617289 0.13616987 0.13617824
 0.1361833  0.13618229 0.13618326 0.13617506 0.1361967  0.13618597
 0.1361872  0.1361877  0.13618807 0.13620691 0.13620704 0.13621138
 0.13621658 0.1362137 ]
[0. 0. 0.]
-----------end of analyzing the loss ratio:76.93597936630249
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444dc2a34c0>
---------------------------------
SparseEpoch: [124][1/398]	Time 0.580	Data 0.000	Loss 1.4737	
SparseEpoch: [124][101/398]	Time 0.582	Data 0.000	Loss 1.1768	
SparseEpoch: [124][201/398]	Time 0.582	Data 0.000	Loss 0.8014	
SparseEpoch: [124][301/398]	Time 0.582	Data 0.000	Loss 0.9618	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.8071	
Epoch(adapt):{0} Loss 0.7230	
Epoch(adapt):{0} Loss 1.0200	
Epoch(adapt):{0} Loss 0.7013	
------------------the total time cost:1182.031553030014
>>>>>meta updating
Epoch: 0124 | TRAIN: 0.3557 0.7437 0.8881 | 0.3355 0.3355 0.1508 | 0.1216 23.0957 18.2546 0.3047 0.6060 0.7364 ||TEST: 1.2230 0.4123 0.6657 | 0.5477 0.5477 0.2120 | 0.1429 25.5138 20.7908 0.2703 0.5434 0.6743 | 118.0433
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.33267464 0.33271838 0.33271496 0.33271869 0.33277117 0.33286146
 0.33279736 0.33279967 0.332769   0.33283656 0.33279392 0.33279547
 0.33279435 0.33281107 0.33277799 0.33277794 0.33278165 0.33282744
 0.3327938  0.33284491]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.33277829 0.3327785  0.33277762 0.33278211 0.33277735 0.33278593
 0.33279894 0.33279447 0.33281462 0.33283431 0.33282601 0.33281156
 0.33281653 0.33280284 0.3327998  0.33280199 0.33280296 0.33279373
 0.33279445 0.33280594]
[0. 0. 0.]
-----------end of analyzing the loss ratio:76.37491345405579
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d70974f0>
---------------------------------
SparseEpoch: [125][1/398]	Time 0.586	Data 0.000	Loss 0.1681	
SparseEpoch: [125][101/398]	Time 0.594	Data 0.000	Loss 0.3654	
SparseEpoch: [125][201/398]	Time 0.588	Data 0.000	Loss 0.5016	
SparseEpoch: [125][301/398]	Time 0.586	Data 0.000	Loss 0.6479	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.41799523 0.41805398 0.4179328  0.41790046 0.41779217 0.41771444
 0.41785588 0.41782113 0.41768639 0.41775263 0.4177783  0.41773481
 0.41791113 0.41804298 0.41809776 0.41827054 0.41825086 0.41840301
 0.41856127 0.41871239]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.41763648 0.41766192 0.4176374  0.41762953 0.41765091 0.4176548
 0.41770402 0.41767156 0.41767301 0.41771703 0.41769014 0.41772233
 0.41774978 0.41773081 0.41773324 0.4177554  0.41775279 0.41773534
 0.4177452  0.41773342]
[0. 0. 0.]
-----------end of analyzing the loss ratio:75.44494795799255
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc326860>
---------------------------------
SparseEpoch: [125][1/398]	Time 0.578	Data 0.000	Loss 0.3567	
SparseEpoch: [125][101/398]	Time 0.580	Data 0.000	Loss 0.3505	
SparseEpoch: [125][201/398]	Time 0.580	Data 0.000	Loss 0.3902	
SparseEpoch: [125][301/398]	Time 0.580	Data 0.000	Loss 0.2043	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.13480119 0.13479916 0.13477364 0.13474072 0.13473163 0.13472564
 0.13472674 0.13471292 0.13471813 0.13473419 0.13472991 0.13471678
 0.13469605 0.13471744 0.13470492 0.13468632 0.13467739 0.1346504
 0.1346374  0.13464883]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.13474982 0.13475175 0.1347401  0.13473958 0.134728   0.13473168
 0.13472344 0.13472443 0.13474597 0.13472569 0.13472548 0.13472429
 0.13472834 0.13470691 0.13470776 0.13470649 0.13470927 0.13470954
 0.13469442 0.13470131]
[0.44736842 0.44736842 0.        ]
-----------end of analyzing the loss ratio:75.36393594741821
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc42f9d0>
---------------------------------
SparseEpoch: [125][1/398]	Time 0.604	Data 0.000	Loss 1.2984	
SparseEpoch: [125][101/398]	Time 0.580	Data 0.000	Loss 2.3614	
SparseEpoch: [125][201/398]	Time 0.581	Data 0.000	Loss 1.5893	
SparseEpoch: [125][301/398]	Time 0.582	Data 0.000	Loss 1.4213	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.6862	
Epoch(adapt):{0} Loss 0.6966	
Epoch(adapt):{0} Loss 0.5447	
Epoch(adapt):{0} Loss 0.6918	
------------------the total time cost:1169.66925907135
>>>>>meta updating
Epoch: 0125 | TRAIN: 0.3538 0.7387 0.8890 | 0.3507 0.3507 0.1615 | 0.1199 22.7747 17.7315 0.3181 0.6164 0.7423 ||TEST: 1.2353 0.4073 0.6660 | 0.5464 0.5464 0.2136 | 0.1423 25.2930 20.3326 0.2806 0.5525 0.6809 | 116.8988
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.36553314 0.3654667  0.36546734 0.36545942 0.36546727 0.36547083
 0.36547389 0.36549732 0.3654252  0.3653973  0.36536785 0.36536495
 0.3653766  0.36542142 0.36542011 0.36545592 0.3654141  0.36540536
 0.3654369  0.36542792]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.36540298 0.36538987 0.36540537 0.36539137 0.36537722 0.36536685
 0.36536696 0.36536745 0.3653685  0.365394   0.36538982 0.3653875
 0.36536587 0.3654024  0.36540617 0.36539863 0.36538979 0.36538956
 0.36539255 0.36540895]
[0.         0.07894737 0.13157895]
-----------end of analyzing the loss ratio:75.63513493537903
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc5096f0>
---------------------------------
SparseEpoch: [126][1/398]	Time 0.579	Data 0.000	Loss 0.5281	
SparseEpoch: [126][101/398]	Time 0.581	Data 0.000	Loss 0.5884	
SparseEpoch: [126][201/398]	Time 0.581	Data 0.000	Loss 0.5316	
SparseEpoch: [126][301/398]	Time 0.581	Data 0.000	Loss 0.7413	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.36382832 0.36366212 0.36361121 0.36348099 0.36334545 0.36325848
 0.36305562 0.36293634 0.36263405 0.36256525 0.3623599  0.3622631
 0.36209484 0.36200521 0.36186603 0.36174734 0.36156867 0.36139237
 0.36130094 0.36113127]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.36250366 0.36249399 0.36248146 0.36249929 0.36250772 0.36248232
 0.36248454 0.3624794  0.36244228 0.3624503  0.36244065 0.36243613
 0.36241828 0.36242435 0.36240907 0.36240204 0.36238305 0.36238421
 0.36238212 0.36236615]
[0.5 0.  0.5]
-----------end of analyzing the loss ratio:75.38470268249512
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6c5d510>
---------------------------------
SparseEpoch: [126][1/398]	Time 0.578	Data 0.000	Loss 1.0053	
SparseEpoch: [126][101/398]	Time 0.582	Data 0.000	Loss 0.9119	
SparseEpoch: [126][201/398]	Time 0.582	Data 0.000	Loss 1.4807	
SparseEpoch: [126][301/398]	Time 0.581	Data 0.000	Loss 1.5750	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.1201938  0.1201987  0.12017272 0.1201704  0.1201682  0.12016014
 0.12017146 0.12015378 0.12016007 0.12015119 0.12014022 0.12012848
 0.12013528 0.1201223  0.12011611 0.1200966  0.12010636 0.12010978
 0.12011778 0.120118  ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.12009687 0.12010103 0.12010012 0.12011904 0.12011397 0.1201297
 0.12013496 0.12013565 0.12014114 0.1201497  0.12014335 0.12013374
 0.12017831 0.12018405 0.12020607 0.12019261 0.12015938 0.12017139
 0.12015977 0.1201592 ]
[0.28947368 0.         0.        ]
-----------end of analyzing the loss ratio:75.19420027732849
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc2aceb0>
---------------------------------
SparseEpoch: [126][1/398]	Time 0.579	Data 0.000	Loss 0.8861	
SparseEpoch: [126][101/398]	Time 0.580	Data 0.000	Loss 1.1602	
SparseEpoch: [126][201/398]	Time 0.581	Data 0.000	Loss 2.2530	
SparseEpoch: [126][301/398]	Time 0.581	Data 0.000	Loss 1.0794	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.7263	
Epoch(adapt):{0} Loss 0.4831	
Epoch(adapt):{0} Loss 0.7315	
Epoch(adapt):{0} Loss 0.6418	
------------------the total time cost:1167.891535282135
>>>>>meta updating
Epoch: 0126 | TRAIN: 0.3582 0.7343 0.8865 | 0.3378 0.3378 0.1654 | 0.1184 22.5392 17.4546 0.3242 0.6239 0.7493 ||TEST: 1.2703 0.4116 0.6618 | 0.5365 0.5365 0.2193 | 0.1420 25.2365 20.2570 0.2823 0.5543 0.6822 | 116.5779
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.359276   0.3592462  0.35921974 0.35927716 0.35929561 0.35927839
 0.35923479 0.35922288 0.35923041 0.35924462 0.35926569 0.35926337
 0.35925816 0.35929873 0.35923689 0.35926594 0.35928853 0.3592824
 0.35930044 0.35931028]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.35925642 0.35925678 0.3592603  0.35926704 0.35925589 0.35925512
 0.35924648 0.35924561 0.35925815 0.35925595 0.35926182 0.35925469
 0.35926932 0.3592403  0.35924782 0.35924177 0.35923899 0.35925381
 0.35925801 0.35925846]
[0.         0.         0.34210526]
-----------end of analyzing the loss ratio:75.35187983512878
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc37ff70>
---------------------------------
SparseEpoch: [127][1/398]	Time 0.579	Data 0.000	Loss 0.7799	
SparseEpoch: [127][101/398]	Time 0.580	Data 0.000	Loss 0.7333	
SparseEpoch: [127][201/398]	Time 0.580	Data 0.000	Loss 0.8862	
SparseEpoch: [127][301/398]	Time 0.580	Data 0.000	Loss 0.6349	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.56432616 0.56430244 0.56423868 0.56420068 0.56413742 0.56408063
 0.56401207 0.56396301 0.56387979 0.56374543 0.56364574 0.56359595
 0.5635373  0.56352302 0.56346034 0.56339236 0.56334225 0.5631968
 0.56311041 0.56306509]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.56389462 0.56389717 0.56388994 0.56389017 0.56386799 0.56380251
 0.56377379 0.56377331 0.56373972 0.56367294 0.56365258 0.56364764
 0.56364821 0.56360555 0.56359448 0.56361375 0.56365064 0.56366707
 0.56366768 0.56360463]
[0.5        0.         0.23684211]
-----------end of analyzing the loss ratio:75.1260678768158
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc42da20>
---------------------------------
SparseEpoch: [127][1/398]	Time 0.579	Data 0.000	Loss 0.7064	
SparseEpoch: [127][101/398]	Time 0.580	Data 0.000	Loss 0.6436	
SparseEpoch: [127][201/398]	Time 0.581	Data 0.000	Loss 0.7788	
SparseEpoch: [127][301/398]	Time 0.581	Data 0.000	Loss 0.6655	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.12431    0.12430239 0.12429298 0.12425339 0.12423314 0.12424433
 0.1242461  0.12424132 0.12422171 0.12420505 0.12420614 0.12413691
 0.12407584 0.12406947 0.12401999 0.12401687 0.12398593 0.12397727
 0.12397211 0.12395208]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.12417758 0.12420204 0.12419786 0.12420927 0.12418459 0.1241857
 0.12417906 0.1241997  0.12421159 0.12421325 0.12422117 0.12417827
 0.12414151 0.12414344 0.12414154 0.12413863 0.1241161  0.12410022
 0.12409338 0.12410713]
[0.5        0.44736842 0.        ]
-----------end of analyzing the loss ratio:75.0963625907898
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444dc12e290>
---------------------------------
SparseEpoch: [127][1/398]	Time 0.579	Data 0.000	Loss 1.2429	
SparseEpoch: [127][101/398]	Time 0.581	Data 0.000	Loss 1.3509	
SparseEpoch: [127][201/398]	Time 0.581	Data 0.000	Loss 1.3861	
SparseEpoch: [127][301/398]	Time 0.581	Data 0.000	Loss 1.3550	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.6168	
Epoch(adapt):{0} Loss 0.6010	
Epoch(adapt):{0} Loss 0.9340	
Epoch(adapt):{0} Loss 0.5420	
------------------the total time cost:1165.508507013321
>>>>>meta updating
Epoch: 0127 | TRAIN: 0.3628 0.7383 0.8848 | 0.3412 0.3412 0.1600 | 0.1200 22.7156 17.6306 0.3226 0.6181 0.7424 ||TEST: 1.2752 0.4101 0.6663 | 0.5406 0.5406 0.2135 | 0.1423 25.2688 20.2883 0.2837 0.5529 0.6798 | 116.6229
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.40156818 0.40163109 0.40170774 0.40168513 0.40164272 0.4016325
 0.40176058 0.40182067 0.40180081 0.40170345 0.40178021 0.40172001
 0.4017393  0.40176897 0.40175208 0.4017706  0.40174997 0.40177973
 0.4017573  0.40175986]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.40170995 0.40171648 0.40172241 0.40174126 0.40175628 0.40175591
 0.40177255 0.40177613 0.4017143  0.40169705 0.4016798  0.40170524
 0.40169002 0.40169334 0.40169235 0.401716   0.40171858 0.40173357
 0.40171543 0.40172188]
[0.         0.         0.02631579]
-----------end of analyzing the loss ratio:75.60029077529907
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6f97bb0>
---------------------------------
SparseEpoch: [128][1/398]	Time 0.578	Data 0.000	Loss 0.3470	
SparseEpoch: [128][101/398]	Time 0.581	Data 0.000	Loss 0.3487	
SparseEpoch: [128][201/398]	Time 0.581	Data 0.000	Loss 0.3282	
SparseEpoch: [128][301/398]	Time 0.581	Data 0.000	Loss 0.1980	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.43949019 0.43947503 0.43949468 0.43947679 0.43948055 0.43947904
 0.43950778 0.43939314 0.43934587 0.43937753 0.43934057 0.43933846
 0.4393267  0.4392952  0.43931808 0.4392975  0.43938318 0.43940942
 0.43941404 0.439364  ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.4393926  0.43938522 0.43937979 0.43936633 0.43936843 0.43936353
 0.4393638  0.43936923 0.43936219 0.43935392 0.43935036 0.43935063
 0.43935772 0.43936158 0.43935478 0.43933363 0.43933357 0.43933042
 0.43933384 0.43932271]
[0.18421053 0.         0.5       ]
-----------end of analyzing the loss ratio:75.36593770980835
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x74460816b970>
---------------------------------
SparseEpoch: [128][1/398]	Time 0.578	Data 0.000	Loss 1.1019	
SparseEpoch: [128][101/398]	Time 0.581	Data 0.000	Loss 0.9607	
SparseEpoch: [128][201/398]	Time 0.580	Data 0.000	Loss 0.9465	
SparseEpoch: [128][301/398]	Time 0.581	Data 0.000	Loss 0.8813	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.14304369 0.14305306 0.14304491 0.14306551 0.14307916 0.14308563
 0.14307847 0.1430845  0.14308277 0.14308246 0.14308285 0.14306187
 0.14304817 0.14303622 0.1430315  0.14302284 0.14302677 0.14301739
 0.14300985 0.14298981]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.14304791 0.14304379 0.143047   0.14305627 0.14306163 0.14306714
 0.14307042 0.14307679 0.14308724 0.14308128 0.14308589 0.14308133
 0.14307773 0.14307839 0.14307378 0.14307229 0.14307703 0.14308643
 0.14308574 0.14306837]
[0.5 0.  0. ]
-----------end of analyzing the loss ratio:75.34673023223877
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc2f4340>
---------------------------------
SparseEpoch: [128][1/398]	Time 0.579	Data 0.000	Loss 1.0382	
SparseEpoch: [128][101/398]	Time 0.581	Data 0.000	Loss 1.4182	
SparseEpoch: [128][201/398]	Time 0.580	Data 0.000	Loss 0.8899	
SparseEpoch: [128][301/398]	Time 0.580	Data 0.000	Loss 1.0703	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.0941	
Epoch(adapt):{0} Loss 0.9029	
Epoch(adapt):{0} Loss 0.5618	
Epoch(adapt):{0} Loss 1.5144	
------------------the total time cost:1165.9432997703552
>>>>>meta updating
Epoch: 0128 | TRAIN: 0.3690 0.7376 0.8839 | 0.3234 0.3234 0.1488 | 0.1186 22.4745 17.2377 0.3295 0.6289 0.7508 ||TEST: 1.2982 0.4115 0.6624 | 0.5333 0.5333 0.2078 | 0.1413 25.0894 19.9681 0.2878 0.5603 0.6866 | 116.7134
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.37842939 0.37840621 0.37841579 0.37846127 0.37846983 0.3784798
 0.37841088 0.37847472 0.37835121 0.37828511 0.37822491 0.37821276
 0.37809861 0.37810092 0.37820154 0.37812965 0.37812883 0.37838552
 0.378481   0.3784379 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.37817421 0.37815644 0.37814571 0.37811304 0.37810136 0.3781183
 0.37815078 0.37818535 0.37822062 0.37829405 0.37829056 0.37828397
 0.37824574 0.37828195 0.3782862  0.37827165 0.3782843  0.37829211
 0.37830594 0.37822997]
[0.         0.13157895 0.        ]
-----------end of analyzing the loss ratio:75.25802898406982
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc278340>
---------------------------------
SparseEpoch: [129][1/398]	Time 0.578	Data 0.000	Loss 0.2565	
SparseEpoch: [129][101/398]	Time 0.581	Data 0.000	Loss 0.9990	
SparseEpoch: [129][201/398]	Time 0.581	Data 0.000	Loss 0.6000	
SparseEpoch: [129][301/398]	Time 0.580	Data 0.000	Loss 0.6599	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.33224355 0.3321524  0.33192765 0.3317587  0.3315062  0.33140726
 0.33142623 0.331201   0.33095933 0.33089228 0.33079118 0.33066333
 0.33057234 0.33051904 0.33040547 0.33031585 0.33016124 0.33011499
 0.33003809 0.3299913 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.33090063 0.33088527 0.33092102 0.33094753 0.33094019 0.33091006
 0.33090124 0.33089494 0.3308855  0.33086385 0.33086005 0.33088002
 0.3308739  0.33086248 0.33086945 0.33086346 0.33084958 0.33082782
 0.33078894 0.33080532]
[0.5        0.         0.44736842]
-----------end of analyzing the loss ratio:75.22347402572632
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6b91a80>
---------------------------------
SparseEpoch: [129][1/398]	Time 0.578	Data 0.000	Loss 0.7223	
SparseEpoch: [129][101/398]	Time 0.581	Data 0.000	Loss 1.0850	
SparseEpoch: [129][201/398]	Time 0.581	Data 0.000	Loss 0.9032	
SparseEpoch: [129][301/398]	Time 0.581	Data 0.000	Loss 0.9129	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.13365138 0.13365048 0.13363741 0.13363459 0.13362999 0.13363546
 0.13362205 0.13363522 0.13363649 0.13363634 0.13362082 0.13362836
 0.13363484 0.13363957 0.13363231 0.1336256  0.13361869 0.1335966
 0.13357351 0.13357915]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.13365878 0.13365665 0.13365905 0.13365139 0.13364732 0.13363869
 0.1336306  0.13362857 0.13362446 0.13362573 0.13363554 0.13362373
 0.13363074 0.13363913 0.13362295 0.13363594 0.13363088 0.13361561
 0.13361661 0.13362104]
[0.44736842 0.39473684 0.        ]
-----------end of analyzing the loss ratio:75.50191140174866
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d70962c0>
---------------------------------
SparseEpoch: [129][1/398]	Time 0.580	Data 0.000	Loss 0.9531	
SparseEpoch: [129][101/398]	Time 0.582	Data 0.000	Loss 1.1578	
SparseEpoch: [129][201/398]	Time 0.582	Data 0.000	Loss 1.2481	
SparseEpoch: [129][301/398]	Time 0.581	Data 0.000	Loss 1.6889	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.1320	
Epoch(adapt):{0} Loss 1.1155	
Epoch(adapt):{0} Loss 0.6460	
Epoch(adapt):{0} Loss 0.6968	
------------------the total time cost:1167.1287813186646
>>>>>meta updating
Epoch: 0129 | TRAIN: 0.3607 0.7397 0.8869 | 0.3120 0.3120 0.1522 | 0.1191 22.7293 17.8106 0.3151 0.6161 0.7442 ||TEST: 1.3192 0.4151 0.6622 | 0.5241 0.5241 0.2136 | 0.1434 25.4973 20.7149 0.2744 0.5444 0.6745 | 116.3263
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.43140806 0.43140342 0.43137957 0.431365   0.43141421 0.43143174
 0.43137982 0.43136857 0.4313176  0.43129805 0.43125405 0.43121829
 0.43117733 0.43119115 0.43116073 0.43108886 0.43102797 0.43103076
 0.43103899 0.43101295]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.43129694 0.43128476 0.43127613 0.43128835 0.43129285 0.4312937
 0.4312734  0.43127327 0.43128536 0.43129093 0.43129248 0.43128825
 0.43129609 0.43131652 0.43131452 0.43130282 0.43128767 0.43131542
 0.43130521 0.43131123]
[0.  0.5 0. ]
-----------end of analyzing the loss ratio:75.38076663017273
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d72d2410>
---------------------------------
SparseEpoch: [130][1/398]	Time 0.579	Data 0.000	Loss 0.3817	
SparseEpoch: [130][101/398]	Time 0.581	Data 0.000	Loss 0.5729	
SparseEpoch: [130][201/398]	Time 0.580	Data 0.000	Loss 0.5251	
SparseEpoch: [130][301/398]	Time 0.580	Data 0.000	Loss 0.3369	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.38935799 0.38940997 0.38935557 0.38935466 0.38940036 0.38932228
 0.38932095 0.38921316 0.38919954 0.38909462 0.38912369 0.38911158
 0.38905461 0.3890222  0.38899514 0.38895534 0.3890115  0.38902858
 0.38896778 0.38889542]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.3891396  0.38912329 0.38912705 0.3891129  0.38910272 0.38909433
 0.38911058 0.38913613 0.38915755 0.38914559 0.38913352 0.38913202
 0.38910497 0.38908734 0.38908623 0.38908995 0.38910921 0.38907833
 0.38911717 0.38910866]
[0.5        0.         0.39473684]
-----------end of analyzing the loss ratio:75.41081404685974
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7446096ea890>
---------------------------------
SparseEpoch: [130][1/398]	Time 0.578	Data 0.000	Loss 1.4888	
SparseEpoch: [130][101/398]	Time 0.580	Data 0.000	Loss 0.8074	
SparseEpoch: [130][201/398]	Time 0.581	Data 0.000	Loss 1.0811	
SparseEpoch: [130][301/398]	Time 0.581	Data 0.000	Loss 1.1188	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.119177   0.11915998 0.11914964 0.11915212 0.11915575 0.11914998
 0.11915504 0.11916298 0.11915975 0.11916342 0.11917163 0.11918089
 0.11918638 0.11918913 0.11919862 0.11918706 0.11919145 0.11918387
 0.1191804  0.11917077]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11923409 0.119236   0.11924208 0.11923227 0.11922542 0.11920668
 0.1191938  0.11916757 0.11916366 0.11916481 0.11918888 0.11918171
 0.11918151 0.1191816  0.11917304 0.11917039 0.11914365 0.11914564
 0.11914101 0.11912363]
[0.  0.5 0. ]
-----------end of analyzing the loss ratio:75.62309074401855
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6bd0100>
---------------------------------
SparseEpoch: [130][1/398]	Time 0.578	Data 0.000	Loss 0.9605	
SparseEpoch: [130][101/398]	Time 0.581	Data 0.000	Loss 1.3020	
SparseEpoch: [130][201/398]	Time 0.580	Data 0.000	Loss 1.7907	
SparseEpoch: [130][301/398]	Time 0.580	Data 0.000	Loss 1.5261	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.7161	
Epoch(adapt):{0} Loss 0.6635	
Epoch(adapt):{0} Loss 0.4463	
Epoch(adapt):{0} Loss 0.7560	
------------------the total time cost:1167.3439674377441
>>>>>meta updating
Epoch: 0130 | TRAIN: 0.3441 0.7546 0.8928 | 0.3241 0.3241 0.1471 | 0.1169 22.3599 17.3658 0.3290 0.6266 0.7505 ||TEST: 1.2555 0.4146 0.6639 | 0.5436 0.5436 0.2117 | 0.1423 25.2543 20.3049 0.2840 0.5528 0.6804 | 116.7040
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.38445178 0.38445614 0.38439558 0.38445133 0.38437827 0.38436703
 0.38439993 0.38445857 0.38439937 0.38438202 0.38436334 0.38441029
 0.38442384 0.38443579 0.3844785  0.38436167 0.38437199 0.38441432
 0.3844299  0.38430087]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.38453936 0.38455953 0.38456834 0.38456087 0.384473   0.3844739
 0.38446663 0.38444747 0.38445937 0.38442449 0.38436164 0.38432656
 0.38437045 0.38438736 0.38439165 0.38439158 0.38440659 0.38434013
 0.38432338 0.38434311]
[0.         0.5        0.44736842]
-----------end of analyzing the loss ratio:75.46070170402527
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc1a76a0>
---------------------------------
SparseEpoch: [131][1/398]	Time 0.579	Data 0.000	Loss 1.0832	
SparseEpoch: [131][101/398]	Time 0.580	Data 0.000	Loss 0.9454	
SparseEpoch: [131][201/398]	Time 0.581	Data 0.000	Loss 0.9232	
SparseEpoch: [131][301/398]	Time 0.581	Data 0.000	Loss 0.7449	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.30288758 0.30283296 0.30284741 0.30289801 0.30290506 0.30296744
 0.30296753 0.30291817 0.30285082 0.30278652 0.30279046 0.30285207
 0.30279542 0.30281871 0.30272709 0.30272326 0.30265308 0.30266329
 0.30258087 0.30256578]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.30278485 0.3027749  0.30277361 0.30277806 0.3027871  0.30278257
 0.30276483 0.30275613 0.30277219 0.30278113 0.30278284 0.30278331
 0.30277675 0.30278901 0.30278507 0.30279965 0.30279087 0.30278056
 0.30276721 0.30275629]
[0.5 0.  0. ]
-----------end of analyzing the loss ratio:75.29635047912598
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6d07be0>
---------------------------------
SparseEpoch: [131][1/398]	Time 0.578	Data 0.000	Loss 0.4458	
SparseEpoch: [131][101/398]	Time 0.580	Data 0.000	Loss 0.3438	
SparseEpoch: [131][201/398]	Time 0.581	Data 0.000	Loss 0.4940	
SparseEpoch: [131][301/398]	Time 0.581	Data 0.000	Loss 0.4138	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.13291155 0.13291717 0.13291648 0.13290537 0.13289255 0.13289535
 0.13288457 0.13287514 0.13285264 0.13285264 0.13286579 0.13288808
 0.13285691 0.13287744 0.13285108 0.13284028 0.13283719 0.13282594
 0.13279128 0.13279021]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.13292058 0.13289829 0.13288925 0.1328844  0.13287441 0.13286473
 0.13285061 0.13285652 0.13286079 0.13286266 0.13285936 0.13285769
 0.13284302 0.13283768 0.13284119 0.13284909 0.13284401 0.13285314
 0.13284485 0.1328531 ]
[0.5        0.18421053 0.        ]
-----------end of analyzing the loss ratio:75.26250791549683
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x74460925f0a0>
---------------------------------
SparseEpoch: [131][1/398]	Time 0.579	Data 0.000	Loss 1.6379	
SparseEpoch: [131][101/398]	Time 0.582	Data 0.000	Loss 1.8881	
SparseEpoch: [131][201/398]	Time 0.581	Data 0.000	Loss 2.0624	
SparseEpoch: [131][301/398]	Time 0.581	Data 0.000	Loss 1.1919	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.8003	
Epoch(adapt):{0} Loss 0.6203	
Epoch(adapt):{0} Loss 0.6080	
Epoch(adapt):{0} Loss 0.5059	
------------------the total time cost:1166.8914995193481
>>>>>meta updating
Epoch: 0131 | TRAIN: 0.3386 0.7487 0.8935 | 0.3183 0.3183 0.1564 | 0.1194 22.6952 17.7368 0.3208 0.6179 0.7436 ||TEST: 1.2872 0.4124 0.6643 | 0.5247 0.5247 0.2135 | 0.1433 25.4157 20.5553 0.2797 0.5476 0.6761 | 116.5409
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.33123229 0.33128181 0.33129954 0.3312847  0.3312598  0.33128024
 0.33131086 0.33133217 0.33133138 0.33130844 0.33130561 0.3313328
 0.33134971 0.3313164  0.33129146 0.33128285 0.33133425 0.33134086
 0.33134274 0.33133735]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.33134164 0.33129402 0.33130199 0.33129318 0.33130706 0.3312967
 0.33135093 0.3313287  0.33133201 0.33133514 0.33131028 0.33129591
 0.33130378 0.33132613 0.33132378 0.33131922 0.33131389 0.33135627
 0.33133716 0.33132762]
[0. 0. 0.]
-----------end of analyzing the loss ratio:75.5590889453888
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc11feb0>
---------------------------------
SparseEpoch: [132][1/398]	Time 0.578	Data 0.000	Loss 0.4001	
SparseEpoch: [132][101/398]	Time 0.579	Data 0.000	Loss 0.4496	
SparseEpoch: [132][201/398]	Time 0.580	Data 0.000	Loss 0.8224	
SparseEpoch: [132][301/398]	Time 0.580	Data 0.000	Loss 0.5043	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.42539849 0.42539064 0.42531384 0.4252629  0.42517634 0.4251087
 0.42504421 0.42496801 0.42499565 0.42486535 0.42482469 0.42474825
 0.42475913 0.42477963 0.42476825 0.42461588 0.42459584 0.42462428
 0.42458104 0.42456478]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.42491556 0.42490004 0.42494521 0.42492266 0.42494527 0.42491579
 0.42485045 0.42486315 0.42487159 0.42485513 0.42479603 0.42481258
 0.42478735 0.42476792 0.42474734 0.42474123 0.42475141 0.42471057
 0.42470553 0.42473985]
[0.5        0.         0.44736842]
-----------end of analyzing the loss ratio:75.36587572097778
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6b93460>
---------------------------------
SparseEpoch: [132][1/398]	Time 0.579	Data 0.000	Loss 1.1919	
SparseEpoch: [132][101/398]	Time 0.581	Data 0.000	Loss 1.1454	
SparseEpoch: [132][201/398]	Time 0.581	Data 0.000	Loss 1.5105	
SparseEpoch: [132][301/398]	Time 0.581	Data 0.000	Loss 0.5550	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.12869667 0.12871926 0.12872383 0.12871127 0.12871432 0.12870203
 0.12869791 0.12869472 0.12867851 0.12870072 0.12869996 0.12872791
 0.12870382 0.12869322 0.12870932 0.12872689 0.12873282 0.12874091
 0.12874706 0.12873673]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.12869315 0.12868226 0.12869321 0.12868767 0.12871177 0.12871594
 0.1286924  0.12870229 0.12871327 0.12870179 0.12870381 0.12869409
 0.12869245 0.12869263 0.12867175 0.12868499 0.12870381 0.12870566
 0.12872469 0.12873386]
[0.         0.23684211 0.        ]
-----------end of analyzing the loss ratio:75.69474291801453
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6b45150>
---------------------------------
SparseEpoch: [132][1/398]	Time 0.579	Data 0.000	Loss 1.0967	
SparseEpoch: [132][101/398]	Time 0.581	Data 0.000	Loss 2.0282	
SparseEpoch: [132][201/398]	Time 0.581	Data 0.000	Loss 1.6615	
SparseEpoch: [132][301/398]	Time 0.581	Data 0.000	Loss 1.6314	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.6422	
Epoch(adapt):{0} Loss 0.4847	
Epoch(adapt):{0} Loss 0.6908	
Epoch(adapt):{0} Loss 0.8250	
------------------the total time cost:1167.8758625984192
>>>>>meta updating
Epoch: 0132 | TRAIN: 0.3410 0.7528 0.8935 | 0.3399 0.3399 0.1548 | 0.1214 23.0787 18.1959 0.3042 0.6079 0.7378 ||TEST: 1.2559 0.4116 0.6644 | 0.5490 0.5490 0.2084 | 0.1425 25.4913 20.7293 0.2698 0.5443 0.6756 | 117.1846
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.40760291 0.4076444  0.40763222 0.40763339 0.40770032 0.4077052
 0.40769218 0.4076825  0.40766159 0.40766512 0.40767784 0.40766294
 0.40763419 0.407649   0.40762115 0.40759158 0.40759601 0.40759023
 0.40751306 0.407558  ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.40771763 0.40771357 0.40769974 0.40771334 0.40771119 0.40770656
 0.40770941 0.40770897 0.40769374 0.40769088 0.40769355 0.40768023
 0.40767772 0.40766019 0.4076593  0.40763595 0.40763768 0.40763439
 0.40764103 0.40763946]
[0.         0.44736842 0.39473684]
-----------end of analyzing the loss ratio:75.64564561843872
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7446091a2ef0>
---------------------------------
SparseEpoch: [133][1/398]	Time 0.579	Data 0.000	Loss 0.7588	
SparseEpoch: [133][101/398]	Time 0.580	Data 0.000	Loss 1.0458	
SparseEpoch: [133][201/398]	Time 0.581	Data 0.000	Loss 0.9663	
SparseEpoch: [133][301/398]	Time 0.581	Data 0.000	Loss 1.0305	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.31836371 0.3182907  0.31827516 0.3182783  0.3182905  0.31829126
 0.31833268 0.31834168 0.31832664 0.31834086 0.31832345 0.31830282
 0.31828219 0.31826811 0.31827029 0.31828469 0.31832795 0.3183277
 0.31835801 0.31835053]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.31836575 0.31837104 0.31837902 0.31839113 0.31838094 0.31838889
 0.31837414 0.3183623  0.31836288 0.31837339 0.31836197 0.31834612
 0.31834784 0.31833174 0.3183275  0.31833965 0.3183288  0.31834128
 0.3183355  0.31834036]
[0.18421053 0.         0.23684211]
-----------end of analyzing the loss ratio:75.2961699962616
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6bf0940>
---------------------------------
SparseEpoch: [133][1/398]	Time 0.579	Data 0.000	Loss 0.3653	
SparseEpoch: [133][101/398]	Time 0.583	Data 0.000	Loss 0.5457	
SparseEpoch: [133][201/398]	Time 0.582	Data 0.000	Loss 0.5535	
SparseEpoch: [133][301/398]	Time 0.581	Data 0.000	Loss 0.6048	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.13130729 0.13131451 0.13131728 0.13129284 0.13128993 0.13128993
 0.13128672 0.13130972 0.13131998 0.1313219  0.1313196  0.13130155
 0.13130021 0.13128355 0.1312814  0.13125923 0.13125343 0.13126246
 0.13126121 0.13125817]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.13133072 0.13132832 0.13131483 0.13129874 0.13131409 0.13132814
 0.1313412  0.1313341  0.13133203 0.13132498 0.13131236 0.13127901
 0.13126568 0.13125986 0.13125025 0.1312659  0.13124332 0.13121701
 0.1312153  0.13122389]
[0.34210526 0.44736842 0.        ]
-----------end of analyzing the loss ratio:75.25021839141846
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc168190>
---------------------------------
SparseEpoch: [133][1/398]	Time 0.579	Data 0.000	Loss 1.3646	
SparseEpoch: [133][101/398]	Time 0.581	Data 0.000	Loss 1.4737	
SparseEpoch: [133][201/398]	Time 0.581	Data 0.000	Loss 1.1932	
SparseEpoch: [133][301/398]	Time 0.581	Data 0.000	Loss 0.9905	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.5652	
Epoch(adapt):{0} Loss 0.4326	
Epoch(adapt):{0} Loss 0.8503	
Epoch(adapt):{0} Loss 0.8526	
------------------the total time cost:1166.3689863681793
>>>>>meta updating
Epoch: 0133 | TRAIN: 0.3409 0.7565 0.8932 | 0.3083 0.3083 0.1525 | 0.1184 22.5813 17.5493 0.3204 0.6224 0.7485 ||TEST: 1.3144 0.4156 0.6649 | 0.5239 0.5239 0.2086 | 0.1417 25.2509 20.3806 0.2801 0.5517 0.6815 | 116.4887
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.44613803 0.44612744 0.44615821 0.44615816 0.44613726 0.44611442
 0.44613629 0.44611162 0.44618811 0.44615074 0.44608262 0.44607221
 0.44609189 0.44606085 0.44606056 0.44606433 0.44610528 0.44609806
 0.44609868 0.4460194 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.44605076 0.44605535 0.44608313 0.44608825 0.44609671 0.44613191
 0.44610563 0.44609385 0.44610053 0.44609113 0.44609061 0.44611818
 0.44613056 0.44605895 0.44611065 0.44611465 0.44612053 0.44613753
 0.44615608 0.4461838 ]
[0.  0.5 0. ]
-----------end of analyzing the loss ratio:75.4365782737732
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6e944f0>
---------------------------------
SparseEpoch: [134][1/398]	Time 0.578	Data 0.000	Loss 0.4093	
SparseEpoch: [134][101/398]	Time 0.580	Data 0.000	Loss 0.3908	
SparseEpoch: [134][201/398]	Time 0.580	Data 0.000	Loss 0.4190	
SparseEpoch: [134][301/398]	Time 0.580	Data 0.000	Loss 0.8289	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.36275171 0.36275831 0.36276056 0.36279773 0.36274579 0.36269016
 0.36264315 0.36263692 0.36265627 0.36262522 0.36260861 0.3626036
 0.36255321 0.36250214 0.36248218 0.3624527  0.3624644  0.36240499
 0.36247447 0.36247907]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.36258747 0.36259315 0.36258575 0.36258783 0.36258273 0.36258483
 0.36259383 0.36258678 0.36258776 0.36259023 0.36259369 0.36258223
 0.36258819 0.36258874 0.36258615 0.36259651 0.3626045  0.36259868
 0.3626357  0.36263144]
[0.39473684 0.         0.07894737]
-----------end of analyzing the loss ratio:75.79011249542236
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc5523e0>
---------------------------------
SparseEpoch: [134][1/398]	Time 0.587	Data 0.000	Loss 0.4871	
SparseEpoch: [134][101/398]	Time 0.581	Data 0.000	Loss 0.5661	
SparseEpoch: [134][201/398]	Time 0.581	Data 0.000	Loss 0.6335	
SparseEpoch: [134][301/398]	Time 0.581	Data 0.000	Loss 0.4140	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.12930204 0.12929997 0.12930172 0.12927701 0.12925868 0.12923446
 0.1292265  0.12923967 0.12921985 0.12924247 0.12926884 0.1292565
 0.12925398 0.12921108 0.12922685 0.12922123 0.12921041 0.12920715
 0.12922433 0.1291761 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.12922333 0.12921069 0.1291992  0.12921184 0.12921263 0.12922589
 0.12923782 0.12924435 0.12925141 0.12925963 0.12925513 0.12924739
 0.12924325 0.1292536  0.12924362 0.1292483  0.12925683 0.1292339
 0.12924378 0.12924314]
[0.5 0.  0. ]
-----------end of analyzing the loss ratio:75.4139449596405
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x744609945ab0>
---------------------------------
SparseEpoch: [134][1/398]	Time 0.578	Data 0.000	Loss 2.1332	
SparseEpoch: [134][101/398]	Time 0.579	Data 0.000	Loss 0.7785	
SparseEpoch: [134][201/398]	Time 0.580	Data 0.000	Loss 1.5786	
SparseEpoch: [134][301/398]	Time 0.580	Data 0.000	Loss 1.0134	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.6932	
Epoch(adapt):{0} Loss 0.7639	
Epoch(adapt):{0} Loss 0.6920	
Epoch(adapt):{0} Loss 0.7875	
------------------the total time cost:1167.3577597141266
>>>>>meta updating
Epoch: 0134 | TRAIN: 0.3255 0.7562 0.8955 | 0.2999 0.2999 0.1420 | 0.1156 22.1509 16.9918 0.3361 0.6340 0.7556 ||TEST: 1.3236 0.4130 0.6643 | 0.5288 0.5288 0.2115 | 0.1418 25.1638 20.1694 0.2866 0.5562 0.6831 | 117.3429
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.36868339 0.3686513  0.36867327 0.36860967 0.36857915 0.36859643
 0.36857277 0.36861401 0.36855084 0.36858294 0.36851473 0.36848716
 0.36842248 0.36841082 0.36842118 0.36842014 0.36847488 0.36844736
 0.36842818 0.36845865]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.36865913 0.36868778 0.36866387 0.36866733 0.36866132 0.36862528
 0.36863983 0.36856117 0.36856834 0.36852811 0.36851153 0.36843767
 0.36852292 0.36848471 0.36850033 0.36846098 0.36845029 0.36839805
 0.36839593 0.36840334]
[0.         0.18421053 0.44736842]
-----------end of analyzing the loss ratio:75.49676370620728
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc3880a0>
---------------------------------
SparseEpoch: [135][1/398]	Time 0.581	Data 0.000	Loss 0.8483	
SparseEpoch: [135][101/398]	Time 0.582	Data 0.000	Loss 0.8593	
SparseEpoch: [135][201/398]	Time 0.581	Data 0.000	Loss 0.6756	
SparseEpoch: [135][301/398]	Time 0.581	Data 0.000	Loss 0.9880	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.3874478  0.38738351 0.38716891 0.38705138 0.38683102 0.38675357
 0.38652384 0.38638306 0.38633437 0.38613891 0.38596578 0.38586906
 0.38566348 0.38554944 0.38534847 0.3851294  0.38507388 0.38511084
 0.38505866 0.38492954]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.38624188 0.38619864 0.3861807  0.38618623 0.38618405 0.38613204
 0.38605301 0.38601758 0.38600547 0.38601722 0.38600435 0.38600758
 0.38599973 0.38596478 0.38597376 0.38597319 0.38597156 0.38595937
 0.38598461 0.3859611 ]
[0.5        0.         0.39473684]
-----------end of analyzing the loss ratio:75.49792814254761
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d71a36a0>
---------------------------------
SparseEpoch: [135][1/398]	Time 0.579	Data 0.000	Loss 0.5859	
SparseEpoch: [135][101/398]	Time 0.581	Data 0.000	Loss 1.0246	
SparseEpoch: [135][201/398]	Time 0.581	Data 0.000	Loss 0.8254	
SparseEpoch: [135][301/398]	Time 0.581	Data 0.000	Loss 0.7036	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.12176922 0.12176738 0.12176527 0.1217743  0.12176543 0.12176903
 0.1217675  0.12176138 0.12176367 0.12175343 0.12174805 0.12174701
 0.12171684 0.12173047 0.12175058 0.12174869 0.12172819 0.12172702
 0.12172567 0.12173033]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.12175464 0.12172017 0.12172722 0.12175146 0.1217335  0.12173715
 0.12172999 0.12175087 0.12173154 0.12174878 0.1217595  0.12177231
 0.12176651 0.12177468 0.12177911 0.12178503 0.12182302 0.12183535
 0.12181475 0.12179694]
[0.13157895 0.         0.        ]
-----------end of analyzing the loss ratio:75.31358242034912
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7446099ff820>
---------------------------------
SparseEpoch: [135][1/398]	Time 0.578	Data 0.000	Loss 1.1366	
SparseEpoch: [135][101/398]	Time 0.582	Data 0.000	Loss 1.0082	
SparseEpoch: [135][201/398]	Time 0.581	Data 0.000	Loss 1.6785	
SparseEpoch: [135][301/398]	Time 0.581	Data 0.000	Loss 1.9111	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.7256	
Epoch(adapt):{0} Loss 0.9601	
Epoch(adapt):{0} Loss 0.5816	
Epoch(adapt):{0} Loss 0.4784	
------------------the total time cost:1166.6698939800262
>>>>>meta updating
Epoch: 0135 | TRAIN: 0.3183 0.7731 0.8999 | 0.2994 0.2994 0.1440 | 0.1149 22.0769 16.9501 0.3363 0.6363 0.7576 ||TEST: 1.3518 0.4192 0.6638 | 0.5203 0.5203 0.2079 | 0.1412 25.1213 20.0753 0.2862 0.5571 0.6841 | 116.8954
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.35961451 0.35954344 0.3594584  0.35941821 0.3594182  0.35938525
 0.35939036 0.3593387  0.35931725 0.35926951 0.35929089 0.35928489
 0.35922135 0.3591573  0.35910505 0.35907107 0.35907623 0.35916333
 0.35910176 0.35902681]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.35927239 0.35927135 0.35926356 0.35927959 0.35928465 0.35928521
 0.35928741 0.35927477 0.35927293 0.359282   0.35927721 0.35927073
 0.35926103 0.35925875 0.35927036 0.35924946 0.35925934 0.35925323
 0.35924681 0.3592509 ]
[0.         0.5        0.44736842]
-----------end of analyzing the loss ratio:75.40015864372253
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc12f790>
---------------------------------
SparseEpoch: [136][1/398]	Time 0.579	Data 0.000	Loss 1.1089	
SparseEpoch: [136][101/398]	Time 0.581	Data 0.000	Loss 0.6728	
SparseEpoch: [136][201/398]	Time 0.581	Data 0.000	Loss 0.6828	
SparseEpoch: [136][301/398]	Time 0.581	Data 0.000	Loss 0.9521	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.45050041 0.45018667 0.44980245 0.44958272 0.44922946 0.44899703
 0.44875109 0.4484076  0.44797275 0.44777545 0.44749621 0.44741693
 0.44703339 0.44660652 0.44624819 0.44586863 0.44571803 0.44539331
 0.44511542 0.44498418]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.44771844 0.44771984 0.44771754 0.44770748 0.44770086 0.4477
 0.44770482 0.4476739  0.44767502 0.44768089 0.44767904 0.44767069
 0.44766321 0.44766057 0.44766225 0.44767456 0.44767544 0.44765127
 0.44766056 0.44764546]
[0.5 0.  0.5]
-----------end of analyzing the loss ratio:75.68772268295288
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc0ef970>
---------------------------------
SparseEpoch: [136][1/398]	Time 0.579	Data 0.000	Loss 0.7829	
SparseEpoch: [136][101/398]	Time 0.581	Data 0.000	Loss 1.1692	
SparseEpoch: [136][201/398]	Time 0.581	Data 0.000	Loss 1.3238	
SparseEpoch: [136][301/398]	Time 0.581	Data 0.000	Loss 1.1278	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.13736621 0.13735952 0.13734715 0.13735927 0.13735833 0.13735728
 0.13733348 0.13733553 0.13731569 0.13731496 0.13732528 0.13732504
 0.13731062 0.13728779 0.1372759  0.13726322 0.13726847 0.13725866
 0.13724486 0.13724256]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.13728232 0.13727907 0.13728897 0.13729582 0.13730829 0.13729902
 0.13730891 0.13729627 0.13730196 0.13731771 0.13732461 0.13731915
 0.13733461 0.1373449  0.13733819 0.13733375 0.13732713 0.13731424
 0.13730485 0.13731975]
[0.5 0.  0. ]
-----------end of analyzing the loss ratio:75.69567847251892
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc0be440>
---------------------------------
SparseEpoch: [136][1/398]	Time 0.578	Data 0.000	Loss 1.6192	
SparseEpoch: [136][101/398]	Time 0.580	Data 0.000	Loss 1.5240	
SparseEpoch: [136][201/398]	Time 0.581	Data 0.000	Loss 1.3439	
SparseEpoch: [136][301/398]	Time 0.580	Data 0.000	Loss 1.4784	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.6840	
Epoch(adapt):{0} Loss 0.7280	
Epoch(adapt):{0} Loss 0.8811	
Epoch(adapt):{0} Loss 0.8669	
------------------the total time cost:1167.9511897563934
>>>>>meta updating
Epoch: 0136 | TRAIN: 0.3193 0.7678 0.8997 | 0.3357 0.3357 0.1535 | 0.1172 22.4911 17.4173 0.3215 0.6252 0.7504 ||TEST: 1.2301 0.4133 0.6661 | 0.5527 0.5527 0.2111 | 0.1413 25.3112 20.4369 0.2746 0.5506 0.6807 | 117.0673
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.29525839 0.29525065 0.29517308 0.29511359 0.29512751 0.29516139
 0.29514118 0.29506522 0.29503733 0.29499918 0.29497696 0.29497464
 0.29490334 0.29487936 0.29492016 0.2949237  0.29494908 0.29494305
 0.29491735 0.29487362]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.2950092  0.29500715 0.29499394 0.29499112 0.29498364 0.29497916
 0.29497977 0.2949744  0.29498528 0.29498044 0.29496328 0.29497843
 0.29497678 0.2949891  0.29497482 0.29497292 0.29497698 0.29497672
 0.29497583 0.29497377]
[0.         0.5        0.02631579]
-----------end of analyzing the loss ratio:75.25796389579773
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x744609947670>
---------------------------------
SparseEpoch: [137][1/398]	Time 0.590	Data 0.000	Loss 0.4068	
SparseEpoch: [137][101/398]	Time 0.581	Data 0.000	Loss 0.5411	
SparseEpoch: [137][201/398]	Time 0.581	Data 0.000	Loss 0.7793	
SparseEpoch: [137][301/398]	Time 0.581	Data 0.000	Loss 0.4201	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.43843695 0.43838739 0.43836908 0.43837878 0.43820252 0.4380964
 0.43800254 0.43794278 0.43788309 0.43781862 0.43776724 0.43776414
 0.43777773 0.43771184 0.43776007 0.43776076 0.43769346 0.43768468
 0.4376536  0.43765285]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.43791404 0.43790872 0.4378953  0.4378873  0.43786622 0.43785878
 0.43784205 0.43784788 0.4378616  0.43787056 0.437866   0.43781847
 0.4377984  0.43772579 0.43773704 0.43771877 0.43775526 0.43774399
 0.43772264 0.43771528]
[0.5 0.  0.5]
-----------end of analyzing the loss ratio:75.63141965866089
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444dc3b4cd0>
---------------------------------
SparseEpoch: [137][1/398]	Time 0.597	Data 0.000	Loss 1.3556	
SparseEpoch: [137][101/398]	Time 0.582	Data 0.000	Loss 1.1983	
SparseEpoch: [137][201/398]	Time 0.582	Data 0.000	Loss 1.3666	
SparseEpoch: [137][301/398]	Time 0.582	Data 0.000	Loss 1.0216	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.12120061 0.12120326 0.12119798 0.12119466 0.12120813 0.12119206
 0.12116359 0.12113019 0.1211503  0.12111993 0.1211113  0.121097
 0.12108154 0.12104828 0.121035   0.12101347 0.12102959 0.12101784
 0.12100127 0.1210148 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.12112873 0.1211337  0.1211215  0.12110661 0.1211153  0.12110379
 0.12111053 0.12111918 0.12111569 0.12111959 0.12111474 0.12111452
 0.12111894 0.12112327 0.12111287 0.12110862 0.121097   0.1210973
 0.12109292 0.12108338]
[0.44736842 0.5        0.        ]
-----------end of analyzing the loss ratio:75.42261385917664
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6f0f310>
---------------------------------
SparseEpoch: [137][1/398]	Time 0.580	Data 0.000	Loss 1.5994	
SparseEpoch: [137][101/398]	Time 0.581	Data 0.000	Loss 1.3191	
SparseEpoch: [137][201/398]	Time 0.581	Data 0.000	Loss 1.3508	
SparseEpoch: [137][301/398]	Time 0.581	Data 0.000	Loss 2.4631	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.7451	
Epoch(adapt):{0} Loss 0.6376	
Epoch(adapt):{0} Loss 0.6520	
Epoch(adapt):{0} Loss 0.5692	
------------------the total time cost:1167.7338485717773
>>>>>meta updating
Epoch: 0137 | TRAIN: 0.3302 0.7597 0.8973 | 0.3369 0.3369 0.1508 | 0.1153 22.1580 17.0512 0.3342 0.6336 0.7561 ||TEST: 1.2348 0.4128 0.6672 | 0.5563 0.5563 0.2122 | 0.1415 25.1449 20.1310 0.2854 0.5566 0.6843 | 116.6312
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.32496559 0.32497986 0.32493786 0.3249435  0.32488411 0.32484404
 0.3248443  0.32483819 0.32484676 0.3248318  0.32487342 0.32489792
 0.32491207 0.32486109 0.32489023 0.32488366 0.32492519 0.32497023
 0.32498902 0.32494226]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.3248799  0.32489351 0.3248807  0.32488554 0.32485906 0.32486784
 0.32486781 0.32487642 0.32484634 0.32484716 0.32484394 0.32486819
 0.32488178 0.32488357 0.32490418 0.32491282 0.32492475 0.32492255
 0.32494053 0.32494545]
[0.         0.         0.02631579]
-----------end of analyzing the loss ratio:75.43929386138916
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444dc2bb790>
---------------------------------
SparseEpoch: [138][1/398]	Time 0.578	Data 0.000	Loss 0.2991	
SparseEpoch: [138][101/398]	Time 0.580	Data 0.000	Loss 0.2603	
SparseEpoch: [138][201/398]	Time 0.580	Data 0.000	Loss 0.3310	
SparseEpoch: [138][301/398]	Time 0.580	Data 0.000	Loss 0.6166	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.35993323 0.35992815 0.35994895 0.36005903 0.36008907 0.36003548
 0.36002796 0.36001796 0.36003436 0.36007946 0.36009806 0.36003048
 0.35996937 0.35997781 0.35992572 0.35992288 0.35986088 0.35994338
 0.35988734 0.35991753]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.36006676 0.36008314 0.36008343 0.3600926  0.36009315 0.36010969
 0.360102   0.36009751 0.36008935 0.36008543 0.36007794 0.36007528
 0.36008587 0.36008323 0.36010635 0.36011522 0.36012375 0.36010874
 0.36008259 0.36009743]
[0.34210526 0.         0.        ]
-----------end of analyzing the loss ratio:75.77865362167358
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc324ca0>
---------------------------------
SparseEpoch: [138][1/398]	Time 0.578	Data 0.000	Loss 0.2734	
SparseEpoch: [138][101/398]	Time 0.581	Data 0.000	Loss 0.5806	
SparseEpoch: [138][201/398]	Time 0.581	Data 0.000	Loss 0.3497	
SparseEpoch: [138][301/398]	Time 0.581	Data 0.000	Loss 0.3817	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.12055606 0.12055851 0.12055495 0.12054566 0.12054999 0.1205533
 0.12054967 0.12054881 0.12053923 0.12053227 0.12053372 0.12052703
 0.12052468 0.12052412 0.12052036 0.12051669 0.12051376 0.12051418
 0.12052419 0.12051676]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.12053546 0.12053632 0.12052963 0.12053222 0.12053475 0.12053319
 0.12053702 0.12053236 0.12052955 0.12053171 0.12053134 0.12053369
 0.12054214 0.12053911 0.12054424 0.12054098 0.1205394  0.12053908
 0.12053497 0.12053578]
[0.34210526 0.         0.        ]
-----------end of analyzing the loss ratio:75.41437649726868
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444dc17bb50>
---------------------------------
SparseEpoch: [138][1/398]	Time 0.578	Data 0.000	Loss 0.7266	
SparseEpoch: [138][101/398]	Time 0.580	Data 0.000	Loss 1.1775	
SparseEpoch: [138][201/398]	Time 0.580	Data 0.000	Loss 1.1562	
SparseEpoch: [138][301/398]	Time 0.580	Data 0.000	Loss 1.1329	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.6044	
Epoch(adapt):{0} Loss 0.8238	
Epoch(adapt):{0} Loss 0.6361	
Epoch(adapt):{0} Loss 0.7430	
------------------the total time cost:1167.3500945568085
>>>>>meta updating
Epoch: 0138 | TRAIN: 0.3101 0.7666 0.9013 | 0.3138 0.3138 0.1521 | 0.1157 22.2262 17.2577 0.3310 0.6292 0.7542 ||TEST: 1.2955 0.4193 0.6703 | 0.5241 0.5241 0.2085 | 0.1426 25.2775 20.3196 0.2850 0.5520 0.6793 | 116.6600
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.26997693 0.26989343 0.26990097 0.2698656  0.26991047 0.2699042
 0.26992385 0.26994027 0.2699667  0.26994295 0.26992835 0.26987239
 0.26984209 0.26978821 0.26984377 0.26978572 0.26983688 0.26984432
 0.26990186 0.26988336]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.26995343 0.26996223 0.26996099 0.26995145 0.26992301 0.26992904
 0.26992791 0.26993443 0.26993497 0.26994419 0.26994956 0.26996088
 0.26997236 0.26997257 0.26998402 0.26996234 0.26996688 0.26997422
 0.26994663 0.26995524]
[0.         0.28947368 0.        ]
-----------end of analyzing the loss ratio:75.57670474052429
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6cdbaf0>
---------------------------------
SparseEpoch: [139][1/398]	Time 0.578	Data 0.000	Loss 0.2780	
SparseEpoch: [139][101/398]	Time 0.581	Data 0.000	Loss 0.4444	
SparseEpoch: [139][201/398]	Time 0.580	Data 0.000	Loss 0.3683	
SparseEpoch: [139][301/398]	Time 0.580	Data 0.000	Loss 0.7029	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.41073056 0.41063227 0.41050979 0.41044354 0.41038469 0.41024457
 0.41020045 0.41018886 0.41014923 0.41012833 0.41013292 0.409993
 0.40993066 0.40990888 0.40983548 0.40984425 0.40978214 0.40977128
 0.4096943  0.40965646]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.41011322 0.41012791 0.41013184 0.41011551 0.41011319 0.41009412
 0.41008549 0.4100749  0.41010377 0.41012425 0.41011151 0.41009997
 0.41010485 0.4101026  0.41010443 0.41011408 0.41011418 0.41011655
 0.41012894 0.41012164]
[0.5 0.  0. ]
-----------end of analyzing the loss ratio:75.69989156723022
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6bd1b10>
---------------------------------
SparseEpoch: [139][1/398]	Time 0.584	Data 0.000	Loss 0.5424	
SparseEpoch: [139][101/398]	Time 0.581	Data 0.000	Loss 0.4840	
SparseEpoch: [139][201/398]	Time 0.581	Data 0.000	Loss 0.4540	
SparseEpoch: [139][301/398]	Time 0.581	Data 0.000	Loss 0.4502	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.1327991  0.13277175 0.13274652 0.13274287 0.13273217 0.13270115
 0.13266893 0.13266887 0.13269804 0.13267927 0.1326354  0.13261639
 0.13257111 0.13259389 0.13255576 0.13252144 0.13249416 0.13249222
 0.13245798 0.13243206]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.13276328 0.13277527 0.13274415 0.13273091 0.13271062 0.13266749
 0.1326703  0.13268167 0.13268539 0.13267516 0.13264062 0.13262643
 0.13258993 0.1326102  0.13262306 0.13263195 0.13259045 0.13254707
 0.13251522 0.13247573]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:75.47033166885376
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc27ae30>
---------------------------------
SparseEpoch: [139][1/398]	Time 0.578	Data 0.000	Loss 1.9436	
SparseEpoch: [139][101/398]	Time 0.582	Data 0.000	Loss 1.0592	
SparseEpoch: [139][201/398]	Time 0.582	Data 0.000	Loss 0.9204	
SparseEpoch: [139][301/398]	Time 0.582	Data 0.000	Loss 0.8961	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.7307	
Epoch(adapt):{0} Loss 0.8361	
Epoch(adapt):{0} Loss 0.7419	
Epoch(adapt):{0} Loss 0.5853	
------------------the total time cost:1168.8484303951263
>>>>>meta updating
Epoch: 0139 | TRAIN: 0.3062 0.7758 0.9022 | 0.3090 0.3090 0.1557 | 0.1178 22.5126 17.5467 0.3243 0.6208 0.7471 ||TEST: 1.3412 0.4165 0.6679 | 0.5165 0.5165 0.2101 | 0.1440 25.3939 20.4709 0.2862 0.5486 0.6758 | 116.7505
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.32806315 0.32804594 0.32809016 0.32810664 0.32809247 0.32812267
 0.32803819 0.32804397 0.32804018 0.32806025 0.3281397  0.32814671
 0.32819629 0.32826397 0.32833623 0.32832685 0.32834101 0.32834863
 0.32838086 0.32824091]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.32811809 0.32809275 0.32809646 0.3280976  0.32808276 0.32808693
 0.3281059  0.32810584 0.32811439 0.32814946 0.32815952 0.32812466
 0.32814167 0.32811792 0.32812764 0.32812769 0.32812795 0.32814978
 0.32812543 0.32812338]
[0. 0. 0.]
-----------end of analyzing the loss ratio:75.58764576911926
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6d06830>
---------------------------------
SparseEpoch: [140][1/398]	Time 0.580	Data 0.000	Loss 0.6682	
SparseEpoch: [140][101/398]	Time 0.580	Data 0.000	Loss 0.4631	
SparseEpoch: [140][201/398]	Time 0.580	Data 0.000	Loss 0.6308	
SparseEpoch: [140][301/398]	Time 0.580	Data 0.000	Loss 0.2867	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.37576391 0.37576126 0.37568063 0.37565398 0.3756381  0.37555171
 0.37554197 0.3755207  0.37548087 0.37545185 0.37539258 0.37536455
 0.37545631 0.37543649 0.37550897 0.37535927 0.37539812 0.37530961
 0.37523126 0.37529967]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.37548744 0.37546848 0.37546033 0.37544723 0.37545992 0.37544995
 0.37546049 0.37543713 0.3754195  0.37543821 0.37543631 0.37542398
 0.37542012 0.37543232 0.37540508 0.37540359 0.37545191 0.37544882
 0.37545186 0.37547274]
[0.44736842 0.         0.28947368]
-----------end of analyzing the loss ratio:75.61614727973938
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc129a50>
---------------------------------
SparseEpoch: [140][1/398]	Time 0.579	Data 0.000	Loss 0.8308	
SparseEpoch: [140][101/398]	Time 0.581	Data 0.000	Loss 0.7649	
SparseEpoch: [140][201/398]	Time 0.581	Data 0.000	Loss 0.5665	
SparseEpoch: [140][301/398]	Time 0.581	Data 0.000	Loss 0.9329	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.12843924 0.12843311 0.12843038 0.12842603 0.12841693 0.12842015
 0.12842543 0.12842202 0.12842607 0.12842532 0.12843234 0.12842852
 0.12842076 0.1284295  0.12842445 0.12842792 0.12843428 0.12843297
 0.12843885 0.12843553]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.12845442 0.12844841 0.12843318 0.12843899 0.12844286 0.12844648
 0.1284463  0.12843349 0.12842799 0.12843267 0.12842911 0.1284296
 0.12842705 0.1284308  0.12843436 0.12843941 0.12844073 0.12844808
 0.12845386 0.12844551]
[0.         0.13157895 0.        ]
-----------end of analyzing the loss ratio:75.39605450630188
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6bd2680>
---------------------------------
SparseEpoch: [140][1/398]	Time 0.578	Data 0.000	Loss 1.4104	
SparseEpoch: [140][101/398]	Time 0.581	Data 0.000	Loss 1.1858	
SparseEpoch: [140][201/398]	Time 0.580	Data 0.000	Loss 1.0951	
SparseEpoch: [140][301/398]	Time 0.580	Data 0.000	Loss 1.1259	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.8606	
Epoch(adapt):{0} Loss 0.7439	
Epoch(adapt):{0} Loss 0.8166	
Epoch(adapt):{0} Loss 0.5622	
------------------the total time cost:1166.8156967163086
>>>>>meta updating
Epoch: 0140 | TRAIN: 0.3031 0.7775 0.9042 | 0.3173 0.3173 0.1446 | 0.1156 22.2640 17.2871 0.3288 0.6283 0.7526 ||TEST: 1.2836 0.4221 0.6705 | 0.5390 0.5390 0.2104 | 0.1421 25.3111 20.5112 0.2804 0.5484 0.6778 | 116.9960
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.29035819 0.29036891 0.29032319 0.29039596 0.2903974  0.29041738
 0.29040846 0.29040358 0.29050874 0.29043284 0.29053295 0.29055113
 0.29052873 0.29054447 0.29044831 0.29052952 0.29056695 0.29049017
 0.290595   0.29060392]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.29037478 0.29039364 0.29040522 0.29041543 0.29040213 0.29041082
 0.29042087 0.29041248 0.29042373 0.2904389  0.29049335 0.2905357
 0.29053678 0.29054803 0.29053581 0.29056827 0.29063805 0.29063828
 0.29063311 0.29064574]
[0. 0. 0.]
-----------end of analyzing the loss ratio:75.45390176773071
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6d4d420>
---------------------------------
SparseEpoch: [141][1/398]	Time 0.577	Data 0.000	Loss 0.3180	
SparseEpoch: [141][101/398]	Time 0.581	Data 0.000	Loss 0.2199	
SparseEpoch: [141][201/398]	Time 0.581	Data 0.000	Loss 0.2696	
SparseEpoch: [141][301/398]	Time 0.580	Data 0.000	Loss 0.2763	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.35322067 0.35312735 0.35288434 0.35269196 0.35258972 0.35256056
 0.35240384 0.35227868 0.35218647 0.35206115 0.35180617 0.35165394
 0.35154434 0.35138232 0.35125061 0.35113403 0.35095857 0.35084345
 0.35073184 0.35060556]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.35215473 0.35206917 0.35204629 0.35206183 0.35208046 0.3520432
 0.35198343 0.35196551 0.35196467 0.35197559 0.35193554 0.35192236
 0.35185473 0.35183408 0.35181248 0.3517721  0.3517504  0.35176148
 0.35171522 0.35171191]
[0.5 0.  0.5]
-----------end of analyzing the loss ratio:75.83207511901855
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc2f4070>
---------------------------------
SparseEpoch: [141][1/398]	Time 0.578	Data 0.000	Loss 0.8521	
SparseEpoch: [141][101/398]	Time 0.581	Data 0.000	Loss 1.1048	
SparseEpoch: [141][201/398]	Time 0.581	Data 0.000	Loss 1.2171	
SparseEpoch: [141][301/398]	Time 0.581	Data 0.000	Loss 1.1572	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11611632 0.11610785 0.11610041 0.11609755 0.11608638 0.11607348
 0.11607597 0.11608502 0.11608711 0.11607304 0.11607711 0.1160744
 0.11607482 0.11605969 0.11605733 0.11605732 0.1160435  0.11605091
 0.11605168 0.1160616 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11609996 0.1160987  0.11608503 0.11610609 0.11609355 0.11608639
 0.11608581 0.11607542 0.11607834 0.11607935 0.11608387 0.11607422
 0.11608545 0.11607719 0.11606843 0.11607774 0.11606204 0.11606163
 0.11605712 0.11606203]
[0.34210526 0.44736842 0.        ]
-----------end of analyzing the loss ratio:75.61636424064636
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6cda320>
---------------------------------
SparseEpoch: [141][1/398]	Time 0.579	Data 0.000	Loss 0.9060	
SparseEpoch: [141][101/398]	Time 0.580	Data 0.000	Loss 0.8212	
SparseEpoch: [141][201/398]	Time 0.580	Data 0.000	Loss 1.3546	
SparseEpoch: [141][301/398]	Time 0.581	Data 0.000	Loss 1.9255	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.5531	
Epoch(adapt):{0} Loss 0.4752	
Epoch(adapt):{0} Loss 0.6370	
Epoch(adapt):{0} Loss 0.5655	
------------------the total time cost:1168.3791887760162
>>>>>meta updating
Epoch: 0141 | TRAIN: 0.3025 0.7763 0.9052 | 0.3081 0.3081 0.1467 | 0.1158 22.2909 17.3162 0.3271 0.6284 0.7532 ||TEST: 1.2897 0.4139 0.6690 | 0.5265 0.5265 0.2125 | 0.1432 25.3983 20.5377 0.2805 0.5479 0.6760 | 116.6076
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.35350148 0.3535     0.35345304 0.35350517 0.3535172  0.35357355
 0.35353204 0.35354876 0.35353162 0.35351838 0.35353317 0.35352688
 0.35347295 0.35350734 0.35349821 0.35350461 0.35348038 0.35352075
 0.35354373 0.35350271]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.35356462 0.3535655  0.35357375 0.35357131 0.35352664 0.35352807
 0.35353373 0.35353494 0.35351949 0.35352115 0.35352624 0.3535273
 0.35352605 0.35352735 0.35353127 0.35354245 0.35355372 0.35352369
 0.35352637 0.35352444]
[0. 0. 0.]
-----------end of analyzing the loss ratio:75.67392206192017
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6d4e710>
---------------------------------
SparseEpoch: [142][1/398]	Time 0.577	Data 0.000	Loss 0.2612	
SparseEpoch: [142][101/398]	Time 0.580	Data 0.000	Loss 0.2105	
SparseEpoch: [142][201/398]	Time 0.580	Data 0.000	Loss 0.6645	
SparseEpoch: [142][301/398]	Time 0.580	Data 0.000	Loss 0.3086	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.42116059 0.4212009  0.42123417 0.42118983 0.42120799 0.42117653
 0.42116409 0.42123649 0.42126206 0.42130701 0.42133483 0.42131896
 0.42129155 0.42125667 0.42123839 0.42118188 0.4211199  0.42109682
 0.42107396 0.42106052]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.42131207 0.42131414 0.42129698 0.42131235 0.42131598 0.42133414
 0.42133435 0.42129872 0.42128418 0.42133651 0.42134399 0.4213419
 0.42132141 0.42132098 0.42130613 0.42127055 0.42126883 0.42122963
 0.4212342  0.42119876]
[0.5 0.  0.5]
-----------end of analyzing the loss ratio:75.75096797943115
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7446096eb580>
---------------------------------
SparseEpoch: [142][1/398]	Time 0.579	Data 0.000	Loss 0.9587	
SparseEpoch: [142][101/398]	Time 0.581	Data 0.000	Loss 1.0355	
SparseEpoch: [142][201/398]	Time 0.581	Data 0.000	Loss 0.5849	
SparseEpoch: [142][301/398]	Time 0.581	Data 0.000	Loss 1.1286	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.10993256 0.10992717 0.10993295 0.1099318  0.10993464 0.10993076
 0.10993003 0.10991889 0.10992705 0.10994281 0.10993369 0.10993887
 0.10994917 0.10995148 0.10996869 0.10997255 0.10997999 0.10998741
 0.10997559 0.10995865]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.10992714 0.10993645 0.10993127 0.10993273 0.10993139 0.10992806
 0.10992216 0.10993181 0.10991976 0.10992253 0.10994037 0.10994934
 0.10995865 0.10996951 0.10997819 0.10998426 0.10998412 0.10998792
 0.10999186 0.10998326]
[0. 0. 0.]
-----------end of analyzing the loss ratio:75.56270551681519
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc0ed0c0>
---------------------------------
SparseEpoch: [142][1/398]	Time 0.577	Data 0.000	Loss 1.1695	
SparseEpoch: [142][101/398]	Time 0.579	Data 0.000	Loss 1.1605	
SparseEpoch: [142][201/398]	Time 0.579	Data 0.000	Loss 1.1377	
SparseEpoch: [142][301/398]	Time 0.579	Data 0.000	Loss 1.5257	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.7231	
Epoch(adapt):{0} Loss 0.7515	
Epoch(adapt):{0} Loss 1.0474	
Epoch(adapt):{0} Loss 0.7655	
------------------the total time cost:1167.6130728721619
>>>>>meta updating
Epoch: 0142 | TRAIN: 0.3170 0.7698 0.9000 | 0.3155 0.3155 0.1464 | 0.1150 22.1338 17.1965 0.3323 0.6330 0.7572 ||TEST: 1.3265 0.4243 0.6678 | 0.5349 0.5349 0.2104 | 0.1420 25.2072 20.2284 0.2854 0.5544 0.6820 | 116.8405
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.29190208 0.29190383 0.29201117 0.29200632 0.29200392 0.29201425
 0.29191847 0.29184695 0.29182133 0.29181181 0.29182407 0.29183359
 0.29186712 0.29184828 0.29187612 0.29184414 0.29178132 0.29176566
 0.29180531 0.29184409]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.29186533 0.29188837 0.29186901 0.29187154 0.291872   0.29183168
 0.29181666 0.29181193 0.2918028  0.29181848 0.29178332 0.29179401
 0.29180555 0.29183368 0.29181756 0.29182254 0.2918396  0.291821
 0.29181548 0.29183141]
[0.         0.39473684 0.02631579]
-----------end of analyzing the loss ratio:75.70611786842346
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6f0df90>
---------------------------------
SparseEpoch: [143][1/398]	Time 0.579	Data 0.000	Loss 0.4892	
SparseEpoch: [143][101/398]	Time 0.581	Data 0.000	Loss 0.3722	
SparseEpoch: [143][201/398]	Time 0.581	Data 0.000	Loss 0.5808	
SparseEpoch: [143][301/398]	Time 0.581	Data 0.000	Loss 0.4877	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.38677369 0.38673221 0.38675332 0.38669967 0.38665386 0.38668157
 0.38662604 0.38661845 0.386658   0.38671996 0.38675115 0.38668688
 0.38664396 0.38665875 0.38669349 0.38663238 0.38660763 0.38663948
 0.38668178 0.38666932]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.38673264 0.38673964 0.38674559 0.38676349 0.38676867 0.38677375
 0.38676962 0.38677095 0.38678109 0.38674973 0.3867617  0.38677387
 0.3867819  0.38678229 0.38677617 0.38676151 0.38675984 0.38673878
 0.38672276 0.38672369]
[0.34210526 0.         0.44736842]
-----------end of analyzing the loss ratio:75.80264210700989
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6d06050>
---------------------------------
SparseEpoch: [143][1/398]	Time 0.594	Data 0.000	Loss 0.8038	
SparseEpoch: [143][101/398]	Time 0.581	Data 0.000	Loss 0.7060	
SparseEpoch: [143][201/398]	Time 0.581	Data 0.000	Loss 0.9818	
SparseEpoch: [143][301/398]	Time 0.581	Data 0.000	Loss 0.6867	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11503811 0.11501537 0.11501607 0.11504686 0.11502216 0.11502761
 0.11499529 0.11493953 0.11491616 0.1148689  0.1148311  0.11481795
 0.11482268 0.11477789 0.11477436 0.11475334 0.11470867 0.114723
 0.11473805 0.11476386]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11504654 0.11500204 0.11501985 0.11500905 0.11501371 0.11500167
 0.11498264 0.1149565  0.1149276  0.11486883 0.11482864 0.11481763
 0.11478437 0.11479057 0.11477784 0.11476721 0.11474416 0.11474018
 0.11478781 0.11475521]
[0.34210526 0.39473684 0.        ]
-----------end of analyzing the loss ratio:75.49890780448914
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc509c00>
---------------------------------
SparseEpoch: [143][1/398]	Time 0.579	Data 0.000	Loss 1.7511	
SparseEpoch: [143][101/398]	Time 0.582	Data 0.000	Loss 1.0646	
SparseEpoch: [143][201/398]	Time 0.582	Data 0.000	Loss 1.5571	
SparseEpoch: [143][301/398]	Time 0.582	Data 0.000	Loss 1.2743	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.7344	
Epoch(adapt):{0} Loss 0.5208	
Epoch(adapt):{0} Loss 1.2512	
Epoch(adapt):{0} Loss 0.7293	
------------------the total time cost:1168.9449474811554
>>>>>meta updating
Epoch: 0143 | TRAIN: 0.3082 0.7688 0.9035 | 0.3310 0.3310 0.1533 | 0.1156 22.2568 17.3006 0.3273 0.6304 0.7547 ||TEST: 1.2793 0.4121 0.6663 | 0.5458 0.5458 0.2156 | 0.1416 25.2528 20.3744 0.2811 0.5514 0.6803 | 117.1537
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.25864418 0.25852527 0.25856524 0.25857523 0.258585   0.2584811
 0.25852097 0.2585532  0.25849815 0.25854111 0.25851975 0.25847395
 0.25844487 0.25839704 0.25827231 0.25827245 0.25824642 0.25820891
 0.25815925 0.25815841]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.25849963 0.25849463 0.25849676 0.25850255 0.25851019 0.2585461
 0.25854146 0.25854299 0.25854079 0.2585558  0.25854104 0.25853903
 0.25853808 0.25854326 0.25854514 0.25855188 0.25855892 0.25855917
 0.25853893 0.25854148]
[0.  0.5 0. ]
-----------end of analyzing the loss ratio:75.55076670646667
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6aa2e60>
---------------------------------
SparseEpoch: [144][1/398]	Time 0.578	Data 0.000	Loss 0.4385	
SparseEpoch: [144][101/398]	Time 0.581	Data 0.000	Loss 0.6049	
SparseEpoch: [144][201/398]	Time 0.580	Data 0.000	Loss 0.3279	
SparseEpoch: [144][301/398]	Time 0.580	Data 0.000	Loss 0.4895	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.32632806 0.32632215 0.32627978 0.32629283 0.32634665 0.32635691
 0.32637957 0.32634189 0.32638735 0.32636383 0.32631698 0.32636836
 0.32640031 0.32640703 0.32641767 0.32642654 0.32640962 0.32646639
 0.32646716 0.32648797]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.32639187 0.32639038 0.32639145 0.32637803 0.3263567  0.32635757
 0.32635991 0.32637248 0.32637848 0.32637468 0.32636031 0.3263708
 0.32637749 0.32635177 0.32636648 0.32637328 0.32636626 0.32636986
 0.32637899 0.32635429]
[0.         0.         0.18421053]
-----------end of analyzing the loss ratio:75.64233207702637
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6b90a00>
---------------------------------
SparseEpoch: [144][1/398]	Time 0.578	Data 0.000	Loss 0.5625	
SparseEpoch: [144][101/398]	Time 0.581	Data 0.000	Loss 0.4193	
SparseEpoch: [144][201/398]	Time 0.581	Data 0.000	Loss 0.7119	
SparseEpoch: [144][301/398]	Time 0.581	Data 0.000	Loss 0.4208	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.1196676  0.11965309 0.11964301 0.11963557 0.11963978 0.11962951
 0.11962652 0.11962999 0.11964473 0.11965733 0.11966065 0.11967177
 0.11966741 0.11966382 0.11964797 0.11964498 0.11965076 0.11963468
 0.1196323  0.1196232 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11968051 0.1196798  0.11966828 0.11966508 0.11966136 0.11964847
 0.1196553  0.11964315 0.11964911 0.11965266 0.1196529  0.11966452
 0.11966981 0.1196597  0.11965603 0.11965169 0.11964941 0.11964375
 0.1196483  0.11965341]
[0.5 0.  0. ]
-----------end of analyzing the loss ratio:75.72411751747131
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6cb1480>
---------------------------------
SparseEpoch: [144][1/398]	Time 0.579	Data 0.000	Loss 1.7097	
SparseEpoch: [144][101/398]	Time 0.580	Data 0.000	Loss 0.8468	
SparseEpoch: [144][201/398]	Time 0.580	Data 0.000	Loss 1.3852	
SparseEpoch: [144][301/398]	Time 0.580	Data 0.000	Loss 1.4523	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.7837	
Epoch(adapt):{0} Loss 0.6046	
Epoch(adapt):{0} Loss 0.6561	
Epoch(adapt):{0} Loss 0.5067	
------------------the total time cost:1167.4325835704803
>>>>>meta updating
Epoch: 0144 | TRAIN: 0.3090 0.7782 0.9027 | 0.3019 0.3019 0.1533 | 0.1148 22.0634 17.0105 0.3371 0.6354 0.7572 ||TEST: 1.4242 0.4158 0.6652 | 0.5131 0.5131 0.2114 | 0.1415 25.1144 20.0884 0.2889 0.5564 0.6837 | 117.4039
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.2570865  0.25708674 0.25706969 0.2570279  0.25713716 0.25717983
 0.25719443 0.25720017 0.25713362 0.25714802 0.25716191 0.25717474
 0.25718758 0.25710127 0.25711103 0.25709928 0.25695662 0.25689077
 0.25677617 0.25679726]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.25709738 0.25709266 0.25708932 0.25708855 0.25710957 0.25712948
 0.25714469 0.25714339 0.25715502 0.25714624 0.25714822 0.25714384
 0.25713605 0.25713287 0.25715678 0.25716073 0.25714894 0.25716107
 0.2571528  0.25716611]
[0.         0.44736842 0.        ]
-----------end of analyzing the loss ratio:75.62122464179993
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444dc17a9b0>
---------------------------------
SparseEpoch: [145][1/398]	Time 0.578	Data 0.000	Loss 0.3569	
SparseEpoch: [145][101/398]	Time 0.580	Data 0.000	Loss 0.5877	
SparseEpoch: [145][201/398]	Time 0.580	Data 0.000	Loss 0.3070	
SparseEpoch: [145][301/398]	Time 0.581	Data 0.000	Loss 0.8478	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.34127635 0.34126316 0.3411697  0.34120648 0.34118668 0.34120076
 0.34118683 0.34119644 0.34117163 0.34120683 0.34126788 0.34128716
 0.34135971 0.34131687 0.34129707 0.34125282 0.34127722 0.34124965
 0.34126974 0.34118599]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.34124893 0.34123544 0.34123799 0.34125115 0.34123827 0.34122078
 0.34122747 0.34123019 0.34124908 0.34127465 0.34126315 0.34125249
 0.34124825 0.34125815 0.34124003 0.34125539 0.34125639 0.34126377
 0.34125907 0.34127796]
[0. 0. 0.]
-----------end of analyzing the loss ratio:75.6576521396637
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7446091a21d0>
---------------------------------
SparseEpoch: [145][1/398]	Time 0.578	Data 0.000	Loss 0.2484	
SparseEpoch: [145][101/398]	Time 0.579	Data 0.000	Loss 0.2230	
SparseEpoch: [145][201/398]	Time 0.579	Data 0.000	Loss 0.3348	
SparseEpoch: [145][301/398]	Time 0.579	Data 0.000	Loss 0.2907	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11243173 0.11240374 0.11239735 0.11240472 0.11242853 0.11240449
 0.11242393 0.112378   0.1123664  0.11237676 0.11240711 0.11240032
 0.11240152 0.11241891 0.11242388 0.11239905 0.11240202 0.11238492
 0.11236522 0.11234505]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11242967 0.11242176 0.11241594 0.11243513 0.11242633 0.11242451
 0.11242781 0.11241305 0.11240667 0.11240202 0.11239954 0.11238289
 0.1123688  0.11236839 0.11237429 0.112378   0.11237259 0.11235976
 0.1123762  0.11238049]
[0.5        0.39473684 0.        ]
-----------end of analyzing the loss ratio:75.89823698997498
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d7044a60>
---------------------------------
SparseEpoch: [145][1/398]	Time 0.579	Data 0.000	Loss 1.1775	
SparseEpoch: [145][101/398]	Time 0.581	Data 0.000	Loss 1.3975	
SparseEpoch: [145][201/398]	Time 0.581	Data 0.000	Loss 0.9043	
SparseEpoch: [145][301/398]	Time 0.580	Data 0.000	Loss 1.4141	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.2983	
Epoch(adapt):{0} Loss 0.4931	
Epoch(adapt):{0} Loss 0.8523	
Epoch(adapt):{0} Loss 0.6870	
------------------the total time cost:1167.5732250213623
>>>>>meta updating
Epoch: 0145 | TRAIN: 0.3097 0.7738 0.9002 | 0.3026 0.3026 0.1522 | 0.1133 21.8444 16.6805 0.3441 0.6419 0.7619 ||TEST: 1.3206 0.4120 0.6661 | 0.5178 0.5178 0.2119 | 0.1417 25.0939 19.9907 0.2912 0.5581 0.6845 | 117.3030
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.34185835 0.34186953 0.3419729  0.34209337 0.34207084 0.34210785
 0.34202879 0.34203555 0.34204694 0.34208394 0.34214456 0.34215183
 0.34213799 0.34216904 0.34217512 0.34219061 0.34219361 0.34222331
 0.3422151  0.34219767]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.34213879 0.34213181 0.34214117 0.34213375 0.34213522 0.34213638
 0.34213126 0.34213229 0.34213706 0.34211165 0.3421174  0.34209722
 0.34208129 0.34205351 0.34204375 0.34199758 0.34196413 0.34198181
 0.34198582 0.3419862 ]
[0.         0.         0.34210526]
-----------end of analyzing the loss ratio:75.50215148925781
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444dc2a2260>
---------------------------------
SparseEpoch: [146][1/398]	Time 0.580	Data 0.000	Loss 1.0291	
SparseEpoch: [146][101/398]	Time 0.580	Data 0.000	Loss 0.5561	
SparseEpoch: [146][201/398]	Time 0.581	Data 0.000	Loss 0.9545	
SparseEpoch: [146][301/398]	Time 0.581	Data 0.000	Loss 0.4351	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.35921647 0.35915931 0.35898005 0.35885811 0.35872244 0.35858306
 0.35846008 0.35834786 0.35829338 0.35813359 0.35796966 0.35789508
 0.35784587 0.35774402 0.35754195 0.3574563  0.35733889 0.35726161
 0.35713695 0.35701713]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.35815904 0.35813401 0.35814893 0.35809115 0.35807265 0.35805563
 0.35807556 0.3580498  0.35808165 0.35806234 0.35802621 0.35799615
 0.35797647 0.35796225 0.35793188 0.35791125 0.35791723 0.35794163
 0.35796411 0.35795819]
[0.5        0.         0.28947368]
-----------end of analyzing the loss ratio:75.53000378608704
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6b443a0>
---------------------------------
SparseEpoch: [146][1/398]	Time 0.582	Data 0.000	Loss 0.5965	
SparseEpoch: [146][101/398]	Time 0.581	Data 0.000	Loss 0.8371	
SparseEpoch: [146][201/398]	Time 0.581	Data 0.000	Loss 0.6923	
SparseEpoch: [146][301/398]	Time 0.581	Data 0.000	Loss 0.8554	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.1179705  0.11794036 0.11793652 0.1178754  0.11787639 0.11783142
 0.11780504 0.11780043 0.11774328 0.11765378 0.11760712 0.11758541
 0.11755592 0.11749179 0.11740308 0.11734525 0.11727983 0.11720473
 0.1171623  0.11711467]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11775121 0.11774464 0.11774617 0.11774289 0.11775299 0.11777677
 0.11774239 0.11769898 0.11767359 0.11765112 0.11764232 0.11761686
 0.11760455 0.1176048  0.11759951 0.11758791 0.11759888 0.11757559
 0.11752492 0.11752079]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:75.80642747879028
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6c5c160>
---------------------------------
SparseEpoch: [146][1/398]	Time 0.589	Data 0.000	Loss 1.2969	
SparseEpoch: [146][101/398]	Time 0.581	Data 0.000	Loss 1.3014	
SparseEpoch: [146][201/398]	Time 0.581	Data 0.000	Loss 1.4197	
SparseEpoch: [146][301/398]	Time 0.581	Data 0.000	Loss 1.4222	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 1.0012	
Epoch(adapt):{0} Loss 0.7830	
Epoch(adapt):{0} Loss 0.6816	
Epoch(adapt):{0} Loss 0.6269	
------------------the total time cost:1167.0069777965546
>>>>>meta updating
Epoch: 0146 | TRAIN: 0.2932 0.7810 0.9072 | 0.3036 0.3036 0.1528 | 0.1119 21.7138 16.5580 0.3448 0.6451 0.7647 ||TEST: 1.3562 0.4162 0.6664 | 0.5185 0.5185 0.2122 | 0.1413 25.0668 19.9603 0.2896 0.5597 0.6864 | 117.2648
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.26206869 0.26213959 0.26211806 0.26199677 0.26209011 0.26218509
 0.26225086 0.26224976 0.26224183 0.26220808 0.26225989 0.26233399
 0.26233228 0.26230731 0.26229597 0.26232635 0.2623467  0.26242223
 0.26230348 0.26227196]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.26222912 0.26224318 0.26223824 0.2622393  0.26223789 0.26224846
 0.26224262 0.2622424  0.26223961 0.26223917 0.26223986 0.26224066
 0.26224128 0.26224266 0.26222944 0.26223194 0.26223789 0.26223393
 0.26223747 0.26222808]
[0.  0.  0.5]
-----------end of analyzing the loss ratio:75.64816188812256
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc5eb8b0>
---------------------------------
SparseEpoch: [147][1/398]	Time 0.578	Data 0.000	Loss 0.8097	
SparseEpoch: [147][101/398]	Time 0.581	Data 0.000	Loss 1.1549	
SparseEpoch: [147][201/398]	Time 0.581	Data 0.000	Loss 0.7602	
SparseEpoch: [147][301/398]	Time 0.581	Data 0.000	Loss 0.9703	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.37559031 0.37549961 0.37545705 0.37532268 0.37522517 0.37527207
 0.37518176 0.37502092 0.37492649 0.3747822  0.37464561 0.37459264
 0.3744961  0.37438422 0.37431887 0.37427864 0.3741815  0.37407561
 0.3740056  0.3739408 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.37498506 0.37493971 0.37492717 0.37493051 0.37490641 0.37485839
 0.37481638 0.37477855 0.37476282 0.37473522 0.37470954 0.37469994
 0.3746766  0.37466547 0.3746393  0.37463498 0.37464377 0.37466471
 0.37465389 0.3746424 ]
[0.5        0.         0.28947368]
-----------end of analyzing the loss ratio:75.74631190299988
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc11d4b0>
---------------------------------
SparseEpoch: [147][1/398]	Time 0.579	Data 0.000	Loss 0.6501	
SparseEpoch: [147][101/398]	Time 0.580	Data 0.000	Loss 0.7428	
SparseEpoch: [147][201/398]	Time 0.581	Data 0.000	Loss 1.0968	
SparseEpoch: [147][301/398]	Time 0.581	Data 0.000	Loss 0.7362	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11087772 0.11088734 0.11087169 0.11086931 0.11087412 0.1108625
 0.11086586 0.11087882 0.11089185 0.11087999 0.11086096 0.11086937
 0.11088944 0.11089603 0.11088717 0.11085629 0.11085299 0.11085805
 0.11087644 0.11088261]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.1108859  0.11088511 0.11087822 0.11087823 0.11087403 0.11086968
 0.11087425 0.11087374 0.11088294 0.11088256 0.11086745 0.11087115
 0.11086758 0.11085625 0.11085923 0.11085328 0.11086019 0.11085899
 0.11085732 0.11085653]
[0.34210526 0.28947368 0.        ]
-----------end of analyzing the loss ratio:75.7539803981781
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444dc3b56f0>
---------------------------------
SparseEpoch: [147][1/398]	Time 0.579	Data 0.000	Loss 1.3084	
SparseEpoch: [147][101/398]	Time 0.581	Data 0.000	Loss 1.5560	
SparseEpoch: [147][201/398]	Time 0.581	Data 0.000	Loss 1.4031	
SparseEpoch: [147][301/398]	Time 0.581	Data 0.000	Loss 1.2353	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.9056	
Epoch(adapt):{0} Loss 0.9554	
Epoch(adapt):{0} Loss 0.4833	
Epoch(adapt):{0} Loss 0.5105	
------------------the total time cost:1168.1321485042572
>>>>>meta updating
Epoch: 0147 | TRAIN: 0.3025 0.7800 0.9050 | 0.3215 0.3215 0.1472 | 0.1126 21.9026 16.8973 0.3336 0.6405 0.7635 ||TEST: 1.2664 0.4125 0.6655 | 0.5401 0.5401 0.2110 | 0.1408 25.1622 20.2779 0.2804 0.5550 0.6845 | 116.9181
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.32274269 0.32269307 0.32264967 0.32273027 0.32265145 0.32261478
 0.32265097 0.32267992 0.32272165 0.32279676 0.3228265  0.32283363
 0.32276452 0.32275361 0.32253255 0.32254609 0.32262466 0.32258952
 0.32258281 0.3225975 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.32276621 0.32275871 0.3227479  0.32278052 0.32276772 0.32273912
 0.32273993 0.32273984 0.3227815  0.32279898 0.32281077 0.3227712
 0.32277031 0.32275223 0.32275585 0.32275242 0.3227503  0.32280284
 0.32280717 0.32277169]
[0.         0.23684211 0.        ]
-----------end of analyzing the loss ratio:75.62833881378174
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc326e60>
---------------------------------
SparseEpoch: [148][1/398]	Time 0.579	Data 0.000	Loss 0.2431	
SparseEpoch: [148][101/398]	Time 0.580	Data 0.000	Loss 0.4273	
SparseEpoch: [148][201/398]	Time 0.580	Data 0.000	Loss 1.1103	
SparseEpoch: [148][301/398]	Time 0.580	Data 0.000	Loss 0.4374	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.30835389 0.30832835 0.30835543 0.30832652 0.30836571 0.30839268
 0.30839779 0.3084414  0.30849114 0.30840835 0.30843702 0.30835865
 0.30832601 0.30826825 0.30829256 0.30828654 0.30828181 0.30832778
 0.30837498 0.3083832 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.30848283 0.30848253 0.30849763 0.30848133 0.30846628 0.30844661
 0.30839731 0.30840713 0.3084202  0.30840142 0.30840056 0.30843938
 0.30843178 0.30839233 0.30838795 0.30835961 0.30830053 0.30831833
 0.30831114 0.30834155]
[0.18421053 0.         0.34210526]
-----------end of analyzing the loss ratio:75.64721632003784
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc11f190>
---------------------------------
SparseEpoch: [148][1/398]	Time 0.579	Data 0.000	Loss 0.5671	
SparseEpoch: [148][101/398]	Time 0.582	Data 0.000	Loss 0.7557	
SparseEpoch: [148][201/398]	Time 0.581	Data 0.000	Loss 0.8593	
SparseEpoch: [148][301/398]	Time 0.581	Data 0.000	Loss 0.9648	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.1118378  0.11182004 0.11182023 0.11180796 0.11179568 0.11180584
 0.1117933  0.11179525 0.11179774 0.11179088 0.11178288 0.11175898
 0.11175326 0.11174119 0.11172429 0.11171088 0.11171345 0.1117026
 0.11169719 0.11170382]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11196455 0.1119418  0.1119011  0.11185949 0.11186254 0.11187239
 0.11183717 0.11184925 0.11183845 0.11179444 0.11177167 0.11176118
 0.11170939 0.11167721 0.11165658 0.11165466 0.11164013 0.11159407
 0.11154175 0.1115824 ]
[0.44736842 0.44736842 0.        ]
-----------end of analyzing the loss ratio:75.6192786693573
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc0bf580>
---------------------------------
SparseEpoch: [148][1/398]	Time 0.579	Data 0.000	Loss 0.9296	
SparseEpoch: [148][101/398]	Time 0.581	Data 0.000	Loss 1.2704	
SparseEpoch: [148][201/398]	Time 0.581	Data 0.000	Loss 1.8539	
SparseEpoch: [148][301/398]	Time 0.581	Data 0.000	Loss 2.0253	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.6772	
Epoch(adapt):{0} Loss 0.7109	
Epoch(adapt):{0} Loss 0.4607	
Epoch(adapt):{0} Loss 0.5933	
------------------the total time cost:1167.8984971046448
>>>>>meta updating
Epoch: 0148 | TRAIN: 0.2900 0.7801 0.9080 | 0.2911 0.2911 0.1457 | 0.1111 21.6116 16.4868 0.3467 0.6489 0.7683 ||TEST: 1.3908 0.4132 0.6663 | 0.5177 0.5177 0.2098 | 0.1416 25.1173 20.0130 0.2876 0.5587 0.6857 | 116.8824
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.29493171 0.29495561 0.29498507 0.29498013 0.29513395 0.29513178
 0.29515435 0.29521231 0.29527487 0.29530567 0.29535473 0.29543085
 0.29549525 0.29552945 0.29556137 0.29566719 0.29580096 0.29581978
 0.29581205 0.29578824]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.29536032 0.29534161 0.29535464 0.29537126 0.2953423  0.29533968
 0.29533165 0.29534628 0.29535369 0.29536553 0.2953613  0.29535587
 0.29536561 0.29535289 0.29533826 0.29534157 0.29533167 0.29533111
 0.2953194  0.29534066]
[0.         0.         0.44736842]
-----------end of analyzing the loss ratio:75.51368975639343
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d7077550>
---------------------------------
SparseEpoch: [149][1/398]	Time 0.578	Data 0.000	Loss 0.8619	
SparseEpoch: [149][101/398]	Time 0.581	Data 0.000	Loss 0.9496	
SparseEpoch: [149][201/398]	Time 0.581	Data 0.000	Loss 1.1113	
SparseEpoch: [149][301/398]	Time 0.581	Data 0.000	Loss 1.0176	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.37105945 0.37108632 0.3711352  0.37116064 0.37116043 0.37112279
 0.37119225 0.37118841 0.37121156 0.37128203 0.37121511 0.37118751
 0.37125626 0.37126135 0.37126943 0.37125972 0.37133939 0.37125145
 0.37113542 0.37104168]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.37129353 0.37130631 0.37131325 0.37130614 0.37130763 0.37129953
 0.37127781 0.37127734 0.37127101 0.37129741 0.37129469 0.37127976
 0.37126921 0.37122652 0.37122194 0.37123743 0.37122517 0.37122548
 0.37120923 0.37120819]
[0.5 0.  0.5]
-----------end of analyzing the loss ratio:75.53169918060303
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc12dc30>
---------------------------------
SparseEpoch: [149][1/398]	Time 0.579	Data 0.000	Loss 0.7104	
SparseEpoch: [149][101/398]	Time 0.581	Data 0.000	Loss 1.1018	
SparseEpoch: [149][201/398]	Time 0.581	Data 0.000	Loss 0.8809	
SparseEpoch: [149][301/398]	Time 0.581	Data 0.000	Loss 1.0194	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.10929657 0.10928589 0.10927314 0.10927638 0.10924249 0.10924017
 0.10922633 0.1092084  0.10922791 0.10922479 0.10922493 0.10922665
 0.10919428 0.1091949  0.10918694 0.10920061 0.10919074 0.10919032
 0.10919273 0.10920032]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.10921425 0.10921581 0.10922824 0.10923182 0.10922464 0.10923752
 0.1092389  0.10923758 0.10922071 0.10922912 0.10922901 0.10922284
 0.10921627 0.10923225 0.10924302 0.10924981 0.10925113 0.10924538
 0.10923396 0.10924037]
[0.23684211 0.         0.        ]
-----------end of analyzing the loss ratio:75.8848671913147
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d69b5ae0>
---------------------------------
SparseEpoch: [149][1/398]	Time 0.578	Data 0.000	Loss 0.9636	
SparseEpoch: [149][101/398]	Time 0.580	Data 0.000	Loss 0.9214	
SparseEpoch: [149][201/398]	Time 0.580	Data 0.000	Loss 1.8994	
SparseEpoch: [149][301/398]	Time 0.580	Data 0.000	Loss 1.2530	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.6872	
Epoch(adapt):{0} Loss 0.4881	
Epoch(adapt):{0} Loss 0.7092	
Epoch(adapt):{0} Loss 0.8360	
------------------the total time cost:1167.1047842502594
>>>>>meta updating
Epoch: 0149 | TRAIN: 0.2991 0.7810 0.9056 | 0.3091 0.3091 0.1396 | 0.1125 21.8756 16.8808 0.3356 0.6410 0.7633 ||TEST: 1.3086 0.4105 0.6608 | 0.5397 0.5397 0.2079 | 0.1418 25.2563 20.3595 0.2808 0.5516 0.6812 | 117.1921
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.34851478 0.34847569 0.3484358  0.34846856 0.34849616 0.34849292
 0.34851582 0.34852123 0.34855447 0.34851274 0.34851235 0.34857403
 0.34859302 0.34857806 0.34863701 0.34864656 0.34865326 0.34864867
 0.34865205 0.34863625]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.34852825 0.34853255 0.34852442 0.34854905 0.34852897 0.34850736
 0.34850651 0.34848541 0.34850526 0.34847573 0.34849767 0.34851187
 0.34852152 0.3485368  0.34853811 0.34855218 0.34856056 0.34857388
 0.34854553 0.34855744]
[0. 0. 0.]
-----------end of analyzing the loss ratio:75.79093837738037
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444dc12ce80>
---------------------------------
SparseEpoch: [150][1/398]	Time 0.578	Data 0.000	Loss 0.2560	
SparseEpoch: [150][101/398]	Time 0.579	Data 0.000	Loss 0.3146	
SparseEpoch: [150][201/398]	Time 0.580	Data 0.000	Loss 0.2843	
SparseEpoch: [150][301/398]	Time 0.580	Data 0.000	Loss 0.3866	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.32444744 0.3244235  0.3243561  0.32435354 0.3242643  0.32422037
 0.32420679 0.32417909 0.32413547 0.32415506 0.32410575 0.3240655
 0.32415585 0.32412538 0.32409939 0.32408578 0.32403807 0.32404831
 0.32399588 0.32404878]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.32415497 0.32415566 0.32416076 0.32416721 0.32416856 0.32415569
 0.3241292  0.32412559 0.32414646 0.32413781 0.32412871 0.32413005
 0.32415116 0.32413829 0.32414742 0.32413252 0.32411637 0.32411155
 0.32410685 0.32410401]
[0.44736842 0.         0.5       ]
-----------end of analyzing the loss ratio:75.8031702041626
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc1c7bb0>
---------------------------------
SparseEpoch: [150][1/398]	Time 0.578	Data 0.000	Loss 1.4086	
SparseEpoch: [150][101/398]	Time 0.582	Data 0.000	Loss 0.9273	
SparseEpoch: [150][201/398]	Time 0.581	Data 0.000	Loss 1.2822	
SparseEpoch: [150][301/398]	Time 0.581	Data 0.000	Loss 0.7496	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.1118681  0.11185395 0.11184917 0.11185241 0.1118571  0.1118548
 0.11185207 0.11184946 0.11184548 0.11182342 0.11181816 0.11180422
 0.11179417 0.11179236 0.1117982  0.11181414 0.11182209 0.1117946
 0.11180292 0.11180865]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.1118214  0.11182123 0.11182647 0.1118405  0.11183938 0.11183743
 0.11183301 0.11182817 0.11182128 0.11181307 0.11181657 0.11182024
 0.11181324 0.11180468 0.11179562 0.11178706 0.11178743 0.11178636
 0.11179026 0.11179312]
[0.18421053 0.39473684 0.        ]
-----------end of analyzing the loss ratio:75.63982367515564
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6aa2290>
---------------------------------
SparseEpoch: [150][1/398]	Time 0.579	Data 0.000	Loss 1.0778	
SparseEpoch: [150][101/398]	Time 0.581	Data 0.000	Loss 1.1518	
SparseEpoch: [150][201/398]	Time 0.581	Data 0.000	Loss 1.6754	
SparseEpoch: [150][301/398]	Time 0.581	Data 0.000	Loss 1.0277	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.5918	
Epoch(adapt):{0} Loss 0.6106	
Epoch(adapt):{0} Loss 0.8124	
Epoch(adapt):{0} Loss 0.4982	
------------------the total time cost:1169.4007275104523
>>>>>meta updating
Epoch: 0150 | TRAIN: 0.2907 0.7861 0.9086 | 0.2897 0.2897 0.1362 | 0.1109 21.6055 16.4863 0.3455 0.6491 0.7689 ||TEST: 1.4326 0.4110 0.6607 | 0.5225 0.5225 0.2090 | 0.1409 25.0185 19.8909 0.2911 0.5607 0.6868 | 117.0196
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.2816937  0.28171061 0.28170287 0.28176991 0.28179075 0.28178116
 0.28170016 0.28166485 0.28167556 0.28168823 0.28167276 0.28169646
 0.28163586 0.28165267 0.28168036 0.28172245 0.28169108 0.2817058
 0.2816444  0.28161525]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.28166691 0.28166327 0.28168295 0.28169021 0.28168468 0.28169456
 0.2816641  0.28168517 0.28168257 0.28166955 0.28165929 0.28166592
 0.28167773 0.28168666 0.28169655 0.28169138 0.28169559 0.28168826
 0.28170612 0.28171326]
[0.         0.5        0.02631579]
-----------end of analyzing the loss ratio:76.01199173927307
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc550190>
---------------------------------
SparseEpoch: [151][1/398]	Time 0.579	Data 0.000	Loss 0.3825	
SparseEpoch: [151][101/398]	Time 0.581	Data 0.000	Loss 1.5651	
SparseEpoch: [151][201/398]	Time 0.581	Data 0.000	Loss 0.3731	
SparseEpoch: [151][301/398]	Time 0.581	Data 0.000	Loss 1.0059	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.40847577 0.40817169 0.40832117 0.40813468 0.40802935 0.40791305
 0.40773745 0.40753501 0.40729119 0.40711139 0.40700929 0.40676847
 0.40667354 0.40677717 0.40656984 0.40656648 0.40660428 0.40658942
 0.40639005 0.40645912]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.40697531 0.40699073 0.40698973 0.40705027 0.40703244 0.40704848
 0.40708507 0.40710683 0.40705758 0.40704259 0.40704608 0.40708438
 0.407073   0.40704364 0.40705114 0.40704658 0.40703692 0.40703456
 0.4069989  0.4070164 ]
[0.44736842 0.         0.        ]
-----------end of analyzing the loss ratio:75.61825942993164
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6e95840>
---------------------------------
SparseEpoch: [151][1/398]	Time 0.578	Data 0.000	Loss 0.2657	
SparseEpoch: [151][101/398]	Time 0.580	Data 0.000	Loss 0.4653	
SparseEpoch: [151][201/398]	Time 0.581	Data 0.000	Loss 0.3411	
SparseEpoch: [151][301/398]	Time 0.581	Data 0.000	Loss 0.3452	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.09759533 0.0976055  0.09761187 0.09760799 0.09759929 0.0975907
 0.09759612 0.09759164 0.09758539 0.09759775 0.09760119 0.09760453
 0.09760007 0.09760896 0.09760324 0.09760773 0.09760403 0.09758729
 0.09758498 0.0975755 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.09762555 0.09763634 0.09763341 0.0976217  0.09762664 0.09761583
 0.09761317 0.09760671 0.09762014 0.09760039 0.09759101 0.09758186
 0.09758548 0.09760554 0.0975992  0.09759052 0.09758361 0.09756435
 0.09756969 0.09755733]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:75.67110228538513
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc41cdc0>
---------------------------------
SparseEpoch: [151][1/398]	Time 0.579	Data 0.000	Loss 1.0666	
SparseEpoch: [151][101/398]	Time 0.581	Data 0.000	Loss 1.4996	
SparseEpoch: [151][201/398]	Time 0.581	Data 0.000	Loss 1.4470	
SparseEpoch: [151][301/398]	Time 0.581	Data 0.000	Loss 2.0434	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.3634	
Epoch(adapt):{0} Loss 0.8218	
Epoch(adapt):{0} Loss 0.7581	
Epoch(adapt):{0} Loss 0.5704	
------------------the total time cost:1168.5616827011108
>>>>>meta updating
Epoch: 0151 | TRAIN: 0.2902 0.7863 0.9082 | 0.3324 0.3324 0.1443 | 0.1153 22.2995 17.4525 0.3219 0.6261 0.7539 ||TEST: 1.2938 0.4135 0.6686 | 0.5508 0.5508 0.2108 | 0.1429 25.4224 20.6803 0.2775 0.5453 0.6756 | 117.2306
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.24632256 0.24631919 0.24635626 0.24635939 0.24637436 0.24635055
 0.2463436  0.24636007 0.24630232 0.24633873 0.246363   0.24639135
 0.24647729 0.24655685 0.24658987 0.2465777  0.24657812 0.2465797
 0.24662559 0.24661583]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.24634137 0.24634115 0.24634738 0.24634408 0.24634628 0.24636006
 0.24635497 0.2463484  0.24637023 0.2463723  0.2463491  0.24633135
 0.246313   0.24637895 0.24637741 0.24639831 0.24638439 0.24640612
 0.24639718 0.24640259]
[0.         0.         0.13157895]
-----------end of analyzing the loss ratio:75.75466203689575
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6f0c4f0>
---------------------------------
SparseEpoch: [152][1/398]	Time 0.578	Data 0.000	Loss 0.4858	
SparseEpoch: [152][101/398]	Time 0.580	Data 0.000	Loss 0.3596	
SparseEpoch: [152][201/398]	Time 0.580	Data 0.000	Loss 0.3349	
SparseEpoch: [152][301/398]	Time 0.580	Data 0.000	Loss 0.5999	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.35104872 0.3510118  0.35099998 0.3509811  0.35095855 0.35096189
 0.35086466 0.3508468  0.35079803 0.35076111 0.35086069 0.35089301
 0.35093649 0.35095419 0.35092163 0.35095225 0.3509403  0.35092445
 0.35094388 0.35096896]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.35094468 0.35095272 0.350944   0.35095636 0.35092655 0.35089501
 0.35089229 0.35087032 0.35085726 0.35084087 0.35084051 0.35082033
 0.3507992  0.35080765 0.35081124 0.35081899 0.35082504 0.35080463
 0.35081201 0.35081468]
[0.         0.         0.13157895]
-----------end of analyzing the loss ratio:75.69606947898865
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d722f190>
---------------------------------
SparseEpoch: [152][1/398]	Time 0.578	Data 0.000	Loss 0.5815	
SparseEpoch: [152][101/398]	Time 0.580	Data 0.000	Loss 0.3979	
SparseEpoch: [152][201/398]	Time 0.580	Data 0.000	Loss 0.3100	
SparseEpoch: [152][301/398]	Time 0.580	Data 0.000	Loss 0.5458	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11163633 0.11151661 0.1114259  0.11140277 0.11138217 0.11127865
 0.11121221 0.11113218 0.11101862 0.11089259 0.11077531 0.11063942
 0.11048447 0.1103969  0.11032169 0.1102534  0.11015191 0.11005293
 0.11005127 0.10995756]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.1111422  0.11109204 0.11107181 0.11101154 0.1110014  0.11099951
 0.11093049 0.11089293 0.11085866 0.11084964 0.1108247  0.11084146
 0.11076907 0.11071336 0.11067219 0.11062968 0.1106227  0.11055367
 0.11054901 0.11051348]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:76.07273364067078
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6bd1510>
---------------------------------
SparseEpoch: [152][1/398]	Time 0.579	Data 0.000	Loss 1.3463	
SparseEpoch: [152][101/398]	Time 0.581	Data 0.000	Loss 1.0346	
SparseEpoch: [152][201/398]	Time 0.581	Data 0.000	Loss 1.6652	
SparseEpoch: [152][301/398]	Time 0.581	Data 0.000	Loss 1.4490	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.6562	
Epoch(adapt):{0} Loss 0.7346	
Epoch(adapt):{0} Loss 0.8070	
Epoch(adapt):{0} Loss 0.4105	
------------------the total time cost:1168.3065576553345
>>>>>meta updating
Epoch: 0152 | TRAIN: 0.2847 0.7917 0.9096 | 0.3086 0.3086 0.1429 | 0.1131 21.9621 16.9899 0.3333 0.6367 0.7601 ||TEST: 1.3986 0.4181 0.6680 | 0.5362 0.5362 0.2082 | 0.1422 25.2366 20.2910 0.2851 0.5528 0.6807 | 117.4199
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.35383547 0.35383424 0.35377197 0.35380602 0.35391272 0.35389516
 0.35384935 0.3538766  0.35380093 0.35378348 0.35382963 0.35379682
 0.35377975 0.35381566 0.35382749 0.35376228 0.35376792 0.35374967
 0.35374556 0.3536966 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.35381526 0.35381746 0.35381284 0.35380972 0.35381047 0.3538123
 0.35380684 0.35380199 0.35380831 0.35380971 0.35380423 0.35380544
 0.35380598 0.35380535 0.35378651 0.35377116 0.35376614 0.35378199
 0.35376613 0.35379107]
[0.         0.5        0.44736842]
-----------end of analyzing the loss ratio:75.52746820449829
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6fd6aa0>
---------------------------------
SparseEpoch: [153][1/398]	Time 0.580	Data 0.000	Loss 0.8341	
SparseEpoch: [153][101/398]	Time 0.581	Data 0.000	Loss 0.9532	
SparseEpoch: [153][201/398]	Time 0.581	Data 0.000	Loss 1.1116	
SparseEpoch: [153][301/398]	Time 0.581	Data 0.000	Loss 0.6821	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.31547153 0.31545487 0.31547343 0.31542858 0.31537323 0.31534827
 0.31524274 0.31515478 0.31514636 0.31504891 0.31500568 0.31497978
 0.31499212 0.31496831 0.3149501  0.31487557 0.31487367 0.31487351
 0.31482096 0.31482315]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.3150894  0.31507689 0.3150867  0.31509014 0.31506922 0.31504469
 0.31504725 0.3150405  0.31504156 0.31503628 0.31502534 0.3150249
 0.31502839 0.31501552 0.31504159 0.31505139 0.31504768 0.3150453
 0.31504449 0.31503868]
[0.44736842 0.         0.18421053]
-----------end of analyzing the loss ratio:75.64516377449036
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6d4d060>
---------------------------------
SparseEpoch: [153][1/398]	Time 0.591	Data 0.000	Loss 0.5287	
SparseEpoch: [153][101/398]	Time 0.581	Data 0.000	Loss 0.6904	
SparseEpoch: [153][201/398]	Time 0.581	Data 0.000	Loss 0.6495	
SparseEpoch: [153][301/398]	Time 0.581	Data 0.000	Loss 0.7523	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.10202849 0.10200867 0.10199197 0.10198209 0.10195497 0.1019317
 0.10193742 0.10192447 0.10189821 0.10190849 0.10190321 0.10191818
 0.10189676 0.10188124 0.10188213 0.10186868 0.10186632 0.10184714
 0.10185502 0.10184143]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.10189645 0.10189002 0.10190017 0.10189461 0.10189415 0.10189571
 0.10189646 0.10189143 0.10191472 0.10191624 0.10191523 0.1019179
 0.10191522 0.10191331 0.1019155  0.10191264 0.10191072 0.10190787
 0.10189861 0.10190779]
[0.5 0.  0. ]
-----------end of analyzing the loss ratio:75.77844333648682
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc025ed0>
---------------------------------
SparseEpoch: [153][1/398]	Time 0.581	Data 0.000	Loss 0.7502	
SparseEpoch: [153][101/398]	Time 0.580	Data 0.000	Loss 1.2337	
SparseEpoch: [153][201/398]	Time 0.581	Data 0.000	Loss 1.2686	
SparseEpoch: [153][301/398]	Time 0.581	Data 0.000	Loss 1.5939	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.4582	
Epoch(adapt):{0} Loss 0.5232	
Epoch(adapt):{0} Loss 0.6709	
Epoch(adapt):{0} Loss 0.6417	
------------------the total time cost:1167.894184589386
>>>>>meta updating
Epoch: 0153 | TRAIN: 0.2947 0.7772 0.9073 | 0.3135 0.3135 0.1501 | 0.1110 21.7258 16.6955 0.3375 0.6476 0.7686 ||TEST: 1.3135 0.4118 0.6649 | 0.5338 0.5338 0.2143 | 0.1401 25.1138 20.1460 0.2796 0.5567 0.6869 | 117.0792
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.3140289  0.31404567 0.31398698 0.31404852 0.3138681  0.3137787
 0.31372649 0.31373353 0.31376788 0.31387353 0.31387563 0.31376265
 0.31379535 0.31377663 0.31376939 0.31379059 0.31363588 0.31364801
 0.31364194 0.31351838]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.31390196 0.31390403 0.31390533 0.31389779 0.31387841 0.31388771
 0.31388888 0.31389807 0.31390307 0.31393195 0.31390258 0.31390275
 0.31388766 0.31388911 0.31388853 0.31389796 0.31389966 0.31389844
 0.31389444 0.31389443]
[0.  0.5 0. ]
-----------end of analyzing the loss ratio:75.71161317825317
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6b5fbe0>
---------------------------------
SparseEpoch: [154][1/398]	Time 0.579	Data 0.000	Loss 0.4049	
SparseEpoch: [154][101/398]	Time 0.580	Data 0.000	Loss 0.3995	
SparseEpoch: [154][201/398]	Time 0.580	Data 0.000	Loss 0.7225	
SparseEpoch: [154][301/398]	Time 0.580	Data 0.000	Loss 0.3327	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.34946533 0.34925048 0.34916829 0.34913386 0.34916111 0.34914855
 0.34908688 0.34900159 0.34889396 0.34883453 0.34876774 0.3487303
 0.34873979 0.34867984 0.34865844 0.34853969 0.3485167  0.34849446
 0.34840779 0.34840018]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.34885799 0.34885353 0.34886713 0.34886454 0.34887121 0.34885984
 0.34883649 0.34880993 0.34876547 0.34875677 0.34875472 0.34876771
 0.34876169 0.34876113 0.3487663  0.34876796 0.34876042 0.34877729
 0.34876377 0.34875963]
[0.5        0.         0.02631579]
-----------end of analyzing the loss ratio:75.82225632667542
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6e13dc0>
---------------------------------
SparseEpoch: [154][1/398]	Time 0.580	Data 0.000	Loss 0.2981	
SparseEpoch: [154][101/398]	Time 0.580	Data 0.000	Loss 0.4059	
SparseEpoch: [154][201/398]	Time 0.581	Data 0.000	Loss 0.4302	
SparseEpoch: [154][301/398]	Time 0.581	Data 0.000	Loss 0.4891	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.10887296 0.10887453 0.10887238 0.1088586  0.10884967 0.10884492
 0.10884304 0.10884686 0.10884204 0.10884466 0.10884997 0.10883631
 0.10883356 0.10881836 0.10881451 0.10881664 0.10881629 0.10882241
 0.10883466 0.10885056]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.1088375  0.10883109 0.10884364 0.10885684 0.10886204 0.10884945
 0.10886232 0.10885353 0.10882992 0.10884445 0.10883609 0.10884374
 0.10883326 0.10883388 0.10883221 0.10883313 0.10883538 0.1088428
 0.10884389 0.1088384 ]
[0.23684211 0.         0.        ]
-----------end of analyzing the loss ratio:76.18772602081299
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6ddc850>
---------------------------------
SparseEpoch: [154][1/398]	Time 0.578	Data 0.000	Loss 0.9143	
SparseEpoch: [154][101/398]	Time 0.580	Data 0.000	Loss 1.1190	
SparseEpoch: [154][201/398]	Time 0.581	Data 0.000	Loss 1.0206	
SparseEpoch: [154][301/398]	Time 0.581	Data 0.000	Loss 0.8454	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.5268	
Epoch(adapt):{0} Loss 0.5150	
Epoch(adapt):{0} Loss 0.4404	
Epoch(adapt):{0} Loss 0.5241	
------------------the total time cost:1168.3151104450226
>>>>>meta updating
Epoch: 0154 | TRAIN: 0.2830 0.7888 0.9111 | 0.3030 0.3030 0.1452 | 0.1120 21.9047 17.0464 0.3320 0.6369 0.7622 ||TEST: 1.3513 0.4124 0.6634 | 0.5256 0.5256 0.2091 | 0.1444 25.5715 20.7541 0.2745 0.5435 0.6739 | 117.3003
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.30047269 0.30054103 0.3004709  0.30051742 0.30043877 0.30042149
 0.30046555 0.30047315 0.300483   0.30044513 0.30049337 0.30044901
 0.30035908 0.30034315 0.30029389 0.3002947  0.30028197 0.30024091
 0.30026315 0.30018183]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.30047818 0.30048246 0.30047384 0.3004833  0.30048115 0.30048679
 0.30046889 0.30047329 0.30048994 0.30047181 0.30047775 0.30046262
 0.30046267 0.30048999 0.30050305 0.30047243 0.30044931 0.30044214
 0.30044392 0.30040012]
[0.  0.5 0.5]
-----------end of analyzing the loss ratio:75.7740912437439
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444dc17b340>
---------------------------------
SparseEpoch: [155][1/398]	Time 0.579	Data 0.000	Loss 1.1263	
SparseEpoch: [155][101/398]	Time 0.581	Data 0.000	Loss 0.8065	
SparseEpoch: [155][201/398]	Time 0.581	Data 0.000	Loss 0.9824	
SparseEpoch: [155][301/398]	Time 0.582	Data 0.000	Loss 0.8825	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.39184755 0.39182855 0.39157823 0.39133089 0.39118138 0.39099767
 0.39078109 0.39035676 0.39022524 0.38988799 0.38983541 0.38968418
 0.38934623 0.38926606 0.38921947 0.38919312 0.38901363 0.38882475
 0.38875948 0.38867838]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.39011853 0.3900503  0.3900294  0.38999027 0.38995343 0.38988286
 0.38990391 0.38988402 0.3898279  0.38980029 0.38979296 0.38980019
 0.38978024 0.38982593 0.38981157 0.38980401 0.38977773 0.38977696
 0.38975193 0.38972431]
[0.5 0.  0.5]
-----------end of analyzing the loss ratio:75.81764960289001
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc5e84f0>
---------------------------------
SparseEpoch: [155][1/398]	Time 0.578	Data 0.000	Loss 1.0277	
SparseEpoch: [155][101/398]	Time 0.581	Data 0.000	Loss 0.8566	
SparseEpoch: [155][201/398]	Time 0.581	Data 0.000	Loss 1.4362	
SparseEpoch: [155][301/398]	Time 0.581	Data 0.000	Loss 0.7809	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.12416852 0.12415422 0.1241373  0.12413218 0.12410145 0.12410215
 0.12410034 0.12407745 0.12408394 0.12407972 0.12406601 0.12406026
 0.12404826 0.1240382  0.12403935 0.12404041 0.12401176 0.12399356
 0.12399455 0.12397138]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.12413197 0.12411045 0.1241039  0.1240779  0.12407444 0.12408234
 0.1240895  0.12407601 0.12408305 0.12407811 0.12408032 0.12407393
 0.12407918 0.12406864 0.12404568 0.12404351 0.12404187 0.12403449
 0.12403142 0.12402011]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:75.72002148628235
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6c5fc40>
---------------------------------
SparseEpoch: [155][1/398]	Time 0.579	Data 0.000	Loss 2.1836	
SparseEpoch: [155][101/398]	Time 0.581	Data 0.000	Loss 1.8376	
SparseEpoch: [155][201/398]	Time 0.581	Data 0.000	Loss 1.2064	
SparseEpoch: [155][301/398]	Time 0.581	Data 0.000	Loss 1.4209	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.9587	
Epoch(adapt):{0} Loss 0.7488	
Epoch(adapt):{0} Loss 0.5036	
Epoch(adapt):{0} Loss 0.9495	
------------------the total time cost:1169.2788472175598
>>>>>meta updating
Epoch: 0155 | TRAIN: 0.2870 0.7817 0.9082 | 0.2936 0.2936 0.1409 | 0.1105 21.5426 16.3925 0.3487 0.6506 0.7699 ||TEST: 1.3622 0.4149 0.6653 | 0.5201 0.5201 0.2082 | 0.1401 24.9374 19.8618 0.2926 0.5621 0.6882 | 117.4395
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.31797542 0.31793165 0.31789023 0.317884   0.31790703 0.31786422
 0.31791491 0.31785621 0.3178416  0.31783079 0.3177857  0.31778766
 0.31775551 0.3178003  0.31773757 0.31774112 0.31766294 0.31772814
 0.31772975 0.31764137]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.31778699 0.31781292 0.31779741 0.31779656 0.31782472 0.31781222
 0.31782659 0.31780707 0.31781974 0.31780473 0.31779208 0.31780035
 0.3177873  0.31778493 0.31779126 0.31780071 0.3177759  0.31780985
 0.31777004 0.31776569]
[0.  0.5 0.5]
-----------end of analyzing the loss ratio:75.53340435028076
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d7192560>
---------------------------------
SparseEpoch: [156][1/398]	Time 0.579	Data 0.000	Loss 0.6539	
SparseEpoch: [156][101/398]	Time 0.581	Data 0.000	Loss 0.7270	
SparseEpoch: [156][201/398]	Time 0.581	Data 0.000	Loss 1.2007	
SparseEpoch: [156][301/398]	Time 0.581	Data 0.000	Loss 0.6360	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.3647327  0.36434813 0.36416708 0.36392912 0.36361368 0.36324014
 0.36300532 0.36274058 0.36231524 0.36185706 0.36146042 0.36106859
 0.36113236 0.3608236  0.36075449 0.36036609 0.36020399 0.35993317
 0.35956054 0.35932315]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.36188694 0.3618699  0.36188224 0.36184076 0.36181398 0.36178986
 0.36173826 0.36175283 0.36171719 0.36163631 0.36157856 0.36154056
 0.36151996 0.36151751 0.36155016 0.36151184 0.3614842  0.36142638
 0.36141729 0.36143305]
[0.5        0.         0.44736842]
-----------end of analyzing the loss ratio:75.69614386558533
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6ddcc40>
---------------------------------
SparseEpoch: [156][1/398]	Time 0.579	Data 0.000	Loss 0.7208	
SparseEpoch: [156][101/398]	Time 0.581	Data 0.000	Loss 0.6874	
SparseEpoch: [156][201/398]	Time 0.580	Data 0.000	Loss 0.8841	
SparseEpoch: [156][301/398]	Time 0.581	Data 0.000	Loss 0.7842	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.13343679 0.13343865 0.13343674 0.13342836 0.13341964 0.13343073
 0.13343051 0.13342645 0.13343281 0.13343    0.13342977 0.1334278
 0.13342209 0.13343047 0.13342301 0.13340437 0.13340896 0.13342533
 0.1334164  0.13342322]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.13343066 0.13343502 0.13343222 0.13343475 0.13342978 0.13343253
 0.13342838 0.13343027 0.13342434 0.13342548 0.13342666 0.1334246
 0.13342409 0.13342103 0.13342422 0.13342707 0.1334181  0.1334134
 0.13342004 0.13341548]
[0.28947368 0.39473684 0.        ]
-----------end of analyzing the loss ratio:75.81417894363403
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc2afa90>
---------------------------------
SparseEpoch: [156][1/398]	Time 0.579	Data 0.000	Loss 1.1265	
SparseEpoch: [156][101/398]	Time 0.581	Data 0.000	Loss 1.1025	
SparseEpoch: [156][201/398]	Time 0.581	Data 0.000	Loss 0.9760	
SparseEpoch: [156][301/398]	Time 0.581	Data 0.000	Loss 1.3408	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.3610	
Epoch(adapt):{0} Loss 0.7154	
Epoch(adapt):{0} Loss 0.5592	
Epoch(adapt):{0} Loss 0.5262	
------------------the total time cost:1168.0886797904968
>>>>>meta updating
Epoch: 0156 | TRAIN: 0.2795 0.7945 0.9119 | 0.3151 0.3151 0.1396 | 0.1087 21.4527 16.5350 0.3406 0.6526 0.7741 ||TEST: 1.2948 0.4092 0.6658 | 0.5469 0.5469 0.2094 | 0.1414 25.2021 20.2946 0.2798 0.5542 0.6841 | 117.1723
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.32540426 0.32538289 0.32532268 0.32532372 0.32514995 0.32508842
 0.32507061 0.32510814 0.32509971 0.32500783 0.3248998  0.32481262
 0.32470452 0.3246465  0.3246045  0.32459466 0.32457299 0.32447304
 0.32442717 0.32444982]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.32482344 0.32482843 0.32484086 0.32485972 0.32486101 0.3248761
 0.3248575  0.32487823 0.32490632 0.32495131 0.32493951 0.32496068
 0.32501736 0.32501657 0.32503008 0.32504186 0.32507387 0.32508345
 0.3250904  0.32510477]
[0.         0.44736842 0.        ]
-----------end of analyzing the loss ratio:75.62806248664856
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc2645e0>
---------------------------------
SparseEpoch: [157][1/398]	Time 0.578	Data 0.000	Loss 0.3565	
SparseEpoch: [157][101/398]	Time 0.580	Data 0.000	Loss 0.4382	
SparseEpoch: [157][201/398]	Time 0.581	Data 0.000	Loss 0.3708	
SparseEpoch: [157][301/398]	Time 0.581	Data 0.000	Loss 0.4849	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.33255521 0.33254991 0.33249373 0.33246379 0.33243762 0.33243284
 0.3323953  0.33238139 0.33232706 0.33227816 0.33226725 0.33223205
 0.33220282 0.3322114  0.33214954 0.33216384 0.33222855 0.33216723
 0.33215393 0.33213454]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.33235267 0.33230815 0.33232244 0.33230433 0.33228959 0.33230066
 0.33230124 0.33228725 0.33229665 0.33229809 0.33228359 0.33228997
 0.33227122 0.33224253 0.33223442 0.33224531 0.33223486 0.33224231
 0.33226691 0.33223651]
[0.5        0.         0.23684211]
-----------end of analyzing the loss ratio:75.56082653999329
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc0bd2a0>
---------------------------------
SparseEpoch: [157][1/398]	Time 0.580	Data 0.000	Loss 0.4417	
SparseEpoch: [157][101/398]	Time 0.580	Data 0.000	Loss 0.7991	
SparseEpoch: [157][201/398]	Time 0.581	Data 0.000	Loss 0.5467	
SparseEpoch: [157][301/398]	Time 0.581	Data 0.000	Loss 0.7172	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11573617 0.11575568 0.11575747 0.11576013 0.11577144 0.11576902
 0.11576821 0.11577837 0.11577218 0.11576729 0.11576284 0.11574748
 0.11573795 0.11573299 0.11573409 0.11572176 0.11571723 0.11571806
 0.11571755 0.1157136 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11573456 0.11574287 0.11574197 0.11575122 0.11574607 0.11575726
 0.11575201 0.1157729  0.11576819 0.11577597 0.11575322 0.11573758
 0.11571785 0.1157297  0.11571422 0.11571566 0.11571937 0.11573347
 0.11573797 0.11572098]
[0.5        0.23684211 0.        ]
-----------end of analyzing the loss ratio:75.95053720474243
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6d4c490>
---------------------------------
SparseEpoch: [157][1/398]	Time 0.587	Data 0.000	Loss 2.0271	
SparseEpoch: [157][101/398]	Time 0.581	Data 0.000	Loss 1.6643	
SparseEpoch: [157][201/398]	Time 0.581	Data 0.000	Loss 1.2168	
SparseEpoch: [157][301/398]	Time 0.581	Data 0.000	Loss 1.8120	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.5574	
Epoch(adapt):{0} Loss 0.6126	
Epoch(adapt):{0} Loss 0.5559	
Epoch(adapt):{0} Loss 0.4584	
------------------the total time cost:1169.3737626075745
>>>>>meta updating
Epoch: 0157 | TRAIN: 0.2725 0.7956 0.9133 | 0.2935 0.2935 0.1329 | 0.1089 21.4104 16.4088 0.3476 0.6526 0.7731 ||TEST: 1.3551 0.4112 0.6660 | 0.5282 0.5282 0.2083 | 0.1410 25.0771 20.0778 0.2875 0.5579 0.6854 | 116.9610
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.27672202 0.27675512 0.27678296 0.27678128 0.27676252 0.27673
 0.276715   0.27664942 0.27660672 0.27657064 0.27645394 0.27638771
 0.27637603 0.27630174 0.27632001 0.27636388 0.27639167 0.27643099
 0.27639446 0.2763247 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.27664511 0.27665582 0.27662878 0.27662023 0.27661835 0.27660732
 0.27659134 0.27654975 0.27653208 0.27651832 0.27650801 0.27651346
 0.27648921 0.27647956 0.2764634  0.27647224 0.27645978 0.2765224
 0.27645188 0.27643415]
[0.         0.18421053 0.5       ]
-----------end of analyzing the loss ratio:75.61953091621399
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6e11ab0>
---------------------------------
SparseEpoch: [158][1/398]	Time 0.578	Data 0.000	Loss 0.7744	
SparseEpoch: [158][101/398]	Time 0.582	Data 0.000	Loss 0.9681	
SparseEpoch: [158][201/398]	Time 0.581	Data 0.000	Loss 0.5974	
SparseEpoch: [158][301/398]	Time 0.581	Data 0.000	Loss 0.7465	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.26828518 0.26817793 0.26814103 0.26818413 0.26815866 0.26811502
 0.26811781 0.26817477 0.26818796 0.26811932 0.26803728 0.26797167
 0.26796008 0.26792302 0.26790687 0.26793614 0.26786141 0.26778037
 0.26776481 0.26776805]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.26813681 0.26811363 0.26811577 0.26810904 0.26809675 0.2681004
 0.26809377 0.26809803 0.26809691 0.26804822 0.26803967 0.26805571
 0.26803746 0.26803972 0.26800097 0.26799956 0.26800389 0.26797729
 0.26796871 0.26795343]
[0.44736842 0.         0.5       ]
-----------end of analyzing the loss ratio:75.64161992073059
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc35c160>
---------------------------------
SparseEpoch: [158][1/398]	Time 0.579	Data 0.000	Loss 1.1428	
SparseEpoch: [158][101/398]	Time 0.581	Data 0.000	Loss 1.2984	
SparseEpoch: [158][201/398]	Time 0.581	Data 0.000	Loss 0.7852	
SparseEpoch: [158][301/398]	Time 0.581	Data 0.000	Loss 0.9365	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.15145633 0.15146774 0.15146407 0.15146598 0.15146465 0.15147755
 0.15149406 0.15149278 0.15148892 0.15148308 0.15148625 0.15148968
 0.15146    0.15146873 0.15149679 0.15150531 0.1514891  0.15148235
 0.15147581 0.15149898]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.1514868  0.15148661 0.15148312 0.1514879  0.15150241 0.15150043
 0.15148807 0.15147997 0.15148882 0.15148247 0.15148214 0.1514834
 0.1514759  0.15148222 0.15148072 0.15147523 0.15146742 0.15147225
 0.15148829 0.15148439]
[0.         0.34210526 0.        ]
-----------end of analyzing the loss ratio:75.74270176887512
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7446096c6410>
---------------------------------
SparseEpoch: [158][1/398]	Time 0.578	Data 0.000	Loss 1.1177	
SparseEpoch: [158][101/398]	Time 0.581	Data 0.000	Loss 1.0948	
SparseEpoch: [158][201/398]	Time 0.581	Data 0.000	Loss 1.1790	
SparseEpoch: [158][301/398]	Time 0.581	Data 0.000	Loss 1.5181	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.5118	
Epoch(adapt):{0} Loss 0.5686	
Epoch(adapt):{0} Loss 0.5580	
Epoch(adapt):{0} Loss 0.7090	
------------------the total time cost:1168.452518939972
>>>>>meta updating
Epoch: 0158 | TRAIN: 0.2626 0.7969 0.9155 | 0.3088 0.3088 0.1369 | 0.1087 21.4967 16.5815 0.3391 0.6509 0.7735 ||TEST: 1.3096 0.4170 0.6703 | 0.5350 0.5350 0.2117 | 0.1400 25.0807 20.1100 0.2817 0.5573 0.6864 | 117.0500
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.29205361 0.29210869 0.29215824 0.29213954 0.29211742 0.29210467
 0.29214976 0.29216751 0.2921335  0.29215968 0.2921574  0.29227902
 0.29233461 0.2923094  0.29237834 0.29241691 0.29247835 0.29243192
 0.29242184 0.29246063]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.29221733 0.29220362 0.29221029 0.29220538 0.29216206 0.29215937
 0.29217575 0.29216456 0.29216761 0.29216695 0.2921748  0.29216539
 0.29217174 0.29222222 0.29222368 0.29223993 0.29223234 0.29222105
 0.29223555 0.29224165]
[0. 0. 0.]
-----------end of analyzing the loss ratio:75.86796474456787
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6e7b4c0>
---------------------------------
SparseEpoch: [159][1/398]	Time 0.578	Data 0.000	Loss 0.3590	
SparseEpoch: [159][101/398]	Time 0.579	Data 0.000	Loss 0.3658	
SparseEpoch: [159][201/398]	Time 0.580	Data 0.000	Loss 0.2896	
SparseEpoch: [159][301/398]	Time 0.580	Data 0.000	Loss 0.2029	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.37138088 0.37138033 0.37135951 0.37137    0.37130412 0.37124267
 0.37123584 0.37120132 0.37119022 0.37115683 0.37111091 0.37108604
 0.37110198 0.3710379  0.37102395 0.37099815 0.37101635 0.37101316
 0.37102515 0.37109072]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.37118615 0.37118472 0.37118513 0.37118269 0.37117869 0.37118112
 0.37118458 0.37116775 0.37114617 0.37114155 0.37114348 0.37114835
 0.37111391 0.3711088  0.37109274 0.37109799 0.3711018  0.37108676
 0.3711115  0.37110439]
[0.28947368 0.         0.39473684]
-----------end of analyzing the loss ratio:75.70944452285767
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6cd8b50>
---------------------------------
SparseEpoch: [159][1/398]	Time 0.578	Data 0.000	Loss 0.3945	
SparseEpoch: [159][101/398]	Time 0.582	Data 0.000	Loss 0.4805	
SparseEpoch: [159][201/398]	Time 0.581	Data 0.000	Loss 0.7904	
SparseEpoch: [159][301/398]	Time 0.581	Data 0.000	Loss 0.9752	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11409109 0.11409059 0.11408058 0.11408173 0.11408158 0.11406205
 0.114057   0.11404567 0.11405951 0.11406577 0.1140708  0.11406386
 0.11406419 0.11404673 0.11404742 0.11403249 0.11402664 0.11401932
 0.11401618 0.11402445]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.1140758  0.11407015 0.11407551 0.11406764 0.11407195 0.11407956
 0.11409469 0.11407959 0.11407781 0.11406925 0.11406794 0.11405789
 0.11405202 0.11404463 0.11403532 0.11403444 0.11403527 0.11403191
 0.11403568 0.11403444]
[0.44736842 0.39473684 0.        ]
-----------end of analyzing the loss ratio:75.7799277305603
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6feb400>
---------------------------------
SparseEpoch: [159][1/398]	Time 0.581	Data 0.000	Loss 1.2826	
SparseEpoch: [159][101/398]	Time 0.580	Data 0.000	Loss 1.6013	
SparseEpoch: [159][201/398]	Time 0.580	Data 0.000	Loss 1.6601	
SparseEpoch: [159][301/398]	Time 0.580	Data 0.000	Loss 1.5827	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.6070	
Epoch(adapt):{0} Loss 0.6238	
Epoch(adapt):{0} Loss 0.4569	
Epoch(adapt):{0} Loss 0.3774	
------------------the total time cost:1168.1282694339752
>>>>>meta updating
Epoch: 0159 | TRAIN: 0.2743 0.7922 0.9136 | 0.2872 0.2872 0.1364 | 0.1099 21.5096 16.5069 0.3468 0.6486 0.7688 ||TEST: 1.3786 0.4184 0.6704 | 0.5203 0.5203 0.2095 | 0.1416 25.1578 20.2073 0.2875 0.5539 0.6816 | 117.0296
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.32823027 0.32827037 0.32825514 0.3282678  0.32825104 0.3282533
 0.3282868  0.32823795 0.3282368  0.32815538 0.32806774 0.32808823
 0.32804781 0.32806991 0.32789502 0.3279358  0.32795979 0.32789752
 0.32787547 0.32776684]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.32811996 0.3281151  0.32807223 0.32806834 0.3280786  0.32805649
 0.3280854  0.32804596 0.32806116 0.32806549 0.32806279 0.32806232
 0.32813369 0.32815191 0.32820194 0.32817698 0.32819296 0.32818829
 0.3282344  0.32816733]
[0.  0.5 0. ]
-----------end of analyzing the loss ratio:75.85403728485107
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444dc31a800>
---------------------------------
SparseEpoch: [160][1/398]	Time 0.579	Data 0.000	Loss 0.2792	
SparseEpoch: [160][101/398]	Time 0.580	Data 0.000	Loss 0.4939	
SparseEpoch: [160][201/398]	Time 0.580	Data 0.000	Loss 0.4837	
SparseEpoch: [160][301/398]	Time 0.580	Data 0.000	Loss 0.5398	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.3096199  0.30968936 0.3096549  0.30963056 0.30964532 0.30963771
 0.30963671 0.30967182 0.30966295 0.30967665 0.30968512 0.30964368
 0.3096109  0.30958343 0.30961937 0.30962488 0.30967626 0.30965212
 0.30960583 0.30961173]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.3096747  0.30966431 0.30967695 0.30968949 0.30969039 0.30968582
 0.30968424 0.30969382 0.30966799 0.30966909 0.30967924 0.30967523
 0.30968252 0.30969075 0.30969707 0.30969646 0.30969301 0.30969426
 0.3096922  0.30967522]
[0.18421053 0.         0.        ]
-----------end of analyzing the loss ratio:75.901052236557
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6c3d9f0>
---------------------------------
SparseEpoch: [160][1/398]	Time 0.578	Data 0.000	Loss 0.3045	
SparseEpoch: [160][101/398]	Time 0.580	Data 0.000	Loss 0.3027	
SparseEpoch: [160][201/398]	Time 0.580	Data 0.000	Loss 0.3051	
SparseEpoch: [160][301/398]	Time 0.580	Data 0.000	Loss 0.2653	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11837257 0.11837603 0.11837971 0.11837944 0.11838243 0.11837487
 0.11837631 0.11838071 0.11837686 0.11837887 0.11839336 0.11839526
 0.11837938 0.11837697 0.11837394 0.11837693 0.11838161 0.11837702
 0.11838101 0.11837871]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11841127 0.11840324 0.11840843 0.11840069 0.11841336 0.11842619
 0.11840011 0.11839214 0.11838581 0.11839134 0.11838036 0.11838527
 0.118388   0.11838716 0.11837401 0.11837671 0.11837552 0.1183809
 0.11838117 0.11837048]
[0.  0.5 0. ]
-----------end of analyzing the loss ratio:75.64862632751465
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6aec6d0>
---------------------------------
SparseEpoch: [160][1/398]	Time 0.578	Data 0.000	Loss 2.2464	
SparseEpoch: [160][101/398]	Time 0.581	Data 0.000	Loss 1.2058	
SparseEpoch: [160][201/398]	Time 0.581	Data 0.000	Loss 1.3105	
SparseEpoch: [160][301/398]	Time 0.580	Data 0.000	Loss 1.2068	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.6195	
Epoch(adapt):{0} Loss 0.5910	
Epoch(adapt):{0} Loss 0.5713	
Epoch(adapt):{0} Loss 0.6614	
------------------the total time cost:1167.0981435775757
>>>>>meta updating
Epoch: 0160 | TRAIN: 0.2733 0.7981 0.9129 | 0.2823 0.2823 0.1391 | 0.1087 21.3079 16.2103 0.3548 0.6549 0.7729 ||TEST: 1.3950 0.4160 0.6686 | 0.5132 0.5132 0.2084 | 0.1411 25.0867 20.0993 0.2884 0.5568 0.6845 | 117.5161
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.32807057 0.32802286 0.32795946 0.3279928  0.32804887 0.32805785
 0.32807994 0.32808604 0.32803008 0.32803842 0.32800145 0.32797127
 0.32798625 0.32803626 0.32805717 0.32805016 0.32808598 0.3280453
 0.3279701  0.32802616]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.32802881 0.32803585 0.32803215 0.32803284 0.32803867 0.32803928
 0.32803786 0.32804164 0.32800658 0.32800931 0.32801629 0.32801645
 0.32803296 0.32802165 0.32801511 0.32798136 0.32798969 0.32799985
 0.32801114 0.32801241]
[0.         0.         0.28947368]
-----------end of analyzing the loss ratio:75.62888884544373
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6b5f340>
---------------------------------
SparseEpoch: [161][1/398]	Time 0.577	Data 0.000	Loss 0.4474	
SparseEpoch: [161][101/398]	Time 0.580	Data 0.000	Loss 0.8356	
SparseEpoch: [161][201/398]	Time 0.580	Data 0.000	Loss 0.6243	
SparseEpoch: [161][301/398]	Time 0.580	Data 0.000	Loss 0.4969	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.33290921 0.33283223 0.3326739  0.3324885  0.33222518 0.33204467
 0.33183022 0.33178556 0.3317044  0.33151321 0.33131938 0.33135147
 0.33111574 0.33093988 0.33072736 0.33067513 0.33045023 0.33022552
 0.33013765 0.3301008 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.33150864 0.3315185  0.33153113 0.33150855 0.33147835 0.33149686
 0.33147944 0.3314668  0.33145114 0.33141408 0.33140308 0.33139769
 0.33140429 0.33136793 0.33135622 0.33136837 0.33134926 0.33135867
 0.33133532 0.33131689]
[0.5 0.  0.5]
-----------end of analyzing the loss ratio:75.6209921836853
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc0ee2f0>
---------------------------------
SparseEpoch: [161][1/398]	Time 0.588	Data 0.000	Loss 1.2117	
SparseEpoch: [161][101/398]	Time 0.580	Data 0.000	Loss 0.8003	
SparseEpoch: [161][201/398]	Time 0.581	Data 0.000	Loss 1.3820	
SparseEpoch: [161][301/398]	Time 0.581	Data 0.000	Loss 1.1102	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11620783 0.11621888 0.11622654 0.11622444 0.11621937 0.11622149
 0.1162245  0.11623729 0.11624262 0.11624081 0.1162475  0.11624991
 0.11624398 0.11624923 0.11625565 0.11624874 0.11623834 0.11623428
 0.11623182 0.11623315]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11618239 0.11618941 0.11619985 0.1162064  0.11621889 0.11623303
 0.11622971 0.11624542 0.116246   0.11624216 0.11624604 0.11625804
 0.11625351 0.11623713 0.11624852 0.11625438 0.11624367 0.11624815
 0.11624817 0.11624479]
[0. 0. 0.]
-----------end of analyzing the loss ratio:75.6796383857727
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d69299c0>
---------------------------------
SparseEpoch: [161][1/398]	Time 0.577	Data 0.000	Loss 0.8726	
SparseEpoch: [161][101/398]	Time 0.580	Data 0.000	Loss 0.6985	
SparseEpoch: [161][201/398]	Time 0.580	Data 0.000	Loss 1.0086	
SparseEpoch: [161][301/398]	Time 0.580	Data 0.000	Loss 0.9653	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.5028	
Epoch(adapt):{0} Loss 0.5294	
Epoch(adapt):{0} Loss 0.5434	
Epoch(adapt):{0} Loss 0.7393	
------------------the total time cost:1167.443617105484
>>>>>meta updating
Epoch: 0161 | TRAIN: 0.2702 0.7959 0.9139 | 0.3008 0.3008 0.1525 | 0.1090 21.3004 16.1215 0.3552 0.6584 0.7756 ||TEST: 1.3679 0.4241 0.6722 | 0.5182 0.5182 0.2125 | 0.1396 24.8849 19.7832 0.2929 0.5639 0.6901 | 117.0697
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.33245492 0.3324889  0.33250138 0.33239765 0.3323999  0.33244507
 0.33244952 0.33245908 0.33242465 0.33246882 0.33243557 0.33242664
 0.3323629  0.33231733 0.33230691 0.33224021 0.33219233 0.33220091
 0.33219843 0.33216897]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.3324397  0.33244134 0.33243594 0.33242792 0.33244731 0.33243769
 0.33247257 0.33244762 0.33245819 0.33245784 0.33248048 0.33248757
 0.33245859 0.33247164 0.33248063 0.33249497 0.33248011 0.33248635
 0.33248721 0.33243651]
[0.  0.5 0. ]
-----------end of analyzing the loss ratio:76.06196522712708
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444dc151630>
---------------------------------
SparseEpoch: [162][1/398]	Time 0.578	Data 0.000	Loss 0.4616	
SparseEpoch: [162][101/398]	Time 0.581	Data 0.000	Loss 0.4615	
SparseEpoch: [162][201/398]	Time 0.581	Data 0.000	Loss 0.3662	
SparseEpoch: [162][301/398]	Time 0.581	Data 0.000	Loss 0.3261	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.32894873 0.32893273 0.32894343 0.32889531 0.32894452 0.32892602
 0.32893253 0.32894725 0.32885996 0.32883834 0.32891498 0.3288939
 0.32886959 0.32887864 0.32888448 0.32892727 0.32890915 0.32893362
 0.32885042 0.32882545]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.32889009 0.3288508  0.32884754 0.3288402  0.32884409 0.32886485
 0.32885047 0.32885641 0.32886468 0.32887989 0.32887131 0.32888427
 0.32890114 0.32892135 0.3289122  0.32894093 0.32894397 0.32891331
 0.32887175 0.32885754]
[0.5 0.  0. ]
-----------end of analyzing the loss ratio:75.78290581703186
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6cc9f30>
---------------------------------
SparseEpoch: [162][1/398]	Time 0.578	Data 0.000	Loss 0.3348	
SparseEpoch: [162][101/398]	Time 0.580	Data 0.000	Loss 0.5784	
SparseEpoch: [162][201/398]	Time 0.580	Data 0.000	Loss 0.3266	
SparseEpoch: [162][301/398]	Time 0.580	Data 0.000	Loss 0.2363	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.10096564 0.1009699  0.1009768  0.10096904 0.1009668  0.10094912
 0.10095304 0.10093585 0.10093184 0.10092596 0.10093157 0.10094281
 0.10093932 0.10093623 0.10092385 0.10090763 0.10088676 0.10087761
 0.10088308 0.10088648]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.10107297 0.10103897 0.10104535 0.10099679 0.10098312 0.10097135
 0.10094929 0.10095047 0.10093436 0.10092413 0.10094021 0.10093816
 0.10091637 0.1008871  0.10084744 0.10084626 0.10083218 0.10079979
 0.10079508 0.1007902 ]
[0.39473684 0.5        0.        ]
-----------end of analyzing the loss ratio:75.78672170639038
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6f52890>
---------------------------------
SparseEpoch: [162][1/398]	Time 0.579	Data 0.000	Loss 0.9781	
SparseEpoch: [162][101/398]	Time 0.581	Data 0.000	Loss 2.7129	
SparseEpoch: [162][201/398]	Time 0.581	Data 0.000	Loss 1.2729	
SparseEpoch: [162][301/398]	Time 0.581	Data 0.000	Loss 1.1626	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.8421	
Epoch(adapt):{0} Loss 0.4125	
Epoch(adapt):{0} Loss 0.7152	
Epoch(adapt):{0} Loss 0.7462	
------------------the total time cost:1167.726092338562
>>>>>meta updating
Epoch: 0162 | TRAIN: 0.2668 0.7974 0.9158 | 0.2995 0.2995 0.1380 | 0.1115 21.8812 17.1498 0.3300 0.6354 0.7626 ||TEST: 1.3131 0.4206 0.6683 | 0.5307 0.5307 0.2090 | 0.1441 25.5490 20.8184 0.2759 0.5416 0.6724 | 117.4823
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.21294888 0.21294896 0.21290406 0.21290354 0.21290109 0.21285832
 0.21284787 0.21284541 0.21283087 0.21287697 0.21284451 0.21283787
 0.2128546  0.21283782 0.21284283 0.21282033 0.21277533 0.21276017
 0.2127337  0.21276142]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.21279791 0.21280923 0.21282052 0.21282926 0.21284703 0.21285289
 0.21284639 0.21283852 0.21283644 0.21286718 0.21286166 0.21287013
 0.21285947 0.21284383 0.2128493  0.21285589 0.21288994 0.21289829
 0.21291349 0.21289085]
[0.         0.44736842 0.        ]
-----------end of analyzing the loss ratio:75.7489926815033
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc045600>
---------------------------------
SparseEpoch: [163][1/398]	Time 0.578	Data 0.000	Loss 0.3763	
SparseEpoch: [163][101/398]	Time 0.580	Data 0.000	Loss 0.3963	
SparseEpoch: [163][201/398]	Time 0.580	Data 0.000	Loss 0.4785	
SparseEpoch: [163][301/398]	Time 0.580	Data 0.000	Loss 0.4450	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.27862809 0.27856376 0.27847175 0.27836439 0.27840076 0.27835255
 0.27841318 0.27832904 0.27829368 0.27828475 0.27824373 0.27825215
 0.2782731  0.2782107  0.27813874 0.27819297 0.27811266 0.27813922
 0.27807708 0.27804638]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.27832119 0.2783177  0.27833816 0.27829963 0.27828531 0.27827592
 0.27827216 0.2782744  0.27825725 0.27825526 0.27826643 0.27824575
 0.27825555 0.27825296 0.27820683 0.27822729 0.27822374 0.278206
 0.27823237 0.27820322]
[0.5 0.  0.5]
-----------end of analyzing the loss ratio:75.62337613105774
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc16af80>
---------------------------------
SparseEpoch: [163][1/398]	Time 0.579	Data 0.000	Loss 0.9964	
SparseEpoch: [163][101/398]	Time 0.580	Data 0.000	Loss 0.7278	
SparseEpoch: [163][201/398]	Time 0.581	Data 0.000	Loss 0.8650	
SparseEpoch: [163][301/398]	Time 0.581	Data 0.000	Loss 0.9469	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11472143 0.11472623 0.11472949 0.11472799 0.11473433 0.11474199
 0.11473697 0.11473559 0.11472633 0.11472876 0.11473885 0.11474146
 0.11474348 0.11473261 0.11473039 0.11472948 0.11472929 0.11473593
 0.11473707 0.11472151]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11477036 0.11476406 0.11475405 0.11475599 0.11475632 0.11477248
 0.11476087 0.11474718 0.11475092 0.11473064 0.11474191 0.11473088
 0.11470266 0.11472049 0.11472282 0.1147212  0.11473074 0.11474391
 0.11473082 0.11472184]
[0.         0.13157895 0.        ]
-----------end of analyzing the loss ratio:75.87453937530518
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc2ae200>
---------------------------------
SparseEpoch: [163][1/398]	Time 0.578	Data 0.000	Loss 1.1088	
SparseEpoch: [163][101/398]	Time 0.580	Data 0.000	Loss 0.9905	
SparseEpoch: [163][201/398]	Time 0.580	Data 0.000	Loss 1.0182	
SparseEpoch: [163][301/398]	Time 0.580	Data 0.000	Loss 1.1481	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.4932	
Epoch(adapt):{0} Loss 0.6620	
Epoch(adapt):{0} Loss 0.4981	
Epoch(adapt):{0} Loss 0.5251	
------------------the total time cost:1168.244155406952
>>>>>meta updating
Epoch: 0163 | TRAIN: 0.2701 0.7977 0.9145 | 0.3143 0.3143 0.1407 | 0.1106 21.8384 17.1357 0.3272 0.6385 0.7647 ||TEST: 1.2782 0.4207 0.6689 | 0.5467 0.5467 0.2129 | 0.1420 25.4251 20.7458 0.2716 0.5439 0.6765 | 117.1504
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.24432853 0.24427653 0.24440617 0.244351   0.24434058 0.24435223
 0.24427451 0.24428153 0.24427052 0.24426392 0.24431966 0.24433207
 0.24428203 0.24442019 0.24429589 0.24429072 0.24423006 0.24430135
 0.24426574 0.24428115]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.24431074 0.2443108  0.24431445 0.2443317  0.24433017 0.24434221
 0.24433599 0.2443363  0.24433759 0.24434834 0.24433219 0.2443214
 0.24432546 0.2443283  0.24432227 0.2443296  0.24431469 0.24430309
 0.24430425 0.24429821]
[0.         0.34210526 0.5       ]
-----------end of analyzing the loss ratio:76.17757558822632
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc327100>
---------------------------------
SparseEpoch: [164][1/398]	Time 0.603	Data 0.000	Loss 0.8066	
SparseEpoch: [164][101/398]	Time 0.582	Data 0.000	Loss 1.2155	
SparseEpoch: [164][201/398]	Time 0.581	Data 0.000	Loss 0.9193	
SparseEpoch: [164][301/398]	Time 0.581	Data 0.000	Loss 1.5432	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.38326974 0.38324067 0.38320307 0.38321147 0.38322027 0.38323314
 0.38323957 0.38320951 0.38321992 0.38330737 0.38333681 0.38330733
 0.38332882 0.38331558 0.3833367  0.38335034 0.38332582 0.38337327
 0.38335117 0.38340136]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.38330876 0.38328587 0.38327633 0.38322397 0.38330937 0.38330998
 0.38331882 0.38331999 0.38330546 0.3833216  0.38332638 0.38331896
 0.3833041  0.38327968 0.3832825  0.38329125 0.3833309  0.38332947
 0.38332828 0.38333159]
[0. 0. 0.]
-----------end of analyzing the loss ratio:76.00401830673218
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6928a60>
---------------------------------
SparseEpoch: [164][1/398]	Time 0.578	Data 0.000	Loss 0.2490	
SparseEpoch: [164][101/398]	Time 0.580	Data 0.000	Loss 0.2037	
SparseEpoch: [164][201/398]	Time 0.580	Data 0.000	Loss 0.2564	
SparseEpoch: [164][301/398]	Time 0.580	Data 0.000	Loss 0.3479	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11329732 0.11330523 0.11330656 0.11332582 0.11331793 0.11331374
 0.11331419 0.11331568 0.11331415 0.11331092 0.11329892 0.11330643
 0.11330913 0.11330692 0.1133242  0.11330802 0.11329153 0.11330183
 0.11328757 0.11325913]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11331806 0.11332265 0.11332145 0.11331595 0.11332344 0.11333339
 0.11331921 0.11331226 0.11331592 0.11330238 0.11330212 0.1133044
 0.11328979 0.11328656 0.11328708 0.11327882 0.11327868 0.11328791
 0.11330616 0.11329874]
[0.5        0.34210526 0.        ]
-----------end of analyzing the loss ratio:76.02214789390564
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6c5cee0>
---------------------------------
SparseEpoch: [164][1/398]	Time 0.579	Data 0.000	Loss 1.2897	
SparseEpoch: [164][101/398]	Time 0.581	Data 0.000	Loss 1.0102	
SparseEpoch: [164][201/398]	Time 0.581	Data 0.000	Loss 1.3550	
SparseEpoch: [164][301/398]	Time 0.581	Data 0.000	Loss 1.5646	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.4703	
Epoch(adapt):{0} Loss 0.5294	
Epoch(adapt):{0} Loss 0.8723	
Epoch(adapt):{0} Loss 0.8166	
------------------the total time cost:1168.739651441574
>>>>>meta updating
Epoch: 0164 | TRAIN: 0.2664 0.8035 0.9148 | 0.2863 0.2863 0.1385 | 0.1077 21.2447 16.2344 0.3531 0.6556 0.7751 ||TEST: 1.4019 0.4200 0.6692 | 0.5218 0.5218 0.2106 | 0.1413 25.0403 19.9099 0.2927 0.5601 0.6856 | 117.5339
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.26333699 0.26330117 0.2634142  0.26338967 0.26349637 0.26366641
 0.26349418 0.26347515 0.2635023  0.26366559 0.26355964 0.2636463
 0.26370005 0.26372627 0.26356277 0.263655   0.2637062  0.2637592
 0.26368886 0.26378227]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.26358339 0.26354323 0.26355209 0.26357934 0.26353412 0.26353353
 0.2635227  0.26352387 0.26350754 0.26347087 0.26348121 0.26356584
 0.26359178 0.2636302  0.26361525 0.2636629  0.26369591 0.26375674
 0.26377318 0.26377284]
[0. 0. 0.]
-----------end of analyzing the loss ratio:75.94139409065247
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d72ba050>
---------------------------------
SparseEpoch: [165][1/398]	Time 0.585	Data 0.000	Loss 0.4132	
SparseEpoch: [165][101/398]	Time 0.580	Data 0.000	Loss 0.3767	
SparseEpoch: [165][201/398]	Time 0.580	Data 0.000	Loss 0.2627	
SparseEpoch: [165][301/398]	Time 0.580	Data 0.000	Loss 0.1938	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.37379574 0.37372523 0.37381276 0.37389625 0.3738462  0.37387888
 0.37385333 0.37373651 0.37373687 0.37374468 0.3735416  0.37353272
 0.37359709 0.37366168 0.3735776  0.37354622 0.37347807 0.37338375
 0.37329736 0.37326127]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.37374747 0.37375742 0.37373691 0.37374994 0.37371258 0.37370062
 0.37367124 0.37368633 0.37367925 0.37368179 0.37364689 0.37363748
 0.37363119 0.37360398 0.3735442  0.37351265 0.3734913  0.37347822
 0.37345186 0.37345818]
[0.5        0.         0.44736842]
-----------end of analyzing the loss ratio:75.89026403427124
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7446095cfe50>
---------------------------------
SparseEpoch: [165][1/398]	Time 0.581	Data 0.000	Loss 0.9388	
SparseEpoch: [165][101/398]	Time 0.583	Data 0.000	Loss 1.1142	
SparseEpoch: [165][201/398]	Time 0.582	Data 0.000	Loss 1.0589	
SparseEpoch: [165][301/398]	Time 0.582	Data 0.000	Loss 1.1650	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.0999181  0.09992272 0.09991262 0.09993431 0.09994035 0.09993876
 0.09993649 0.09992139 0.09991604 0.09992343 0.09992638 0.09991117
 0.09990264 0.0998821  0.09989135 0.09989015 0.0998731  0.09987603
 0.09986936 0.09987144]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.09992442 0.09990784 0.09991132 0.09991698 0.09990137 0.09990304
 0.09990782 0.09991284 0.09991616 0.09992129 0.0999247  0.0999176
 0.09991911 0.09991391 0.0999127  0.09990378 0.09991279 0.09990281
 0.09989616 0.09988149]
[0.44736842 0.5        0.        ]
-----------end of analyzing the loss ratio:75.96773338317871
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6c3f5e0>
---------------------------------
SparseEpoch: [165][1/398]	Time 0.578	Data 0.000	Loss 1.0936	
SparseEpoch: [165][101/398]	Time 0.581	Data 0.000	Loss 1.3424	
SparseEpoch: [165][201/398]	Time 0.581	Data 0.000	Loss 1.7258	
SparseEpoch: [165][301/398]	Time 0.581	Data 0.000	Loss 1.9549	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.5911	
Epoch(adapt):{0} Loss 0.5312	
Epoch(adapt):{0} Loss 0.4772	
Epoch(adapt):{0} Loss 0.4961	
------------------the total time cost:1167.7954621315002
>>>>>meta updating
Epoch: 0165 | TRAIN: 0.2656 0.8001 0.9154 | 0.2785 0.2785 0.1377 | 0.1073 21.1872 16.1505 0.3558 0.6570 0.7754 ||TEST: 1.4716 0.4157 0.6682 | 0.5117 0.5117 0.2102 | 0.1415 25.0673 19.9708 0.2925 0.5591 0.6844 | 117.2362
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.2403789  0.24039983 0.24039154 0.24038049 0.24033509 0.24032724
 0.24027892 0.24031563 0.24033534 0.24026645 0.24026957 0.24024644
 0.24026393 0.24028021 0.24026553 0.24018287 0.24020357 0.24018277
 0.24015996 0.2401587 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.24015728 0.24015799 0.24015897 0.24021215 0.24023415 0.24025879
 0.2402304  0.24024413 0.24022894 0.24023637 0.24025406 0.24024917
 0.24024897 0.24026381 0.24025535 0.24024219 0.24023281 0.24026927
 0.24033237 0.24032674]
[0.  0.5 0. ]
-----------end of analyzing the loss ratio:76.18355560302734
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc37dfc0>
---------------------------------
SparseEpoch: [166][1/398]	Time 0.578	Data 0.000	Loss 0.4547	
SparseEpoch: [166][101/398]	Time 0.581	Data 0.000	Loss 0.2917	
SparseEpoch: [166][201/398]	Time 0.581	Data 0.000	Loss 0.6038	
SparseEpoch: [166][301/398]	Time 0.581	Data 0.000	Loss 0.5691	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.32539621 0.32534577 0.32532568 0.32527232 0.32526407 0.32524582
 0.32528204 0.32524061 0.32519418 0.32522655 0.32513695 0.32514564
 0.32518395 0.32517371 0.32516775 0.32518384 0.3251306  0.32512033
 0.32510838 0.3251209 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.3252028  0.32520398 0.32521516 0.32521043 0.32520226 0.32519768
 0.32518378 0.32515693 0.32517752 0.32517048 0.32517205 0.32515202
 0.32515704 0.32515165 0.3251369  0.32514414 0.32515047 0.32517112
 0.32516485 0.32515963]
[0.44736842 0.         0.23684211]
-----------end of analyzing the loss ratio:76.07448697090149
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6dc01c0>
---------------------------------
SparseEpoch: [166][1/398]	Time 0.578	Data 0.000	Loss 0.8666	
SparseEpoch: [166][101/398]	Time 0.581	Data 0.000	Loss 0.3800	
SparseEpoch: [166][201/398]	Time 0.581	Data 0.000	Loss 0.6927	
SparseEpoch: [166][301/398]	Time 0.581	Data 0.000	Loss 0.7243	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.09924477 0.0992389  0.0992545  0.09926167 0.0992669  0.09926938
 0.09928253 0.09926886 0.09928183 0.09926682 0.0992842  0.09928527
 0.0992767  0.09929298 0.0992763  0.09926562 0.09925907 0.09925848
 0.09925242 0.09923851]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.09930152 0.09930803 0.09930445 0.09929411 0.09929509 0.09929084
 0.09927737 0.09926555 0.09927799 0.09926791 0.09926362 0.09926688
 0.09926505 0.09925159 0.0992368  0.09922586 0.09921889 0.09921537
 0.09921237 0.09919663]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:76.14135074615479
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6f536a0>
---------------------------------
SparseEpoch: [166][1/398]	Time 0.578	Data 0.000	Loss 1.5879	
SparseEpoch: [166][101/398]	Time 0.581	Data 0.000	Loss 1.0801	
SparseEpoch: [166][201/398]	Time 0.581	Data 0.000	Loss 1.0002	
SparseEpoch: [166][301/398]	Time 0.581	Data 0.000	Loss 1.1663	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.4799	
Epoch(adapt):{0} Loss 0.6077	
Epoch(adapt):{0} Loss 0.6183	
Epoch(adapt):{0} Loss 0.4344	
------------------the total time cost:1169.473750591278
>>>>>meta updating
Epoch: 0166 | TRAIN: 0.2773 0.7870 0.9116 | 0.3284 0.3284 0.1410 | 0.1096 21.6104 16.7279 0.3364 0.6466 0.7699 ||TEST: 1.2762 0.4151 0.6705 | 0.5598 0.5598 0.2121 | 0.1426 25.3971 20.6024 0.2763 0.5470 0.6778 | 117.0775
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.27494757 0.27493448 0.27491698 0.27492371 0.27493444 0.27491862
 0.27491466 0.27491363 0.2749179  0.27487882 0.27487891 0.27489285
 0.27488923 0.27497139 0.27495151 0.27494241 0.27495297 0.27492086
 0.27495063 0.27494867]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.27487603 0.27491486 0.27492059 0.27493841 0.27493749 0.27493755
 0.2749448  0.27492334 0.27488478 0.27486498 0.27487747 0.27487123
 0.27488955 0.27491083 0.27491698 0.27495472 0.27494397 0.27495422
 0.2749699  0.27497825]
[0. 0. 0.]
-----------end of analyzing the loss ratio:76.37365698814392
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444dc0ebfd0>
---------------------------------
SparseEpoch: [167][1/398]	Time 0.578	Data 0.000	Loss 0.3888	
SparseEpoch: [167][101/398]	Time 0.579	Data 0.000	Loss 0.2456	
SparseEpoch: [167][201/398]	Time 0.580	Data 0.000	Loss 0.4215	
SparseEpoch: [167][301/398]	Time 0.580	Data 0.000	Loss 0.1617	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.32637204 0.32635952 0.32635844 0.32632427 0.32630074 0.32624083
 0.32620649 0.32607301 0.32601196 0.32607256 0.3259852  0.326011
 0.32588309 0.32581728 0.32576976 0.3257684  0.32577509 0.32575829
 0.32558054 0.32551682]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.32607564 0.32607341 0.32604414 0.3260152  0.32602049 0.32599217
 0.3259798  0.32597849 0.32598447 0.32596567 0.32595487 0.32597527
 0.32597523 0.32597064 0.32597101 0.32598185 0.3259771  0.32599028
 0.32599322 0.32598364]
[0.5        0.         0.02631579]
-----------end of analyzing the loss ratio:76.43498396873474
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc11c910>
---------------------------------
SparseEpoch: [167][1/398]	Time 0.579	Data 0.000	Loss 0.3452	
SparseEpoch: [167][101/398]	Time 0.581	Data 0.000	Loss 0.3634	
SparseEpoch: [167][201/398]	Time 0.581	Data 0.000	Loss 0.4619	
SparseEpoch: [167][301/398]	Time 0.581	Data 0.000	Loss 0.3312	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.10828353 0.108248   0.10824183 0.10822216 0.10821328 0.10818085
 0.10816475 0.10810109 0.10812475 0.10814364 0.10813067 0.10807999
 0.10806496 0.10801467 0.10801262 0.10797731 0.10796667 0.10795045
 0.10791849 0.1078733 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.1082071  0.1082079  0.1081966  0.10819141 0.10817719 0.10812151
 0.10811699 0.10813322 0.10811737 0.10814081 0.10813242 0.10809739
 0.10808487 0.1080673  0.10802271 0.10797619 0.10794843 0.10794562
 0.10794131 0.1079583 ]
[0.5        0.44736842 0.        ]
-----------end of analyzing the loss ratio:75.8554036617279
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6f536a0>
---------------------------------
SparseEpoch: [167][1/398]	Time 0.581	Data 0.000	Loss 1.9808	
SparseEpoch: [167][101/398]	Time 0.580	Data 0.000	Loss 1.0827	
SparseEpoch: [167][201/398]	Time 0.581	Data 0.000	Loss 1.9889	
SparseEpoch: [167][301/398]	Time 0.580	Data 0.000	Loss 1.2470	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.5353	
Epoch(adapt):{0} Loss 0.4139	
Epoch(adapt):{0} Loss 0.4834	
Epoch(adapt):{0} Loss 0.6408	
------------------the total time cost:1169.3868596553802
>>>>>meta updating
Epoch: 0167 | TRAIN: 0.2659 0.8006 0.9153 | 0.2971 0.2971 0.1469 | 0.1091 21.4929 16.5444 0.3427 0.6507 0.7712 ||TEST: 1.3320 0.4199 0.6704 | 0.5218 0.5218 0.2121 | 0.1428 25.3086 20.3275 0.2839 0.5517 0.6792 | 117.0771
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.32127085 0.32136393 0.32140563 0.32146228 0.32137296 0.32133871
 0.32138559 0.32128655 0.3213593  0.32136157 0.32133138 0.32140851
 0.32137782 0.32130629 0.32123636 0.32122288 0.32129319 0.32130072
 0.32130548 0.32135087]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.32135449 0.32135628 0.32137013 0.32136584 0.32136679 0.32137862
 0.32138606 0.32138722 0.32137287 0.32137304 0.32134    0.32134776
 0.32133069 0.32134398 0.32133617 0.32133298 0.32133989 0.32133455
 0.32132192 0.32132007]
[0.         0.28947368 0.5       ]
-----------end of analyzing the loss ratio:75.8695228099823
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc552500>
---------------------------------
SparseEpoch: [168][1/398]	Time 0.586	Data 0.000	Loss 0.7118	
SparseEpoch: [168][101/398]	Time 0.582	Data 0.000	Loss 0.9936	
SparseEpoch: [168][201/398]	Time 0.581	Data 0.000	Loss 0.9567	
SparseEpoch: [168][301/398]	Time 0.581	Data 0.000	Loss 1.1712	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.37368729 0.3736833  0.37376237 0.37368233 0.37356475 0.37349468
 0.37340997 0.37327391 0.37321398 0.37316461 0.37317702 0.37301113
 0.37288704 0.37291269 0.3729235  0.37275874 0.37274159 0.37263194
 0.37260816 0.37267082]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.37319281 0.37316    0.37314012 0.37315315 0.37314588 0.37316046
 0.37318776 0.37319632 0.37317364 0.37315488 0.37315337 0.37313123
 0.37313011 0.37314304 0.37315771 0.37314979 0.37314812 0.37317713
 0.37317229 0.37317999]
[0.44736842 0.         0.13157895]
-----------end of analyzing the loss ratio:76.01601004600525
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc551960>
---------------------------------
SparseEpoch: [168][1/398]	Time 0.585	Data 0.000	Loss 0.4200	
SparseEpoch: [168][101/398]	Time 0.582	Data 0.000	Loss 0.4893	
SparseEpoch: [168][201/398]	Time 0.581	Data 0.000	Loss 0.2987	
SparseEpoch: [168][301/398]	Time 0.581	Data 0.000	Loss 0.6513	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.10320355 0.10321897 0.10316632 0.10317274 0.10315272 0.10312682
 0.10311637 0.1031083  0.10309582 0.1030946  0.10310887 0.10308403
 0.10306661 0.10306436 0.10303648 0.10301185 0.10296177 0.102987
 0.10295115 0.10298804]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.10311041 0.10312765 0.10312591 0.10311779 0.10311441 0.10309142
 0.10310927 0.10310366 0.10309311 0.10309466 0.10310833 0.10309662
 0.10309123 0.10306722 0.10307385 0.10306286 0.1030618  0.10306869
 0.10307578 0.1030822 ]
[0.44736842 0.34210526 0.        ]
-----------end of analyzing the loss ratio:75.76611399650574
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6b445e0>
---------------------------------
SparseEpoch: [168][1/398]	Time 0.578	Data 0.000	Loss 1.3688	
SparseEpoch: [168][101/398]	Time 0.581	Data 0.000	Loss 0.9718	
SparseEpoch: [168][201/398]	Time 0.581	Data 0.000	Loss 0.9194	
SparseEpoch: [168][301/398]	Time 0.581	Data 0.000	Loss 1.3854	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.6935	
Epoch(adapt):{0} Loss 0.8531	
Epoch(adapt):{0} Loss 0.7085	
Epoch(adapt):{0} Loss 0.5660	
------------------the total time cost:1169.7795023918152
>>>>>meta updating
Epoch: 0168 | TRAIN: 0.2693 0.7965 0.9150 | 0.2940 0.2940 0.1498 | 0.1080 21.1823 16.0317 0.3559 0.6626 0.7789 ||TEST: 1.4303 0.4177 0.6682 | 0.5215 0.5215 0.2131 | 0.1408 24.9434 19.7539 0.2922 0.5653 0.6921 | 116.9684
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.33153284 0.33145545 0.33142904 0.33143068 0.33140553 0.33143903
 0.33134466 0.33126869 0.33126301 0.33125543 0.33109432 0.33102541
 0.33102375 0.33108826 0.33108394 0.33116643 0.33110214 0.33107214
 0.33109059 0.33097563]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.33119408 0.3311679  0.33117189 0.33117312 0.33116647 0.33117606
 0.331179   0.33118594 0.33119183 0.33118986 0.33121475 0.33121009
 0.33120182 0.33121461 0.33120275 0.33120914 0.331212   0.33121481
 0.33121338 0.33120445]
[0.  0.5 0. ]
-----------end of analyzing the loss ratio:76.06810092926025
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d67cd870>
---------------------------------
SparseEpoch: [169][1/398]	Time 0.578	Data 0.000	Loss 0.3521	
SparseEpoch: [169][101/398]	Time 0.580	Data 0.000	Loss 0.3625	
SparseEpoch: [169][201/398]	Time 0.580	Data 0.000	Loss 0.4821	
SparseEpoch: [169][301/398]	Time 0.580	Data 0.000	Loss 0.5065	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.37014575 0.36981335 0.36941641 0.36900159 0.36869887 0.3684067
 0.36791242 0.36740467 0.36698637 0.36673667 0.36638206 0.36614884
 0.36592431 0.36579746 0.36542236 0.36488637 0.36438462 0.36382804
 0.36340438 0.36315825]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.36705896 0.36696424 0.36694728 0.36687556 0.36679503 0.36678273
 0.36672026 0.36669842 0.36664893 0.36659538 0.36655511 0.36645458
 0.36643203 0.36633663 0.36639654 0.3662932  0.36614875 0.36622849
 0.36613417 0.36617042]
[0.5        0.         0.44736842]
-----------end of analyzing the loss ratio:76.1878297328949
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d72d2530>
---------------------------------
SparseEpoch: [169][1/398]	Time 0.580	Data 0.000	Loss 1.0906	
SparseEpoch: [169][101/398]	Time 0.581	Data 0.000	Loss 0.7743	
SparseEpoch: [169][201/398]	Time 0.582	Data 0.000	Loss 0.9288	
SparseEpoch: [169][301/398]	Time 0.581	Data 0.000	Loss 0.7823	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.12353296 0.12353142 0.12353443 0.12353005 0.12351453 0.12349507
 0.12348035 0.12346712 0.12346718 0.12347521 0.12347854 0.12347407
 0.12346599 0.12346402 0.12347222 0.12347726 0.1234666  0.12345588
 0.12342823 0.12342098]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.12355402 0.1235503  0.12355689 0.12353665 0.1235341  0.12353556
 0.12352611 0.12351003 0.12347733 0.12345751 0.12347119 0.12348742
 0.12347057 0.12345114 0.1234332  0.12342942 0.12343503 0.12342172
 0.12342241 0.12341712]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:75.75957798957825
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc278df0>
---------------------------------
SparseEpoch: [169][1/398]	Time 0.578	Data 0.000	Loss 1.4164	
SparseEpoch: [169][101/398]	Time 0.581	Data 0.000	Loss 1.5297	
SparseEpoch: [169][201/398]	Time 0.581	Data 0.000	Loss 1.0760	
SparseEpoch: [169][301/398]	Time 0.581	Data 0.000	Loss 1.0551	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.5173	
Epoch(adapt):{0} Loss 0.8401	
Epoch(adapt):{0} Loss 0.5513	
Epoch(adapt):{0} Loss 0.3254	
------------------the total time cost:1169.6833808422089
>>>>>meta updating
Epoch: 0169 | TRAIN: 0.2521 0.8087 0.9194 | 0.2885 0.2885 0.1297 | 0.1061 21.0498 16.0254 0.3547 0.6636 0.7822 ||TEST: 1.4220 0.4165 0.6649 | 0.5247 0.5247 0.2061 | 0.1406 24.9996 19.9476 0.2897 0.5607 0.6883 | 117.0867
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.23475794 0.23477095 0.23483119 0.23482881 0.23483781 0.23494401
 0.23501128 0.23494115 0.23482221 0.23480592 0.23474381 0.23482914
 0.23477593 0.23469805 0.23462768 0.23459699 0.23460144 0.23458121
 0.23463046 0.23467049]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.23476647 0.23475864 0.2347645  0.23476027 0.2347529  0.23475866
 0.23476287 0.23475974 0.23476545 0.23478215 0.23477428 0.2347723
 0.23476617 0.23476716 0.23476612 0.23476987 0.23477848 0.23477966
 0.23479537 0.23481463]
[0.         0.39473684 0.        ]
-----------end of analyzing the loss ratio:75.96701383590698
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x74460819b5e0>
---------------------------------
SparseEpoch: [170][1/398]	Time 0.578	Data 0.000	Loss 0.2748	
SparseEpoch: [170][101/398]	Time 0.581	Data 0.000	Loss 0.2815	
SparseEpoch: [170][201/398]	Time 0.581	Data 0.000	Loss 0.3253	
SparseEpoch: [170][301/398]	Time 0.581	Data 0.000	Loss 1.5778	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.28965411 0.28962333 0.28964202 0.28969371 0.2896695  0.28962793
 0.28962784 0.2896007  0.28959027 0.28958393 0.28960726 0.28954314
 0.28958367 0.28959381 0.28956707 0.28951914 0.28951676 0.28951844
 0.28948915 0.28949142]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.2895994  0.28958317 0.28959041 0.28958485 0.28959622 0.28959346
 0.28958076 0.28957358 0.28958515 0.28956811 0.28957177 0.28956861
 0.28959651 0.28958837 0.28958012 0.28960202 0.28959939 0.28958605
 0.2895976  0.28959901]
[0.44736842 0.         0.        ]
-----------end of analyzing the loss ratio:75.91570782661438
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d731f490>
---------------------------------
SparseEpoch: [170][1/398]	Time 0.577	Data 0.000	Loss 0.3708	
SparseEpoch: [170][101/398]	Time 0.580	Data 0.000	Loss 0.2938	
SparseEpoch: [170][201/398]	Time 0.581	Data 0.000	Loss 0.3340	
SparseEpoch: [170][301/398]	Time 0.580	Data 0.000	Loss 0.7308	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11315739 0.11314943 0.11314632 0.1131478  0.11316255 0.11317592
 0.11316414 0.11314259 0.11314917 0.11314481 0.11312283 0.11313745
 0.11313916 0.11313411 0.11313285 0.11311397 0.11310964 0.11310091
 0.11309957 0.11311308]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11319305 0.11318456 0.11318474 0.11317794 0.11316687 0.11316782
 0.11317249 0.11314039 0.11314849 0.11315039 0.11312065 0.11314899
 0.11314486 0.1131232  0.11311907 0.11310685 0.11308897 0.1130961
 0.11309301 0.11308239]
[0.44736842 0.5        0.        ]
-----------end of analyzing the loss ratio:75.77068758010864
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6e79bd0>
---------------------------------
SparseEpoch: [170][1/398]	Time 0.578	Data 0.000	Loss 1.3123	
SparseEpoch: [170][101/398]	Time 0.580	Data 0.000	Loss 1.0899	
SparseEpoch: [170][201/398]	Time 0.581	Data 0.000	Loss 0.8312	
SparseEpoch: [170][301/398]	Time 0.581	Data 0.000	Loss 0.8603	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.5838	
Epoch(adapt):{0} Loss 0.5056	
Epoch(adapt):{0} Loss 0.6180	
Epoch(adapt):{0} Loss 0.3931	
------------------the total time cost:1167.9883143901825
>>>>>meta updating
Epoch: 0170 | TRAIN: 0.2632 0.8039 0.9158 | 0.2814 0.2814 0.1353 | 0.1098 21.5812 16.7942 0.3404 0.6446 0.7694 ||TEST: 1.3859 0.4191 0.6683 | 0.5197 0.5197 0.2069 | 0.1440 25.4367 20.5663 0.2825 0.5466 0.6753 | 117.7134
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.27341151 0.27353131 0.27359351 0.27361651 0.27360855 0.27366856
 0.27358786 0.27358664 0.27359375 0.27353013 0.27357595 0.27351408
 0.27361925 0.27358583 0.27357301 0.27364589 0.27370416 0.27380978
 0.27372362 0.27371744]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.27379493 0.27379032 0.27367541 0.27362504 0.27361801 0.2736053
 0.27359605 0.27362431 0.27363337 0.27366838 0.27356062 0.27355341
 0.27359072 0.27358173 0.27365654 0.27362423 0.27363146 0.27355704
 0.27348438 0.27347496]
[0.  0.  0.5]
-----------end of analyzing the loss ratio:76.38188624382019
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d70742e0>
---------------------------------
SparseEpoch: [171][1/398]	Time 0.578	Data 0.000	Loss 0.7194	
SparseEpoch: [171][101/398]	Time 0.580	Data 0.000	Loss 0.8674	
SparseEpoch: [171][201/398]	Time 0.580	Data 0.000	Loss 0.6510	
SparseEpoch: [171][301/398]	Time 0.580	Data 0.000	Loss 1.0035	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.34289169 0.34284992 0.34280051 0.34275478 0.34278578 0.3428244
 0.34284626 0.34285323 0.34278732 0.34271857 0.34270136 0.34272502
 0.34269897 0.34271221 0.34272945 0.34274189 0.34272878 0.34270384
 0.34270072 0.34270142]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.34270867 0.34270503 0.34270621 0.34268253 0.3426802  0.34265976
 0.34266683 0.34264217 0.34266427 0.34268001 0.34268541 0.34267344
 0.34267701 0.34268492 0.34267119 0.3426782  0.34267623 0.34268077
 0.34268494 0.34269624]
[0.13157895 0.         0.        ]
-----------end of analyzing the loss ratio:75.89904880523682
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x74460925cb50>
---------------------------------
SparseEpoch: [171][1/398]	Time 0.579	Data 0.000	Loss 0.1358	
SparseEpoch: [171][101/398]	Time 0.581	Data 0.000	Loss 0.3100	
SparseEpoch: [171][201/398]	Time 0.581	Data 0.000	Loss 0.4085	
SparseEpoch: [171][301/398]	Time 0.581	Data 0.000	Loss 0.3502	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.1267167  0.12670738 0.1267168  0.1267179  0.12669572 0.12668872
 0.12668954 0.12666099 0.12667293 0.126659   0.12665611 0.12663248
 0.12662221 0.12662305 0.12662745 0.12663962 0.12661759 0.1266066
 0.12659403 0.12657185]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.12668231 0.12666765 0.12666422 0.12666698 0.12666734 0.12667006
 0.12666908 0.12667067 0.12666548 0.12665768 0.12665086 0.12665234
 0.12663434 0.1266421  0.12663308 0.12662898 0.12662359 0.12662297
 0.12662174 0.12661718]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:75.95694994926453
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444dc3b7a60>
---------------------------------
SparseEpoch: [171][1/398]	Time 0.578	Data 0.000	Loss 1.1167	
SparseEpoch: [171][101/398]	Time 0.582	Data 0.000	Loss 1.5133	
SparseEpoch: [171][201/398]	Time 0.581	Data 0.000	Loss 1.4195	
SparseEpoch: [171][301/398]	Time 0.581	Data 0.000	Loss 1.9591	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.3659	
Epoch(adapt):{0} Loss 1.0611	
Epoch(adapt):{0} Loss 0.6917	
Epoch(adapt):{0} Loss 0.4684	
------------------the total time cost:1169.4720628261566
>>>>>meta updating
Epoch: 0171 | TRAIN: 0.2549 0.8044 0.9188 | 0.2962 0.2962 0.1479 | 0.1068 21.1762 16.2099 0.3527 0.6570 0.7769 ||TEST: 1.3871 0.4262 0.6745 | 0.5159 0.5159 0.2099 | 0.1415 25.1482 20.1673 0.2876 0.5549 0.6825 | 117.4104
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.25152238 0.2513941  0.25137139 0.25137478 0.2513335  0.2512848
 0.25117733 0.25113398 0.2511415  0.25109377 0.25101767 0.25096203
 0.25095864 0.25098011 0.2509348  0.25091749 0.25090833 0.25081245
 0.25074006 0.25072232]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.25117149 0.25116783 0.25116092 0.25115757 0.2511407  0.25114965
 0.25109839 0.25107633 0.25107579 0.2510326  0.25101338 0.25100072
 0.25098976 0.25100038 0.25098388 0.25099001 0.25099447 0.25098129
 0.25098627 0.25102102]
[0.         0.5        0.39473684]
-----------end of analyzing the loss ratio:76.05683302879333
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d71937f0>
---------------------------------
SparseEpoch: [172][1/398]	Time 0.579	Data 0.000	Loss 0.9500	
SparseEpoch: [172][101/398]	Time 0.581	Data 0.000	Loss 0.5954	
SparseEpoch: [172][201/398]	Time 0.582	Data 0.000	Loss 0.7037	
SparseEpoch: [172][301/398]	Time 0.581	Data 0.000	Loss 0.6554	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.2730272  0.27302904 0.27304806 0.27303919 0.2730101  0.27302243
 0.27298575 0.27290578 0.27289596 0.27286983 0.27289091 0.27287338
 0.27286205 0.27287753 0.27284762 0.27281595 0.2728228  0.27281428
 0.27279956 0.27279377]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.27283749 0.27283186 0.27285232 0.27285075 0.27286414 0.27287581
 0.27288561 0.27287494 0.27288576 0.27288771 0.27288227 0.27288348
 0.2728805  0.27288001 0.27287213 0.27288003 0.27286635 0.27287096
 0.27286308 0.27285751]
[0.5 0.  0. ]
-----------end of analyzing the loss ratio:75.94279170036316
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6f95930>
---------------------------------
SparseEpoch: [172][1/398]	Time 0.578	Data 0.000	Loss 0.2517	
SparseEpoch: [172][101/398]	Time 0.580	Data 0.000	Loss 0.4504	
SparseEpoch: [172][201/398]	Time 0.581	Data 0.000	Loss 0.2942	
SparseEpoch: [172][301/398]	Time 0.581	Data 0.000	Loss 0.4564	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11432226 0.11430556 0.1143029  0.11429992 0.11428419 0.11428687
 0.11427504 0.11426029 0.11425913 0.11426871 0.11425412 0.11422789
 0.11420144 0.11421449 0.11419655 0.11418121 0.11415675 0.11415615
 0.11416148 0.11415206]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11425262 0.11426085 0.11426525 0.11426703 0.11427101 0.11427097
 0.11427317 0.11426894 0.1142628  0.11425356 0.11424654 0.11424807
 0.11423937 0.11423157 0.11423087 0.11422528 0.11421558 0.11421331
 0.1142153  0.11420718]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:76.19013214111328
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6b93d00>
---------------------------------
SparseEpoch: [172][1/398]	Time 0.579	Data 0.000	Loss 0.9692	
SparseEpoch: [172][101/398]	Time 0.581	Data 0.000	Loss 1.9020	
SparseEpoch: [172][201/398]	Time 0.581	Data 0.000	Loss 1.2064	
SparseEpoch: [172][301/398]	Time 0.581	Data 0.000	Loss 1.0028	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.4382	
Epoch(adapt):{0} Loss 0.4371	
Epoch(adapt):{0} Loss 0.8851	
Epoch(adapt):{0} Loss 0.4292	
------------------the total time cost:1169.728154182434
>>>>>meta updating
Epoch: 0172 | TRAIN: 0.2492 0.8128 0.9207 | 0.2737 0.2737 0.1322 | 0.1056 20.9978 16.0432 0.3577 0.6621 0.7804 ||TEST: 1.4456 0.4165 0.6673 | 0.5172 0.5172 0.2092 | 0.1415 25.1068 20.0888 0.2894 0.5566 0.6839 | 116.9389
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.22872562 0.2287307  0.22871364 0.22870278 0.22865938 0.22863736
 0.22866585 0.22873039 0.22877894 0.22877719 0.22874098 0.22869454
 0.22867939 0.22862426 0.22859708 0.22857176 0.2285787  0.22852867
 0.22852644 0.22859449]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.22875307 0.22876358 0.22877598 0.22873829 0.22874336 0.22875481
 0.22873215 0.2287588  0.22873956 0.2287252  0.22877921 0.22874891
 0.22866346 0.2286899  0.22873226 0.22870203 0.22863951 0.2286342
 0.22863154 0.22861741]
[0.         0.44736842 0.5       ]
-----------end of analyzing the loss ratio:76.05905604362488
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6fd5420>
---------------------------------
SparseEpoch: [173][1/398]	Time 0.579	Data 0.000	Loss 0.6537	
SparseEpoch: [173][101/398]	Time 0.582	Data 0.000	Loss 1.0822	
SparseEpoch: [173][201/398]	Time 0.581	Data 0.000	Loss 0.6198	
SparseEpoch: [173][301/398]	Time 0.581	Data 0.000	Loss 0.8023	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.32720306 0.32719813 0.32721355 0.32723311 0.32724214 0.32724422
 0.32725199 0.32725308 0.32724077 0.3272535  0.32726825 0.32730635
 0.32730606 0.32730555 0.32729561 0.32729583 0.32730269 0.32731771
 0.3273142  0.32730971]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.32733967 0.32734034 0.32733833 0.32732985 0.32728398 0.32729914
 0.32726463 0.32726683 0.32724264 0.32725502 0.32727391 0.32727721
 0.32726155 0.32726728 0.32727172 0.32726401 0.32726807 0.32729558
 0.327288   0.32727917]
[0. 0. 0.]
-----------end of analyzing the loss ratio:75.74059009552002
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7446095cd600>
---------------------------------
SparseEpoch: [173][1/398]	Time 0.577	Data 0.000	Loss 0.6365	
SparseEpoch: [173][101/398]	Time 0.579	Data 0.000	Loss 0.2531	
SparseEpoch: [173][201/398]	Time 0.579	Data 0.000	Loss 0.2845	
SparseEpoch: [173][301/398]	Time 0.579	Data 0.000	Loss 0.1886	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11625156 0.1162496  0.11625321 0.11623975 0.11625006 0.11624855
 0.11624628 0.11624811 0.11625178 0.11625038 0.11626362 0.11626573
 0.11626632 0.11627014 0.11624448 0.11621783 0.11622547 0.11622018
 0.11621166 0.1162264 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11625298 0.11624608 0.1162203  0.11624751 0.11623003 0.11623391
 0.11622733 0.11620709 0.11623788 0.11624728 0.11626011 0.11625367
 0.11625221 0.11625694 0.11625432 0.11624722 0.11623121 0.1162059
 0.11621456 0.11621292]
[0.44736842 0.39473684 0.        ]
-----------end of analyzing the loss ratio:75.84131336212158
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6bf3f70>
---------------------------------
SparseEpoch: [173][1/398]	Time 0.579	Data 0.000	Loss 1.2732	
SparseEpoch: [173][101/398]	Time 0.581	Data 0.000	Loss 1.0632	
SparseEpoch: [173][201/398]	Time 0.581	Data 0.000	Loss 1.4167	
SparseEpoch: [173][301/398]	Time 0.581	Data 0.000	Loss 0.6985	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.3799	
Epoch(adapt):{0} Loss 0.4687	
Epoch(adapt):{0} Loss 0.5360	
Epoch(adapt):{0} Loss 0.4962	
------------------the total time cost:1168.6988286972046
>>>>>meta updating
Epoch: 0173 | TRAIN: 0.2512 0.8096 0.9200 | 0.2760 0.2760 0.1276 | 0.1057 20.9745 15.9482 0.3598 0.6646 0.7814 ||TEST: 1.4152 0.4156 0.6710 | 0.5216 0.5216 0.2053 | 0.1410 25.0828 20.0720 0.2877 0.5577 0.6853 | 117.1463
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.25553207 0.25552166 0.25547842 0.25544715 0.25532318 0.25538507
 0.25535418 0.2552255  0.25516353 0.25518362 0.25515846 0.25522227
 0.25525098 0.25526504 0.25528833 0.25535335 0.2554079  0.25541608
 0.25538618 0.25534486]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.2553001  0.25525413 0.25520482 0.25522093 0.25520721 0.2552044
 0.2552074  0.2551819  0.25515759 0.25514651 0.25514419 0.25516787
 0.25518456 0.25517941 0.25517536 0.25516621 0.25515877 0.25515525
 0.25516729 0.25516017]
[0.         0.02631579 0.02631579]
-----------end of analyzing the loss ratio:75.85872316360474
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc2f6800>
---------------------------------
SparseEpoch: [174][1/398]	Time 0.578	Data 0.000	Loss 0.3175	
SparseEpoch: [174][101/398]	Time 0.581	Data 0.000	Loss 0.3178	
SparseEpoch: [174][201/398]	Time 0.581	Data 0.000	Loss 0.5669	
SparseEpoch: [174][301/398]	Time 0.581	Data 0.000	Loss 0.2621	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.25156336 0.25141747 0.25123986 0.25108235 0.2510626  0.25102763
 0.25102089 0.25100931 0.25092692 0.25102928 0.25089697 0.25090274
 0.2509021  0.25096333 0.25098276 0.25088487 0.25091501 0.25094312
 0.25092303 0.25090388]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.25097876 0.25095991 0.25096067 0.25096351 0.25095235 0.2509412
 0.25094543 0.25095092 0.25094871 0.25094843 0.25092796 0.25093442
 0.25094557 0.25094437 0.25097124 0.25097277 0.25097433 0.25097126
 0.25094984 0.25095471]
[0.28947368 0.         0.02631579]
-----------end of analyzing the loss ratio:75.85804629325867
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6ddd030>
---------------------------------
SparseEpoch: [174][1/398]	Time 0.578	Data 0.000	Loss 0.2485	
SparseEpoch: [174][101/398]	Time 0.581	Data 0.000	Loss 0.3771	
SparseEpoch: [174][201/398]	Time 0.581	Data 0.000	Loss 0.4168	
SparseEpoch: [174][301/398]	Time 0.581	Data 0.000	Loss 0.3036	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11875924 0.11873419 0.11872164 0.1186789  0.11868407 0.11865622
 0.1186446  0.11860924 0.11856689 0.11855602 0.11853945 0.1185064
 0.11848665 0.11846568 0.11844679 0.11843885 0.11841505 0.11839327
 0.11840947 0.11838465]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11856869 0.11855643 0.11856161 0.11856229 0.11856758 0.11856446
 0.11855141 0.11855206 0.1185511  0.11854283 0.11853966 0.11853784
 0.1185338  0.11852861 0.1185323  0.11853507 0.11852305 0.11852179
 0.11851535 0.11850068]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:75.99716711044312
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d692e050>
---------------------------------
SparseEpoch: [174][1/398]	Time 0.579	Data 0.000	Loss 0.9208	
SparseEpoch: [174][101/398]	Time 0.582	Data 0.000	Loss 1.7680	
SparseEpoch: [174][201/398]	Time 0.582	Data 0.000	Loss 1.5345	
SparseEpoch: [174][301/398]	Time 0.581	Data 0.000	Loss 1.4938	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.5602	
Epoch(adapt):{0} Loss 0.4736	
Epoch(adapt):{0} Loss 0.5398	
Epoch(adapt):{0} Loss 0.8572	
------------------the total time cost:1167.786657333374
>>>>>meta updating
Epoch: 0174 | TRAIN: 0.2484 0.8135 0.9214 | 0.2932 0.2932 0.1421 | 0.1031 20.7053 15.6897 0.3631 0.6714 0.7875 ||TEST: 1.3575 0.4246 0.6703 | 0.5249 0.5249 0.2120 | 0.1394 24.9154 19.9007 0.2897 0.5617 0.6898 | 117.1898
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.21696758 0.21693989 0.216925   0.21694176 0.21692654 0.21692917
 0.21689023 0.21687347 0.21691376 0.21696059 0.21702249 0.21701624
 0.21704896 0.21702588 0.21704199 0.21710181 0.21711304 0.21713147
 0.21711725 0.21711743]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.21701852 0.21705492 0.2170549  0.21704787 0.21703743 0.21702806
 0.21702231 0.21701382 0.21699743 0.21697611 0.21695222 0.21694317
 0.21694333 0.21694107 0.21694061 0.21694316 0.21692711 0.21692475
 0.21692723 0.21692366]
[0.  0.  0.5]
-----------end of analyzing the loss ratio:76.12139868736267
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6cda200>
---------------------------------
SparseEpoch: [175][1/398]	Time 0.579	Data 0.000	Loss 0.9993	
SparseEpoch: [175][101/398]	Time 0.580	Data 0.000	Loss 0.9448	
SparseEpoch: [175][201/398]	Time 0.580	Data 0.000	Loss 0.4651	
SparseEpoch: [175][301/398]	Time 0.580	Data 0.000	Loss 1.0675	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.38016329 0.37997423 0.3797847  0.37963571 0.37940107 0.37926135
 0.37908749 0.37897061 0.37901095 0.37883145 0.37871342 0.37857307
 0.37851149 0.37826282 0.37823724 0.37818237 0.37807869 0.37796571
 0.37780022 0.37765877]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.37902225 0.37898874 0.37893356 0.37889598 0.37891104 0.37886851
 0.37885228 0.37882151 0.37876655 0.378769   0.37871228 0.37869549
 0.37863446 0.37865639 0.37862761 0.37862376 0.37857039 0.37857192
 0.37854267 0.3785165 ]
[0.5 0.  0.5]
-----------end of analyzing the loss ratio:76.13483572006226
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444dc153e20>
---------------------------------
SparseEpoch: [175][1/398]	Time 0.578	Data 0.000	Loss 0.8050	
SparseEpoch: [175][101/398]	Time 0.581	Data 0.000	Loss 0.6929	
SparseEpoch: [175][201/398]	Time 0.581	Data 0.000	Loss 0.8585	
SparseEpoch: [175][301/398]	Time 0.582	Data 0.000	Loss 1.0004	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.12223527 0.12222289 0.12219065 0.12217337 0.1221509  0.12212855
 0.1221165  0.12210593 0.12209252 0.12209879 0.12207803 0.12204161
 0.12203326 0.12200707 0.1219796  0.12196659 0.12195319 0.1219389
 0.1219164  0.1219113 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.1222962  0.12229324 0.122265   0.12223747 0.12221537 0.12219654
 0.12215928 0.12211933 0.12211259 0.12209368 0.12206755 0.12203332
 0.12201064 0.12197779 0.12197182 0.12192268 0.12193285 0.12190641
 0.12189165 0.12187823]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:75.86388635635376
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6cb3730>
---------------------------------
SparseEpoch: [175][1/398]	Time 0.578	Data 0.000	Loss 1.1562	
SparseEpoch: [175][101/398]	Time 0.581	Data 0.000	Loss 1.4012	
SparseEpoch: [175][201/398]	Time 0.581	Data 0.000	Loss 1.5467	
SparseEpoch: [175][301/398]	Time 0.581	Data 0.000	Loss 1.5255	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.6204	
Epoch(adapt):{0} Loss 0.4104	
Epoch(adapt):{0} Loss 0.7049	
Epoch(adapt):{0} Loss 0.4833	
------------------the total time cost:1168.9948456287384
>>>>>meta updating
Epoch: 0175 | TRAIN: 0.2479 0.8144 0.9220 | 0.2970 0.2970 0.1326 | 0.1052 20.9049 15.8437 0.3614 0.6665 0.7830 ||TEST: 1.4090 0.4135 0.6691 | 0.5324 0.5324 0.2078 | 0.1395 24.8424 19.6824 0.2950 0.5657 0.6912 | 117.4196
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.23193988 0.2319334  0.23198805 0.23205895 0.23207579 0.23202156
 0.23202625 0.23202255 0.2320276  0.23202945 0.23204632 0.23205066
 0.23199853 0.23201571 0.23202343 0.23202204 0.23198045 0.231963
 0.23193109 0.23195176]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.23203943 0.2320629  0.23204219 0.23204364 0.23204159 0.23203379
 0.23203508 0.23202706 0.23203659 0.23202053 0.23202206 0.23202896
 0.23203877 0.23203585 0.23203613 0.23204565 0.23204    0.23201254
 0.23201275 0.23200719]
[0.         0.44736842 0.5       ]
-----------end of analyzing the loss ratio:75.92586588859558
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d72a2c80>
---------------------------------
SparseEpoch: [176][1/398]	Time 0.581	Data 0.000	Loss 0.7040	
SparseEpoch: [176][101/398]	Time 0.581	Data 0.000	Loss 0.6660	
SparseEpoch: [176][201/398]	Time 0.581	Data 0.000	Loss 0.9335	
SparseEpoch: [176][301/398]	Time 0.581	Data 0.000	Loss 1.0326	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.37785363 0.37765714 0.37749212 0.37721447 0.37697411 0.3766064
 0.37643922 0.37609119 0.37572716 0.37539145 0.37524642 0.37507847
 0.37483514 0.37454972 0.37429124 0.37419653 0.37391907 0.37362493
 0.37332682 0.37310565]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.37538787 0.37539848 0.37539901 0.37536512 0.37535764 0.37534026
 0.37530529 0.37531725 0.37532121 0.37531595 0.37533066 0.37531216
 0.37531585 0.37530946 0.37528923 0.37530243 0.37529248 0.37530122
 0.37531878 0.37528631]
[0.5 0.  0.5]
-----------end of analyzing the loss ratio:75.81364488601685
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d7192cb0>
---------------------------------
SparseEpoch: [176][1/398]	Time 0.581	Data 0.000	Loss 0.7324	
SparseEpoch: [176][101/398]	Time 0.581	Data 0.000	Loss 0.9875	
SparseEpoch: [176][201/398]	Time 0.580	Data 0.000	Loss 0.9030	
SparseEpoch: [176][301/398]	Time 0.581	Data 0.000	Loss 0.6602	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.10925424 0.10925047 0.10924683 0.10924937 0.10923797 0.10923261
 0.10923245 0.10922858 0.10922081 0.10921374 0.10921856 0.10920553
 0.10920436 0.10920159 0.10919672 0.10919375 0.10919558 0.10919206
 0.10919373 0.10918832]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.10928065 0.10927407 0.10928007 0.10926045 0.10926747 0.10925813
 0.10923969 0.10923883 0.10923524 0.10921447 0.10920994 0.10920976
 0.10919158 0.10916944 0.10915295 0.10915934 0.10914676 0.10913284
 0.10910968 0.10909839]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:75.97154831886292
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x74460925eb30>
---------------------------------
SparseEpoch: [176][1/398]	Time 0.581	Data 0.000	Loss 1.2309	
SparseEpoch: [176][101/398]	Time 0.581	Data 0.000	Loss 1.8502	
SparseEpoch: [176][201/398]	Time 0.581	Data 0.000	Loss 2.1134	
SparseEpoch: [176][301/398]	Time 0.581	Data 0.000	Loss 0.7481	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.3749	
Epoch(adapt):{0} Loss 0.5911	
Epoch(adapt):{0} Loss 0.4523	
Epoch(adapt):{0} Loss 0.5728	
------------------the total time cost:1168.5471639633179
>>>>>meta updating
Epoch: 0176 | TRAIN: 0.2409 0.8226 0.9236 | 0.3148 0.3148 0.1415 | 0.1049 20.8565 15.6957 0.3627 0.6711 0.7853 ||TEST: 1.3246 0.4209 0.6733 | 0.5488 0.5488 0.2147 | 0.1402 24.9408 19.7009 0.2915 0.5653 0.6907 | 117.0381
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.2335815  0.23350677 0.23348287 0.23350119 0.23351972 0.23351175
 0.23349867 0.23352269 0.2334353  0.23341147 0.23335423 0.23333267
 0.2333281  0.23335401 0.23334743 0.233327   0.23327035 0.23323363
 0.23326034 0.23326484]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.23341413 0.23341398 0.23341552 0.23341207 0.23341331 0.2334076
 0.23341383 0.23341309 0.23340547 0.233407   0.23339801 0.23341566
 0.23342036 0.23342558 0.23343443 0.23342728 0.23343311 0.23345128
 0.23345352 0.23347183]
[0.         0.39473684 0.02631579]
-----------end of analyzing the loss ratio:76.03824043273926
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6aeea40>
---------------------------------
SparseEpoch: [177][1/398]	Time 0.579	Data 0.000	Loss 0.5234	
SparseEpoch: [177][101/398]	Time 0.582	Data 0.000	Loss 0.2640	
SparseEpoch: [177][201/398]	Time 0.581	Data 0.000	Loss 0.5095	
SparseEpoch: [177][301/398]	Time 0.581	Data 0.000	Loss 0.3635	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.26404566 0.26406611 0.26407553 0.26404922 0.26398566 0.26393594
 0.2638956  0.26384475 0.26385437 0.26384217 0.26382566 0.26383714
 0.26378982 0.26374467 0.2637559  0.26371506 0.26375187 0.26373236
 0.26369939 0.26367186]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.263977   0.26392483 0.26391251 0.26390852 0.26388831 0.26386209
 0.26382567 0.26384974 0.26380447 0.26381775 0.26382266 0.26384434
 0.26386878 0.26387994 0.26383196 0.26382723 0.26381896 0.26384765
 0.26381961 0.26382084]
[0.5 0.  0. ]
-----------end of analyzing the loss ratio:75.94846653938293
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444dc2bb250>
---------------------------------
SparseEpoch: [177][1/398]	Time 0.578	Data 0.000	Loss 0.3032	
SparseEpoch: [177][101/398]	Time 0.581	Data 0.000	Loss 0.6963	
SparseEpoch: [177][201/398]	Time 0.580	Data 0.000	Loss 0.2889	
SparseEpoch: [177][301/398]	Time 0.581	Data 0.000	Loss 0.3851	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.10828259 0.10829158 0.108274   0.10828051 0.10827441 0.1082829
 0.1082849  0.10827948 0.10828577 0.10829133 0.10829158 0.1082991
 0.10829226 0.10828044 0.10829104 0.10830506 0.10831743 0.10832019
 0.10832343 0.10832378]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.10830786 0.10829265 0.10827441 0.10828896 0.108273   0.10826257
 0.10829109 0.10828849 0.10829047 0.10829438 0.10829605 0.10829383
 0.10829284 0.10828655 0.10830062 0.10828169 0.10829532 0.1082851
 0.10827143 0.10829195]
[0. 0. 0.]
-----------end of analyzing the loss ratio:75.88461518287659
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc2ad1e0>
---------------------------------
SparseEpoch: [177][1/398]	Time 0.578	Data 0.000	Loss 0.7492	
SparseEpoch: [177][101/398]	Time 0.580	Data 0.000	Loss 1.1728	
SparseEpoch: [177][201/398]	Time 0.579	Data 0.000	Loss 1.6149	
SparseEpoch: [177][301/398]	Time 0.580	Data 0.000	Loss 0.8803	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.4704	
Epoch(adapt):{0} Loss 0.4984	
Epoch(adapt):{0} Loss 0.5122	
Epoch(adapt):{0} Loss 0.5151	
------------------the total time cost:1168.2340257167816
>>>>>meta updating
Epoch: 0177 | TRAIN: 0.2572 0.8098 0.9181 | 0.2784 0.2784 0.1396 | 0.1046 20.9108 15.9294 0.3566 0.6664 0.7843 ||TEST: 1.4444 0.4205 0.6683 | 0.5176 0.5176 0.2089 | 0.1402 25.0160 20.0239 0.2881 0.5586 0.6868 | 117.6521
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.1943217  0.19431944 0.19424985 0.19422296 0.1942175  0.19416089
 0.19411645 0.19414578 0.19419777 0.19416584 0.19412372 0.19409073
 0.19408911 0.19413079 0.19413407 0.19412118 0.194134   0.19408266
 0.19409383 0.19410281]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.19414747 0.19416816 0.19416796 0.1941181  0.19412786 0.19413283
 0.19415514 0.1941632  0.19417384 0.19416956 0.194169   0.19418933
 0.1941755  0.19415784 0.19415043 0.19413579 0.19413967 0.19414028
 0.19413728 0.19413462]
[0.         0.39473684 0.        ]
-----------end of analyzing the loss ratio:76.08054256439209
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc025060>
---------------------------------
SparseEpoch: [178][1/398]	Time 0.585	Data 0.000	Loss 0.3251	
SparseEpoch: [178][101/398]	Time 0.582	Data 0.000	Loss 0.3930	
SparseEpoch: [178][201/398]	Time 0.581	Data 0.000	Loss 0.3052	
SparseEpoch: [178][301/398]	Time 0.581	Data 0.000	Loss 0.3981	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.34452809 0.34431327 0.34414901 0.34416041 0.34403126 0.34405581
 0.34386124 0.34367131 0.34333551 0.34305508 0.34285266 0.34260909
 0.34255166 0.34239925 0.34225099 0.3420613  0.34183071 0.34158493
 0.34144925 0.34126213]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.34313873 0.34309661 0.34308324 0.34302472 0.34299008 0.3429649
 0.34299028 0.34292361 0.3429199  0.34286388 0.34286183 0.34283363
 0.34284739 0.34283637 0.34285725 0.34282742 0.34286637 0.34285417
 0.34286665 0.34287841]
[0.5        0.         0.28947368]
-----------end of analyzing the loss ratio:76.46332287788391
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7446095ce050>
---------------------------------
SparseEpoch: [178][1/398]	Time 0.579	Data 0.000	Loss 0.4209	
SparseEpoch: [178][101/398]	Time 0.580	Data 0.000	Loss 0.7991	
SparseEpoch: [178][201/398]	Time 0.581	Data 0.000	Loss 0.5828	
SparseEpoch: [178][301/398]	Time 0.581	Data 0.000	Loss 0.5258	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.09440706 0.09440712 0.09439656 0.09438561 0.09438794 0.0944026
 0.09440894 0.09440829 0.09442424 0.09442512 0.09442967 0.09445248
 0.09445184 0.09444256 0.09443777 0.09443818 0.09443099 0.09443057
 0.09442762 0.09443304]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.09442023 0.09442363 0.09442708 0.0944232  0.09441664 0.0944118
 0.09441578 0.09442284 0.09441932 0.09443038 0.09443591 0.09443241
 0.09444357 0.0944394  0.09445022 0.09445329 0.09444907 0.0944532
 0.09443967 0.09443219]
[0. 0. 0.]
-----------end of analyzing the loss ratio:76.19951152801514
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc026b90>
---------------------------------
SparseEpoch: [178][1/398]	Time 0.577	Data 0.000	Loss 1.0482	
SparseEpoch: [178][101/398]	Time 0.580	Data 0.000	Loss 0.9799	
SparseEpoch: [178][201/398]	Time 0.579	Data 0.000	Loss 1.2113	
SparseEpoch: [178][301/398]	Time 0.579	Data 0.000	Loss 1.7393	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.5033	
Epoch(adapt):{0} Loss 0.3604	
Epoch(adapt):{0} Loss 0.8783	
Epoch(adapt):{0} Loss 0.5922	
------------------the total time cost:1169.1166353225708
>>>>>meta updating
Epoch: 0178 | TRAIN: 0.2423 0.8170 0.9229 | 0.2936 0.2936 0.1290 | 0.1055 21.0554 16.1590 0.3506 0.6621 0.7821 ||TEST: 1.3307 0.4184 0.6710 | 0.5405 0.5405 0.2073 | 0.1409 25.1024 20.1866 0.2855 0.5563 0.6856 | 117.5916
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.2357879  0.23587916 0.23605389 0.23613556 0.23607035 0.23595708
 0.23593674 0.23597954 0.23593777 0.235924   0.23579645 0.23582211
 0.23581266 0.2358607  0.23587608 0.23588772 0.23590151 0.23593192
 0.23583979 0.23567861]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.23594088 0.23593504 0.23592812 0.23591723 0.23590004 0.23590418
 0.23592149 0.23590987 0.2359159  0.23592496 0.23591271 0.23590529
 0.23591206 0.23591267 0.23590635 0.23590706 0.23587927 0.23586989
 0.23586014 0.23581768]
[0.  0.5 0.5]
-----------end of analyzing the loss ratio:76.13069033622742
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6cb0310>
---------------------------------
SparseEpoch: [179][1/398]	Time 0.587	Data 0.000	Loss 0.7711	
SparseEpoch: [179][101/398]	Time 0.582	Data 0.000	Loss 0.5386	
SparseEpoch: [179][201/398]	Time 0.582	Data 0.000	Loss 0.9662	
SparseEpoch: [179][301/398]	Time 0.581	Data 0.000	Loss 0.9561	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.37177559 0.37180732 0.37170352 0.37169716 0.37162678 0.37162953
 0.37151721 0.37151394 0.37156072 0.37154427 0.37153051 0.37161294
 0.37161811 0.37157111 0.37158352 0.37158532 0.37168563 0.37172426
 0.37172005 0.37172235]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.37156943 0.37156736 0.37155603 0.37153923 0.37151523 0.37152055
 0.37151441 0.37151    0.37150447 0.37149692 0.37149184 0.37149982
 0.37149367 0.37152042 0.37152363 0.37151786 0.37152558 0.37153635
 0.37154805 0.37155049]
[0.         0.         0.02631579]
-----------end of analyzing the loss ratio:76.08484649658203
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d72d1510>
---------------------------------
SparseEpoch: [179][1/398]	Time 0.577	Data 0.000	Loss 0.3096	
SparseEpoch: [179][101/398]	Time 0.581	Data 0.000	Loss 0.4622	
SparseEpoch: [179][201/398]	Time 0.580	Data 0.000	Loss 0.2010	
SparseEpoch: [179][301/398]	Time 0.580	Data 0.000	Loss 0.2493	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11247042 0.11245942 0.11245351 0.1124577  0.11244057 0.11244026
 0.11244602 0.11245465 0.11246818 0.11245273 0.11245754 0.11245804
 0.11244822 0.11245062 0.11245281 0.11244354 0.1124407  0.11243782
 0.1124577  0.11244432]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11245555 0.11245249 0.1124584  0.11245543 0.11245977 0.11245221
 0.11245814 0.11245306 0.11245521 0.11245118 0.11245636 0.11246121
 0.11246212 0.11245925 0.112455   0.11246228 0.11247084 0.11246733
 0.11246139 0.11245725]
[0.39473684 0.         0.        ]
-----------end of analyzing the loss ratio:76.0822856426239
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6aa9330>
---------------------------------
SparseEpoch: [179][1/398]	Time 0.578	Data 0.000	Loss 1.3703	
SparseEpoch: [179][101/398]	Time 0.581	Data 0.000	Loss 0.9903	
SparseEpoch: [179][201/398]	Time 0.580	Data 0.000	Loss 1.1906	
SparseEpoch: [179][301/398]	Time 0.580	Data 0.000	Loss 0.5485	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.5332	
Epoch(adapt):{0} Loss 0.5106	
Epoch(adapt):{0} Loss 0.5915	
Epoch(adapt):{0} Loss 0.4847	
------------------the total time cost:1168.982284784317
>>>>>meta updating
Epoch: 0179 | TRAIN: 0.2539 0.8144 0.9195 | 0.2845 0.2845 0.1341 | 0.1054 20.9745 15.9920 0.3557 0.6664 0.7835 ||TEST: 1.3800 0.4129 0.6679 | 0.5296 0.5296 0.2081 | 0.1395 24.9503 19.9897 0.2877 0.5602 0.6884 | 117.4629
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.22007304 0.21998996 0.21997783 0.2200105  0.21995621 0.21984307
 0.21986518 0.21991244 0.21991996 0.21994315 0.2198784  0.21989415
 0.21996105 0.21979659 0.21988547 0.21994405 0.21985983 0.21992151
 0.21987726 0.21991692]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.2198694  0.21987272 0.21985869 0.21986777 0.21987794 0.21989105
 0.2199032  0.21990289 0.21991092 0.21990905 0.21991308 0.21989271
 0.21991638 0.21992044 0.21993638 0.21993055 0.21992705 0.21991946
 0.21992076 0.21992869]
[0.         0.18421053 0.        ]
-----------end of analyzing the loss ratio:76.2125289440155
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d73701c0>
---------------------------------
SparseEpoch: [180][1/398]	Time 0.582	Data 0.000	Loss 0.2506	
SparseEpoch: [180][101/398]	Time 0.581	Data 0.000	Loss 0.5302	
SparseEpoch: [180][201/398]	Time 0.581	Data 0.000	Loss 0.2730	
SparseEpoch: [180][301/398]	Time 0.581	Data 0.000	Loss 0.4168	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.30200327 0.30201395 0.302072   0.30204336 0.30203721 0.30202919
 0.30214943 0.30212888 0.30219765 0.30218334 0.30215307 0.30208437
 0.30208918 0.30212627 0.30211203 0.30216587 0.30214322 0.3021062
 0.30211944 0.30211243]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.30214035 0.3021583  0.3021524  0.30215554 0.30216066 0.30215878
 0.30216862 0.30216614 0.30217153 0.30218506 0.30216797 0.30215558
 0.30215335 0.30216533 0.30216916 0.30215711 0.30215983 0.30214739
 0.30216689 0.30214422]
[0. 0. 0.]
-----------end of analyzing the loss ratio:75.90366721153259
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d69b5330>
---------------------------------
SparseEpoch: [180][1/398]	Time 0.579	Data 0.000	Loss 0.2633	
SparseEpoch: [180][101/398]	Time 0.579	Data 0.000	Loss 0.3492	
SparseEpoch: [180][201/398]	Time 0.580	Data 0.000	Loss 0.2095	
SparseEpoch: [180][301/398]	Time 0.580	Data 0.000	Loss 0.1938	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.109729   0.10969536 0.1096806  0.10964156 0.1096015  0.10953445
 0.10947536 0.10943474 0.10936597 0.10930415 0.10922971 0.10924847
 0.10923185 0.10917786 0.10908218 0.1090261  0.10898688 0.10893756
 0.10892736 0.10889729]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.10939399 0.10938318 0.10935667 0.10933852 0.10932565 0.109314
 0.10931137 0.10929939 0.10928194 0.10927134 0.10925689 0.10925024
 0.10926473 0.10925695 0.10924144 0.10924966 0.1092482  0.1092571
 0.10925827 0.10925454]
[0.5        0.23684211 0.        ]
-----------end of analyzing the loss ratio:75.93218350410461
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc153160>
---------------------------------
SparseEpoch: [180][1/398]	Time 0.581	Data 0.000	Loss 0.9911	
SparseEpoch: [180][101/398]	Time 0.581	Data 0.000	Loss 1.9694	
SparseEpoch: [180][201/398]	Time 0.581	Data 0.000	Loss 1.1264	
SparseEpoch: [180][301/398]	Time 0.581	Data 0.000	Loss 1.0868	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.5965	
Epoch(adapt):{0} Loss 0.4192	
Epoch(adapt):{0} Loss 0.3517	
Epoch(adapt):{0} Loss 0.5047	
------------------the total time cost:1169.5328385829926
>>>>>meta updating
Epoch: 0180 | TRAIN: 0.2551 0.8087 0.9194 | 0.2719 0.2719 0.1368 | 0.1046 20.7480 15.5822 0.3693 0.6725 0.7865 ||TEST: 1.4797 0.4213 0.6695 | 0.5068 0.5068 0.2089 | 0.1403 24.8520 19.6226 0.2983 0.5665 0.6915 | 117.1277
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.24204878 0.24206575 0.24204677 0.24203446 0.24201008 0.24200726
 0.24201717 0.24205365 0.24205382 0.24214526 0.24212966 0.24214511
 0.24214105 0.24212308 0.24214078 0.2421188  0.24212392 0.24217673
 0.24222847 0.24219924]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.24205533 0.24206151 0.24207895 0.24208967 0.24207461 0.24214926
 0.24215136 0.24214538 0.24214047 0.24213874 0.24213028 0.24212586
 0.24212429 0.24210505 0.24210609 0.2421199  0.24211787 0.24210715
 0.24214085 0.24215085]
[0. 0. 0.]
-----------end of analyzing the loss ratio:76.08234429359436
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d7076ec0>
---------------------------------
SparseEpoch: [181][1/398]	Time 0.577	Data 0.000	Loss 0.2751	
SparseEpoch: [181][101/398]	Time 0.580	Data 0.000	Loss 0.1818	
SparseEpoch: [181][201/398]	Time 0.580	Data 0.000	Loss 0.4383	
SparseEpoch: [181][301/398]	Time 0.580	Data 0.000	Loss 0.4540	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.26074324 0.26069227 0.26074796 0.26077018 0.26082831 0.26076317
 0.26074305 0.26076794 0.2607428  0.26073012 0.26075082 0.26074501
 0.26064626 0.26061924 0.26060186 0.2605612  0.26048791 0.26046271
 0.26048204 0.26048216]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.26074699 0.26075523 0.26075842 0.26076105 0.26075282 0.26075487
 0.26074167 0.26074374 0.2607522  0.26075707 0.26074263 0.26073986
 0.2607479  0.26076687 0.26076285 0.26076453 0.26075477 0.26075421
 0.26074018 0.26074608]
[0.39473684 0.         0.07894737]
-----------end of analyzing the loss ratio:76.24977946281433
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc151720>
---------------------------------
SparseEpoch: [181][1/398]	Time 0.597	Data 0.000	Loss 0.4908	
SparseEpoch: [181][101/398]	Time 0.582	Data 0.000	Loss 0.5017	
SparseEpoch: [181][201/398]	Time 0.581	Data 0.000	Loss 0.3833	
SparseEpoch: [181][301/398]	Time 0.582	Data 0.000	Loss 0.5151	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.10309212 0.1030756  0.10306108 0.10303562 0.10303261 0.10302719
 0.10302458 0.1030049  0.10296801 0.10295454 0.10296344 0.10294774
 0.10293223 0.1029317  0.10294096 0.10291901 0.10293689 0.10294669
 0.10291473 0.10292017]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.1029855  0.10298191 0.10297716 0.10297022 0.10295708 0.10294982
 0.10296808 0.10297468 0.10297472 0.10297824 0.10297132 0.10295532
 0.1029562  0.10294808 0.10294541 0.10294482 0.10294685 0.10293571
 0.10294877 0.10294203]
[0.44736842 0.39473684 0.        ]
-----------end of analyzing the loss ratio:76.06383872032166
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d69b74f0>
---------------------------------
SparseEpoch: [181][1/398]	Time 0.586	Data 0.000	Loss 0.6641	
SparseEpoch: [181][101/398]	Time 0.581	Data 0.000	Loss 1.5600	
SparseEpoch: [181][201/398]	Time 0.581	Data 0.000	Loss 1.4824	
SparseEpoch: [181][301/398]	Time 0.581	Data 0.000	Loss 0.9301	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.4417	
Epoch(adapt):{0} Loss 0.4473	
Epoch(adapt):{0} Loss 0.4571	
Epoch(adapt):{0} Loss 0.4983	
------------------the total time cost:1169.6578073501587
>>>>>meta updating
Epoch: 0181 | TRAIN: 0.2388 0.8209 0.9233 | 0.2799 0.2799 0.1382 | 0.1058 21.0916 16.2093 0.3523 0.6597 0.7793 ||TEST: 1.4259 0.4227 0.6678 | 0.5221 0.5221 0.2102 | 0.1417 25.2212 20.3457 0.2839 0.5513 0.6804 | 117.6095
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.26413114 0.26415402 0.26414667 0.26411483 0.2641439  0.26414985
 0.26418956 0.26419768 0.26423185 0.26423384 0.26422038 0.26422716
 0.264203   0.26420739 0.26417642 0.26416977 0.26416394 0.26416606
 0.26412341 0.26413723]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.26424147 0.26425202 0.26425494 0.26425725 0.26425365 0.26424931
 0.26422734 0.26422931 0.26423001 0.26422171 0.26421721 0.26423021
 0.26423836 0.26424225 0.26423682 0.26423839 0.26424712 0.26424789
 0.26424739 0.26426182]
[0.         0.         0.02631579]
-----------end of analyzing the loss ratio:76.19550132751465
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x74460925e800>
---------------------------------
SparseEpoch: [182][1/398]	Time 0.580	Data 0.000	Loss 0.7507	
SparseEpoch: [182][101/398]	Time 0.580	Data 0.000	Loss 0.6904	
SparseEpoch: [182][201/398]	Time 0.580	Data 0.000	Loss 0.4894	
SparseEpoch: [182][301/398]	Time 0.580	Data 0.000	Loss 0.5949	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.33578318 0.33576332 0.33572255 0.33560832 0.33552416 0.33548994
 0.33543614 0.3354378  0.3353708  0.3353353  0.33519001 0.33504356
 0.33498882 0.33492971 0.33479913 0.33473547 0.33467782 0.33463667
 0.33457516 0.33448744]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.33532524 0.33534006 0.33531477 0.33530673 0.33532921 0.33532505
 0.33532613 0.33532554 0.33533309 0.33531138 0.33530267 0.33526624
 0.33525275 0.33522078 0.33519426 0.33516618 0.3351583  0.33512477
 0.33511717 0.33511803]
[0.5        0.         0.44736842]
-----------end of analyzing the loss ratio:76.20085287094116
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6cb12a0>
---------------------------------
SparseEpoch: [182][1/398]	Time 0.578	Data 0.000	Loss 0.6654	
SparseEpoch: [182][101/398]	Time 0.581	Data 0.000	Loss 0.9341	
SparseEpoch: [182][201/398]	Time 0.581	Data 0.000	Loss 0.6344	
SparseEpoch: [182][301/398]	Time 0.581	Data 0.000	Loss 0.8830	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.12216325 0.12215    0.12214426 0.12213469 0.12213074 0.1221227
 0.12210827 0.12211055 0.1221045  0.1221049  0.12211061 0.12210581
 0.12209241 0.12209553 0.12209714 0.12210363 0.12210052 0.12210431
 0.1220987  0.1220966 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.12222922 0.12223893 0.12221532 0.1221986  0.12219489 0.12217519
 0.12213966 0.12212757 0.1221181  0.12210374 0.12210628 0.12209699
 0.12209523 0.12210703 0.12209384 0.12210562 0.12209398 0.12209338
 0.12208761 0.12208298]
[0.13157895 0.5        0.        ]
-----------end of analyzing the loss ratio:76.1550703048706
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc002a70>
---------------------------------
SparseEpoch: [182][1/398]	Time 0.580	Data 0.000	Loss 1.0195	
SparseEpoch: [182][101/398]	Time 0.582	Data 0.000	Loss 1.3221	
SparseEpoch: [182][201/398]	Time 0.581	Data 0.000	Loss 1.4838	
SparseEpoch: [182][301/398]	Time 0.581	Data 0.000	Loss 0.9976	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.4277	
Epoch(adapt):{0} Loss 0.8686	
Epoch(adapt):{0} Loss 0.5269	
Epoch(adapt):{0} Loss 0.4579	
------------------the total time cost:1169.4627182483673
>>>>>meta updating
Epoch: 0182 | TRAIN: 0.2373 0.8207 0.9239 | 0.2676 0.2676 0.1296 | 0.1058 21.0441 16.0407 0.3530 0.6636 0.7825 ||TEST: 1.4534 0.4179 0.6707 | 0.5173 0.5173 0.2093 | 0.1422 25.1997 20.1736 0.2844 0.5562 0.6846 | 117.8013
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.2327776  0.23276378 0.23270937 0.23266657 0.23262824 0.23255104
 0.23250085 0.23248536 0.23248026 0.23256743 0.23256489 0.23255568
 0.23267241 0.23269975 0.23271039 0.23266027 0.232752   0.2327379
 0.23274044 0.23283722]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.23256448 0.23256161 0.23256428 0.23255339 0.23255105 0.23257671
 0.2325668  0.23257193 0.23255564 0.23257543 0.23257346 0.23256158
 0.23257572 0.23257354 0.23256101 0.23254456 0.23257447 0.23258351
 0.23258987 0.23255384]
[0.         0.         0.28947368]
-----------end of analyzing the loss ratio:76.40520071983337
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d72cb3d0>
---------------------------------
SparseEpoch: [183][1/398]	Time 0.578	Data 0.000	Loss 0.5590	
SparseEpoch: [183][101/398]	Time 0.581	Data 0.000	Loss 0.8811	
SparseEpoch: [183][201/398]	Time 0.580	Data 0.000	Loss 0.6060	
SparseEpoch: [183][301/398]	Time 0.580	Data 0.000	Loss 0.8365	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.41883587 0.41885764 0.41888577 0.41894079 0.41895161 0.41898642
 0.4189662  0.41896621 0.41902352 0.4190295  0.41904792 0.41909
 0.41910823 0.41914275 0.41917256 0.41919782 0.41924054 0.41928288
 0.41927681 0.41937538]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.41906541 0.41907732 0.41907312 0.41907976 0.41907546 0.41906778
 0.4190786  0.41907642 0.41907659 0.41907093 0.4190583  0.41905182
 0.4190484  0.41904582 0.41904183 0.41904149 0.41903367 0.4190131
 0.41902032 0.41901543]
[0.         0.         0.39473684]
-----------end of analyzing the loss ratio:76.26679039001465
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7446091a3220>
---------------------------------
SparseEpoch: [183][1/398]	Time 0.580	Data 0.000	Loss 0.5604	
SparseEpoch: [183][101/398]	Time 0.581	Data 0.000	Loss 0.7817	
SparseEpoch: [183][201/398]	Time 0.581	Data 0.000	Loss 0.5058	
SparseEpoch: [183][301/398]	Time 0.580	Data 0.000	Loss 0.4296	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11196752 0.11196923 0.11197472 0.1119781  0.11196845 0.11196273
 0.11195304 0.11195298 0.11194801 0.11194811 0.11194421 0.11194167
 0.11193829 0.11194026 0.11193736 0.11193731 0.11193917 0.11193367
 0.11193178 0.11192429]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11189823 0.11190228 0.11191788 0.11193456 0.11192777 0.11192749
 0.11193122 0.11193888 0.11193968 0.1119433  0.11194821 0.11196858
 0.11194724 0.11195889 0.11195347 0.11198366 0.11198182 0.11197645
 0.11198036 0.11198763]
[0.5 0.  0. ]
-----------end of analyzing the loss ratio:75.86686897277832
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6c3fb80>
---------------------------------
SparseEpoch: [183][1/398]	Time 0.591	Data 0.000	Loss 1.2333	
SparseEpoch: [183][101/398]	Time 0.580	Data 0.000	Loss 0.7398	
SparseEpoch: [183][201/398]	Time 0.580	Data 0.000	Loss 1.0023	
SparseEpoch: [183][301/398]	Time 0.580	Data 0.000	Loss 1.4510	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.5053	
Epoch(adapt):{0} Loss 0.5736	
Epoch(adapt):{0} Loss 0.5930	
Epoch(adapt):{0} Loss 0.4064	
------------------the total time cost:1168.9322531223297
>>>>>meta updating
Epoch: 0183 | TRAIN: 0.2323 0.8256 0.9262 | 0.2866 0.2866 0.1336 | 0.1024 20.6124 15.6250 0.3645 0.6747 0.7903 ||TEST: 1.4449 0.4142 0.6717 | 0.5249 0.5249 0.2080 | 0.1411 25.0520 19.9653 0.2890 0.5603 0.6872 | 117.6249
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.2587489  0.25874969 0.25880672 0.25883348 0.2588195  0.25882305
 0.25882806 0.25881324 0.25883034 0.25886395 0.25888449 0.25883072
 0.2588075  0.25885509 0.2588552  0.25880328 0.25880611 0.25874917
 0.25877138 0.25878896]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.25880635 0.25881017 0.25881291 0.25879626 0.2588088  0.25884752
 0.25886752 0.25886996 0.25886534 0.25887143 0.25890581 0.25888985
 0.25888751 0.25887897 0.25889973 0.25889113 0.25890713 0.25888948
 0.25889785 0.2589073 ]
[0. 0. 0.]
-----------end of analyzing the loss ratio:76.29608726501465
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d7371090>
---------------------------------
SparseEpoch: [184][1/398]	Time 0.578	Data 0.000	Loss 0.2697	
SparseEpoch: [184][101/398]	Time 0.580	Data 0.000	Loss 0.2162	
SparseEpoch: [184][201/398]	Time 0.580	Data 0.000	Loss 0.1925	
SparseEpoch: [184][301/398]	Time 0.579	Data 0.000	Loss 0.3727	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.36936863 0.36936807 0.36932795 0.36928404 0.36925969 0.36923103
 0.36922789 0.36922616 0.36919913 0.3692017  0.36919007 0.36920887
 0.36921069 0.3691751  0.36914691 0.36914545 0.36915242 0.36912944
 0.36909102 0.36907497]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.36921482 0.36923166 0.36923293 0.36922922 0.3692141  0.36920637
 0.36919506 0.3691958  0.36920114 0.36919348 0.3691885  0.36917669
 0.36918713 0.36918612 0.36919586 0.36920005 0.36919841 0.36920039
 0.36922173 0.36922571]
[0.5        0.         0.07894737]
-----------end of analyzing the loss ratio:76.28632473945618
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc5ff010>
---------------------------------
SparseEpoch: [184][1/398]	Time 0.579	Data 0.000	Loss 0.4945	
SparseEpoch: [184][101/398]	Time 0.582	Data 0.000	Loss 0.6688	
SparseEpoch: [184][201/398]	Time 0.581	Data 0.000	Loss 0.4302	
SparseEpoch: [184][301/398]	Time 0.581	Data 0.000	Loss 0.6753	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.10279713 0.1028038  0.10281971 0.10281658 0.10281667 0.10280319
 0.10278777 0.1027845  0.10278252 0.10280966 0.10280382 0.10278672
 0.10277916 0.1027747  0.10279104 0.10281846 0.10282205 0.10281416
 0.10280887 0.10282892]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.10280671 0.10281302 0.10282845 0.10280727 0.10281369 0.10281366
 0.10280984 0.10280101 0.10280226 0.10281222 0.10281408 0.10279798
 0.10277924 0.10276862 0.10276166 0.1027567  0.10279517 0.10279151
 0.10280954 0.10280774]
[0.18421053 0.28947368 0.        ]
-----------end of analyzing the loss ratio:76.4955186843872
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc42ee30>
---------------------------------
SparseEpoch: [184][1/398]	Time 0.579	Data 0.000	Loss 1.1194	
SparseEpoch: [184][101/398]	Time 0.581	Data 0.000	Loss 1.0404	
SparseEpoch: [184][201/398]	Time 0.581	Data 0.000	Loss 1.0543	
SparseEpoch: [184][301/398]	Time 0.581	Data 0.000	Loss 0.7846	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.5265	
Epoch(adapt):{0} Loss 0.3809	
Epoch(adapt):{0} Loss 0.5989	
Epoch(adapt):{0} Loss 0.2750	
------------------the total time cost:1169.0656654834747
>>>>>meta updating
Epoch: 0184 | TRAIN: 0.2362 0.8196 0.9246 | 0.2738 0.2738 0.1361 | 0.1030 20.5604 15.3967 0.3735 0.6767 0.7895 ||TEST: 1.4980 0.4189 0.6675 | 0.5169 0.5169 0.2119 | 0.1407 24.9062 19.6532 0.2968 0.5655 0.6901 | 117.6174
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.27541688 0.27545552 0.27543266 0.27543302 0.27546097 0.27546793
 0.27544406 0.27544169 0.27548524 0.27546377 0.27545162 0.27537919
 0.27540951 0.27539653 0.27537922 0.27539235 0.27537462 0.27534658
 0.27530243 0.2753125 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.27541786 0.27541539 0.27540543 0.27540806 0.27541793 0.27542627
 0.2754391  0.27544414 0.27544747 0.2754513  0.27545451 0.27545354
 0.27545618 0.27544562 0.27543602 0.27542019 0.27541451 0.27540627
 0.2754166  0.27541484]
[0.         0.44736842 0.        ]
-----------end of analyzing the loss ratio:76.19451212882996
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc11e470>
---------------------------------
SparseEpoch: [185][1/398]	Time 0.578	Data 0.000	Loss 0.3020	
SparseEpoch: [185][101/398]	Time 0.581	Data 0.000	Loss 0.2486	
SparseEpoch: [185][201/398]	Time 0.580	Data 0.000	Loss 0.7065	
SparseEpoch: [185][301/398]	Time 0.580	Data 0.000	Loss 0.5922	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.34787183 0.34776334 0.34763482 0.34750544 0.34732826 0.34716138
 0.34696471 0.34673414 0.34653164 0.34645462 0.34635388 0.34624868
 0.34609307 0.34588689 0.34569528 0.34544094 0.34529154 0.34521797
 0.34507591 0.34497467]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.34652987 0.34652784 0.34652062 0.34651126 0.34647921 0.34645047
 0.3464212  0.34642434 0.34642093 0.34639824 0.34641761 0.34640536
 0.34638799 0.34637304 0.34631322 0.3462851  0.34627036 0.34626372
 0.34624875 0.34626777]
[0.5        0.         0.44736842]
-----------end of analyzing the loss ratio:76.32179045677185
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444dc0eb850>
---------------------------------
SparseEpoch: [185][1/398]	Time 0.578	Data 0.000	Loss 1.0588	
SparseEpoch: [185][101/398]	Time 0.581	Data 0.000	Loss 0.8275	
SparseEpoch: [185][201/398]	Time 0.581	Data 0.000	Loss 0.8452	
SparseEpoch: [185][301/398]	Time 0.581	Data 0.000	Loss 0.7134	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11082822 0.11081616 0.1108093  0.11080278 0.11077291 0.11075445
 0.11074876 0.11073813 0.11072852 0.11073518 0.11074477 0.1107672
 0.11076136 0.11074765 0.11071436 0.11070586 0.11068233 0.11065915
 0.11062188 0.11062388]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.1108664  0.11083964 0.11082671 0.11081614 0.11079342 0.11077865
 0.11077358 0.11075933 0.11073755 0.11073098 0.11074501 0.1107639
 0.11075251 0.11075436 0.11070886 0.11068141 0.11065521 0.11062378
 0.11060073 0.1105722 ]
[0.44736842 0.5        0.        ]
-----------end of analyzing the loss ratio:76.27333760261536
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d66b89a0>
---------------------------------
SparseEpoch: [185][1/398]	Time 0.579	Data 0.000	Loss 1.0970	
SparseEpoch: [185][101/398]	Time 0.582	Data 0.000	Loss 1.9155	
SparseEpoch: [185][201/398]	Time 0.582	Data 0.000	Loss 1.7075	
SparseEpoch: [185][301/398]	Time 0.581	Data 0.000	Loss 0.8854	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.4352	
Epoch(adapt):{0} Loss 0.4630	
Epoch(adapt):{0} Loss 0.6048	
Epoch(adapt):{0} Loss 0.7495	
------------------the total time cost:1169.9591267108917
>>>>>meta updating
Epoch: 0185 | TRAIN: 0.2354 0.8172 0.9239 | 0.2915 0.2915 0.1411 | 0.1039 20.8453 15.8852 0.3569 0.6677 0.7862 ||TEST: 1.4004 0.4215 0.6727 | 0.5247 0.5247 0.2118 | 0.1416 25.1626 20.1694 0.2864 0.5551 0.6830 | 117.3978
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.17238514 0.1723982  0.17239326 0.17239925 0.17236783 0.172361
 0.17234771 0.17234978 0.17231178 0.17231433 0.1723139  0.17228972
 0.17227214 0.17226712 0.17227569 0.17227477 0.17229124 0.17229363
 0.1722662  0.17227413]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.17231197 0.17231365 0.17231494 0.17231221 0.17231007 0.17230405
 0.17230873 0.17229155 0.17229187 0.17230535 0.17231082 0.17230357
 0.17231021 0.17230879 0.17230059 0.17229713 0.17229888 0.1722989
 0.17231191 0.17230647]
[0.         0.44736842 0.        ]
-----------end of analyzing the loss ratio:76.32110667228699
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6929330>
---------------------------------
SparseEpoch: [186][1/398]	Time 0.581	Data 0.000	Loss 0.5401	
SparseEpoch: [186][101/398]	Time 0.580	Data 0.000	Loss 0.5165	
SparseEpoch: [186][201/398]	Time 0.580	Data 0.000	Loss 0.3849	
SparseEpoch: [186][301/398]	Time 0.580	Data 0.000	Loss 0.5173	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.32764087 0.32746661 0.32751618 0.32752358 0.32747756 0.32734465
 0.32730534 0.32724484 0.32721246 0.32722547 0.327143   0.32705458
 0.32700896 0.32688052 0.32674146 0.32676069 0.32670458 0.32670605
 0.3267155  0.32670677]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.32719905 0.32720667 0.32720218 0.32719743 0.32720019 0.32719665
 0.32717132 0.32716263 0.3271549  0.32717182 0.32715867 0.3271557
 0.32715165 0.32714048 0.32714361 0.32715898 0.3271646  0.32713323
 0.32713748 0.32713866]
[0.34210526 0.         0.39473684]
-----------end of analyzing the loss ratio:76.24720501899719
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc42c790>
---------------------------------
SparseEpoch: [186][1/398]	Time 0.578	Data 0.000	Loss 0.8068	
SparseEpoch: [186][101/398]	Time 0.581	Data 0.000	Loss 0.8137	
SparseEpoch: [186][201/398]	Time 0.581	Data 0.000	Loss 1.0911	
SparseEpoch: [186][301/398]	Time 0.581	Data 0.000	Loss 0.7164	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.10785781 0.10784411 0.10782891 0.10781661 0.10781669 0.10780748
 0.1078006  0.1077953  0.10777696 0.10777373 0.10777458 0.10777318
 0.10777957 0.10776259 0.10775084 0.10774611 0.10775322 0.1077532
 0.10775449 0.10774873]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.10779775 0.10779865 0.10779872 0.10779304 0.10778894 0.1077875
 0.10778317 0.1077839  0.10776905 0.10775847 0.1077865  0.10779958
 0.10780889 0.10781593 0.10780941 0.10782827 0.10781628 0.10781782
 0.10782146 0.10781729]
[0.28947368 0.         0.        ]
-----------end of analyzing the loss ratio:76.21036577224731
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7446091a1090>
---------------------------------
SparseEpoch: [186][1/398]	Time 0.578	Data 0.000	Loss 1.4117	
SparseEpoch: [186][101/398]	Time 0.580	Data 0.000	Loss 1.5249	
SparseEpoch: [186][201/398]	Time 0.580	Data 0.000	Loss 1.0698	
SparseEpoch: [186][301/398]	Time 0.580	Data 0.000	Loss 0.8940	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.5581	
Epoch(adapt):{0} Loss 0.5390	
Epoch(adapt):{0} Loss 0.4581	
Epoch(adapt):{0} Loss 0.5550	
------------------the total time cost:1170.276258468628
>>>>>meta updating
Epoch: 0186 | TRAIN: 0.2296 0.8234 0.9259 | 0.2981 0.2981 0.1365 | 0.1047 21.0029 16.1642 0.3514 0.6622 0.7822 ||TEST: 1.3702 0.4153 0.6690 | 0.5340 0.5340 0.2101 | 0.1406 25.1525 20.2560 0.2822 0.5540 0.6827 | 117.6647
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.2365074  0.23652566 0.23647118 0.23651857 0.23661561 0.23664871
 0.23662445 0.23667218 0.23655819 0.23655072 0.23652753 0.23654463
 0.23659101 0.23662634 0.23663357 0.23666815 0.23659424 0.23656551
 0.23657961 0.23664044]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.23654178 0.23653865 0.2365353  0.23652313 0.23652078 0.2365159
 0.23650713 0.23651898 0.23651539 0.23652089 0.2365191  0.23651569
 0.2365149  0.23652171 0.23652576 0.23651845 0.23652012 0.2365193
 0.23652306 0.23652087]
[0. 0. 0.]
-----------end of analyzing the loss ratio:76.06081962585449
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d692b730>
---------------------------------
SparseEpoch: [187][1/398]	Time 0.579	Data 0.000	Loss 0.0917	
SparseEpoch: [187][101/398]	Time 0.580	Data 0.000	Loss 0.2706	
SparseEpoch: [187][201/398]	Time 0.579	Data 0.000	Loss 0.4497	
SparseEpoch: [187][301/398]	Time 0.579	Data 0.000	Loss 0.3711	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.33509273 0.3350007  0.33494802 0.33487388 0.33489391 0.33487409
 0.33479172 0.33464195 0.33452427 0.33433918 0.33423837 0.33406927
 0.33406467 0.33391821 0.33396906 0.33387197 0.33391986 0.33381306
 0.33373923 0.33368332]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.33438978 0.33440128 0.33437247 0.33437582 0.33436147 0.33434064
 0.33431135 0.33430296 0.33430488 0.33427354 0.33424825 0.33425811
 0.3342424  0.33426241 0.33424935 0.33424248 0.334208   0.33421161
 0.33419133 0.33418748]
[0.5 0.  0.5]
-----------end of analyzing the loss ratio:76.26296424865723
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7446095cefe0>
---------------------------------
SparseEpoch: [187][1/398]	Time 0.589	Data 0.000	Loss 1.0104	
SparseEpoch: [187][101/398]	Time 0.581	Data 0.000	Loss 1.2719	
SparseEpoch: [187][201/398]	Time 0.581	Data 0.000	Loss 1.0961	
SparseEpoch: [187][301/398]	Time 0.581	Data 0.000	Loss 1.0295	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11721386 0.11718754 0.11719511 0.11718284 0.11717721 0.11715022
 0.1171305  0.11714255 0.11713553 0.11712198 0.11712846 0.11712734
 0.11714444 0.11710488 0.11709187 0.11708723 0.11708658 0.11710116
 0.11708407 0.11707606]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11713595 0.11713245 0.11713895 0.1171401  0.11712438 0.11712753
 0.11714025 0.11713837 0.11712293 0.11712752 0.11712332 0.11712071
 0.11710775 0.11710321 0.11710529 0.11711413 0.11712509 0.11713991
 0.11714031 0.1171384 ]
[0.5        0.18421053 0.        ]
-----------end of analyzing the loss ratio:76.10002851486206
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6b5d9c0>
---------------------------------
SparseEpoch: [187][1/398]	Time 0.578	Data 0.000	Loss 1.1471	
SparseEpoch: [187][101/398]	Time 0.581	Data 0.000	Loss 0.9778	
SparseEpoch: [187][201/398]	Time 0.581	Data 0.000	Loss 0.9664	
SparseEpoch: [187][301/398]	Time 0.581	Data 0.000	Loss 0.8943	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.4781	
Epoch(adapt):{0} Loss 0.3881	
Epoch(adapt):{0} Loss 0.4563	
Epoch(adapt):{0} Loss 0.5192	
------------------the total time cost:1169.7857217788696
>>>>>meta updating
Epoch: 0187 | TRAIN: 0.2309 0.8268 0.9265 | 0.2695 0.2695 0.1301 | 0.1017 20.4964 15.5005 0.3685 0.6778 0.7929 ||TEST: 1.4407 0.4212 0.6696 | 0.5149 0.5149 0.2083 | 0.1407 24.9853 19.8900 0.2908 0.5622 0.6890 | 117.6290
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.19126734 0.19130128 0.19128757 0.19128317 0.19136586 0.19136156
 0.19127171 0.19119318 0.19107353 0.19104975 0.19112474 0.19103384
 0.19104724 0.19117111 0.19115988 0.19109038 0.19114787 0.19120761
 0.19114336 0.19107846]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.19113138 0.19110806 0.19110414 0.19110685 0.19110386 0.19109837
 0.19107522 0.19106275 0.19106294 0.19107356 0.19107411 0.191076
 0.19106214 0.19105718 0.19105844 0.19107066 0.19107091 0.19106502
 0.19108177 0.19108662]
[0.         0.07894737 0.18421053]
-----------end of analyzing the loss ratio:76.03765487670898
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6dc1ae0>
---------------------------------
SparseEpoch: [188][1/398]	Time 0.579	Data 0.000	Loss 0.4293	
SparseEpoch: [188][101/398]	Time 0.581	Data 0.000	Loss 0.5775	
SparseEpoch: [188][201/398]	Time 0.581	Data 0.000	Loss 0.3538	
SparseEpoch: [188][301/398]	Time 0.581	Data 0.000	Loss 0.5100	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.34035515 0.34033173 0.34028846 0.34025722 0.34028867 0.34024493
 0.34025862 0.34027691 0.34028576 0.34023443 0.34021207 0.3401843
 0.34016025 0.34013148 0.34014079 0.34010616 0.34006724 0.34005102
 0.34003412 0.34003726]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.34027454 0.34027217 0.34025507 0.34025694 0.34025219 0.34024913
 0.34024714 0.34024197 0.34023041 0.34022872 0.3402328  0.34022559
 0.34021101 0.3402272  0.34019966 0.34020497 0.34019372 0.34018884
 0.34018883 0.3401709 ]
[0.44736842 0.         0.5       ]
-----------end of analyzing the loss ratio:76.01279711723328
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7446096eae60>
---------------------------------
SparseEpoch: [188][1/398]	Time 0.587	Data 0.000	Loss 0.7925	
SparseEpoch: [188][101/398]	Time 0.581	Data 0.000	Loss 0.7121	
SparseEpoch: [188][201/398]	Time 0.581	Data 0.000	Loss 0.6742	
SparseEpoch: [188][301/398]	Time 0.581	Data 0.000	Loss 0.6576	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.09550816 0.09546124 0.09547344 0.09548163 0.09547029 0.09545041
 0.0953996  0.09539711 0.09540059 0.09539293 0.09537405 0.09534202
 0.09530712 0.09529476 0.09526761 0.09527938 0.09527351 0.09522799
 0.09522905 0.09518728]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.09539865 0.09540367 0.09540552 0.09540234 0.09540663 0.09540722
 0.09540178 0.09540578 0.09540251 0.09539335 0.09538355 0.09537054
 0.09536326 0.09535382 0.09531828 0.09532216 0.09533684 0.09533477
 0.0953117  0.0952913 ]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:76.33221364021301
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6ce2770>
---------------------------------
SparseEpoch: [188][1/398]	Time 0.578	Data 0.000	Loss 1.5200	
SparseEpoch: [188][101/398]	Time 0.582	Data 0.000	Loss 1.0942	
SparseEpoch: [188][201/398]	Time 0.581	Data 0.000	Loss 1.2973	
SparseEpoch: [188][301/398]	Time 0.581	Data 0.000	Loss 1.5537	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.4845	
Epoch(adapt):{0} Loss 0.6124	
Epoch(adapt):{0} Loss 0.3903	
Epoch(adapt):{0} Loss 0.6620	
------------------the total time cost:1169.8767776489258
>>>>>meta updating
Epoch: 0188 | TRAIN: 0.2321 0.8307 0.9265 | 0.2709 0.2709 0.1311 | 0.1035 20.7258 15.6719 0.3640 0.6728 0.7879 ||TEST: 1.3993 0.4196 0.6718 | 0.5198 0.5198 0.2098 | 0.1394 24.8798 19.7637 0.2926 0.5640 0.6900 | 117.6161
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.23236775 0.23242614 0.23238962 0.23237337 0.23234256 0.23235567
 0.23235519 0.23230825 0.23236676 0.23237011 0.2323327  0.23231784
 0.23228391 0.23220441 0.23217286 0.23206427 0.2320612  0.23214197
 0.23212058 0.23212156]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.23235872 0.23236083 0.232357   0.23235992 0.2323743  0.23237228
 0.2323668  0.23237695 0.2323875  0.23237784 0.23235914 0.23234301
 0.23233376 0.23233693 0.23233608 0.23234011 0.23233246 0.23231642
 0.23231097 0.23231848]
[0.         0.34210526 0.44736842]
-----------end of analyzing the loss ratio:76.34728002548218
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7446095ce800>
---------------------------------
SparseEpoch: [189][1/398]	Time 0.579	Data 0.000	Loss 0.9757	
SparseEpoch: [189][101/398]	Time 0.581	Data 0.000	Loss 0.7240	
SparseEpoch: [189][201/398]	Time 0.581	Data 0.000	Loss 0.5492	
SparseEpoch: [189][301/398]	Time 0.581	Data 0.000	Loss 0.7215	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.31057517 0.31056506 0.31057216 0.31054587 0.3104751  0.31051845
 0.31056723 0.31052714 0.31049941 0.31046896 0.31049657 0.31048537
 0.31042939 0.3103982  0.31032597 0.31030616 0.31027751 0.31022479
 0.31022125 0.31020679]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.31047999 0.31048105 0.31047399 0.31048302 0.3104695  0.31046933
 0.31047519 0.31047814 0.31046989 0.3104799  0.31048308 0.31048554
 0.31048626 0.31047134 0.31046288 0.31046356 0.31045982 0.31046201
 0.31047723 0.31048689]
[0.5        0.         0.34210526]
-----------end of analyzing the loss ratio:76.26968312263489
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6f51570>
---------------------------------
SparseEpoch: [189][1/398]	Time 0.585	Data 0.000	Loss 0.6088	
SparseEpoch: [189][101/398]	Time 0.582	Data 0.000	Loss 0.9110	
SparseEpoch: [189][201/398]	Time 0.581	Data 0.000	Loss 0.6592	
SparseEpoch: [189][301/398]	Time 0.581	Data 0.000	Loss 1.0661	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.09953888 0.09954837 0.09953955 0.09955299 0.09957464 0.09958179
 0.09957244 0.09958182 0.09957801 0.09958345 0.09958511 0.09958904
 0.09959897 0.09959331 0.09961985 0.09962354 0.09963735 0.09963238
 0.09961631 0.09961615]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.09958168 0.09957442 0.0995693  0.09957128 0.09957883 0.09956861
 0.09956126 0.0995654  0.09958454 0.09957668 0.09958407 0.09958398
 0.09958358 0.09958423 0.09958882 0.09960261 0.09959961 0.09959295
 0.09959116 0.09959564]
[0. 0. 0.]
-----------end of analyzing the loss ratio:76.16919374465942
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6c5d4b0>
---------------------------------
SparseEpoch: [189][1/398]	Time 0.577	Data 0.000	Loss 0.7102	
SparseEpoch: [189][101/398]	Time 0.580	Data 0.000	Loss 0.7410	
SparseEpoch: [189][201/398]	Time 0.580	Data 0.000	Loss 0.8151	
SparseEpoch: [189][301/398]	Time 0.579	Data 0.000	Loss 0.9786	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.4837	
Epoch(adapt):{0} Loss 0.6752	
Epoch(adapt):{0} Loss 0.5452	
Epoch(adapt):{0} Loss 0.4728	
------------------the total time cost:1169.7932169437408
>>>>>meta updating
Epoch: 0189 | TRAIN: 0.2275 0.8297 0.9277 | 0.2808 0.2808 0.1373 | 0.1004 20.2582 15.1529 0.3790 0.6853 0.7965 ||TEST: 1.4153 0.4168 0.6697 | 0.5218 0.5218 0.2108 | 0.1389 24.7398 19.5195 0.2980 0.5692 0.6941 | 117.8460
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.21142102 0.21138782 0.21138457 0.21137411 0.2113346  0.21131356
 0.21127496 0.21130885 0.21128542 0.21133224 0.21140358 0.2113736
 0.21135735 0.21128358 0.21133143 0.21134896 0.21131417 0.21128834
 0.21125262 0.21125409]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.21135609 0.21135784 0.21136563 0.21136182 0.21135553 0.21136395
 0.21135529 0.21134083 0.2113689  0.21137942 0.21138415 0.21136401
 0.21136775 0.2113699  0.21136675 0.21136385 0.21137072 0.21136752
 0.21136412 0.21137055]
[0.         0.44736842 0.        ]
-----------end of analyzing the loss ratio:76.13407158851624
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d7045d20>
---------------------------------
SparseEpoch: [190][1/398]	Time 0.578	Data 0.000	Loss 0.4004	
SparseEpoch: [190][101/398]	Time 0.582	Data 0.000	Loss 0.2171	
SparseEpoch: [190][201/398]	Time 0.581	Data 0.000	Loss 0.2756	
SparseEpoch: [190][301/398]	Time 0.581	Data 0.000	Loss 0.5029	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.33527378 0.3351895  0.33513661 0.33503639 0.33501364 0.33492225
 0.33488696 0.33478783 0.33464638 0.33461734 0.33452619 0.33429672
 0.33426596 0.33420859 0.33416801 0.33404885 0.33419262 0.33411594
 0.33414138 0.33411671]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.33465812 0.33465425 0.33465983 0.33463051 0.33463016 0.33462995
 0.33463219 0.33460712 0.33461328 0.33463011 0.3346259  0.33463102
 0.33463146 0.33460265 0.33451577 0.33448965 0.33445002 0.33442867
 0.33439331 0.33434664]
[0.28947368 0.         0.5       ]
-----------end of analyzing the loss ratio:76.10981321334839
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6ce0730>
---------------------------------
SparseEpoch: [190][1/398]	Time 0.579	Data 0.000	Loss 0.5901	
SparseEpoch: [190][101/398]	Time 0.582	Data 0.000	Loss 1.1364	
SparseEpoch: [190][201/398]	Time 0.581	Data 0.000	Loss 1.0611	
SparseEpoch: [190][301/398]	Time 0.581	Data 0.000	Loss 0.9136	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.10737062 0.1073653  0.10735483 0.10734269 0.10734223 0.10734914
 0.10734384 0.10733344 0.10734609 0.10734091 0.10734817 0.10733949
 0.1073283  0.10731962 0.10731738 0.10730222 0.10728079 0.10726067
 0.10724993 0.10724452]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.10736254 0.1073576  0.10736745 0.10736361 0.10736757 0.10734782
 0.10735618 0.10735862 0.10736148 0.10735274 0.1073396  0.10733041
 0.1073038  0.10730578 0.10729976 0.10728935 0.10728427 0.10728179
 0.10728325 0.10730385]
[0.5        0.39473684 0.        ]
-----------end of analyzing the loss ratio:76.22735047340393
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d7193460>
---------------------------------
SparseEpoch: [190][1/398]	Time 0.578	Data 0.000	Loss 1.2231	
SparseEpoch: [190][101/398]	Time 0.580	Data 0.000	Loss 1.4724	
SparseEpoch: [190][201/398]	Time 0.581	Data 0.000	Loss 1.4035	
SparseEpoch: [190][301/398]	Time 0.581	Data 0.000	Loss 1.1186	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.5489	
Epoch(adapt):{0} Loss 0.6174	
Epoch(adapt):{0} Loss 0.3957	
Epoch(adapt):{0} Loss 0.3264	
------------------the total time cost:1170.323257446289
>>>>>meta updating
Epoch: 0190 | TRAIN: 0.2399 0.8162 0.9240 | 0.2633 0.2633 0.1268 | 0.1008 20.3765 15.4030 0.3730 0.6796 0.7939 ||TEST: 1.5668 0.4136 0.6651 | 0.5131 0.5131 0.2044 | 0.1415 24.9909 19.8026 0.2955 0.5631 0.6881 | 117.1985
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.23191503 0.23187785 0.23184263 0.23187679 0.23187759 0.23194535
 0.23192864 0.23194525 0.23199353 0.23199617 0.23204721 0.23203691
 0.23205107 0.23207721 0.23205445 0.23203768 0.23207038 0.23201637
 0.23202074 0.23202032]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.23205753 0.23201411 0.23203409 0.23202571 0.23203845 0.23202529
 0.23203143 0.23205972 0.23206624 0.23201936 0.23198385 0.23200984
 0.23201172 0.23201104 0.23199176 0.23199263 0.23193864 0.23197782
 0.2319824  0.23196735]
[0.         0.         0.34210526]
-----------end of analyzing the loss ratio:76.23440861701965
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6dc2f80>
---------------------------------
SparseEpoch: [191][1/398]	Time 0.578	Data 0.000	Loss 0.6390	
SparseEpoch: [191][101/398]	Time 0.580	Data 0.000	Loss 1.0739	
SparseEpoch: [191][201/398]	Time 0.580	Data 0.000	Loss 0.6521	
SparseEpoch: [191][301/398]	Time 0.580	Data 0.000	Loss 0.8482	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.3435531  0.34349177 0.34344105 0.34340087 0.34343588 0.34343517
 0.34341145 0.34340203 0.34336123 0.34331639 0.34332303 0.34328929
 0.34327492 0.34329974 0.34330423 0.34326032 0.343255   0.34324576
 0.34325157 0.34326409]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.3432578  0.34327581 0.34326324 0.3432716  0.34327619 0.34326155
 0.34327973 0.34330716 0.34334004 0.34335613 0.34334742 0.34336831
 0.34336735 0.34335952 0.34335703 0.34336145 0.34336091 0.34334036
 0.34336066 0.34335124]
[0.39473684 0.         0.        ]
-----------end of analyzing the loss ratio:76.22418737411499
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc073520>
---------------------------------
SparseEpoch: [191][1/398]	Time 0.579	Data 0.000	Loss 0.2659	
SparseEpoch: [191][101/398]	Time 0.580	Data 0.000	Loss 0.3767	
SparseEpoch: [191][201/398]	Time 0.581	Data 0.000	Loss 0.2887	
SparseEpoch: [191][301/398]	Time 0.581	Data 0.000	Loss 0.2724	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.10008669 0.100068   0.10001615 0.09998167 0.09996014 0.09993088
 0.0999321  0.0999071  0.09988826 0.09982868 0.09982386 0.09976385
 0.09976116 0.09970587 0.09967481 0.09969526 0.09971619 0.09965473
 0.09964793 0.09962512]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.09996645 0.09996896 0.09997931 0.09996181 0.09994372 0.09992905
 0.09990479 0.099881   0.09983939 0.09982593 0.09983972 0.09980642
 0.0997855  0.0997584  0.09976606 0.09977042 0.0997355  0.09972824
 0.0996905  0.09967198]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:76.40120697021484
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc508f10>
---------------------------------
SparseEpoch: [191][1/398]	Time 0.578	Data 0.000	Loss 1.1931	
SparseEpoch: [191][101/398]	Time 0.582	Data 0.000	Loss 1.2261	
SparseEpoch: [191][201/398]	Time 0.581	Data 0.000	Loss 1.9865	
SparseEpoch: [191][301/398]	Time 0.581	Data 0.000	Loss 0.8061	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.6371	
Epoch(adapt):{0} Loss 0.4676	
Epoch(adapt):{0} Loss 0.5818	
Epoch(adapt):{0} Loss 0.5567	
------------------the total time cost:1169.4373502731323
>>>>>meta updating
Epoch: 0191 | TRAIN: 0.2156 0.8334 0.9307 | 0.2970 0.2970 0.1403 | 0.1014 20.5566 15.7308 0.3619 0.6747 0.7919 ||TEST: 1.3891 0.4239 0.6734 | 0.5273 0.5273 0.2108 | 0.1414 25.1020 20.0573 0.2876 0.5578 0.6860 | 117.3766
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.21256231 0.21255623 0.21259356 0.21263559 0.21265935 0.21272269
 0.21268227 0.21271195 0.21271347 0.2126889  0.21270318 0.21266236
 0.21264408 0.2126659  0.21275315 0.21276338 0.21274394 0.21273309
 0.21272196 0.2127689 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.21266701 0.21266374 0.21267313 0.21266471 0.21268637 0.21268794
 0.21268195 0.21269338 0.21269302 0.21269404 0.21271002 0.21269972
 0.21269862 0.21269546 0.21269627 0.21269128 0.21267969 0.21268234
 0.21266795 0.21266505]
[0. 0. 0.]
-----------end of analyzing the loss ratio:76.05412149429321
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x744608169180>
---------------------------------
SparseEpoch: [192][1/398]	Time 0.578	Data 0.000	Loss 0.1558	
SparseEpoch: [192][101/398]	Time 0.580	Data 0.000	Loss 0.2157	
SparseEpoch: [192][201/398]	Time 0.579	Data 0.000	Loss 0.1504	
SparseEpoch: [192][301/398]	Time 0.579	Data 0.000	Loss 0.3663	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.32970439 0.3296991  0.32969619 0.32968684 0.32965153 0.32965168
 0.32958041 0.32959123 0.32957311 0.32956014 0.32955451 0.32957555
 0.32954768 0.32954926 0.32953097 0.32949376 0.3294751  0.32947326
 0.32949173 0.32950597]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.3295857  0.32958502 0.3295746  0.32957709 0.3295565  0.32954645
 0.32954695 0.32954725 0.32954314 0.32954051 0.32954434 0.32955109
 0.32956479 0.32957494 0.32957331 0.32958892 0.3295893  0.32959284
 0.32959605 0.32958507]
[0.39473684 0.         0.        ]
-----------end of analyzing the loss ratio:76.40930581092834
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6929930>
---------------------------------
SparseEpoch: [192][1/398]	Time 0.578	Data 0.000	Loss 0.2649	
SparseEpoch: [192][101/398]	Time 0.580	Data 0.000	Loss 0.2851	
SparseEpoch: [192][201/398]	Time 0.580	Data 0.000	Loss 0.2521	
SparseEpoch: [192][301/398]	Time 0.581	Data 0.000	Loss 0.3881	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.10963448 0.10962706 0.10963597 0.1096311  0.10963042 0.10963083
 0.10962605 0.10963857 0.10964177 0.10965255 0.10966563 0.10966284
 0.10966848 0.10968104 0.109687   0.10968701 0.1096804  0.10968447
 0.10968718 0.10968134]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.10967736 0.10968257 0.10968429 0.10967069 0.10966462 0.10967237
 0.1096643  0.10965919 0.10965702 0.1096476  0.10965091 0.10966541
 0.10966645 0.1096631  0.10966191 0.10965598 0.10965233 0.10965286
 0.1096501  0.10964257]
[0.  0.5 0. ]
-----------end of analyzing the loss ratio:75.97638010978699
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444dc179180>
---------------------------------
SparseEpoch: [192][1/398]	Time 0.579	Data 0.000	Loss 1.0040	
SparseEpoch: [192][101/398]	Time 0.580	Data 0.000	Loss 1.0636	
SparseEpoch: [192][201/398]	Time 0.580	Data 0.000	Loss 1.2661	
SparseEpoch: [192][301/398]	Time 0.580	Data 0.000	Loss 1.5568	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.4108	
Epoch(adapt):{0} Loss 0.6725	
Epoch(adapt):{0} Loss 1.3352	
Epoch(adapt):{0} Loss 0.6593	
------------------the total time cost:1168.2399642467499
>>>>>meta updating
Epoch: 0192 | TRAIN: 0.2410 0.8188 0.9236 | 0.2596 0.2596 0.1310 | 0.1025 20.6409 15.6891 0.3647 0.6722 0.7883 ||TEST: 1.4955 0.4208 0.6712 | 0.5098 0.5098 0.2050 | 0.1408 24.9787 19.8311 0.2935 0.5619 0.6877 | 117.3830
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.23373044 0.23373323 0.2336941  0.23378017 0.23378387 0.23376623
 0.23375892 0.23374483 0.23370684 0.23372296 0.2336665  0.23368388
 0.23366451 0.2336677  0.23362763 0.23365332 0.23360217 0.23349716
 0.2335183  0.23352985]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.23370031 0.23368159 0.23367635 0.23361831 0.23358335 0.23355849
 0.2336686  0.23371642 0.23370786 0.23369463 0.23370654 0.2336786
 0.23367683 0.23366379 0.23369766 0.23369541 0.23372955 0.23371779
 0.2337295  0.2337215 ]
[0.         0.39473684 0.        ]
-----------end of analyzing the loss ratio:76.35456109046936
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d734dcc0>
---------------------------------
SparseEpoch: [193][1/398]	Time 0.578	Data 0.000	Loss 0.2300	
SparseEpoch: [193][101/398]	Time 0.580	Data 0.000	Loss 0.4512	
SparseEpoch: [193][201/398]	Time 0.580	Data 0.000	Loss 0.4407	
SparseEpoch: [193][301/398]	Time 0.581	Data 0.000	Loss 0.2074	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.32096922 0.3209226  0.32095103 0.3209403  0.32095233 0.32089641
 0.3208641  0.32082498 0.3208346  0.32084638 0.32086361 0.32084519
 0.32080532 0.32076335 0.32074655 0.32076893 0.32078837 0.32073572
 0.32077014 0.32073492]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.32086366 0.32086554 0.32085866 0.32085881 0.32087396 0.32085333
 0.32086295 0.32086305 0.32085687 0.32085865 0.32084951 0.32085603
 0.32087368 0.32086615 0.32087503 0.32087845 0.32087414 0.32087607
 0.3208595  0.32085336]
[0.5        0.         0.02631579]
-----------end of analyzing the loss ratio:76.52728652954102
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6bd2920>
---------------------------------
SparseEpoch: [193][1/398]	Time 0.579	Data 0.000	Loss 0.2802	
SparseEpoch: [193][101/398]	Time 0.581	Data 0.000	Loss 0.4110	
SparseEpoch: [193][201/398]	Time 0.581	Data 0.000	Loss 0.7642	
SparseEpoch: [193][301/398]	Time 0.581	Data 0.000	Loss 0.3857	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.10991879 0.10991348 0.10990637 0.10988257 0.10988646 0.10987955
 0.10989649 0.10988892 0.10988109 0.10987425 0.10984813 0.10986751
 0.10989932 0.10990714 0.10989452 0.10988472 0.10988438 0.10990195
 0.10990074 0.10989857]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.10993675 0.10996559 0.10996042 0.1099295  0.10989928 0.1098976
 0.10991235 0.10988572 0.109879   0.10985633 0.10987086 0.1098994
 0.10991758 0.10991969 0.10991669 0.10988225 0.10988452 0.10987808
 0.10986596 0.10987274]
[0.02631579 0.         0.        ]
-----------end of analyzing the loss ratio:76.46458864212036
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444dc25fe20>
---------------------------------
SparseEpoch: [193][1/398]	Time 0.587	Data 0.000	Loss 1.2740	
SparseEpoch: [193][101/398]	Time 0.580	Data 0.000	Loss 0.6750	
SparseEpoch: [193][201/398]	Time 0.580	Data 0.000	Loss 0.9993	
SparseEpoch: [193][301/398]	Time 0.580	Data 0.000	Loss 0.9497	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.5075	
Epoch(adapt):{0} Loss 0.5481	
Epoch(adapt):{0} Loss 0.5961	
Epoch(adapt):{0} Loss 0.3954	
------------------the total time cost:1169.9725060462952
>>>>>meta updating
Epoch: 0193 | TRAIN: 0.2402 0.8225 0.9229 | 0.2595 0.2595 0.1313 | 0.1025 20.6989 15.8238 0.3583 0.6714 0.7893 ||TEST: 1.4555 0.4141 0.6669 | 0.5116 0.5116 0.2070 | 0.1410 25.0752 20.0102 0.2880 0.5589 0.6860 | 117.8504
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.24792775 0.24792397 0.24799924 0.2479183  0.24797368 0.24795582
 0.247882   0.24795337 0.24792757 0.2479976  0.24794117 0.24794811
 0.24796416 0.24798956 0.247963   0.24806404 0.24809045 0.24806241
 0.24807583 0.24805299]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.24800626 0.24798671 0.24798237 0.24796928 0.24797371 0.24797609
 0.24797134 0.24799871 0.24800516 0.24800631 0.2479942  0.24799088
 0.24798923 0.24798933 0.24798653 0.24802227 0.24802288 0.24802197
 0.24803113 0.24803251]
[0. 0. 0.]
-----------end of analyzing the loss ratio:76.2613422870636
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc0eee90>
---------------------------------
SparseEpoch: [194][1/398]	Time 0.577	Data 0.000	Loss 0.3003	
SparseEpoch: [194][101/398]	Time 0.580	Data 0.000	Loss 0.2714	
SparseEpoch: [194][201/398]	Time 0.580	Data 0.000	Loss 0.2812	
SparseEpoch: [194][301/398]	Time 0.580	Data 0.000	Loss 0.1427	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.37595099 0.3759178  0.37584916 0.37584663 0.3757667  0.37578881
 0.37568922 0.37562146 0.37555942 0.37547353 0.37543125 0.37535096
 0.37529978 0.37523557 0.37513567 0.37502927 0.37498468 0.37495701
 0.3749365  0.37487651]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.37555874 0.37553169 0.37553641 0.3755297  0.37548841 0.3754647
 0.37546249 0.3754595  0.37543575 0.37545327 0.37545193 0.37547101
 0.37546279 0.37546076 0.37542762 0.37540534 0.37539297 0.37536183
 0.37535058 0.37534143]
[0.5 0.  0.5]
-----------end of analyzing the loss ratio:76.26378154754639
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d67ad210>
---------------------------------
SparseEpoch: [194][1/398]	Time 0.579	Data 0.000	Loss 0.6250	
SparseEpoch: [194][101/398]	Time 0.581	Data 0.000	Loss 0.6194	
SparseEpoch: [194][201/398]	Time 0.581	Data 0.000	Loss 0.8563	
SparseEpoch: [194][301/398]	Time 0.581	Data 0.000	Loss 1.0228	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.10791832 0.10792674 0.10788472 0.10787008 0.10785631 0.10782756
 0.10780464 0.10777801 0.10776088 0.10776284 0.10775656 0.10774301
 0.10774971 0.10771743 0.10771759 0.10770522 0.10769071 0.10768481
 0.10766519 0.10766296]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.10789355 0.10789467 0.10789014 0.10788864 0.10787663 0.10782304
 0.1078009  0.10777304 0.1077338  0.10775667 0.10776699 0.10775816
 0.10775383 0.10776123 0.10774589 0.10772865 0.10772275 0.1077306
 0.10768284 0.10766006]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:76.03915214538574
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d71923b0>
---------------------------------
SparseEpoch: [194][1/398]	Time 0.579	Data 0.000	Loss 1.6930	
SparseEpoch: [194][101/398]	Time 0.582	Data 0.000	Loss 1.5712	
SparseEpoch: [194][201/398]	Time 0.581	Data 0.000	Loss 1.2166	
SparseEpoch: [194][301/398]	Time 0.582	Data 0.000	Loss 0.9072	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.5374	
Epoch(adapt):{0} Loss 0.6440	
Epoch(adapt):{0} Loss 0.6524	
Epoch(adapt):{0} Loss 0.6914	
------------------the total time cost:1169.6231367588043
>>>>>meta updating
Epoch: 0194 | TRAIN: 0.2327 0.8210 0.9254 | 0.2741 0.2741 0.1332 | 0.1041 20.8062 15.8563 0.3617 0.6676 0.7856 ||TEST: 1.5217 0.4095 0.6685 | 0.5233 0.5233 0.2129 | 0.1425 25.1438 20.0766 0.2916 0.5575 0.6841 | 117.7259
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.23611357 0.23618295 0.23617819 0.23616765 0.23611601 0.23612938
 0.23610326 0.23604643 0.23611164 0.23599103 0.23605696 0.23603687
 0.23597987 0.23593372 0.23585321 0.23583674 0.23580403 0.23572418
 0.23563695 0.23547389]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.23604572 0.23602649 0.23602873 0.23603698 0.23602786 0.23603839
 0.23601437 0.23604387 0.23604569 0.236019   0.23602395 0.23602606
 0.23601778 0.23603238 0.23603229 0.23602048 0.23603407 0.23601752
 0.23601905 0.23601814]
[0.  0.5 0. ]
-----------end of analyzing the loss ratio:76.57536292076111
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6cb3910>
---------------------------------
SparseEpoch: [195][1/398]	Time 0.581	Data 0.000	Loss 0.4858	
SparseEpoch: [195][101/398]	Time 0.580	Data 0.000	Loss 0.5034	
SparseEpoch: [195][201/398]	Time 0.580	Data 0.000	Loss 0.3678	
SparseEpoch: [195][301/398]	Time 0.581	Data 0.000	Loss 0.2959	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.28833534 0.28835993 0.28836843 0.28838125 0.28837217 0.28839804
 0.2883826  0.28835321 0.28834141 0.28835693 0.28835929 0.28838426
 0.28839757 0.28839982 0.2883929  0.28839828 0.28839315 0.28839934
 0.28837337 0.28836571]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.28845636 0.28844433 0.28844457 0.28844777 0.28844722 0.28843891
 0.28840615 0.28839567 0.28838995 0.2883674  0.2883508  0.28833984
 0.28831298 0.28831366 0.28829553 0.28830815 0.28829295 0.28827389
 0.28827779 0.28829095]
[0.         0.         0.39473684]
-----------end of analyzing the loss ratio:76.17677211761475
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc58fe20>
---------------------------------
SparseEpoch: [195][1/398]	Time 0.578	Data 0.000	Loss 0.6085	
SparseEpoch: [195][101/398]	Time 0.580	Data 0.000	Loss 0.3846	
SparseEpoch: [195][201/398]	Time 0.580	Data 0.000	Loss 0.3956	
SparseEpoch: [195][301/398]	Time 0.580	Data 0.000	Loss 0.5225	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11651626 0.11651712 0.11653067 0.11654707 0.11655471 0.11656032
 0.11656243 0.11657073 0.1165441  0.11655849 0.11655104 0.11653189
 0.11651548 0.11650999 0.11650197 0.11649927 0.11648483 0.11647307
 0.11646548 0.11646923]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11648961 0.11649248 0.11649756 0.11648188 0.11649192 0.11648757
 0.11651088 0.11650497 0.11652998 0.1165409  0.11655928 0.11655394
 0.11654384 0.11653643 0.11652857 0.11652477 0.11651832 0.11650929
 0.11651693 0.11653218]
[0.44736842 0.         0.        ]
-----------end of analyzing the loss ratio:76.37263011932373
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6cb0a60>
---------------------------------
SparseEpoch: [195][1/398]	Time 0.579	Data 0.000	Loss 1.0131	
SparseEpoch: [195][101/398]	Time 0.581	Data 0.000	Loss 1.4492	
SparseEpoch: [195][201/398]	Time 0.581	Data 0.000	Loss 1.1502	
SparseEpoch: [195][301/398]	Time 0.581	Data 0.000	Loss 1.3870	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.2866	
Epoch(adapt):{0} Loss 0.5433	
Epoch(adapt):{0} Loss 0.5617	
Epoch(adapt):{0} Loss 0.6027	
------------------the total time cost:1168.846690416336
>>>>>meta updating
Epoch: 0195 | TRAIN: 0.2286 0.8302 0.9259 | 0.2499 0.2499 0.1243 | 0.0990 20.0683 14.9307 0.3856 0.6901 0.7997 ||TEST: 1.5273 0.4110 0.6629 | 0.5096 0.5096 0.2070 | 0.1394 24.7420 19.4352 0.3002 0.5709 0.6942 | 117.4080
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.25055027 0.25050319 0.25058547 0.25059791 0.25058982 0.25054037
 0.25061595 0.25058208 0.25057118 0.25059707 0.25061737 0.25059375
 0.25059348 0.25062246 0.2506369  0.25065388 0.25065486 0.25061636
 0.25061565 0.25059189]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.25062455 0.25062941 0.25064085 0.25063523 0.25062744 0.25064944
 0.2506416  0.25063096 0.25062162 0.25061805 0.25060416 0.25060664
 0.2506163  0.25063989 0.25064624 0.2506328  0.25063336 0.25062802
 0.25061853 0.25061383]
[0.         0.         0.02631579]
-----------end of analyzing the loss ratio:76.13490438461304
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6cd9270>
---------------------------------
SparseEpoch: [196][1/398]	Time 0.578	Data 0.000	Loss 0.2376	
SparseEpoch: [196][101/398]	Time 0.581	Data 0.000	Loss 0.3300	
SparseEpoch: [196][201/398]	Time 0.580	Data 0.000	Loss 0.5894	
SparseEpoch: [196][301/398]	Time 0.580	Data 0.000	Loss 0.1846	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.30171132 0.30157868 0.30146661 0.30144365 0.30141509 0.30130218
 0.30133581 0.3012014  0.30107324 0.3009901  0.3008713  0.30100304
 0.30096214 0.30082136 0.30085213 0.30076959 0.30070715 0.30073945
 0.30072943 0.30067931]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.30112931 0.3011172  0.30107471 0.30107073 0.301051   0.30100269
 0.30099283 0.30096457 0.30096051 0.30096236 0.30094891 0.3009236
 0.30086949 0.30088525 0.30090584 0.30091161 0.30089534 0.30089117
 0.30093709 0.30092786]
[0.5        0.         0.13157895]
-----------end of analyzing the loss ratio:76.83517289161682
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6772a70>
---------------------------------
SparseEpoch: [196][1/398]	Time 0.581	Data 0.000	Loss 0.4728	
SparseEpoch: [196][101/398]	Time 0.581	Data 0.000	Loss 0.5508	
SparseEpoch: [196][201/398]	Time 0.581	Data 0.000	Loss 0.5793	
SparseEpoch: [196][301/398]	Time 0.581	Data 0.000	Loss 0.3257	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.0912847  0.09128247 0.09123979 0.09124744 0.09122831 0.09120852
 0.09121696 0.09120476 0.09117612 0.09117469 0.09111595 0.09110614
 0.09110538 0.09110762 0.09108918 0.09108731 0.09109679 0.09108462
 0.0910778  0.09105102]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.09128153 0.09126475 0.09124942 0.09126036 0.09121376 0.09117458
 0.09117712 0.09118159 0.09118402 0.09114265 0.09112504 0.09112112
 0.09112887 0.09113619 0.09114161 0.09112711 0.0911139  0.09109223
 0.09108461 0.09108725]
[0.5        0.44736842 0.        ]
-----------end of analyzing the loss ratio:76.21175646781921
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6b91090>
---------------------------------
SparseEpoch: [196][1/398]	Time 0.578	Data 0.000	Loss 1.2619	
SparseEpoch: [196][101/398]	Time 0.581	Data 0.000	Loss 1.0884	
SparseEpoch: [196][201/398]	Time 0.581	Data 0.000	Loss 0.8083	
SparseEpoch: [196][301/398]	Time 0.581	Data 0.000	Loss 0.8976	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.6656	
Epoch(adapt):{0} Loss 0.4820	
Epoch(adapt):{0} Loss 0.5766	
Epoch(adapt):{0} Loss 0.6203	
------------------the total time cost:1169.840318441391
>>>>>meta updating
Epoch: 0196 | TRAIN: 0.2196 0.8338 0.9299 | 0.2846 0.2846 0.1341 | 0.1024 20.6676 15.7430 0.3613 0.6713 0.7886 ||TEST: 1.3849 0.4189 0.6700 | 0.5292 0.5292 0.2109 | 0.1411 25.0680 20.0105 0.2890 0.5590 0.6859 | 117.3871
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.18174107 0.18172052 0.18179234 0.18178678 0.18181983 0.18181445
 0.18179102 0.18181355 0.18182164 0.18198605 0.18193601 0.18192156
 0.18186264 0.18187381 0.18187663 0.18191657 0.18181125 0.18176776
 0.18173424 0.18171415]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.18199715 0.18199586 0.18200357 0.18200084 0.18199668 0.18199406
 0.18198801 0.18198961 0.18198749 0.18198187 0.18197192 0.18196802
 0.18197159 0.18194966 0.18192005 0.1819187  0.18192293 0.18193358
 0.18194327 0.18194717]
[0.         0.5        0.28947368]
-----------end of analyzing the loss ratio:76.41502785682678
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6aa0f70>
---------------------------------
SparseEpoch: [197][1/398]	Time 0.597	Data 0.000	Loss 0.6154	
SparseEpoch: [197][101/398]	Time 0.581	Data 0.000	Loss 0.5604	
SparseEpoch: [197][201/398]	Time 0.581	Data 0.000	Loss 0.2845	
SparseEpoch: [197][301/398]	Time 0.581	Data 0.000	Loss 0.5288	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.35142228 0.35089926 0.35010129 0.34935584 0.34851858 0.34766098
 0.34686646 0.34631391 0.34563341 0.34489689 0.34418902 0.34343673
 0.34290719 0.34235153 0.34158688 0.34097438 0.34013415 0.33979488
 0.33920556 0.33849748]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.34496249 0.34494872 0.34498932 0.34490256 0.34484724 0.34482218
 0.34474542 0.34470755 0.34468283 0.34457525 0.34442599 0.34441749
 0.34441269 0.3443803  0.34433028 0.34422334 0.34421207 0.34420389
 0.34415607 0.3440641 ]
[0.5 0.  0.5]
-----------end of analyzing the loss ratio:76.36581635475159
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d72b95a0>
---------------------------------
SparseEpoch: [197][1/398]	Time 0.585	Data 0.000	Loss 0.6522	
SparseEpoch: [197][101/398]	Time 0.582	Data 0.000	Loss 0.6479	
SparseEpoch: [197][201/398]	Time 0.581	Data 0.000	Loss 0.8959	
SparseEpoch: [197][301/398]	Time 0.581	Data 0.000	Loss 0.7449	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11357324 0.11353285 0.11349504 0.11345401 0.11346198 0.11341716
 0.11340898 0.11341494 0.11336407 0.11331015 0.11331406 0.11327263
 0.11322868 0.11321207 0.11320876 0.11321702 0.11317943 0.11315181
 0.11313412 0.11309905]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.11347841 0.11346964 0.11344211 0.11340976 0.11339839 0.11340376
 0.11340136 0.11337851 0.1133516  0.11330278 0.1133109  0.11328837
 0.11323147 0.11322692 0.11324533 0.11323801 0.11324657 0.11323146
 0.11321155 0.1131846 ]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:76.4067063331604
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444dc2bb340>
---------------------------------
SparseEpoch: [197][1/398]	Time 0.579	Data 0.000	Loss 1.2589	
SparseEpoch: [197][101/398]	Time 0.581	Data 0.000	Loss 1.0078	
SparseEpoch: [197][201/398]	Time 0.581	Data 0.000	Loss 1.6832	
SparseEpoch: [197][301/398]	Time 0.581	Data 0.000	Loss 1.2100	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.7249	
Epoch(adapt):{0} Loss 0.5371	
Epoch(adapt):{0} Loss 0.3200	
Epoch(adapt):{0} Loss 0.8029	
------------------the total time cost:1170.996397972107
>>>>>meta updating
Epoch: 0197 | TRAIN: 0.2148 0.8352 0.9310 | 0.2597 0.2597 0.1351 | 0.0996 20.1578 15.1022 0.3802 0.6880 0.7996 ||TEST: 1.5216 0.4169 0.6695 | 0.5045 0.5045 0.2097 | 0.1398 24.7651 19.4313 0.2999 0.5704 0.6948 | 117.7242
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.2115361  0.21152784 0.21154445 0.21159623 0.21155587 0.21142605
 0.21146351 0.2114646  0.21140891 0.21144161 0.2114971  0.21145645
 0.21146791 0.21150621 0.21151886 0.21158302 0.2116529  0.21159025
 0.21153489 0.21155022]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.21145786 0.21145836 0.21147223 0.21147266 0.21147366 0.21147112
 0.2115012  0.21149304 0.2115193  0.21149862 0.21147186 0.2114688
 0.21148903 0.21148688 0.2114593  0.21144767 0.21144723 0.21144228
 0.21144888 0.21144816]
[0.         0.         0.39473684]
-----------end of analyzing the loss ratio:76.38384485244751
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc169900>
---------------------------------
SparseEpoch: [198][1/398]	Time 0.580	Data 0.000	Loss 0.6034	
SparseEpoch: [198][101/398]	Time 0.580	Data 0.000	Loss 0.4229	
SparseEpoch: [198][201/398]	Time 0.580	Data 0.000	Loss 0.6022	
SparseEpoch: [198][301/398]	Time 0.581	Data 0.000	Loss 0.8641	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.26571834 0.26579011 0.26591461 0.2659239  0.26592889 0.26585363
 0.2659019  0.26587888 0.26583727 0.26582337 0.26578678 0.26579401
 0.26585467 0.26594504 0.26602379 0.26599594 0.26601038 0.26602418
 0.26608077 0.26596363]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.2657685  0.2657819  0.26580484 0.26579504 0.26581354 0.26581716
 0.26580196 0.26580773 0.26580243 0.26578784 0.26578684 0.26577968
 0.26577354 0.26578799 0.26579473 0.26579403 0.26578597 0.26577924
 0.26576142 0.26577232]
[0.         0.         0.44736842]
-----------end of analyzing the loss ratio:76.3949875831604
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6fd59f0>
---------------------------------
SparseEpoch: [198][1/398]	Time 0.578	Data 0.000	Loss 0.5280	
SparseEpoch: [198][101/398]	Time 0.580	Data 0.000	Loss 0.6265	
SparseEpoch: [198][201/398]	Time 0.580	Data 0.000	Loss 0.5285	
SparseEpoch: [198][301/398]	Time 0.580	Data 0.000	Loss 0.6164	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.08360874 0.08359801 0.08359374 0.08360349 0.08361211 0.08361936
 0.0836105  0.08362414 0.08362025 0.08362709 0.08361773 0.08361365
 0.08361417 0.08361129 0.08361025 0.08361047 0.08359659 0.08359185
 0.08358505 0.08356748]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.08362769 0.08362079 0.08360998 0.08360529 0.08360433 0.08359668
 0.08359863 0.08360717 0.08362371 0.08362806 0.08362151 0.08361172
 0.08359935 0.08359331 0.08359576 0.08358636 0.08357511 0.08356575
 0.08356903 0.08355914]
[0.5 0.5 0. ]
-----------end of analyzing the loss ratio:76.10254406929016
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d72c89a0>
---------------------------------
SparseEpoch: [198][1/398]	Time 0.579	Data 0.000	Loss 1.4962	
SparseEpoch: [198][101/398]	Time 0.581	Data 0.000	Loss 1.4373	
SparseEpoch: [198][201/398]	Time 0.581	Data 0.000	Loss 1.0732	
SparseEpoch: [198][301/398]	Time 0.581	Data 0.000	Loss 1.5037	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.6191	
Epoch(adapt):{0} Loss 0.4419	
Epoch(adapt):{0} Loss 0.6293	
Epoch(adapt):{0} Loss 0.5861	
------------------the total time cost:1170.349664926529
>>>>>meta updating
Epoch: 0198 | TRAIN: 0.2185 0.8361 0.9304 | 0.2730 0.2730 0.1290 | 0.1002 20.3368 15.3624 0.3724 0.6815 0.7952 ||TEST: 1.4418 0.4204 0.6719 | 0.5215 0.5215 0.2082 | 0.1407 24.9759 19.8352 0.2931 0.5623 0.6886 | 117.6776
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.24241878 0.24244747 0.24250945 0.24254813 0.24267538 0.24271801
 0.2427048  0.24265029 0.24271438 0.24266561 0.24266905 0.24268391
 0.24267665 0.24263728 0.24261519 0.24260622 0.24262707 0.24263606
 0.24265175 0.24262695]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.24264227 0.24264544 0.24267273 0.24266146 0.24266236 0.24264536
 0.24265325 0.24263905 0.24264244 0.24264347 0.2426466  0.24264195
 0.24265217 0.24265936 0.24267227 0.2426858  0.24266423 0.24266353
 0.24267056 0.242669  ]
[0. 0. 0.]
-----------end of analyzing the loss ratio:76.69582748413086
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7445fc0704f0>
---------------------------------
SparseEpoch: [199][1/398]	Time 0.578	Data 0.000	Loss 0.1929	
SparseEpoch: [199][101/398]	Time 0.580	Data 0.000	Loss 0.1672	
SparseEpoch: [199][201/398]	Time 0.579	Data 0.000	Loss 0.1392	
SparseEpoch: [199][301/398]	Time 0.580	Data 0.000	Loss 0.1690	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.32278845 0.32278208 0.32274641 0.32276935 0.32274715 0.3227192
 0.32272914 0.32277269 0.322842   0.32284233 0.3229108  0.32295042
 0.32293261 0.32294167 0.32289009 0.32292509 0.32295541 0.32296042
 0.32296734 0.3229442 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.32282764 0.32281697 0.32283968 0.32285577 0.32286771 0.32289638
 0.32287779 0.32289048 0.32287194 0.32289034 0.32287536 0.32288453
 0.32289483 0.32288444 0.32288611 0.32286769 0.32287692 0.32289919
 0.32292964 0.32294608]
[0. 0. 0.]
-----------end of analyzing the loss ratio:76.42998909950256
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d66c84f0>
---------------------------------
SparseEpoch: [199][1/398]	Time 0.579	Data 0.000	Loss 0.2037	
SparseEpoch: [199][101/398]	Time 0.580	Data 0.000	Loss 0.3179	
SparseEpoch: [199][201/398]	Time 0.580	Data 0.000	Loss 0.3636	
SparseEpoch: [199][301/398]	Time 0.580	Data 0.000	Loss 0.2642	
lr:5e-05
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.10703735 0.10702336 0.10697455 0.10695662 0.10692595 0.10689672
 0.1069104  0.10682759 0.10678673 0.10671406 0.10671454 0.10666258
 0.1066438  0.10662997 0.10660421 0.10660846 0.10660135 0.10655152
 0.10652691 0.1065398 ]
------------------------------------------------------------------
plot_1d_loss_err
------------------------------------------------------------------
train_loss
[0.10678753 0.10679117 0.10677345 0.10675501 0.10673487 0.1067373
 0.10673376 0.10670902 0.10670401 0.10672489 0.10670976 0.10671372
 0.10670634 0.10671621 0.10670495 0.1066963  0.10667266 0.10667154
 0.10667285 0.10665872]
[0.44736842 0.5        0.        ]
-----------end of analyzing the loss ratio:76.22084856033325
-----------loading_static
<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7444d6dc13c0>
---------------------------------
SparseEpoch: [199][1/398]	Time 0.579	Data 0.000	Loss 1.2790	
SparseEpoch: [199][101/398]	Time 0.581	Data 0.000	Loss 0.9804	
SparseEpoch: [199][201/398]	Time 0.581	Data 0.000	Loss 1.3436	
SparseEpoch: [199][301/398]	Time 0.581	Data 0.000	Loss 1.2800	
>>>>>meta updating
>>>>adapting
Epoch(adapt):{0} Loss 0.3912	
Epoch(adapt):{0} Loss 0.5265	
Epoch(adapt):{0} Loss 0.5010	
Epoch(adapt):{0} Loss 0.5468	
------------------the total time cost:1169.540314912796
>>>>>meta updating
Epoch: 0199 | TRAIN: 0.2271 0.8298 0.9274 | 0.2752 0.2752 0.1319 | 0.1005 20.3089 15.3110 0.3748 0.6843 0.7972 ||TEST: 1.4488 0.4223 0.6683 | 0.5208 0.5208 0.2119 | 0.1412 24.9849 19.8685 0.2939 0.5619 0.6885 | 118.2903
